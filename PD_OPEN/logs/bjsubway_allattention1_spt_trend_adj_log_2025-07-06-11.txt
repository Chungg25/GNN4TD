total training epoch, fine tune epoch: 40 , 40
batch_size: 4
folder_dir: MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03ScaledSAtSE0TEallattention1_spt_trend_adj
load file: data/bjsubway.npz
ori length: 1867 , percent: 1.0 , scale: 1867
train: torch.Size([1867, 276, 2, 12]) torch.Size([1867, 276, 2, 12]) torch.Size([1867, 276, 2, 12])
val: torch.Size([405, 276, 2, 12]) torch.Size([405, 276, 2, 12]) torch.Size([405, 276, 2, 12])
test: torch.Size([405, 276, 2, 12]) torch.Size([405, 276, 2, 12]) torch.Size([405, 276, 2, 12])
TemporalPositionalEncoding max_len: 12
h_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
en_lookup_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
EncoderDecoder(
  (encoder): Encoder(
    (layers): ModuleList(
      (0): EncoderLayer(
        (self_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (2): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (3): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (feed_forward_gcn): ModuleList(
          (0): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn_cross): spatialAttentionScaledGCN_cross(
          (Theta1): Linear(in_features=64, out_features=64, bias=False)
          (Theta2): Linear(in_features=64, out_features=64, bias=False)
          (SAt_cross): Spatial_Attention_layer_cross(
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (6): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (7): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (sublayer2): SublayerConnection2(
          (dropout): Dropout(p=0.0, inplace=False)
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): EncoderLayer(
        (self_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (2): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (3): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (feed_forward_gcn): ModuleList(
          (0): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn_cross): spatialAttentionScaledGCN_cross(
          (Theta1): Linear(in_features=64, out_features=64, bias=False)
          (Theta2): Linear(in_features=64, out_features=64, bias=False)
          (SAt_cross): Spatial_Attention_layer_cross(
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (6): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (7): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (sublayer2): SublayerConnection2(
          (dropout): Dropout(p=0.0, inplace=False)
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): EncoderLayer(
        (self_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (2): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (3): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (feed_forward_gcn): ModuleList(
          (0): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn_cross): spatialAttentionScaledGCN_cross(
          (Theta1): Linear(in_features=64, out_features=64, bias=False)
          (Theta2): Linear(in_features=64, out_features=64, bias=False)
          (SAt_cross): Spatial_Attention_layer_cross(
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (6): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (7): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (sublayer2): SublayerConnection2(
          (dropout): Dropout(p=0.0, inplace=False)
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): Decoder(
    (layers): ModuleList(
      (0): DecoderLayer(
        (self_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_qc_kc(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_qc_kc(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (2): MultiHeadAttentionAwareTemporalContex_qc_kc(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (3): MultiHeadAttentionAwareTemporalContex_qc_kc(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (src_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (2): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (3): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (feed_forward_gcn): ModuleList(
          (0): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn_cross): spatialAttentionScaledGCN_cross(
          (Theta1): Linear(in_features=64, out_features=64, bias=False)
          (Theta2): Linear(in_features=64, out_features=64, bias=False)
          (SAt_cross): Spatial_Attention_layer_cross(
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (6): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (7): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (8): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (9): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (sublayer2): SublayerConnection2(
          (dropout): Dropout(p=0.0, inplace=False)
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): DecoderLayer(
        (self_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_qc_kc(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_qc_kc(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (2): MultiHeadAttentionAwareTemporalContex_qc_kc(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (3): MultiHeadAttentionAwareTemporalContex_qc_kc(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (src_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (2): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (3): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (feed_forward_gcn): ModuleList(
          (0): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn_cross): spatialAttentionScaledGCN_cross(
          (Theta1): Linear(in_features=64, out_features=64, bias=False)
          (Theta2): Linear(in_features=64, out_features=64, bias=False)
          (SAt_cross): Spatial_Attention_layer_cross(
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (6): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (7): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (8): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (9): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (sublayer2): SublayerConnection2(
          (dropout): Dropout(p=0.0, inplace=False)
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): DecoderLayer(
        (self_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_qc_kc(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_qc_kc(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (2): MultiHeadAttentionAwareTemporalContex_qc_kc(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (3): MultiHeadAttentionAwareTemporalContex_qc_kc(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (src_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (2): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (3): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (feed_forward_gcn): ModuleList(
          (0): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn_cross): spatialAttentionScaledGCN_cross(
          (Theta1): Linear(in_features=64, out_features=64, bias=False)
          (Theta2): Linear(in_features=64, out_features=64, bias=False)
          (SAt_cross): Spatial_Attention_layer_cross(
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (6): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (7): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (8): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (9): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (sublayer2): SublayerConnection2(
          (dropout): Dropout(p=0.0, inplace=False)
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (src_embed): Sequential(
    (0): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (1): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(276, 64)
    )
  )
  (src_embed2): Sequential(
    (0): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (1): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(276, 64)
    )
  )
  (trg_embed): Sequential(
    (0): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (1): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(276, 64)
    )
  )
  (trg_embed2): Sequential(
    (0): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (1): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(276, 64)
    )
  )
  (prediction_generator): Linear(in_features=64, out_features=1, bias=True)
  (prediction_generator2): Linear(in_features=64, out_features=1, bias=True)
)
delete the old one and create params directory experiments/bjsubway/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03ScaledSAtSE0TEallattention1_spt_trend_adj
Net's state_dict:
encoder.layers.0.self_attn.0.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.0.linears.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.0.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.0.linears.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.1.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.1.linears.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.1.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.1.linears.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.2.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.2.linears.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.2.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.2.linears.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.2.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.2.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.2.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.2.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.3.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.3.linears.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.3.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.3.linears.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.3.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.3.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.3.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.3.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.0.feed_forward_gcn.0.Theta.weight 	 torch.Size([64, 64])
encoder.layers.0.feed_forward_gcn.1.Theta.weight 	 torch.Size([64, 64])
encoder.layers.0.feed_forward_gcn_cross.Theta1.weight 	 torch.Size([64, 64])
encoder.layers.0.feed_forward_gcn_cross.Theta2.weight 	 torch.Size([64, 64])
encoder.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.2.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.2.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.3.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.3.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.4.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.4.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.5.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.5.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.6.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.6.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.7.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.7.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer2.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer2.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer2.norm2.weight 	 torch.Size([64])
encoder.layers.0.sublayer2.norm2.bias 	 torch.Size([64])
encoder.layers.1.self_attn.0.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.0.linears.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.0.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.0.linears.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.1.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.1.linears.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.1.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.1.linears.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.2.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.2.linears.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.2.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.2.linears.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.2.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.2.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.2.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.2.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.3.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.3.linears.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.3.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.3.linears.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.3.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.3.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.3.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.3.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.1.feed_forward_gcn.0.Theta.weight 	 torch.Size([64, 64])
encoder.layers.1.feed_forward_gcn.1.Theta.weight 	 torch.Size([64, 64])
encoder.layers.1.feed_forward_gcn_cross.Theta1.weight 	 torch.Size([64, 64])
encoder.layers.1.feed_forward_gcn_cross.Theta2.weight 	 torch.Size([64, 64])
encoder.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.2.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.2.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.3.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.3.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.4.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.4.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.5.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.5.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.6.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.6.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.7.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.7.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer2.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer2.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer2.norm2.weight 	 torch.Size([64])
encoder.layers.1.sublayer2.norm2.bias 	 torch.Size([64])
encoder.layers.2.self_attn.0.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.0.linears.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.0.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.0.linears.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.0.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.0.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.0.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.0.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.1.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.1.linears.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.1.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.1.linears.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.1.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.1.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.1.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.1.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.2.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.2.linears.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.2.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.2.linears.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.2.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.2.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.2.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.2.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.3.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.3.linears.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.3.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.3.linears.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.3.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.3.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.3.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.3.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.2.feed_forward_gcn.0.Theta.weight 	 torch.Size([64, 64])
encoder.layers.2.feed_forward_gcn.1.Theta.weight 	 torch.Size([64, 64])
encoder.layers.2.feed_forward_gcn_cross.Theta1.weight 	 torch.Size([64, 64])
encoder.layers.2.feed_forward_gcn_cross.Theta2.weight 	 torch.Size([64, 64])
encoder.layers.2.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.2.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.2.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.3.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.3.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.4.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.4.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.5.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.5.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.6.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.6.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.7.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.7.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer2.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer2.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer2.norm2.weight 	 torch.Size([64])
encoder.layers.2.sublayer2.norm2.bias 	 torch.Size([64])
encoder.norm.weight 	 torch.Size([64])
encoder.norm.bias 	 torch.Size([64])
encoder.norm2.weight 	 torch.Size([64])
encoder.norm2.bias 	 torch.Size([64])
decoder.layers.0.self_attn.0.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.0.linears.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.0.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.0.linears.1.bias 	 torch.Size([64])
decoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.0.self_attn.1.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.1.linears.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.1.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.1.linears.1.bias 	 torch.Size([64])
decoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.0.self_attn.2.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.2.linears.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.2.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.2.linears.1.bias 	 torch.Size([64])
decoder.layers.0.self_attn.2.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.self_attn.2.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.2.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.self_attn.2.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.0.self_attn.3.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.3.linears.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.3.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.3.linears.1.bias 	 torch.Size([64])
decoder.layers.0.self_attn.3.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.self_attn.3.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.3.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.self_attn.3.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.0.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.0.linears.0.bias 	 torch.Size([64])
decoder.layers.0.src_attn.0.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.0.linears.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.0.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.0.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.0.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.0.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.1.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.1.linears.0.bias 	 torch.Size([64])
decoder.layers.0.src_attn.1.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.1.linears.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.1.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.1.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.1.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.1.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.2.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.2.linears.0.bias 	 torch.Size([64])
decoder.layers.0.src_attn.2.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.2.linears.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.2.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.2.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.2.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.2.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.3.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.3.linears.0.bias 	 torch.Size([64])
decoder.layers.0.src_attn.3.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.3.linears.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.3.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.3.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.3.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.3.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.feed_forward_gcn.0.Theta.weight 	 torch.Size([64, 64])
decoder.layers.0.feed_forward_gcn.1.Theta.weight 	 torch.Size([64, 64])
decoder.layers.0.feed_forward_gcn_cross.Theta1.weight 	 torch.Size([64, 64])
decoder.layers.0.feed_forward_gcn_cross.Theta2.weight 	 torch.Size([64, 64])
decoder.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.3.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.3.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.4.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.4.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.5.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.5.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.6.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.6.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.7.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.7.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.8.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.8.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.9.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.9.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer2.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer2.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer2.norm2.weight 	 torch.Size([64])
decoder.layers.0.sublayer2.norm2.bias 	 torch.Size([64])
decoder.layers.1.self_attn.0.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.0.linears.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.0.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.0.linears.1.bias 	 torch.Size([64])
decoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.1.self_attn.1.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.1.linears.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.1.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.1.linears.1.bias 	 torch.Size([64])
decoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.1.self_attn.2.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.2.linears.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.2.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.2.linears.1.bias 	 torch.Size([64])
decoder.layers.1.self_attn.2.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.self_attn.2.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.2.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.self_attn.2.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.1.self_attn.3.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.3.linears.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.3.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.3.linears.1.bias 	 torch.Size([64])
decoder.layers.1.self_attn.3.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.self_attn.3.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.3.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.self_attn.3.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.0.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.0.linears.0.bias 	 torch.Size([64])
decoder.layers.1.src_attn.0.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.0.linears.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.0.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.0.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.0.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.0.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.1.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.1.linears.0.bias 	 torch.Size([64])
decoder.layers.1.src_attn.1.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.1.linears.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.1.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.1.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.1.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.1.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.2.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.2.linears.0.bias 	 torch.Size([64])
decoder.layers.1.src_attn.2.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.2.linears.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.2.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.2.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.2.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.2.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.3.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.3.linears.0.bias 	 torch.Size([64])
decoder.layers.1.src_attn.3.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.3.linears.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.3.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.3.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.3.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.3.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.feed_forward_gcn.0.Theta.weight 	 torch.Size([64, 64])
decoder.layers.1.feed_forward_gcn.1.Theta.weight 	 torch.Size([64, 64])
decoder.layers.1.feed_forward_gcn_cross.Theta1.weight 	 torch.Size([64, 64])
decoder.layers.1.feed_forward_gcn_cross.Theta2.weight 	 torch.Size([64, 64])
decoder.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.3.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.3.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.4.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.4.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.5.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.5.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.6.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.6.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.7.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.7.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.8.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.8.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.9.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.9.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer2.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer2.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer2.norm2.weight 	 torch.Size([64])
decoder.layers.1.sublayer2.norm2.bias 	 torch.Size([64])
decoder.layers.2.self_attn.0.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.0.linears.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.0.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.0.linears.1.bias 	 torch.Size([64])
decoder.layers.2.self_attn.0.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.self_attn.0.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.0.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.self_attn.0.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.2.self_attn.1.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.1.linears.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.1.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.1.linears.1.bias 	 torch.Size([64])
decoder.layers.2.self_attn.1.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.self_attn.1.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.1.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.self_attn.1.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.2.self_attn.2.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.2.linears.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.2.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.2.linears.1.bias 	 torch.Size([64])
decoder.layers.2.self_attn.2.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.self_attn.2.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.2.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.self_attn.2.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.2.self_attn.3.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.3.linears.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.3.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.3.linears.1.bias 	 torch.Size([64])
decoder.layers.2.self_attn.3.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.self_attn.3.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.3.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.self_attn.3.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.0.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.0.linears.0.bias 	 torch.Size([64])
decoder.layers.2.src_attn.0.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.0.linears.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.0.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.0.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.0.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.0.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.1.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.1.linears.0.bias 	 torch.Size([64])
decoder.layers.2.src_attn.1.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.1.linears.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.1.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.1.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.1.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.1.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.2.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.2.linears.0.bias 	 torch.Size([64])
decoder.layers.2.src_attn.2.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.2.linears.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.2.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.2.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.2.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.2.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.3.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.3.linears.0.bias 	 torch.Size([64])
decoder.layers.2.src_attn.3.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.3.linears.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.3.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.3.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.3.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.3.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.feed_forward_gcn.0.Theta.weight 	 torch.Size([64, 64])
decoder.layers.2.feed_forward_gcn.1.Theta.weight 	 torch.Size([64, 64])
decoder.layers.2.feed_forward_gcn_cross.Theta1.weight 	 torch.Size([64, 64])
decoder.layers.2.feed_forward_gcn_cross.Theta2.weight 	 torch.Size([64, 64])
decoder.layers.2.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.3.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.3.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.4.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.4.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.5.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.5.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.6.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.6.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.7.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.7.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.8.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.8.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.9.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.9.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer2.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer2.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer2.norm2.weight 	 torch.Size([64])
decoder.layers.2.sublayer2.norm2.bias 	 torch.Size([64])
decoder.norm.weight 	 torch.Size([64])
decoder.norm.bias 	 torch.Size([64])
decoder.norm2.weight 	 torch.Size([64])
decoder.norm2.bias 	 torch.Size([64])
src_embed.0.pe 	 torch.Size([1, 1, 12, 64])
src_embed.1.embedding.weight 	 torch.Size([276, 64])
src_embed2.0.pe 	 torch.Size([1, 1, 12, 64])
src_embed2.1.embedding.weight 	 torch.Size([276, 64])
trg_embed.0.pe 	 torch.Size([1, 1, 12, 64])
trg_embed.1.embedding.weight 	 torch.Size([276, 64])
trg_embed2.0.pe 	 torch.Size([1, 1, 12, 64])
trg_embed2.1.embedding.weight 	 torch.Size([276, 64])
prediction_generator.weight 	 torch.Size([1, 64])
prediction_generator.bias 	 torch.Size([1])
prediction_generator2.weight 	 torch.Size([1, 64])
prediction_generator2.bias 	 torch.Size([1])
Net's total params: 1369986
Optimizer's state_dict:
state 	 {}
param_groups 	 [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'maximize': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459]}]
predicting testing set batch 1 / 102, time: 1.81s
predicting testing set batch 101 / 102, time: 36.68s
test time on whole data:36.91s
3096.189960569855 3419.589245402779 10813.323363190093 -0.07652845564159122 
2938.416167895848 3015.021633117937 9887.39276623346 0.10198853399172277 
3093.7197516014708 3159.1495329274294 10612.792681774905 -0.09175955040453046 
2756.0724767533534 2846.8768870362874 9555.656978617462 -0.08669646333308069 
2576.761212218971 2670.827854793218 8923.972491950311 -0.049516897181541 
2591.1955842907687 2670.1438948203877 8983.476997249078 -0.050322463523674095 
2653.60132139513 2720.739462763869 9231.581994129321 -0.05341824655473299 
2763.4103346794022 2823.095086530346 9661.36255539458 -0.059386531163205344 
2906.731009644195 2959.103515132158 10216.853819363943 -0.06526677130781074 
3031.6243310485665 3076.2256133585656 10730.942617018763 -0.06593932534019425 
3089.8828459416195 3128.960082465167 11039.77093719806 -0.060127731871384364 
3075.2971941239452 3111.7904899409805 11003.472096278612 -0.05116999214172603 
2881.0751825135944 2974.8564064239195 10054.79400376863 -0.05116999214172603 
epoch: 0, train time every whole data:113.76s
epoch: 0, total time:151.52s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.76s
test time on whole data:35.99s
113.7280894561433 147.90972746201476 327.0862040109518 0.8426775448835189 
143.3014910248957 189.83473859302927 411.08787799645177 0.7056711204463618 
166.00384969006637 220.04973480887378 478.11613115109975 0.5684308302650654 
180.74816725616057 239.9784512225632 522.0384543836046 0.4779137707905337 
191.68792017939802 256.9095257092015 546.4055151384375 0.40280805245577034 
197.77179664716132 268.2006163005088 552.8694523972644 0.3540922200495096 
204.16480727216657 277.6736346354649 563.2326719457722 0.31339966454767404 
208.30988612269024 285.21125889008465 565.2830284922502 0.2837494054130584 
209.09687650488945 290.42293209746117 554.5173714814222 0.26674147271837073 
210.45546675749625 294.7399820378948 552.898376334245 0.2510404185088168 
212.3388094608673 299.52739123403495 557.4262764993829 0.23745040082511676 
213.57535168242399 303.90755269201713 553.5941468221789 0.22740150443490806 
187.5985426711966 260.3846254471684 515.3644775631686 0.22740150443490806 
epoch: 1, train time every whole data:113.90s
epoch: 1, total time:302.25s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.80s
test time on whole data:36.04s
70.51306428750586 96.80143691098398 205.24359369447254 0.9365185351013983 
98.26451312730889 138.33119010368108 270.87463471102365 0.8566502100364929 
129.51589766426045 179.26496469310896 355.59958335303116 0.7271158876374361 
163.01545511285158 217.73267275227508 464.38578567083744 0.5659706220751319 
193.5693978013605 253.5467868960989 574.0893952057274 0.40282763007033456 
225.3902452905045 289.16736964196923 702.4467247223894 0.26383161583059117 
255.58108892254631 322.76376533071493 833.809255922823 0.17126205392519953 
283.16049421132533 354.17795032602623 954.8388520904385 0.11487910813497851 
315.9766217658049 392.72838601371825 1096.558344082647 0.07504167660903856 
348.36406924952934 430.90780427099065 1244.9218028498685 0.055405332688514955 
366.77451767062587 452.47507149898496 1334.0376570337353 0.052519295476729996 
369.53119263239773 453.8084793692167 1328.501084718715 0.058510011539971055 
234.97137981133494 320.95750464435827 780.2667180252643 0.058510011539971055 
epoch: 2, train time every whole data:114.12s
epoch: 2, total time:453.25s
predicting testing set batch 1 / 102, time: 0.36s
predicting testing set batch 101 / 102, time: 35.89s
test time on whole data:36.12s
52.836381878219925 76.65580074443969 133.99779657803853 0.9584589632662477 
72.34294590433257 106.25833091624601 179.6407500945094 0.9153711820223824 
93.05085528891772 132.75471340591315 241.35759458965845 0.8613476946677718 
120.20566692242022 165.88452903093446 324.3947233056518 0.7806801334141523 
142.59725400110338 195.41223327373055 402.89453529075547 0.7007066866539731 
162.9105947228855 223.9618773845897 483.2855333420209 0.624993603692535 
181.39989847260816 250.80092259482313 553.6590839549876 0.5580915002475768 
199.94159829252857 277.34617180159864 618.4366692699476 0.49966673711714477 
220.80074866596874 307.1394109045149 693.1557388803451 0.4433192661651155 
237.92941557043372 332.5737071362953 758.9860752862006 0.3983589348437419 
249.48566993863045 351.85332627863886 808.91326429333 0.36538913754484253 
253.61067888196374 357.98358322401316 808.9089395307942 0.3413900892005795 
165.5926423783345 249.5609809049098 500.53622995011705 0.3413900892005795 
epoch: 3, train time every whole data:113.95s
epoch: 3, total time:604.17s
predicting testing set batch 1 / 102, time: 0.36s
predicting testing set batch 101 / 102, time: 35.77s
test time on whole data:36.01s
59.01719597041271 90.18399081565482 99.48417726656496 0.9676755247475227 
83.70402306335386 130.84384599979035 127.98284425358754 0.9367126225932247 
108.00824191384011 167.0315605849857 143.6965164340915 0.8962747197416715 
132.14347360335086 199.80961825190502 177.04551905014353 0.8440371428406704 
153.37657307183105 228.65423062256957 205.37305789982025 0.7835385377628022 
167.35579602051908 249.07800111239652 219.29818954923408 0.7292242826061167 
177.610811761385 264.5394272148012 229.4975082847925 0.6730040075884952 
186.42936972304312 277.25061379745335 241.1140593991151 0.6101308406434505 
194.45380092560632 288.8851877617938 253.33440675041516 0.5423086656131326 
200.23333875965542 298.34262094903454 260.3219385835145 0.4734362252581357 
204.94322265478922 306.13924764654286 267.52824996426517 0.4038151386410792 
210.98206547708077 314.0246858213998 281.0908570934491 0.33656535839475804 
156.52149274540545 244.78630521888456 208.79172887421754 0.33656535839475804 
epoch: 4, train time every whole data:113.95s
epoch: 4, total time:754.99s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.75s
test time on whole data:35.99s
46.99110350302044 70.34614038557176 103.77514099901481 0.9751866028153655 
66.56593481093674 96.52442894966964 139.682913568423 0.9568235929591777 
85.18803206784239 118.74760076875901 156.07484582559678 0.9383569445383828 
104.71913874351245 143.63892855708116 182.75128120166417 0.9095748904758342 
122.66747077830932 167.06867649184002 209.8405933964452 0.8769100162413254 
135.73746125647872 186.17088143125332 227.05951044075064 0.8424211012066626 
145.29374000464688 203.8504891956617 236.86663885572523 0.7966241203896433 
154.36802790990416 221.77995214326833 246.2122863959284 0.7414196241219202 
163.57383744250774 240.0517269495223 257.3919447874859 0.6806754522574758 
171.38513826093254 257.52931441802 263.7115300146008 0.6136938818082343 
175.90334735503282 271.5306366458512 262.0551926088242 0.5461783506238437 
181.28707959915363 283.9515635661842 264.4840465406015 0.4837103031553679 
129.47335931102324 200.12811411218982 212.47420063346755 0.4837103031553679 
epoch: 5, train time every whole data:114.11s
epoch: 5, total time:905.96s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.80s
test time on whole data:36.03s
44.91175076992178 67.24866749958264 123.8608648882674 0.9711455779293177 
58.416919965472815 87.91782308045033 164.75676104915192 0.9504825589510598 
73.78597355776307 107.51394518569536 216.0330141527501 0.9247739778699218 
95.1021507350503 135.89806354278628 292.99049030274284 0.8758719737671289 
113.90855903706672 163.18064729779357 363.0631441781564 0.8182531025140954 
133.45803541558737 192.24666371840542 438.80986173395434 0.7556577862512451 
152.92644583503252 222.9446145562415 507.55555500052037 0.6924244657008148 
171.99073917021062 254.9223112276219 570.0765520972337 0.6320668254631915 
189.4616998128709 286.0946817431715 625.7384697575251 0.578047942282366 
203.63353419478062 312.8649154036961 670.1252477241391 0.532410194688378 
216.02881626905045 336.07536560576733 716.9118222207617 0.4925588601049466 
220.94583285736175 348.86127489499034 725.6853860760513 0.4617752638252853 
139.54753813501407 230.0255983880004 451.2126588429715 0.4617752638252853 
epoch: 6, train time every whole data:114.24s
epoch: 6, total time:1057.09s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.78s
test time on whole data:36.02s
36.00508045155504 60.532109686907845 64.42945021014354 0.976491891628631 
44.81833723115594 76.60319934625488 71.70540547705949 0.9632210878470115 
53.35358986959573 89.19443869672898 80.28110460089188 0.9511352996865056 
62.92218590630647 105.54085764032503 93.11007760326123 0.9303988247607675 
72.15624480438501 121.33441957004204 105.01472846922152 0.9064606403192997 
80.13979259178917 134.51369040195559 113.39148436611006 0.8839994014583527 
87.73766011513608 148.33635817174988 118.40869804061893 0.8542399737445716 
94.84998069702873 161.86961741383982 121.76618242342592 0.8193295585713001 
101.43901969556023 175.35448139460615 124.67960145296149 0.7804111113627741 
108.07944827103316 189.68729154641403 125.98849022817677 0.735031259184574 
113.67555396307635 203.44694073018672 126.20262925068869 0.6841021846466679 
120.06151651216587 216.63705893370312 129.66202908604484 0.633060043487799 
81.26986750906565 148.5207239102019 106.21227256939115 0.633060043487799 
epoch: 7, train time every whole data:113.15s
epoch: 7, total time:1207.11s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.52s
test time on whole data:35.75s
38.71347097341064 66.08868799306062 78.64104387673375 0.9711491048093533 
49.75700845306342 86.44895461733685 105.08325928266925 0.9500185345791481 
62.90105277049902 103.45387430384837 137.74117436804477 0.926202508504018 
75.61988464954818 119.22203427367396 168.65271240691143 0.8954669359319889 
84.6238611792298 131.94098756447906 185.4252927935096 0.865692117685182 
91.89966109004048 142.76229176156298 197.95095217549655 0.8364177032224864 
99.41224146094096 154.9974601364939 209.8189747551861 0.7998177190909592 
107.0079524847999 168.6173271639125 222.46897404693846 0.7563832619652959 
114.49188926140795 184.0874230923104 234.16942717833615 0.7067537195877154 
121.71550299057644 200.52654201798023 241.46229625396987 0.6525779451422699 
129.0506409180065 217.0709137930787 251.13301246867238 0.596540019166086 
135.97469041446232 232.14714239721312 254.42714458639188 0.5456546203479457 
92.59732138716547 158.6700970960617 190.5603885052974 0.5456546203479457 
epoch: 8, train time every whole data:113.00s
epoch: 8, total time:1356.69s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.52s
test time on whole data:35.75s
40.259391733289625 61.26469253876039 90.68799112018709 0.9729757286454194 
53.092266502672075 78.48951400716517 109.13567684115857 0.9547114811825175 
67.83977314460043 93.42053569480471 135.30555248516058 0.9348620164120172 
80.21098894493687 111.10691112449274 157.99519965914345 0.9065044043737602 
91.73202624381786 128.58900011734403 182.59502621955846 0.8729696305350035 
101.13765461850605 143.56880531150344 204.33927593477307 0.8397735875080776 
110.33712661124474 160.96624797166012 226.805012899031 0.7970733761573473 
118.94532593817031 178.8463864622119 249.5249059731324 0.7490299595320046 
126.5870175303511 196.3969289523901 267.8378491565426 0.6990590611670243 
133.74717271541186 213.57843684791814 284.0017301979684 0.6474570501430587 
140.86481083154632 229.30133494745192 300.8435192562648 0.5979090320961815 
146.69573288648536 240.55608553755195 313.42667083487584 0.558553747116639 
100.9541073084194 163.46845750344298 210.17661526931533 0.558553747116639 
epoch: 9, train time every whole data:113.08s
epoch: 9, total time:1506.37s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.56s
test time on whole data:35.79s
52.04460160128065 78.71493929216928 134.5621366585183 0.9563952369688956 
72.7960620143582 109.53963295622876 184.84455948157944 0.9092521829099804 
92.32949048806549 134.52327739147435 235.87203178393952 0.855463447248602 
114.3826253216593 162.472543405232 295.7718838912191 0.7822835193179514 
136.18901537053713 189.17202731584246 357.3596678841029 0.7067632553380578 
157.1142515190291 214.86534466208025 422.20575015605084 0.6382164361074683 
177.5003760717236 241.05032134509318 485.6332813947702 0.5763872167999016 
198.6980533508359 268.57756619513844 554.2890591581863 0.5207297936171612 
220.04898879397751 298.9331804056238 628.1869047465844 0.46924765738828855 
241.12869583207944 330.54530151666467 705.2101174739031 0.42175972417766056 
262.8956716510818 362.6209931599911 792.2725072694512 0.38035187895445727 
280.4318943547278 387.65839955231183 858.7278048000842 0.34895132807531937 
167.12997719744646 250.87769484386266 471.133348463417 0.34895132807531937 
epoch: 10, train time every whole data:112.91s
epoch: 10, total time:1655.91s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.60s
test time on whole data:35.83s
44.48828115557546 76.91722920888257 89.2362804163087 0.9718123052122369 
62.41802090295959 121.49998099939859 115.1567135140539 0.9519354554636754 
82.61139996001958 156.9197260628827 150.62999109908563 0.9376095510458892 
103.95333084302464 198.43649782018065 176.6617912954776 0.9157757160856155 
125.28045440323345 236.61112900718547 196.6530870190573 0.890785914915136 
144.54324243924253 269.8569576971769 213.6552842239062 0.8632104362577142 
162.73015664947638 302.54802213333943 229.36867839031896 0.8245672154362418 
179.39377738717357 333.33426848549385 244.9779295770927 0.7792575324806785 
194.60081120317832 362.1804842162654 263.0287912614357 0.7301815014519398 
208.27459654303513 387.3661644766271 279.9554176692954 0.6775309915353709 
219.47977054983386 406.79677585792643 296.52176769246444 0.6254283291201341 
227.35349303880355 419.77290006225934 309.6319931663007 0.5788163662955317 
146.26061125629622 294.25812745240444 213.76081139272748 0.5788163662955317 
epoch: 11, train time every whole data:113.04s
epoch: 11, total time:1805.62s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.64s
test time on whole data:35.88s
32.40684833840791 58.19916304943084 64.20732910935659 0.9783014318833235 
37.99966526099694 70.4176179821478 78.53557351259477 0.969077531050218 
44.07247370835957 77.76592111805606 100.90249138747292 0.962915379606478 
50.16252034915557 87.55686590246775 118.84303897189498 0.9493444523935617 
56.94927606492619 96.14455809704744 143.51579488600032 0.9330027404731553 
63.77450522532226 102.60308527269203 171.372980550428 0.9185455377554843 
70.92028888838276 110.44949399745116 198.76052017253878 0.9012751458860537 
77.72037602410941 118.58178036368788 224.28238661420195 0.8836844424124716 
84.1783002376843 127.29401212677378 249.3725728764354 0.8663264631644156 
90.9088842856326 137.5400088504367 272.08904629077495 0.8459285812505827 
97.58609986915228 148.26798376766357 295.1502718295381 0.8234445997822799 
103.13372674656402 157.48306210688236 311.90644661434396 0.8018684942998027 
67.48441374989115 111.80218941378898 185.7071216713466 0.8018684942998027 
epoch: 12, train time every whole data:113.10s
epoch: 12, total time:1955.42s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.63s
test time on whole data:35.86s
31.31864508360339 55.145020810031546 48.00900055575446 0.9794494637934064 
37.16803990367245 65.392186291969 52.65102585017218 0.9717608295399125 
43.200067574536035 71.45271116553096 64.4255012892784 0.9678131857109343 
49.160462821501355 80.24076164917975 72.77860549612762 0.9594527612023822 
55.0093474664278 88.38329889838855 80.19628665005423 0.9507160772954175 
59.70891298745611 94.08142551221347 86.3617829879505 0.9446805845223198 
64.78423858664438 103.36703173487835 90.33581926614156 0.9325609367786513 
69.30899495160067 113.89058184640905 91.6647910753217 0.9175571933423529 
73.290826877336 123.99928298681445 91.86157275941997 0.9022241929375001 
77.28950406395207 134.60498242321094 91.4847756127737 0.8839153384688351 
81.00156495635404 145.63479193594162 91.54839517224997 0.8622915146690566 
84.72635223445883 156.10691420120975 91.09825470757211 0.8392804548737299 
60.497246458961925 107.3363467108333 79.36356851147599 0.8392804548737299 
epoch: 13, train time every whole data:113.19s
epoch: 13, total time:2105.29s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.66s
test time on whole data:35.89s
36.85339124713938 71.31631834957412 69.6862436876245 0.9727114280054513 
47.196817500167306 97.29984990776785 90.151933736361 0.953416670429622 
57.24708748144396 119.36844790392564 107.18796306854163 0.9309507281830381 
66.3667840021148 139.08308936141998 124.75729254109258 0.8966739172084577 
74.0654767443979 152.59644930021514 138.25241690821395 0.8618288591282741 
80.56833635879039 160.72771912772956 149.3988537361583 0.8312812020131366 
85.91908844589219 165.78206233446372 156.3530762063386 0.8037659321065068 
90.586129009019 169.12662583381422 159.4278696171345 0.7805792211492757 
94.58321614185404 172.03108489872974 161.4429464033058 0.7613532215560684 
97.38636767063953 175.0476629866571 156.86083864578498 0.74677616742453 
99.98630904951979 178.64867899819492 152.79707848039962 0.7332475050643374 
102.72401703968697 183.02275325184914 150.79521513260713 0.7191511669144478 
77.7902517242221 152.48001266651497 134.75234983578937 0.7191511669144478 
epoch: 14, train time every whole data:113.44s
epoch: 14, total time:2255.51s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.65s
test time on whole data:35.88s
28.744403821870613 55.83183040342021 43.434584930777326 0.9805025962403544 
32.34704697280002 66.28894542297012 49.3706973508508 0.9740694709500431 
35.79949041799785 75.00759258659548 55.619519311078 0.969450768031709 
39.8787855904486 85.82264841123074 60.870823731087164 0.9591026141925149 
43.535892627682315 94.3900800328849 67.40829048072278 0.9478797045211058 
46.028220908951674 99.15373546753843 72.69572775230772 0.9390054031637999 
48.78613084636963 104.39996918298968 77.25374431805668 0.9265818792115647 
50.96223281843757 108.38694197249872 82.05789719603172 0.9132594497358386 
52.934317294179614 111.7109924610622 87.92530370854512 0.9006669813935908 
54.96725172714335 115.04817576144502 93.65165534755731 0.8903913390236647 
56.47606107600808 118.06813612936627 98.67792664321878 0.8815817679505527 
58.09787066560402 121.40561496731311 102.03136931243783 0.8721581762663287 
45.71314206395778 98.44031754321419 74.24143031180043 0.8721581762663287 
epoch: 15, train time every whole data:113.24s
epoch: 15, total time:2405.50s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.66s
test time on whole data:35.90s
29.166222894751634 52.76551900867075 47.07065215921548 0.9798522705456026 
33.53160592854852 60.621913308149054 64.53041495295184 0.9729105002082372 
37.4689378995525 65.06049033735022 77.16809797606365 0.9684980151818473 
42.26902867863839 73.6777896673394 86.33375616277065 0.9586839042527147 
46.62795894761275 82.60229943329865 91.96094799561494 0.9473708847506314 
50.40406623353275 90.44941747990165 96.94137241121435 0.9367742750940377 
55.41354275389114 101.90275091244136 103.13981790739737 0.9198457834808201 
59.58047649251578 112.6081640018274 108.24633185044388 0.9023398582614044 
63.48924827794135 122.2018565247277 114.00266608881363 0.8851671308302537 
67.21745727120773 131.89385371612252 118.83705346831283 0.8657920506771086 
70.45686193553207 141.08323851150283 124.74708645225492 0.8461847885901329 
73.73724604509765 149.71712412778822 130.91191173779194 0.8268772211182572 
52.44688777990186 103.61727917850419 96.98075817239067 0.8268772211182572 
epoch: 16, train time every whole data:113.29s
epoch: 16, total time:2555.51s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.59s
test time on whole data:35.82s
31.17114696221099 53.766638661018824 58.26074892730967 0.979805861090218 
37.06286562265424 63.473871235768264 70.24809846880481 0.9716957097560466 
42.9101088066196 70.70333959743282 84.76953751475637 0.9654004107133763 
48.75212119408838 80.89526887047457 96.00950863685226 0.9529516451665163 
54.717899472140324 90.35631564892418 111.80376563134213 0.9388005625075908 
60.931710711313656 98.74889542763042 129.846438750757 0.9245481490234985 
67.79064182663757 109.70726637570282 146.36536409867045 0.9033799863446133 
74.77412332609805 120.93038687164976 161.87749664186285 0.8787683659630864 
81.5750445770374 132.27968394676938 177.1204192947876 0.8520856531391058 
87.76558094887774 144.47068312579023 190.45886767818683 0.8207110544204668 
93.53787048976248 156.3167260614622 202.74447751044303 0.7870140735263599 
97.5138315548966 165.95577353575595 208.8947104022501 0.756689362820869 
64.87524545769476 113.05757091452422 136.51093341143505 0.756689362820869 
epoch: 17, train time every whole data:113.37s
epoch: 17, total time:2705.52s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.70s
test time on whole data:35.93s
28.025399456650824 51.846848704847616 45.61139970670084 0.9802595600828564 
31.29163648995227 62.038626943889305 57.84979200889232 0.9715055915168188 
33.29160415376101 67.53985591190695 66.65825380816732 0.9665949740000224 
36.82772394685759 78.62120396775929 72.46808047416971 0.956096252939519 
40.06401873049169 87.18418742637644 79.45248371821064 0.9467483969594099 
42.120310061812766 91.71401889490785 85.24255745752347 0.940273787152827 
44.89780608236478 96.6552392384387 91.64043314634577 0.9313953338767329 
47.04186004602828 101.37148229796416 97.7511641593257 0.9233375082809295 
48.984275102945425 104.64115299752484 104.46339071679421 0.9166123420973405 
50.89531144097309 108.18620934986174 110.49645181918453 0.9076775152069699 
52.39694795993887 112.08652367539062 115.40625140102543 0.8989121724511729 
53.97381077135562 115.90800552357726 117.95257196489534 0.8902229907163619 
42.484225353594354 91.99766782662572 87.07313703652137 0.8902229907163619 
epoch: 18, train time every whole data:113.29s
epoch: 18, total time:2855.58s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.59s
test time on whole data:35.82s
32.09870629835375 52.826110532544114 72.62425353880853 0.9813747623455178 
37.09503054113385 60.0630875047771 88.2441186286836 0.9764511661728683 
42.08757437384538 63.97609065467667 106.46209505445216 0.9744219295934925 
47.846323505426845 71.65639628105444 126.11062226715572 0.9671074227912109 
54.46461657874058 80.0015630853198 150.84718624518757 0.9584112142657305 
61.88284093889946 89.07125798090809 178.75208637565336 0.9482209754571451 
70.4929096667051 101.65197970883112 208.2573512243398 0.931505414556069 
78.80102372204541 113.59855116743697 237.25940463785275 0.9140183472744335 
87.4580659887357 126.62255122042642 266.14222516486757 0.894447264948069 
96.54510605004205 140.8757322464999 295.657661676914 0.8713975326066273 
104.61627028051062 154.35343810052004 321.2324611236161 0.8457407722701096 
111.02732007300588 165.95684406004418 338.29613672605535 0.8218354212672191 
68.70131566812039 108.18323460526172 199.1156031008204 0.8218354212672191 
epoch: 19, train time every whole data:113.28s
epoch: 19, total time:3005.50s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.64s
test time on whole data:35.87s
36.28858536900831 60.309250076426075 82.44666159690844 0.9770497885926335 
46.581150106970796 80.21690407845885 108.32725467537978 0.9649896136923881 
56.69430272481145 93.55643868101261 135.20733750850567 0.9570411504178364 
69.23690198514724 111.14522629650637 167.50031557773679 0.9451766590157087 
84.95133148078672 129.88906392649304 217.32993744382884 0.9332750721834222 
102.97124269380113 150.9200454945322 276.57696084034217 0.9196696908437879 
121.92657281370847 175.13878632663767 337.25050278176496 0.8961748806088329 
140.77459164373997 200.4138626952693 393.7833811415881 0.8698677694236263 
158.08089794814427 224.8330659879129 444.66517435291667 0.8428977286031214 
174.74935613713316 249.9668131399773 495.8696951844511 0.805431342520462 
191.46752032856008 277.78089706607517 547.7648155683528 0.7627172101563502 
205.20808321803295 304.5027477484453 584.4041605068277 0.719895629194322 
115.74421137082037 188.10077777221255 315.8475840527116 0.719895629194322 
epoch: 20, train time every whole data:113.25s
epoch: 20, total time:3155.43s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.57s
test time on whole data:35.80s
36.48516365609547 54.35412013843533 106.21696016985784 0.981242156108565 
44.499974903605754 63.37967045072296 136.35116140215163 0.9761415665485952 
51.625407058844004 69.3839290233419 163.48558470808442 0.973628988230924 
60.27717356257518 79.68795722665911 192.87456710159222 0.9662011807569493 
70.59023913017583 92.49673183172489 232.2613673403195 0.9562482336175578 
80.35302481130739 105.15071943289757 271.6133986009451 0.9448372739776948 
89.64894459775782 119.26647746527685 306.3389402939711 0.9281050279009728 
98.12362516034847 133.52908983931547 334.1899307961091 0.9100133575287319 
105.75193578132439 145.40787205553926 357.5272054468152 0.8947728906779921 
113.55311775856156 157.5719636501299 382.0916636384879 0.8764904003230347 
122.22244901562229 172.47642394618964 405.46287420218806 0.8538925671512473 
130.75012888026635 186.44866341733962 422.825365777173 0.8330197871355406 
83.65676535970704 122.57177377115732 275.891450086671 0.8330197871355406 
epoch: 21, train time every whole data:113.10s
epoch: 21, total time:3305.15s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.63s
test time on whole data:35.86s
32.149283033456484 53.8867766073992 56.83253005775445 0.980086185142575 
37.49458466900293 62.34591384534855 68.67876761683772 0.9737276474741742 
40.81864217786776 66.25529786265955 78.04873665786045 0.9694126539985176 
45.317599855109016 74.46208072233003 86.2611568796816 0.9592720961214507 
50.261075793852434 84.13127772210024 95.61024679031297 0.9458756331070166 
55.03554681050842 93.8502787175549 103.26093415155788 0.9312847584768467 
60.54638120432055 106.36552599059276 106.86059671096184 0.9114487890067384 
65.98131349597745 119.53486765258178 108.50675813279543 0.8872847804547117 
70.49046522785058 131.1584708710987 109.24936510758208 0.8643257934851125 
74.31904637511386 143.20855972525004 108.09121038180064 0.8383243151720313 
77.81011597225154 155.8000576085147 107.32682646903669 0.8075681161207015 
80.15635774735821 165.78424505449752 105.70948493765313 0.7809927991793463 
57.531701030222436 110.93640443821069 94.53182899637982 0.7809927991793463 
epoch: 22, train time every whole data:113.24s
epoch: 22, total time:3455.10s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.60s
test time on whole data:35.83s
30.83253914437059 50.90259657807971 61.336398963009145 0.982327958036459 
36.638971362077534 59.12325045011714 75.9664194083167 0.9793586061047526 
41.50601518134655 64.57786522044282 86.62709149265999 0.9786896912345485 
48.21512822805969 76.17313416988698 96.96350940148689 0.973985502153115 
54.36283981258569 86.24596419534072 106.37951450212051 0.9716012637063993 
60.467249827093994 96.01005998122848 115.83678364061842 0.9678495354663547 
67.20100764306633 107.62893672134922 124.90004606322455 0.9594946501107229 
73.68867573090768 118.55969746240501 133.00221877708498 0.9534341384939794 
79.81823155847287 128.42165887611577 142.02930302268376 0.9465161125812822 
86.00430681281875 139.09120555620802 152.23357908305434 0.9363358538783138 
90.51808330214477 148.50713946378315 160.57024091404887 0.9244588890201412 
94.788138135575 159.75219963669755 167.30716931908128 0.9068031662330069 
63.670098894876624 108.69283541999258 118.58142647997182 0.9068031662330069 
epoch: 23, train time every whole data:113.31s
epoch: 23, total time:3605.18s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.56s
test time on whole data:35.79s
26.059473943334133 48.47276497212747 31.384874826114807 0.9828750188435599 
27.912768211644053 53.12805533011588 33.25320523703376 0.9798081793683694 
28.987361925636417 53.213307351856216 35.47179708311718 0.9796318008526538 
31.229649497511552 57.92563673159822 38.33984380852132 0.9755459883934607 
33.049224234817494 62.165087774474316 40.64722834329707 0.9708878068142754 
34.27338159880529 64.69987378699258 42.53839280417434 0.9679031234526422 
36.31154513195208 68.76678836506379 44.67820722378206 0.962839825269211 
37.953748313213325 72.13711823638948 46.45401221603629 0.9582090365440664 
39.23050117214115 73.8491745500143 47.8068715026165 0.9558121239798192 
40.57039995592592 76.55928964292352 48.85614425749822 0.9519776938401164 
41.45099978067313 79.06565858991515 50.53270158142035 0.9483337774126188 
42.41342442818819 81.812616055345 52.45862453559072 0.9444564929663783 
34.953539849486894 66.8344655468944 42.698936098036626 0.9444564929663783 
epoch: 24, train time every whole data:113.35s
epoch: 24, total time:3755.14s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.66s
test time on whole data:35.90s
29.816762318139663 48.97677933741074 62.061744333792824 0.9833140099143023 
33.657246524479326 52.579298886477446 79.8728068981961 0.9818853943896061 
37.43098744632019 55.17113724904086 94.75949199610905 0.9816924095287223 
43.292029178059096 63.25691208798281 112.55796553747413 0.9778169481406374 
50.01385860857823 71.76988477637242 134.2531307322024 0.9729862272929348 
57.18609454018976 81.29596326386499 156.42922868715783 0.9676729253323373 
65.04893814964731 92.8479564494378 176.8501848755722 0.9590534865702973 
73.2865287351894 105.6096778930086 196.45353778812247 0.9468959862714079 
81.12721287113254 118.41933448540128 213.90892330270822 0.9338697310635654 
89.59626277298798 133.4056197190209 230.63473001653486 0.9157113069853289 
97.54722105897223 148.94122562925182 245.974709254703 0.893168605393194 
104.03431307157327 162.8607703556046 254.62440046526385 0.8696169029973995 
63.50312127293908 101.76362044323575 163.1702256152167 0.8696169029973995 
epoch: 25, train time every whole data:113.32s
epoch: 25, total time:3905.20s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.73s
test time on whole data:35.97s
32.7108385418003 62.8775135669783 35.232212914813935 0.9816295168454418 
40.8321103370288 78.8310525654788 37.64180604133443 0.9759430675888355 
49.03302262109523 92.97062794610126 40.63592833323239 0.9694083669081337 
57.136434920219344 106.69640758141959 45.70722408292359 0.9602198907315687 
63.923451603579274 116.0355032660394 51.38736990583001 0.9486370708022148 
69.38823208352093 122.78841778583507 55.97723661232108 0.9404232200152187 
74.63981333472132 129.44697828593 60.824792674215644 0.9360470564988731 
78.84013905360439 134.61787382681376 64.3281102224449 0.9287694380785074 
82.29039502584723 139.03016851324145 66.70691999553111 0.9224229239837867 
85.87847100073105 146.20289830898952 68.49671161273827 0.9114432363616797 
89.07030303949618 153.51876621528334 70.4331204235271 0.8966236812388039 
91.45141543166211 160.19869961681803 72.35812893860553 0.8787660391780313 
67.93288558277551 123.67686845294772 55.80556830517616 0.8787660391780313 
epoch: 26, train time every whole data:113.43s
epoch: 26, total time:4055.54s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.76s
test time on whole data:35.99s
29.30816417344116 50.23521305011512 46.25759470240044 0.982797018206846 
32.14033803164847 52.82009347869198 52.8470576885738 0.9821917536654832 
35.22838799605114 55.86078623951302 59.67714560078642 0.981927855429689 
39.02376388813144 62.2311088042044 63.51001244596649 0.9777001676897947 
42.421368107275924 67.81025500838088 67.14676957469247 0.9738176151290671 
45.60016082135287 72.52468114744565 70.76720845824417 0.9703464027314731 
48.854250017848315 78.33246093235607 74.15764766682378 0.9643149908667447 
51.24908443101032 82.77222117359162 76.49124946348553 0.9587511881492342 
53.04586103168788 86.37974492934342 77.23414694964279 0.9534544019993827 
54.865073944961374 91.02446626617231 79.05772098579756 0.9460829946086327 
56.93963431147753 95.98884821542308 83.60964378035656 0.9371617418492936 
59.471676003605815 102.15249950608707 88.98913522386393 0.9242569126765969 
45.678980229874355 76.67456024834198 69.97348242336238 0.9242569126765969 
epoch: 27, train time every whole data:113.26s
epoch: 27, total time:4205.67s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.69s
test time on whole data:35.92s
32.32364410163265 49.84388049000368 69.79073174758315 0.9821385006943171 
36.42115616215232 53.01125455132879 85.1147487397803 0.9795904365684844 
40.18984810634981 56.00721932072715 99.50992875126747 0.977151415281866 
44.34815375330552 62.57525151379967 109.46266197870868 0.9709648774052416 
48.38358555462543 68.76569277438055 118.89532948390502 0.9642833592293765 
51.83590507872921 74.20645107263414 126.78648389475175 0.9577458534890376 
55.47969764355023 80.93977995461152 134.191606773021 0.9487389138380189 
59.22702178481875 88.08983345072228 141.44015341191394 0.9380111734917623 
62.97282119538148 95.09508614067263 148.3804850213242 0.9266980856062512 
66.29032635311374 101.5222923802235 154.18400433184794 0.9159438492319086 
69.9772712928752 108.9360280603422 159.72608180659327 0.9022854862192107 
74.0608004683187 116.86563483236462 164.40653434912642 0.8871333853341513 
53.45918595790442 82.54692955224945 125.97882145981887 0.8871333853341513 
epoch: 28, train time every whole data:113.23s
epoch: 28, total time:4355.67s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.70s
test time on whole data:35.93s
25.389049324030008 47.54729355470209 31.72251143918553 0.9845561071036733 
26.53297531484203 50.18413141447178 35.99807458178598 0.9831474017760794 
28.15850035441324 54.6850688749063 38.50063672237312 0.9803472867700074 
30.643268092266453 61.38674396216852 39.62134157251301 0.9744081545180989 
32.167206025725484 65.49225110368123 39.740864745615276 0.9703137083648762 
33.58321515819384 68.99831093285081 40.02470771075378 0.9657095907948493 
35.538506624603166 73.77087087883613 40.55583146067888 0.9587357450578431 
35.909104891549305 74.74313911584125 40.49300295029789 0.9568107576546598 
36.340164982236885 75.22383203564442 40.48881503056886 0.9553762476048446 
37.07393327475469 77.06229558687859 41.25067553934369 0.9521731384716258 
37.12602611700928 77.61674048821214 42.13864797565023 0.9512480838271017 
37.17365523922351 77.86165977458387 42.27393326223478 0.9509313497236443 
32.96963378323732 67.88512363899015 39.39985345016471 0.9509313497236443 
epoch: 29, train time every whole data:113.19s
epoch: 29, total time:4505.63s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.70s
test time on whole data:35.94s
25.749388548235633 48.03696126447287 29.361189459914954 0.9836585812110841 
27.485175423719767 53.08953297725929 29.208263064543228 0.9819399325248429 
28.621514920050757 54.406180860193665 30.122587854525474 0.9815431724749731 
31.050553621502356 60.2955701771019 30.87644892414661 0.9779160060431077 
33.433979497645716 66.82385209682118 31.881185803188135 0.9737972841220267 
34.79970244241288 68.49205621939902 32.66983457868242 0.9712821901490172 
36.70860577492008 71.54568220151688 34.173149122722066 0.9664139875339498 
38.950536124792436 78.157292783402 34.830804728766275 0.9589523423386409 
40.1041942238621 78.77534812133669 35.91767034354413 0.9559306959171331 
41.36142838722567 80.69015132874863 37.379100058687634 0.9512815888305939 
42.9004797260949 85.27928107985886 39.3677117644917 0.9443064818821486 
44.126509626129085 88.20279033269274 42.10600390285485 0.9390682648819317 
35.441005693049284 70.63657957356834 33.98906983825816 0.9390682648819317 
epoch: 30, train time every whole data:113.30s
epoch: 30, total time:4655.73s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.79s
test time on whole data:36.02s
31.313935808828482 48.64743291888519 75.82547457038925 0.984752149563551 
34.043500527295606 52.63041159957041 85.48783592547457 0.9828679577023375 
36.17847919315739 56.61601446604795 89.62876239782922 0.9801035445439352 
38.653097831985484 62.33242591824394 94.05539910029873 0.9749257658811261 
40.521428041491376 67.49302881742088 96.19810517458922 0.9690871734475369 
41.20911619925335 70.36054144459821 97.29716071929091 0.9650557662167444 
41.98543680853332 73.09468471373803 97.26670881904784 0.9607699338974055 
42.416236910104516 74.60295557641824 96.37671921323015 0.9575742541065534 
43.08218624683157 77.36228799589986 95.82073525291277 0.9528361571126914 
43.69839355269876 80.70785081330104 95.95760293725802 0.9472541689555609 
44.51200698443793 84.90797848654397 97.72355183396874 0.9402752418751891 
45.97541826055651 90.30386528257573 98.30137775252938 0.9314984384195975 
40.29910303043119 71.00728818085177 93.32669059289096 0.9314984384195975 
epoch: 31, train time every whole data:113.28s
epoch: 31, total time:4805.90s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.58s
test time on whole data:35.81s
24.911382797778874 45.101052152523785 30.440708750900882 0.9854202406170727 
26.07652295081981 46.640607441629214 34.81922727804108 0.9846582372640161 
27.363529191816706 48.85753732455448 37.16114234070826 0.9828698305744041 
29.602661572417286 53.28296491020004 40.590996079845986 0.9793958853397778 
31.014829358738467 56.317899772227506 43.275914653740436 0.976740596620935 
31.95459418101651 58.238238756285284 43.968301749230605 0.9747249801411806 
33.87239673226648 63.09731133966071 44.771527455768684 0.9697897124430489 
34.65676003941234 65.8413091151824 44.38977402679989 0.9663844153527247 
35.36339918894303 68.5317467962909 43.14464861931302 0.9633067073926114 
36.34008411175438 72.25860848797095 42.21272062254582 0.9593933479920795 
36.63411871066064 73.52468556190574 42.205505174198 0.9573063755354656 
36.84475630074686 74.81321104518182 41.309198072992615 0.9553375853516577 
32.05291959469761 61.397702316367464 40.690275118618054 0.9553375853516577 
epoch: 32, train time every whole data:113.25s
epoch: 32, total time:4955.79s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.58s
test time on whole data:35.81s
29.287725003523324 50.02080194554216 48.562138968615365 0.9821571258838125 
32.93642325309857 57.606292489312494 50.071123310102315 0.978389199262935 
36.30096408700776 65.64356164463614 50.47388432694806 0.9746006942211494 
40.823254417574326 77.7911020841766 50.7248920628051 0.9675478128152917 
44.77138844036562 87.97088990305448 50.786354866431296 0.96185395474155 
47.76043950753141 95.60061609818139 51.699077155261755 0.9576894902283515 
50.59462198203246 102.62719155508437 53.44910897585231 0.9529541393264457 
53.30934623268177 108.82609282711547 54.91494782302564 0.9467416147535618 
55.45570088312774 112.71011542254209 57.079901878428295 0.9416853835866039 
57.12810232623849 115.00557380744303 59.50611327001142 0.9394592823053277 
59.22451949118528 118.00016739024055 63.02631111391433 0.9346594067656561 
62.31601272332279 122.89943104850585 67.76689695113922 0.9279446234623481 
47.492374862307464 95.91362185459879 54.835200356179534 0.9279446234623481 
epoch: 33, train time every whole data:113.24s
epoch: 33, total time:5105.72s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.65s
test time on whole data:35.89s
24.68444804250141 47.612292402433035 28.988778509285513 0.9841226248465825 
26.488334590729576 55.159793240165214 28.25504325483785 0.9798544583490756 
28.069810398477554 59.13619815790223 28.127557149621012 0.9770028695374195 
30.581115675189558 65.82845746550592 29.399480350207874 0.9715815179809175 
33.09393855196341 71.6270633560043 30.175763579317845 0.9653969790161453 
35.16808029807802 75.79076506583048 30.90103129596441 0.9603121586878569 
37.4098606124567 79.50146424480548 32.03260101077087 0.955326770489507 
39.47200676801567 84.22438968775651 32.56467710113263 0.9482477394517234 
41.205411702221184 87.68729919597287 32.6142866778042 0.9429275891300011 
42.655330371520755 89.85294608774372 32.978465527065985 0.9397367071981466 
44.64396670336418 94.17073843568498 34.165878867994834 0.9334077414408031 
46.50856278637272 98.8013815075305 35.0653945979567 0.9269632448367611 
35.83173887507423 77.36352023554831 31.271361602684177 0.9269632448367611 
epoch: 34, train time every whole data:113.27s
epoch: 34, total time:5255.69s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.67s
test time on whole data:35.90s
24.031073593729392 42.68497436867348 28.832196924651328 0.9868623052346012 
24.976087980475334 43.975440557596116 28.776163098296493 0.9862434926482849 
25.58309461409391 44.277482992255884 30.082492772648095 0.9861021679286478 
27.25367756366842 48.442153124953904 30.844766102265016 0.9833893942696503 
29.050885414117392 53.09830825692297 31.491015787497208 0.9799188335139033 
30.66993221807222 57.054132445649216 32.50068484337965 0.9766167699240658 
33.07030703507419 63.82049765723763 33.612479173756526 0.970164947523706 
35.02327794601261 70.38504656646127 34.06800986191255 0.9630152527917145 
37.08578929114086 76.22626167515854 34.86989928251183 0.9562117261815564 
38.99083073279297 82.64105971059803 35.52034383221916 0.9476792895356704 
40.88658736955783 90.00423643081905 35.86344165005435 0.9369673927598271 
42.44200926253905 95.26732982326915 36.646175045944595 0.9285345986260196 
32.421962751772845 66.44629009274081 32.757812390697474 0.9285345986260196 
epoch: 35, train time every whole data:113.26s
epoch: 35, total time:5405.69s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.66s
test time on whole data:35.89s
29.838399133663696 46.88463365794868 62.75185817421076 0.9853995503771475 
32.954826084781274 49.92523200330283 75.35574502568426 0.9842756771808776 
35.41559606112578 53.03713664203901 82.63336707232054 0.9824876487314279 
39.24086170632637 59.554385363566816 92.17585749957395 0.9781662260124543 
42.502493526090696 64.5970117348806 100.57704904761766 0.9737654417724375 
45.45693359181743 70.03392239634411 106.97306542136478 0.9684703578530447 
48.93045494272881 77.07491554303648 112.92354396677378 0.9613988367870018 
52.16991901089017 83.01386615582683 118.41742320984817 0.9546632392164905 
55.03612955593494 88.06488025938744 123.55218934878656 0.9484757163959163 
57.89955426292415 93.28192397587408 127.3954376014338 0.9416125168828129 
60.29245613198037 97.72605200763252 131.97736327527812 0.9346008224256274 
63.36498185540487 102.90899834121193 137.8590710581831 0.9263927934711698 
46.92521715530572 76.13437287168126 106.03976673422157 0.9263927934711698 
epoch: 36, train time every whole data:113.24s
epoch: 36, total time:5555.67s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.56s
test time on whole data:35.79s
31.496360021116143 48.92221901441651 66.3581197730443 0.9854768618124699 
36.44771581585403 56.73505947228151 80.61232666842795 0.9828767113834075 
39.304892254127154 61.018227226845866 87.53974293001555 0.9800937085200185 
42.531427487150424 67.19806116420189 91.98364062609737 0.9760738060074822 
45.43140602208225 72.05652969784002 95.52840470141311 0.9718908211665739 
47.62342841068093 76.14855388606206 98.57256122219128 0.9666774160710888 
50.19468763222964 81.45440391693808 101.54770747853719 0.9597632774736095 
52.560517927313995 87.18829444045588 103.71751899155804 0.95246080993258 
54.93794413947887 93.64992284033417 104.89939901360205 0.9430219543153334 
57.22413480842297 100.66954520702689 105.85390894800346 0.9320196821202416 
59.06631645452298 107.75984615088583 107.92261370939174 0.9201620584287696 
61.021489974230896 115.27728414663595 108.30458593631538 0.9069399898770967 
48.15336007893419 83.10842334142149 96.0659541394833 0.9069399898770967 
epoch: 37, train time every whole data:113.28s
epoch: 37, total time:5705.60s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.65s
test time on whole data:35.88s
30.62151301568849 46.61831721620137 68.2425407616372 0.9863936191582486 
34.49489981974212 51.999451414377646 76.61217481738856 0.9841117314355928 
38.76746217332891 58.3393928309744 83.28434867954479 0.9808634987426127 
44.389781648872024 68.39538328484964 90.06797613978354 0.9757502336913708 
50.015831358124245 79.00718461136296 95.44340842973614 0.9698973562989968 
53.84838752567896 85.81012705989818 99.39237476528984 0.9658380496951615 
58.154336423007614 95.26409814615333 102.80835123001685 0.9592140094553457 
61.67029273164072 103.33611972151682 105.08441132207793 0.9541679217163287 
63.09996236828025 105.43371776631388 106.50560152334825 0.9518925295147456 
65.13191013286485 110.7179645159716 107.91124075630518 0.946274484133533 
66.13142538425238 113.02124617484823 110.18650467279174 0.9430588199331152 
66.79911051224147 113.74538512434599 112.56313147560189 0.9370533085368027 
52.76040942447683 89.16477726264841 96.50346109833221 0.9370533085368027 
epoch: 38, train time every whole data:113.20s
epoch: 38, total time:5855.58s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.57s
test time on whole data:35.80s
26.37521799957897 43.99754272765518 38.31609456755118 0.987033172967946 
29.24284455182501 46.891819128820686 41.56584107658471 0.9863646449007086 
31.211316825393478 49.11718221290092 42.74210606626902 0.9857932929854274 
34.40692925856829 54.29282861067753 44.90745095609399 0.9829553946098438 
37.84582539647938 59.02046865036773 48.17975915991831 0.980157712504504 
40.95912462515841 63.677428052672795 50.58593680033287 0.9771372939312646 
44.03274604059885 69.23441267414853 52.62850800224912 0.9726446821764584 
47.15788712242375 74.90469487740218 54.27110595514001 0.9673698292769869 
50.62907352352408 81.68766598313994 55.786717702872494 0.9608347183701657 
54.26321172911036 89.95025530530744 57.094013694434 0.9520048936967361 
57.89290784849896 98.80322956237721 58.67469040318102 0.9415083638577759 
62.00740082603642 108.49840286718002 60.4813304206004 0.928862267250229 
43.002040478933 72.87837348992082 50.433123065066745 0.928862267250229 
epoch: 39, train time every whole data:113.16s
epoch: 39, total time:6005.39s
fine tune the model ... 
epoch: 40, train time every whole data:252.40s
epoch: 40, total time:6257.79s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.66s
test time on whole data:35.89s
21.815581998381266 38.61195232301356 24.28242656013148 0.9892580746627269 
21.532214871440587 38.05149366765517 22.754500578199213 0.989589089126428 
21.56264741474869 38.393392062708806 22.228936551283283 0.989491110851151 
22.25483280376205 40.43657539683388 22.259741329180624 0.9883112715167568 
23.131354153529408 43.04191216129708 22.73905008812986 0.9866220679739247 
23.40355498871992 43.36522524234079 22.77751650810887 0.986407954388759 
24.263763386580347 45.939242444714914 23.292947039403817 0.9845755415032852 
24.772386692301183 47.80815073635443 23.290078804726928 0.9829794848513888 
25.043468485835533 48.100452986225505 23.235626557038085 0.9826684761695421 
25.749010399840724 50.45133605498374 23.601680318439485 0.9808354043886961 
26.380314378646872 52.52152730843839 24.367298544825548 0.979200882957035 
27.116315666779723 54.53693805639061 24.955315642421375 0.9775182604069336 
23.918787103380527 45.43211949626391 23.3150482808825 0.9775182604069336 
epoch: 41, train time every whole data:252.41s
epoch: 41, total time:6546.91s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.66s
test time on whole data:35.89s
21.39779497954663 37.7813409130584 24.378761438815435 0.9896708187241627 
20.815638675464168 36.681210458432005 22.725556240338598 0.9902548094607427 
20.588860085251444 36.75756636335232 22.112305923404694 0.9901807965227521 
21.09911141277458 38.788327578735654 22.073414658003557 0.9889586294631415 
21.562481909872467 40.10912561604998 22.371905969661675 0.9880737723790833 
21.892117873668045 41.166506221292636 22.35450882017841 0.9873150097079417 
22.660893653337318 43.974071328596615 22.823195040415143 0.9853102823487186 
23.069664695796035 44.767721845718796 23.136024453198434 0.9845916909791389 
23.808229359127626 46.73279229300672 23.529264289072852 0.9830824395977386 
24.592954970198644 49.28924295090689 24.08770269496398 0.981042277355131 
25.248097724251423 50.706427606656746 25.355919336062016 0.9799744115791033 
26.30111862853007 53.46571254787906 26.428338342109964 0.9776118597845684 
22.75308033065154 43.696865437611194 23.447385582396226 0.9776118597845684 
epoch: 42, train time every whole data:252.24s
epoch: 42, total time:6835.87s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.66s
test time on whole data:35.90s
21.15457763870304 37.5174641375271 24.050286871583832 0.9896729005032858 
20.610490047931137 36.623369591691215 23.144569358392555 0.990119803450151 
20.41658564633364 36.97846857392064 22.66483904554908 0.9898594017744701 
20.83110981561293 39.044787786982056 22.560017184743213 0.9886791180676139 
21.373497284100587 41.28554584597428 22.55879067867994 0.98735056858323 
21.400299790514925 41.036511679963674 22.521849960558143 0.9873939115698677 
21.990151220152953 43.772190000158325 22.964698250331775 0.9856023127714671 
22.514188068612174 46.16259983991018 23.455789366772514 0.9840805153217715 
22.53507304661593 44.73134417539978 23.41926377764989 0.9847009596545641 
22.997407844173292 46.47009667016856 23.77297123385124 0.9834848543635268 
23.609786983282653 48.7762961307939 24.874398155473884 0.9817777743160858 
24.19069639219994 49.23594904676105 25.616247924888825 0.9809568021609284 
21.968655314852768 42.856236918776524 23.4664849656061 0.9809568021609284 
epoch: 43, train time every whole data:252.51s
epoch: 43, total time:7125.12s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.74s
test time on whole data:35.97s
20.954212574789953 37.053586396530335 23.435452727022636 0.9899462893409392 
20.380076368168293 36.08976704227454 21.958671079095915 0.9904084729943595 
20.20019786637453 36.356075133146035 21.270869391705112 0.9902110037961671 
20.581845532708826 38.23587670373488 20.910529027268375 0.989052722639517 
21.09848469525501 40.11123408959298 20.967889889838013 0.9878032456237752 
21.179731690547033 40.09361671565744 20.938605149968538 0.9876733786528411 
21.707379754047757 42.37730350171437 21.229135510261255 0.9860374549761365 
22.039083879417294 44.11598973567047 21.46591223231116 0.9846476280463995 
22.115808752135422 43.393146038779 21.51521462938959 0.9849492376947864 
22.383632991215926 44.02065913409251 21.89263477867476 0.98441223371252 
22.790014567492122 45.65228473488937 22.902370883616204 0.983135777263143 
23.331161985158026 46.212410820713785 23.726385148780853 0.9826605870077678 
21.563469221442517 41.289782018363745 21.8507549391104 0.9826605870077678 
epoch: 44, train time every whole data:252.71s
epoch: 44, total time:7414.67s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.61s
test time on whole data:35.84s
21.282820930266492 37.10018616438785 25.7461029588642 0.9899075847471777 
20.839948195177982 36.38031371793843 25.352041827620354 0.9902804722883096 
20.781703007487703 36.76317296836792 25.355278541522008 0.9899625113970605 
21.19499860396537 38.69618911250335 25.342986878970343 0.9888640839173666 
21.635102596456953 40.51122987382431 25.288194741387223 0.9877548298861831 
21.7740519294107 40.673030526485476 25.248049130098714 0.9874366602249982 
22.290080544734725 42.81412692532081 25.670287282578197 0.9859748354293543 
22.728792039238584 44.950552445331844 25.831388814348117 0.9844615303450236 
22.80177422382816 43.991284279992996 25.89428774786498 0.9847137292527672 
23.117529693263883 45.088401572262015 26.374746996631032 0.9837851950758078 
23.62129724675696 46.88547494474313 26.99317604875252 0.9823407396354285 
24.08753233078709 47.194195255031595 27.534590040751393 0.9818428094535602 
22.17963594511455 41.92420804390722 25.88553179424323 0.9818428094535602 
epoch: 45, train time every whole data:251.96s
epoch: 45, total time:7703.34s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.60s
test time on whole data:35.83s
20.701481172724517 36.547347771191404 23.269563867942512 0.9902321405472805 
20.0512979214994 35.569376151323695 22.162591872832117 0.9906939490133126 
19.8571864613407 35.97566201927079 21.32285162834988 0.9904299130371347 
20.20597845666893 37.47328944698604 21.311300986067515 0.9894735821793091 
20.51976378877499 38.5208530373058 21.269840819577578 0.9887234408661164 
20.683901685340597 39.206938086267826 21.30529523296925 0.988178285569014 
21.216812941545843 41.27763930705821 21.736652505177943 0.9867130436697825 
21.365722220829486 41.725327748272186 21.88388809842876 0.9862042926804824 
21.5451877470619 42.247907255605 21.807686420781774 0.9856850782138986 
22.0113788615077 43.92798895493025 22.24137866705762 0.9844068653807063 
22.304105474673896 44.57066675830716 23.04927832464833 0.9838573387883229 
22.841277154674895 45.745300737287536 23.857338883301672 0.9829225443008965 
21.10867449055357 40.372228676632055 22.101104230895086 0.9829225443008965 
epoch: 46, train time every whole data:252.51s
epoch: 46, total time:7992.56s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.70s
test time on whole data:35.93s
20.877137421909904 36.60667319615851 23.44210402435225 0.9902689039188537 
20.472283428713965 36.101270865889894 22.35532908726497 0.9906379102028631 
20.288603730479082 36.331850056608445 21.70124329088025 0.9904228799253308 
20.62964201300715 37.81685972541986 21.73495038898843 0.989641431232899 
21.21484095622904 40.248862723241565 22.202105515036344 0.988305657644455 
21.322642307588556 40.03638275337679 22.341842481420272 0.9882200258236166 
21.82658469394505 41.770409771672504 22.62312098230738 0.9869538382395544 
22.288543261179832 43.99186032671149 22.50861116681454 0.9854301028962901 
22.447034948083243 43.3321235473056 22.6892247082896 0.9855057768987947 
22.88558614734586 44.32251660823516 23.269873946649017 0.9846218628637049 
23.358247368793023 45.72106926141013 24.09135686296957 0.9835452897961654 
24.128674619255754 47.003477493482514 25.04537705098613 0.9825857456248513 
21.81165174137754 41.269746557588896 22.83326722325984 0.9825857456248513 
epoch: 47, train time every whole data:252.08s
epoch: 47, total time:8281.44s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.59s
test time on whole data:35.82s
20.839594000342906 36.367809047094624 25.758487440955353 0.9903022283696339 
20.35903215410418 35.737879088265714 25.70195512882186 0.9906289648087269 
20.21932622067954 36.03723141569133 25.081502725815717 0.9903771481631921 
20.60045035634637 37.87788069474472 24.981046769553377 0.9893456666159144 
20.93537967715977 39.500196803582554 24.750114689641276 0.9883607261933413 
21.093371296280754 39.85061898616849 24.927824644706934 0.9880524243733407 
21.59194002065399 41.89816215393604 25.513924420984836 0.9866836751351383 
21.823290895145284 42.91774405850116 25.933450610742607 0.9858687310370844 
21.966590488291736 42.849377127316444 25.936480864895422 0.985547533120041 
22.23340489240748 43.73504964690574 26.341022680379357 0.9847279117328537 
22.580466156167883 44.62551979548171 27.25361154728522 0.9839158045013968 
23.19934247541599 45.84922454146506 28.05087602569018 0.982714687272641 
21.453515719416323 40.744496207652396 25.852008675363308 0.982714687272641 
epoch: 48, train time every whole data:252.46s
epoch: 48, total time:8570.57s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.59s
test time on whole data:35.82s
20.81537065341386 36.47120610927462 25.292995880017394 0.9903915612930141 
20.364309718876964 36.33436028143331 24.739314604101992 0.9906510188453442 
20.1921187136055 36.695606270532956 23.939886665103906 0.9903161656316065 
20.688252855735232 38.85524672065337 23.90822960247965 0.9893076010587827 
21.179137363919374 40.71364705406216 23.80837889833848 0.9884304648873662 
21.297461130096508 41.16878115918654 24.08745523712107 0.9877708739211885 
21.859053961194935 43.26269261304214 24.738264146600812 0.9861106288014041 
22.36104026290887 45.03890313175961 25.236219940983574 0.9849911481776786 
22.407561179233017 44.893867606207756 25.011955755389653 0.9844653759817202 
22.567634089342153 45.28893551635728 25.217615411570566 0.9837072117193659 
22.739243707389818 45.57443990956585 25.968741469554658 0.983374196304015 
23.235760547582505 46.5453550274408 26.5544820152493 0.9823663294273952 
21.642245348608228 41.901980832234095 24.874894049869365 0.9823663294273952 
epoch: 49, train time every whole data:252.00s
epoch: 49, total time:8859.24s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.74s
test time on whole data:35.97s
20.553010754703696 36.101810360277 22.83848883604562 0.9904877297652372 
20.083537218404846 35.91537592876147 21.441898821661702 0.9906832579987686 
19.880941858990187 36.10424900399989 20.86360463726295 0.9904453434797447 
20.16631347054826 37.75831471040124 20.803896941619563 0.9895735164612905 
20.77467287527542 40.37349992333471 21.039933561220035 0.9881475316563468 
20.807126326215652 40.10953419647677 21.105248603079545 0.9880238901777575 
21.169263063942406 41.695718864561265 21.527466210223597 0.9868601353597279 
21.632928490966272 43.84600952197792 21.798002596699543 0.985483450692055 
21.686208887823096 43.08475193589515 21.78547889238572 0.9855247533205383 
21.968206714759425 43.847975460825396 22.172759393735042 0.9847280537124371 
22.336381871987644 44.86419955064132 22.96522243485004 0.9839495669698839 
22.950655412168047 45.6256870274185 23.609808473140095 0.9831739325288349 
21.16743724548208 40.922388266176526 21.828908800699608 0.9831739325288349 
epoch: 50, train time every whole data:252.76s
epoch: 50, total time:9148.83s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.72s
test time on whole data:35.96s
21.22258715835285 36.06521673016196 30.300924334020547 0.990523738317843 
20.991005934548653 35.668572850649866 31.07671715504606 0.9907478828813185 
21.09668464813029 36.31112667359552 30.989967689113502 0.9904044475079423 
21.7309315572117 38.423081732526455 31.465606266476108 0.9893434901896456 
22.429987550444608 40.43855908181788 31.447251212593404 0.9882166417755229 
22.82620693479586 40.9358728849047 31.872015900657168 0.9879444391503963 
23.584835549430895 43.645972181573086 32.57366919974016 0.9863035214730272 
24.302349255416768 45.963669539653765 33.21308757103862 0.9847446833132248 
24.636338592737 46.04106982865159 33.29494238632214 0.9844854067938915 
24.99368003937533 47.043472589867086 33.67342972853532 0.9836295396982184 
25.415453542653378 48.604968844253214 34.28952739620989 0.9822298195441284 
26.043301522962405 50.08442400808328 34.68507757942427 0.9806242444595613 
23.272780190504978 42.72020558302057 32.4061986012282 0.9806242444595613 
epoch: 51, train time every whole data:251.96s
epoch: 51, total time:9437.60s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.54s
test time on whole data:35.77s
21.275964202120097 35.98594511155875 30.32566730604243 0.990546809449248 
21.072386017931123 35.725894431420826 31.359130315021076 0.990735392191724 
21.039534887576554 36.18051226528461 30.698271621439932 0.9903865021513671 
21.475858466914545 37.83892863762426 30.49903745159657 0.9894576553165352 
22.011199528704093 39.811895578350665 30.283812556271876 0.9883497857118991 
22.26820558744139 40.46742436939379 30.352351548490986 0.9877393688289609 
22.620153736152616 41.767821067908066 30.70930280200188 0.9866683113305137 
23.110303647020068 43.68521703207218 31.02390119840547 0.9852972748932165 
23.384953532523916 44.29999686709478 30.86802303874485 0.984486743841074 
23.47451918586158 44.14583547168913 31.17077495540796 0.9842452437255514 
23.607732880989875 44.63764523742044 31.800099524441162 0.9837223972400843 
24.23571996382341 45.989011433433085 32.68463828444254 0.9825547737381181 
22.46471096975494 41.035090016693026 30.980884630608717 0.9825547737381181 
epoch: 52, train time every whole data:251.43s
epoch: 52, total time:9725.67s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.53s
test time on whole data:35.76s
21.162474020234182 35.8596243385962 33.0621267745207 0.9906431434378898 
20.909404126666306 35.60977574491089 33.89280503727058 0.9908095836538725 
20.889086044126763 35.981600452595686 34.05171133234627 0.9905472230325884 
21.354546810169353 37.6680241488572 34.26264271522965 0.9896477903277223 
21.883171253730964 39.23356268129884 34.17984277013254 0.9887836753767877 
22.1574799347019 39.89373368371947 34.54175806819351 0.9882584639198995 
22.8126023377308 42.54184980802728 35.088504724002526 0.9864027978095586 
23.23730359276309 43.536969640523296 35.553253151923286 0.9855959857801905 
23.416989884026833 44.234157565030586 35.126413769436724 0.9847969939640806 
23.865612617365137 46.213821396555076 35.37271966767475 0.9830049256023795 
24.22009698484772 46.98215148968875 36.33620325663036 0.9822000308544199 
24.614655247925487 47.5098670010428 36.829785315665696 0.9816040027258109 
22.543618571190713 41.49344480738117 34.85763240932457 0.9816040027258109 
epoch: 53, train time every whole data:251.60s
epoch: 53, total time:10013.83s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.56s
test time on whole data:35.79s
20.65723637268467 35.53879065112679 25.949543508415747 0.9907369566156025 
20.244976379148465 35.222324201877164 26.251182456366223 0.9908723745665354 
20.100564329980962 35.600787461267565 25.68833169808021 0.9905742492183615 
20.49335819473792 37.16237779777617 25.530833136670132 0.9896807613854067 
20.982036112292224 39.01156642708003 25.604924309674026 0.9885611820848679 
21.201413161208926 39.43470335001855 26.01174383894808 0.9881053893644182 
21.67542819986365 41.066124092845726 26.673142762471368 0.9868933842850754 
22.250485668157285 43.58021459281736 27.12562708366234 0.9850751635499865 
22.352856563612363 43.33892221830019 27.24975559949769 0.9849012831375672 
22.613879863155972 43.86745532264984 27.792436940270626 0.9843315826930821 
23.045716611928086 45.506864868437916 28.607422802022032 0.9830331724730744 
23.527523451129706 46.337904597991574 29.50998150979709 0.9823061820903264 
21.595456242325017 40.6565164089684 26.832241635875935 0.9823061820903264 
epoch: 54, train time every whole data:251.50s
epoch: 54, total time:10301.94s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.55s
test time on whole data:35.78s
20.300396563039417 35.52076887265637 22.185659960234048 0.9908229856575159 
19.930832325888034 35.417539573090785 20.735508659167124 0.9908802811434058 
19.931823650691683 36.147749826174945 20.224194815666753 0.9905042323571939 
20.196135037038314 37.404380611899306 20.056845320650314 0.9897124152541836 
20.758178652141368 39.39864630954373 20.18071212766688 0.9884271769218396 
20.9350286523913 39.64470956257409 20.194786676679485 0.9882258173798815 
21.490672681085787 41.704609481333115 20.576685320757523 0.9867990554099603 
21.868529186296477 43.34608682528842 20.68942367691093 0.9854512412031311 
21.989186036509977 43.05536484513989 20.724771794066676 0.9855954907081035 
22.561924221743507 44.75701193391867 21.237531738323742 0.9844000632436333 
22.88430063528515 45.46552618662214 21.875961304860883 0.9837332508665277 
23.39528948617874 46.4011713614958 22.59569637261799 0.9831451087966621 
21.353524760690814 40.86678153249835 20.939456244540903 0.9831451087966621 
epoch: 55, train time every whole data:251.92s
epoch: 55, total time:10590.51s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.68s
test time on whole data:35.91s
20.372281656290294 35.631988472945665 23.48932550823381 0.9907905985283937 
20.219481964290573 36.499438587399204 22.02881418380109 0.9904886341838398 
20.156260655760914 36.98045039938311 21.607237272154965 0.9901577609830482 
20.54391751303805 38.510577635774446 21.412967446817845 0.989404978951023 
20.99124329712973 40.31343307182993 21.05951302289174 0.9882204366569569 
21.49843969801126 41.98778799478163 21.290944785854464 0.987010930283342 
22.115053649801652 44.03870067750584 21.8071554057155 0.9855224920494854 
22.371744672110243 44.65756216733053 22.023654565130578 0.9846429246176879 
22.76751184439879 45.89091434850694 22.063486103039303 0.9834801720894527 
23.17577807771075 47.02911038929309 22.501307011214024 0.9825051807945485 
23.54373959495559 48.11382568612547 23.120702409077417 0.9812866217202489 
23.958278384172846 48.934725613640666 23.700742531187206 0.9805060563540837 
21.80947758397256 42.62391640941813 22.175147193682612 0.9805060563540837 
epoch: 56, train time every whole data:252.36s
epoch: 56, total time:10879.61s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.69s
test time on whole data:35.92s
20.193090153146535 35.24124834291017 22.56410186470164 0.9909085895950702 
19.708619269616015 34.83071219326414 21.161057272536603 0.9911060000170275 
19.55701995742254 35.195989629795285 20.395055735201257 0.9908479927970835 
19.84887562938052 36.69016895829465 20.13268029402708 0.990013803707873 
20.193647953591565 38.00570725108512 19.868798890449447 0.9891876238851471 
20.443346018365226 38.84200377647154 19.98687880190288 0.9885765111513716 
20.965481870113006 41.063172412592905 20.354947734478955 0.987064398878085 
21.132397534812892 41.3885540651901 20.42726163036721 0.986627981087122 
21.35689740116995 42.08957088100916 20.430965755182335 0.9859557237996878 
21.78111982582256 43.653597241631864 20.85304879670695 0.9847836944882119 
22.035718202145294 43.84757107334547 21.569567481940204 0.9845613954886341 
22.608395089655396 45.06089030402341 22.337783167419882 0.9836187659212889 
20.818717408770123 39.81482524469901 20.83988999586325 0.9836187659212889 
epoch: 57, train time every whole data:252.72s
epoch: 57, total time:11169.09s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.73s
test time on whole data:35.96s
20.37162668779519 35.109127654288145 24.412806044667704 0.9910018985467127 
20.12208134370832 35.46764197750883 24.036952661547954 0.9909080938366874 
20.019871765608293 35.882283782225564 23.439472996487673 0.9906394240200667 
20.40417296070973 37.67996913204674 23.13998364951642 0.9897718958333711 
20.955090815540604 40.16279362075323 22.870019114781247 0.9885148890308575 
21.07338478107903 40.28570483368415 22.968930647398206 0.988173914128028 
21.491702515581125 41.71354636014333 23.55957918823186 0.9871357920488636 
21.979784822313352 43.71833109408491 23.996721742161235 0.9859949366900649 
22.08311302973543 43.01615612223418 24.07157818021198 0.9859080122269451 
22.3927368315343 43.66104297324655 24.65501219446475 0.9851251446973569 
22.54484072323028 43.88302483016592 25.4656941843584 0.9849477148207917 
23.03053603887406 44.178858475553454 26.355724486337124 0.9843663058635136 
21.372411859642476 40.53742204202994 24.080517305160456 0.9843663058635136 
epoch: 58, train time every whole data:252.46s
epoch: 58, total time:11458.37s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.59s
test time on whole data:35.81s
20.378178054332537 35.27257872693892 23.772828092903904 0.9910300335979884 
20.212265045241143 35.36039381943822 24.20228243465567 0.9909849976986436 
20.20871550835113 35.94993551559134 24.430717166948096 0.9906857902943835 
20.59914406964955 37.51624055491028 24.735014200443356 0.989716958668063 
21.053234021970994 38.93494283905433 24.90303691982651 0.9887371579320151 
21.28806732352493 39.50547541215851 25.119094275653193 0.9883400832798759 
21.786823636500706 41.469279867306426 25.525946246698027 0.9869656552272281 
22.15686825682394 42.90743510264006 25.462984230819497 0.9857417133336505 
22.40787843110126 43.136895332550004 25.71693428877343 0.985593622980291 
23.00157203901233 44.930518335298366 26.41406774929517 0.984419383593305 
23.626747759573973 46.80984965957287 26.86400444109413 0.9829076830726037 
24.36332074707225 48.37954879605683 27.634912493086095 0.9819090360565166 
21.75690124109623 41.07211740235713 25.39791246022857 0.9819090360565166 
epoch: 59, train time every whole data:251.91s
epoch: 59, total time:11746.94s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.62s
test time on whole data:35.85s
20.11724009888317 34.86188461108052 23.732405532946448 0.9910957151046934 
19.795423600860012 34.83130288080124 23.017097210857056 0.9911149420520556 
19.724713907144746 35.27042451662409 22.706676250362055 0.9908382034406936 
20.102791670737176 37.039142389913636 22.70512105010808 0.9899135579526297 
20.55506641307083 38.65151995527021 22.671696545356134 0.989010410092094 
20.704696719369625 38.87960838025398 22.93504591183108 0.9887652694410709 
21.077915056761555 40.56700586093157 23.364156249589918 0.9876754301165863 
21.51471017888304 42.65299267742544 23.68021530745939 0.986373484845203 
21.621919175367527 42.405692973469264 23.46932904620528 0.9862518311246904 
21.757214167003454 42.74159005009063 23.78485616344076 0.9858266292307762 
22.170504650082602 44.43863862840528 24.542743094485807 0.9846847990165599 
22.709493687132895 45.366441892975814 25.203888632383848 0.9838116464459179 
20.98764077710805 39.9718528413374 23.484036569768744 0.9838116464459179 
epoch: 60, train time every whole data:252.00s
epoch: 60, total time:12035.63s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.67s
test time on whole data:35.90s
20.204208236089848 35.21303811975097 22.686613222563683 0.9909421499401564 
20.376989988511568 37.24223106438097 22.21546561209028 0.9899456304470109 
20.336298528148603 37.530621514650775 21.899371250874452 0.9896710523667649 
21.03668044255205 40.49708287290702 21.85123700109256 0.9879768597662734 
22.05601693130663 45.15663691455722 21.939686892247405 0.9851776463763126 
21.995511161882177 44.0100269520777 22.032039462009358 0.9855367871763773 
23.002614994517064 48.156617256059384 22.754562367271678 0.9824660796581989 
23.41857286287036 50.72921734051233 22.87846763692912 0.9805717926744858 
23.33859054521113 48.83827696856592 22.883608074520456 0.9814006297865884 
24.04025611450136 50.95525687003333 23.454423424271784 0.979392404751407 
24.296937854736136 51.29213028681626 23.89692432144023 0.9788598729319336 
24.96829270988804 52.26041549342264 24.769072734369843 0.9777424013831049 
22.42258086418458 45.540888097862556 22.771315646095598 0.9777424013831049 
epoch: 61, train time every whole data:251.91s
epoch: 61, total time:12324.29s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.60s
test time on whole data:35.83s
19.99127175222838 34.89006883953121 22.756969233271978 0.9911399864990288 
19.558366842820007 34.83035822982879 20.968053885045293 0.9911213395528576 
19.46961788038426 35.40775511355071 20.345191451136927 0.9907890193584475 
19.740618133749816 36.94720759080067 20.152779912648846 0.9898344635739443 
19.99672903541344 38.018704753716655 20.05650904949995 0.9890936244141039 
20.134430962522767 38.57849759087199 20.16341901754835 0.988663904476558 
20.525404912509433 40.51033660079426 20.386356947648903 0.9872993460718504 
20.69483920388053 40.98243372007678 20.441256266465693 0.9867712527272928 
20.898973010887392 41.50921052331374 20.467414955912417 0.9863374038994303 
21.2012325149838 42.48596521714871 20.85601339416526 0.9856231113715863 
21.5092688977821 43.00537691086101 21.571393534288536 0.9852285201158284 
22.064747828055733 44.16230255161416 22.256669744952088 0.9844329918661411 
20.482125081268137 39.4033510316072 20.868234864350885 0.9844329918661411 
epoch: 62, train time every whole data:252.29s
epoch: 62, total time:12613.24s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.67s
test time on whole data:35.90s
19.991487703889497 34.819604000044045 22.100884980986944 0.9911417542806403 
19.6235267347925 34.80568390865466 20.740376699450124 0.9912036293027204 
19.470744548901173 35.05182598534695 20.266426267917108 0.9909704110897535 
19.757573058350737 36.52351370450659 20.111544218077633 0.99016400609961 
20.057612031588913 37.596530380819836 20.15727996951692 0.9894752123988114 
20.250805317300028 38.33583050141515 20.38032360436356 0.9888905713971055 
20.612151383678167 39.84090267856631 20.86015248909743 0.9878416862756125 
20.81313391156304 40.22360788377754 21.1169195198258 0.9873513801885297 
21.095441664392215 40.87566375946611 21.295962792841568 0.9867329242014189 
21.508724390224387 42.13615806356829 21.797136888884243 0.9858146361018715 
21.84844617205696 42.711668604285975 22.625969441426495 0.9853052832180162 
22.434598847455298 43.673324169023054 23.269676347838832 0.9845552538394987 
20.62202048034941 39.00078070875556 21.226401281770006 0.9845552538394987 
epoch: 63, train time every whole data:252.41s
epoch: 63, total time:12902.42s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.68s
test time on whole data:35.91s
20.282883406230653 34.76270597808088 26.589523060515297 0.9911858590195096 
19.884623609316606 34.71997931559942 25.705224117096286 0.9911463551982144 
19.824665748155205 35.36567289222896 24.773191429761187 0.9907257603942903 
20.11597425994895 36.71958337478501 24.39868126421266 0.9898492008637164 
20.594696015759965 38.69414410660176 23.929947499046698 0.9885643606766528 
20.714825004273496 39.01993852017831 23.784422009937956 0.9882276659623377 
21.072351405598287 40.441608480347256 24.02405204690115 0.9871792590130412 
21.521160570885883 42.72238855280662 24.144107200445205 0.9855163114428438 
21.453551491394194 41.825386854174546 23.994686081090144 0.9859018220539558 
21.718155365684154 42.79712468938934 24.180654200287393 0.9851368509139267 
22.128422223052716 44.45061048983712 24.682542550300386 0.9838981608586337 
22.546421550098046 44.9930043669703 25.22076827935789 0.983409938037522 
20.988144220866513 39.86924876538478 24.61893518569802 0.983409938037522 
epoch: 64, train time every whole data:251.98s
epoch: 64, total time:13191.15s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.66s
test time on whole data:35.89s
19.93031456639324 34.60497678951473 21.926814294281165 0.9912895062833115 
19.61147632327262 34.75419473320241 20.615618376529206 0.9913096520889588 
19.488160276960727 35.13463218088571 20.12781541674434 0.9910668074714594 
19.835061781803848 36.7422370470273 20.13982068419709 0.9902479293408882 
20.17000337197382 37.920627498068995 20.168286213055943 0.9895692676137334 
20.35413795480067 38.612404067202796 20.21694026029409 0.9889396997808741 
20.6873774800185 40.084847422557885 20.43660706915846 0.9879166547606735 
20.892702180053323 40.75515502772113 20.47453136608095 0.9873153099297302 
21.069762443959057 41.10728751286786 20.610116337915183 0.9866816261235002 
21.312028084624952 41.96243960232484 21.09389816722508 0.9860042228034227 
21.651966654926426 42.709186340048866 21.778682276634413 0.9853879278480946 
22.124126699932905 43.20563844805904 22.493764743731294 0.9848183006748011 
20.59392648489334 39.081026342032445 20.83988628992326 0.9848183006748011 
epoch: 65, train time every whole data:251.82s
epoch: 65, total time:13479.74s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.59s
test time on whole data:35.81s
19.937173664548524 34.38752804595835 22.746652977305526 0.9913933069502824 
19.60490254551508 34.24807293080067 21.674319992386724 0.9914556278961119 
19.50021049608832 34.585408308109535 21.2457553595758 0.9912379621254014 
19.80036280253563 36.011970572659045 20.96758205418884 0.9904379580583144 
20.264145424970575 37.74309278860242 21.057350616519606 0.9893943148356739 
20.4205044114374 37.97653136282359 21.127479497561737 0.9890951702252417 
20.867894401935445 39.88669638937164 21.300809605276342 0.987792151661403 
21.251032097022037 41.48112264212105 21.40902271229258 0.9865850346501426 
21.31845696559491 40.997371690912 21.567109086051403 0.9866830787737161 
21.866535253174128 42.954719262600115 22.182611982534596 0.9853135012960132 
22.24171600492075 43.98801109123669 23.17927369703309 0.9844876568828363 
22.772482900836717 44.80149175558882 24.05350919412558 0.9839584138378175 
20.820451414048293 39.25859388384423 21.87548354142632 0.9839584138378175 
epoch: 66, train time every whole data:251.86s
epoch: 66, total time:13768.29s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.57s
test time on whole data:35.80s
19.9359740622195 34.49633502648137 22.084842567044998 0.991313644319227 
19.62832454209009 34.73171719642507 20.711143992896854 0.9911833596093601 
19.516646953103614 35.12333441479408 20.21675065087377 0.9908887014882518 
19.799191540059873 36.76984413764194 20.130028304813244 0.9899755983278808 
20.135723195331515 38.258358762954096 20.054542302376284 0.9890966577229217 
20.30060791744489 38.67848875375096 20.268003364086525 0.9887082532089884 
20.574623000416903 39.96078720835348 20.759121067143727 0.9877929531068365 
20.905364275854737 41.83100818901699 21.083900490735296 0.9865407786363053 
21.037302154572945 41.5572136082373 21.160147573032106 0.9864760275295685 
21.26924858541283 42.032522312089846 21.578824781572774 0.9859631375389245 
21.57156348125301 43.19247123300882 22.301996094085844 0.985128620676803 
21.932889897787152 43.18411558763417 23.140801557021828 0.9849490381256151 
20.550621633795586 39.27740760816891 21.123716228884124 0.9849490381256151 
epoch: 67, train time every whole data:252.01s
epoch: 67, total time:14056.98s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.61s
test time on whole data:35.84s
19.88582198480856 34.431901722839434 22.052613214689742 0.9914309604779499 
19.63187918241785 34.60586965586288 20.63987854795575 0.9913720377671378 
19.55883140702272 35.089748157165005 20.187876997302936 0.9910695205567374 
19.83416704955218 36.51809643075975 20.028111113741154 0.9901849176989065 
20.32267910881679 38.26815796884723 20.156185758617234 0.9890384432964957 
20.451733611793788 38.615146990242806 20.173760542393982 0.9887290396102117 
20.745134279895744 39.94213560089877 20.387266246159943 0.9877670125349943 
21.074173566296306 41.827812895261104 20.33700134207328 0.9862987067095161 
21.091490452332295 41.3804004318388 20.351056005228674 0.9864373222815093 
21.328305026960567 41.9808118581107 20.731841326433795 0.985970985123544 
21.52141505577914 42.68269600835811 21.288390813330253 0.9853915793346752 
21.955815925779735 43.16840756343518 21.999080574717468 0.985031772005919 
20.616787220954638 39.16690305303257 20.6941680665658 0.985031772005919 
epoch: 68, train time every whole data:252.44s
epoch: 68, total time:14346.12s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.74s
test time on whole data:35.97s
20.09971908775806 34.502128539015146 25.174173466167364 0.9912937563623238 
19.916345392938354 35.02470338873215 24.029341977247526 0.991066880315786 
19.76231277384641 35.298877184850916 23.841985185960198 0.9908281764708748 
20.14775993534114 37.34270367099043 23.649715626527904 0.9897612911311818 
20.58720619073039 39.37963641068868 23.546357004740397 0.9886525045867134 
20.539252387577896 39.06663314047439 23.474571507121908 0.9885963188489135 
20.754625639694282 40.43401381890348 23.46237854181999 0.9876883821589116 
21.075793185158112 42.361226189906354 23.57356157821792 0.9864772566579778 
20.959628064735277 41.14688137498955 23.303579172800585 0.9868632440831768 
21.13890957144574 41.58837020730707 23.466378882114007 0.9863953762546221 
21.34219514504395 42.48035501495649 24.430192762074444 0.9857535648032831 
21.723526894012696 42.15500858999355 25.131125833475455 0.985747529646107 
20.670606189023527 39.33641147266189 23.923413887627003 0.985747529646107 
epoch: 69, train time every whole data:252.46s
epoch: 69, total time:14635.40s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.70s
test time on whole data:35.93s
19.86289447269431 34.437175278284776 22.473963937429275 0.991349244943876 
19.7644659809059 35.1681091891428 21.428662698408594 0.9909272728633025 
19.845616567612634 36.235905540497455 21.458447284054976 0.9903188553145402 
20.236895999269077 37.83394274263252 21.312621683612175 0.9894157213086489 
21.01296025025509 41.27451467682815 21.493680075101768 0.987422440396445 
21.13598064036857 41.76850763623902 21.57278705408491 0.9869463345108802 
21.304941629699858 42.03032457613022 21.6771263533217 0.9865740521065678 
21.742675411809316 44.7807957509799 21.912711607541375 0.9847255233944565 
21.667902387146192 44.2042379342648 21.82050975126191 0.9847598284669475 
21.79174698120242 43.323082498691925 22.18782466609269 0.9850498282290258 
22.02283289109174 44.14983002789191 23.02085842233261 0.9843389377614176 
22.425505679802484 44.638813589439145 23.745894109929058 0.983829081624825 
21.067868240988133 40.987762362292905 22.00837509422936 0.983829081624825 
epoch: 70, train time every whole data:252.39s
epoch: 70, total time:14924.54s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.76s
test time on whole data:35.99s
20.02451799936082 34.32024318165121 26.086576265080712 0.9913730874518762 
19.63430090769339 34.270547196626715 25.061256067026555 0.9913298930343619 
19.471991354509946 34.654636511680124 24.011460549219386 0.9910515181878242 
19.760447813021138 36.31475118224575 23.830072449514418 0.9900827972675182 
20.043674459428363 37.66960605308449 23.47520318139653 0.989203891021382 
20.0808783658642 37.66256658613915 23.43679053063764 0.9890561615812385 
20.43049186126696 39.43222307923256 23.75854484561969 0.9878601895836474 
20.689157657703596 40.77131799635394 23.882833913938235 0.9868381547470682 
20.602501042892413 39.83613046529166 23.6022711608374 0.9871981138922585 
20.957567803910955 41.432253786256126 23.906350910468642 0.9860383366231925 
21.32393974427205 42.6434869389616 24.688544310804954 0.9851195889782611 
21.693477330557997 42.923399036902254 25.362037730333935 0.9848431578696806 
20.392745528373485 38.612559830556975 24.2583226152261 0.9848431578696806 
epoch: 71, train time every whole data:252.81s
epoch: 71, total time:15214.22s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.75s
test time on whole data:35.98s
19.65884553948369 34.03239224914005 22.328771072343372 0.9915138859634918 
19.301656100133794 34.12198493702172 20.787482374197065 0.9914196325102157 
19.174462259339133 34.41909058576427 20.418892743584898 0.9912025057404209 
19.42743959087158 35.940446351081384 20.333829378197184 0.9903443536866967 
19.705907075566476 37.27900397151455 20.360534514497065 0.9895146306095943 
19.71794203418987 37.24568993735525 20.461652729093004 0.9894011404275035 
20.067390777158792 39.11235260980051 20.649862500805675 0.9881705708928732 
20.250102330769995 39.686820450531876 20.82185628144774 0.9876348474133734 
20.265316561785205 39.44614736968362 20.85138162478656 0.987584375015413 
20.591165722479204 40.82944129991134 21.177692906714245 0.9865827774670569 
20.801062980724947 40.85430410170385 21.869836477398923 0.9864821426492676 
21.27805660751392 41.70454006629557 22.440977375265252 0.9858248649341167 
20.01994563166805 37.98253228351712 21.041598201273807 0.9858248649341167 
epoch: 72, train time every whole data:252.75s
epoch: 72, total time:15503.83s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.74s
test time on whole data:35.98s
19.7144535102806 34.10170621973898 22.71014860100216 0.9915044847944245 
19.422588466394192 34.364590435281805 21.00323752224275 0.9913248521262891 
19.33417288850687 34.70670209040646 20.656876618865443 0.9910861457866686 
19.603774688625368 36.13701339091695 20.528407258036157 0.9902410151431902 
19.908990667201145 37.59243676881257 20.35891187762391 0.9893163846242786 
20.063342723301314 37.89951194742192 20.491935466779022 0.9890219653731274 
20.36279196574788 39.48176553231767 20.731392354139892 0.9879650596839505 
20.652226624239386 40.957298199202285 20.957052190526408 0.986850888129788 
20.85413783773564 41.04706624847734 20.987535702904953 0.9866214059620022 
21.340526782845657 42.79220768467764 21.43272937133806 0.9854391188391978 
21.671444209046513 43.452903554604184 22.264559917879293 0.9848526725776159 
22.223051697728426 44.58376202819684 22.974260221184117 0.9839117427910081 
20.429291838471084 39.08544709259329 21.257722618242465 0.9839117427910081 
epoch: 73, train time every whole data:252.76s
epoch: 73, total time:15793.38s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.72s
test time on whole data:35.95s
19.61112732552052 33.92570430493782 23.067931314073906 0.9915712496104828 
19.30252092542741 34.102156732661534 21.883072615152276 0.9914301111615337 
19.192805120248018 34.5993016051701 21.365479751165157 0.9911157601880038 
19.435482273165903 35.95851594552582 21.20718348693227 0.9902871030365568 
19.755142200117643 37.24174220217389 20.873015654338488 0.9894435725054792 
19.865628085820124 37.7477852946435 20.875376732671317 0.9890295992347266 
20.232119691299665 39.56337311730379 21.10664992925508 0.9877865990448453 
20.46252958495953 40.547324972897144 21.13112885719048 0.9869751089467863 
20.612690702713405 40.79809940617607 20.962754677702293 0.9866502682958105 
20.89358692029736 41.795258114812896 21.255462040627783 0.9859018628911888 
21.241927960219613 42.60620062427342 21.79465784480052 0.9852670632702458 
21.66239429750315 43.386081813607404 22.374258549940986 0.9846702175068397 
20.18899625727436 38.65897341020214 21.49127805789485 0.9846702175068397 
epoch: 74, train time every whole data:252.77s
epoch: 74, total time:16082.95s
predicting testing set batch 1 / 102, time: 0.36s
predicting testing set batch 101 / 102, time: 35.76s
test time on whole data:35.99s
19.594142586801727 33.829103614569 21.982137017024524 0.9916202314248058 
19.336386591787146 34.1941271351896 20.55709388174451 0.991392254836698 
19.27987725362755 34.84129567834664 20.10257315159936 0.990985543307564 
19.556931667983676 36.264463864719424 19.93981323879254 0.990172451473972 
20.039226222209038 38.47006819317391 19.88609465651196 0.9889028516877757 
20.181615006557344 38.7716867409358 19.997060835353373 0.9885615126451016 
20.3945299722113 39.520591915736816 20.247701399233613 0.987971927741459 
20.74595928904203 41.75155452570132 20.433593349442923 0.986565842455703 
20.802986805865235 41.2416637981349 20.509780643238695 0.9866298488609914 
20.965741085441874 41.40616087407717 20.95043345911776 0.9862878746691353 
21.20730752955491 42.49350882872059 21.634668183545582 0.9854998163987518 
21.6866462388479 42.907806806793786 22.42865575732442 0.9850967834520178 
20.31594585416081 38.93697504168953 20.722106552727595 0.9850967834520178 
epoch: 75, train time every whole data:252.81s
epoch: 75, total time:16372.58s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.75s
test time on whole data:35.98s
19.60672450625986 33.955974939326154 22.50267154746371 0.9915818226247358 
19.29999507100462 34.1906824112486 21.0683044727004 0.9914270664690127 
19.23641568615134 34.710527776844145 20.965893200298044 0.9911097323857851 
19.474419290901142 36.159131287818695 20.798629107647752 0.9902331917159833 
19.83459886542321 37.781026001903214 20.72805510135508 0.9891975275431617 
19.820453635225928 37.48476602281922 20.690305963872603 0.9892222960261681 
20.109525331549545 38.94870830083779 20.87621476327917 0.9882077990116553 
20.437522653590953 40.81602033154388 21.052385348398605 0.9868745493413423 
20.332767759263117 39.52618976235504 20.79170256237129 0.9874915442451493 
20.74250619703253 41.07056635439568 21.08221947090633 0.9864077060501791 
21.102883338787315 42.3009626691774 21.835916708664975 0.9855064279633808 
21.420651532881298 42.04781844627996 22.328097955318025 0.9856464690747833 
20.11820532233924 38.358266266918186 21.22648783390183 0.9856464690747833 
epoch: 76, train time every whole data:252.58s
epoch: 76, total time:16661.99s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.66s
test time on whole data:35.89s
19.931503562969425 34.336949963680226 23.97096558931275 0.9915478737686412 
19.806965214614607 35.08736047735989 23.27235589995066 0.9913611409757102 
19.65283628697138 35.39790906850682 22.538459004706226 0.9911330614428516 
20.014914695862572 37.10914956954585 22.407930239051097 0.9903459487245948 
20.492981493407598 39.1625383658749 22.21329595599505 0.9892629784447474 
20.487961378084098 38.91543114697219 22.22753457024812 0.9891275979265288 
20.741289582829086 40.08521417128485 22.4918228005045 0.988320247862663 
21.1502714439604 42.41951017581833 22.571672794022675 0.9869509745553972 
21.159757477074788 41.33521463992929 22.516895401975113 0.9871484281647778 
21.352060316271626 41.89060181619148 22.88564275945259 0.9865455645327293 
21.46966684421021 42.58187046598331 23.372030597913724 0.9861020143300547 
21.838549400524762 42.64539130731676 24.11474011549236 0.9857927324592248 
20.674896474731714 39.35931905702136 22.881715664087924 0.9857927324592248 
epoch: 77, train time every whole data:252.57s
epoch: 77, total time:16951.28s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.73s
test time on whole data:35.96s
19.759865495477104 34.052803993206595 23.9482832992623 0.991595702452892 
19.568724600944883 34.57699120788471 21.931228326762223 0.9913286099481441 
19.51893091337903 35.11694216015196 21.494588946570687 0.9910398328074936 
19.76075585331107 36.33846996426596 21.263401553068814 0.9902547625270314 
20.325698201905947 38.71149674764436 21.218253974122476 0.9887080582301863 
20.384153837508123 38.73803225610771 21.308815240770397 0.9886366410665445 
20.674448242693565 39.67379284090875 21.538608994031204 0.9879161447407663 
21.0548249485784 41.51291976622277 21.849140272646615 0.9864059631141004 
21.084397570711943 41.083158599815825 21.878947854388645 0.9866203989732648 
21.37683720880402 41.72860259457213 22.3216864373951 0.9862149897984882 
21.636441415043354 42.568673785530684 23.20171638354822 0.9855585745213834 
21.99323730457379 42.54692490053898 23.669246722502283 0.9856652300339428 
20.594859632744267 39.00515807515708 22.134990258218114 0.9856652300339428 
epoch: 78, train time every whole data:252.72s
epoch: 78, total time:17240.81s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.73s
test time on whole data:35.96s
19.629666365702942 34.09953313091711 23.16843028537592 0.9917261275566126 
19.54272372989828 34.81777863598115 22.20704785272903 0.9914022824728137 
19.52821120510435 35.35238202943049 21.78588588138797 0.9909919501463511 
19.87999486609864 37.16230409569964 21.54556926583436 0.989803991732369 
20.320597503432133 39.12255631290801 21.147746168229983 0.9884635531954239 
20.317839118318677 38.868627714004965 21.06516069990451 0.9884794911990474 
20.62114011074786 40.42883790757732 21.210808220469243 0.98734570656925 
20.93967943228361 42.41639617010502 21.332957246677193 0.9858491479571241 
20.9324546319803 41.65554885831397 21.114392191812662 0.9861985938755125 
21.158209434650487 42.284492523403316 21.389450899656133 0.9856922181188023 
21.40331082193604 43.16998905249781 22.081297248110303 0.9850258986632965 
21.744022909679966 43.24828582268165 22.614726274813858 0.984912275802727 
20.50148751081944 39.515919894425735 21.721821666494574 0.984912275802727 
epoch: 79, train time every whole data:252.69s
epoch: 79, total time:17530.40s
predicting testing set batch 1 / 102, time: 0.35s
predicting testing set batch 101 / 102, time: 35.72s
test time on whole data:35.95s
19.9147367232513 33.92862860442981 25.869724825907852 0.991655140910197 
19.853641190673937 34.73352380588686 25.16522905230999 0.991323163772798 
19.904797784308908 35.52071489115827 24.67785393355846 0.9908880557907686 
20.468527024001748 37.547386674710054 24.590091724170396 0.9899742400348774 
21.144763297716274 40.15402927062813 24.452066218007555 0.9886878895111241 
21.33365036624169 40.67809159866694 24.63677736114153 0.9882328214840282 
21.715304462846163 41.88256829201067 24.94860562048338 0.9874770780966418 
22.23528908418735 43.99424574980588 25.204912693794164 0.9863161097409456 
22.2152750561852 43.44079200041574 24.92470806991526 0.9863410042305869 
22.323471189846178 43.55939174955876 25.07581462770998 0.9859496427258168 
22.448436261852944 44.06511662538701 25.741818788502158 0.9855093016483197 
22.661521669545078 43.95120311436676 26.00667634318567 0.9852293454679898 
21.35161784255473 40.45960857618789 25.107659146128743 0.9852293454679898 
save parameters to file: experiments/bjsubway/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03ScaledSAtSE0TEallattention1_spt_trend_adj/epoch_79.params
