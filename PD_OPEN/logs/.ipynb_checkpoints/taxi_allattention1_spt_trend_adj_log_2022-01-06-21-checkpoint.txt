total training epoch, fine tune epoch: 40 , 40
batch_size: 4
folder_dir: MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention1_spt_trend_adj
load file: data/taxi.npz
ori length: 3001 , percent: 1.0 , scale: 3001
train: torch.Size([3001, 266, 2, 12]) torch.Size([3001, 266, 2, 12]) torch.Size([3001, 266, 2, 12])
val: torch.Size([672, 266, 2, 12]) torch.Size([672, 266, 2, 12]) torch.Size([672, 266, 2, 12])
test: torch.Size([672, 266, 2, 12]) torch.Size([672, 266, 2, 12]) torch.Size([672, 266, 2, 12])
TemporalPositionalEncoding max_len: 12
h_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
en_lookup_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
EncoderDecoder(
  (encoder): Encoder(
    (layers): ModuleList(
      (0): EncoderLayer(
        (self_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (2): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (3): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (feed_forward_gcn): ModuleList(
          (0): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn_cross): spatialAttentionScaledGCN_cross(
          (Theta): Linear(in_features=64, out_features=64, bias=False)
          (SAt_cross): Spatial_Attention_layer_cross(
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (Gate): Linear(in_features=64, out_features=1, bias=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (6): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (7): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (sublayer2): SublayerConnection2(
          (dropout): Dropout(p=0.0, inplace=False)
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): EncoderLayer(
        (self_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (2): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (3): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (feed_forward_gcn): ModuleList(
          (0): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn_cross): spatialAttentionScaledGCN_cross(
          (Theta): Linear(in_features=64, out_features=64, bias=False)
          (SAt_cross): Spatial_Attention_layer_cross(
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (Gate): Linear(in_features=64, out_features=1, bias=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (6): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (7): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (sublayer2): SublayerConnection2(
          (dropout): Dropout(p=0.0, inplace=False)
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): EncoderLayer(
        (self_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (2): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (3): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (feed_forward_gcn): ModuleList(
          (0): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn_cross): spatialAttentionScaledGCN_cross(
          (Theta): Linear(in_features=64, out_features=64, bias=False)
          (SAt_cross): Spatial_Attention_layer_cross(
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (Gate): Linear(in_features=64, out_features=1, bias=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (6): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (7): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (sublayer2): SublayerConnection2(
          (dropout): Dropout(p=0.0, inplace=False)
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): Decoder(
    (layers): ModuleList(
      (0): DecoderLayer(
        (self_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_qc_kc(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_qc_kc(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (src_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (2): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (3): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (feed_forward_gcn): ModuleList(
          (0): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn_cross): spatialAttentionScaledGCN_cross(
          (Theta): Linear(in_features=64, out_features=64, bias=False)
          (SAt_cross): Spatial_Attention_layer_cross(
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (Gate): Linear(in_features=64, out_features=1, bias=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (6): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (7): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (8): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (9): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (sublayer2): SublayerConnection2(
          (dropout): Dropout(p=0.0, inplace=False)
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): DecoderLayer(
        (self_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_qc_kc(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_qc_kc(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (src_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (2): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (3): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (feed_forward_gcn): ModuleList(
          (0): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn_cross): spatialAttentionScaledGCN_cross(
          (Theta): Linear(in_features=64, out_features=64, bias=False)
          (SAt_cross): Spatial_Attention_layer_cross(
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (Gate): Linear(in_features=64, out_features=1, bias=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (6): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (7): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (8): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (9): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (sublayer2): SublayerConnection2(
          (dropout): Dropout(p=0.0, inplace=False)
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): DecoderLayer(
        (self_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_qc_kc(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_qc_kc(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (src_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (2): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (3): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (feed_forward_gcn): ModuleList(
          (0): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn_cross): spatialAttentionScaledGCN_cross(
          (Theta): Linear(in_features=64, out_features=64, bias=False)
          (SAt_cross): Spatial_Attention_layer_cross(
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (Gate): Linear(in_features=64, out_features=1, bias=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (6): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (7): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (8): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (9): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (sublayer2): SublayerConnection2(
          (dropout): Dropout(p=0.0, inplace=False)
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (src_embed): Sequential(
    (0): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (1): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(266, 64)
    )
  )
  (src_embed2): Sequential(
    (0): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (1): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(266, 64)
    )
  )
  (trg_embed): Sequential(
    (0): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (1): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(266, 64)
    )
  )
  (trg_embed2): Sequential(
    (0): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (1): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(266, 64)
    )
  )
  (prediction_generator): Linear(in_features=64, out_features=1, bias=True)
  (prediction_generator2): Linear(in_features=64, out_features=1, bias=True)
)
create params directory experiments/taxi/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention1_spt_trend_adj
Net's state_dict:
encoder.layers.0.self_attn.0.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.0.linears.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.0.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.0.linears.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.1.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.1.linears.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.1.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.1.linears.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.2.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.2.linears.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.2.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.2.linears.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.2.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.2.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.2.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.2.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.3.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.3.linears.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.3.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.3.linears.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.3.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.3.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.3.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.3.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.0.feed_forward_gcn.0.Theta.weight 	 torch.Size([64, 64])
encoder.layers.0.feed_forward_gcn.1.Theta.weight 	 torch.Size([64, 64])
encoder.layers.0.feed_forward_gcn_cross.Theta.weight 	 torch.Size([64, 64])
encoder.layers.0.feed_forward_gcn_cross.Gate.weight 	 torch.Size([1, 64])
encoder.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.2.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.2.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.3.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.3.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.4.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.4.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.5.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.5.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.6.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.6.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.7.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.7.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer2.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer2.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer2.norm2.weight 	 torch.Size([64])
encoder.layers.0.sublayer2.norm2.bias 	 torch.Size([64])
encoder.layers.1.self_attn.0.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.0.linears.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.0.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.0.linears.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.1.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.1.linears.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.1.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.1.linears.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.2.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.2.linears.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.2.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.2.linears.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.2.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.2.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.2.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.2.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.3.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.3.linears.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.3.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.3.linears.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.3.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.3.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.3.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.3.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.1.feed_forward_gcn.0.Theta.weight 	 torch.Size([64, 64])
encoder.layers.1.feed_forward_gcn.1.Theta.weight 	 torch.Size([64, 64])
encoder.layers.1.feed_forward_gcn_cross.Theta.weight 	 torch.Size([64, 64])
encoder.layers.1.feed_forward_gcn_cross.Gate.weight 	 torch.Size([1, 64])
encoder.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.2.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.2.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.3.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.3.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.4.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.4.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.5.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.5.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.6.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.6.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.7.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.7.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer2.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer2.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer2.norm2.weight 	 torch.Size([64])
encoder.layers.1.sublayer2.norm2.bias 	 torch.Size([64])
encoder.layers.2.self_attn.0.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.0.linears.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.0.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.0.linears.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.0.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.0.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.0.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.0.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.1.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.1.linears.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.1.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.1.linears.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.1.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.1.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.1.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.1.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.2.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.2.linears.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.2.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.2.linears.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.2.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.2.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.2.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.2.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.3.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.3.linears.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.3.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.3.linears.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.3.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.3.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.3.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.3.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.2.feed_forward_gcn.0.Theta.weight 	 torch.Size([64, 64])
encoder.layers.2.feed_forward_gcn.1.Theta.weight 	 torch.Size([64, 64])
encoder.layers.2.feed_forward_gcn_cross.Theta.weight 	 torch.Size([64, 64])
encoder.layers.2.feed_forward_gcn_cross.Gate.weight 	 torch.Size([1, 64])
encoder.layers.2.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.2.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.2.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.3.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.3.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.4.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.4.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.5.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.5.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.6.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.6.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.7.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.7.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer2.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer2.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer2.norm2.weight 	 torch.Size([64])
encoder.layers.2.sublayer2.norm2.bias 	 torch.Size([64])
encoder.norm.weight 	 torch.Size([64])
encoder.norm.bias 	 torch.Size([64])
encoder.norm2.weight 	 torch.Size([64])
encoder.norm2.bias 	 torch.Size([64])
decoder.layers.0.self_attn.0.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.0.linears.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.0.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.0.linears.1.bias 	 torch.Size([64])
decoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.0.self_attn.1.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.1.linears.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.1.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.1.linears.1.bias 	 torch.Size([64])
decoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.0.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.0.linears.0.bias 	 torch.Size([64])
decoder.layers.0.src_attn.0.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.0.linears.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.0.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.0.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.0.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.0.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.1.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.1.linears.0.bias 	 torch.Size([64])
decoder.layers.0.src_attn.1.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.1.linears.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.1.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.1.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.1.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.1.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.2.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.2.linears.0.bias 	 torch.Size([64])
decoder.layers.0.src_attn.2.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.2.linears.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.2.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.2.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.2.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.2.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.3.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.3.linears.0.bias 	 torch.Size([64])
decoder.layers.0.src_attn.3.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.3.linears.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.3.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.3.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.3.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.3.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.feed_forward_gcn.0.Theta.weight 	 torch.Size([64, 64])
decoder.layers.0.feed_forward_gcn.1.Theta.weight 	 torch.Size([64, 64])
decoder.layers.0.feed_forward_gcn_cross.Theta.weight 	 torch.Size([64, 64])
decoder.layers.0.feed_forward_gcn_cross.Gate.weight 	 torch.Size([1, 64])
decoder.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.3.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.3.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.4.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.4.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.5.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.5.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.6.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.6.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.7.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.7.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.8.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.8.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.9.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.9.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer2.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer2.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer2.norm2.weight 	 torch.Size([64])
decoder.layers.0.sublayer2.norm2.bias 	 torch.Size([64])
decoder.layers.1.self_attn.0.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.0.linears.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.0.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.0.linears.1.bias 	 torch.Size([64])
decoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.1.self_attn.1.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.1.linears.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.1.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.1.linears.1.bias 	 torch.Size([64])
decoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.0.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.0.linears.0.bias 	 torch.Size([64])
decoder.layers.1.src_attn.0.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.0.linears.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.0.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.0.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.0.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.0.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.1.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.1.linears.0.bias 	 torch.Size([64])
decoder.layers.1.src_attn.1.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.1.linears.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.1.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.1.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.1.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.1.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.2.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.2.linears.0.bias 	 torch.Size([64])
decoder.layers.1.src_attn.2.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.2.linears.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.2.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.2.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.2.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.2.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.3.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.3.linears.0.bias 	 torch.Size([64])
decoder.layers.1.src_attn.3.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.3.linears.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.3.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.3.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.3.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.3.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.feed_forward_gcn.0.Theta.weight 	 torch.Size([64, 64])
decoder.layers.1.feed_forward_gcn.1.Theta.weight 	 torch.Size([64, 64])
decoder.layers.1.feed_forward_gcn_cross.Theta.weight 	 torch.Size([64, 64])
decoder.layers.1.feed_forward_gcn_cross.Gate.weight 	 torch.Size([1, 64])
decoder.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.3.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.3.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.4.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.4.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.5.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.5.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.6.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.6.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.7.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.7.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.8.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.8.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.9.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.9.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer2.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer2.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer2.norm2.weight 	 torch.Size([64])
decoder.layers.1.sublayer2.norm2.bias 	 torch.Size([64])
decoder.layers.2.self_attn.0.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.0.linears.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.0.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.0.linears.1.bias 	 torch.Size([64])
decoder.layers.2.self_attn.0.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.self_attn.0.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.0.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.self_attn.0.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.2.self_attn.1.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.1.linears.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.1.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.1.linears.1.bias 	 torch.Size([64])
decoder.layers.2.self_attn.1.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.self_attn.1.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.1.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.self_attn.1.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.0.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.0.linears.0.bias 	 torch.Size([64])
decoder.layers.2.src_attn.0.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.0.linears.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.0.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.0.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.0.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.0.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.1.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.1.linears.0.bias 	 torch.Size([64])
decoder.layers.2.src_attn.1.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.1.linears.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.1.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.1.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.1.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.1.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.2.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.2.linears.0.bias 	 torch.Size([64])
decoder.layers.2.src_attn.2.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.2.linears.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.2.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.2.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.2.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.2.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.3.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.3.linears.0.bias 	 torch.Size([64])
decoder.layers.2.src_attn.3.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.3.linears.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.3.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.3.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.3.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.3.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.feed_forward_gcn.0.Theta.weight 	 torch.Size([64, 64])
decoder.layers.2.feed_forward_gcn.1.Theta.weight 	 torch.Size([64, 64])
decoder.layers.2.feed_forward_gcn_cross.Theta.weight 	 torch.Size([64, 64])
decoder.layers.2.feed_forward_gcn_cross.Gate.weight 	 torch.Size([1, 64])
decoder.layers.2.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.3.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.3.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.4.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.4.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.5.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.5.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.6.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.6.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.7.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.7.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.8.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.8.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.9.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.9.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer2.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer2.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer2.norm2.weight 	 torch.Size([64])
decoder.layers.2.sublayer2.norm2.bias 	 torch.Size([64])
decoder.norm.weight 	 torch.Size([64])
decoder.norm.bias 	 torch.Size([64])
decoder.norm2.weight 	 torch.Size([64])
decoder.norm2.bias 	 torch.Size([64])
src_embed.0.pe 	 torch.Size([1, 1, 12, 64])
src_embed.1.embedding.weight 	 torch.Size([266, 64])
src_embed2.0.pe 	 torch.Size([1, 1, 12, 64])
src_embed2.1.embedding.weight 	 torch.Size([266, 64])
trg_embed.0.pe 	 torch.Size([1, 1, 12, 64])
trg_embed.1.embedding.weight 	 torch.Size([266, 64])
trg_embed2.0.pe 	 torch.Size([1, 1, 12, 64])
trg_embed2.1.embedding.weight 	 torch.Size([266, 64])
prediction_generator.weight 	 torch.Size([1, 64])
prediction_generator.bias 	 torch.Size([1])
prediction_generator2.weight 	 torch.Size([1, 64])
prediction_generator2.bias 	 torch.Size([1])
Net's total params: 1145090
Optimizer's state_dict:
state 	 {}
param_groups 	 [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411]}]
predicting testing set batch 1 / 168, time: 0.79s
predicting testing set batch 101 / 168, time: 36.80s
test time on whole data:61.18s
580.9211902501075 602.3178128260387 8900.2053835624 -0.01003772706905013 
563.5740622920018 589.178023630979 8638.036033132983 -0.011697376298397354 
563.7472587097748 595.7083933660514 8632.392933830291 -0.01097403741669611 
586.545963184898 625.8707146197975 8960.799926557851 -0.00860564331848469 
610.6939141320835 656.1348028797792 9312.920484757353 -0.006986156473505272 
618.5279906481187 668.425052468793 9426.362220135723 -0.006646224309051927 
605.822405798247 659.8481134938844 9235.174859671311 -0.007244970642133103 
589.1780260072045 643.956656448329 8990.016670618246 -0.007868837893045783 
591.8502608346977 640.2879774063973 9040.57382785042 -0.007861893878492999 
624.2848607219116 660.4158123263421 9543.101877773499 -0.0069122225099541275 
668.0904920043778 693.6571281551194 10215.681101711418 -0.00535434640936934 
694.5642378436822 713.4370353286554 10625.991409414852 -0.004122741245292563 
608.1500552022588 646.7969236364586 9293.439409995572 -0.004122741245292563 
epoch: 0, train time every whole data:224.47s
epoch: 0, total time:298.47s
predicting testing set batch 1 / 168, time: 0.38s
predicting testing set batch 101 / 168, time: 38.23s
test time on whole data:63.54s
13.569538855403104 18.895040378291824 209.05714574415316 0.8922923836031107 
13.74838901813233 19.302985885730312 207.12750772784796 0.8850062801625441 
13.980738051296864 20.039647656061543 207.68744919868803 0.8706113040807693 
14.193637104645122 20.871851646327745 208.97217495089535 0.8529540770751357 
14.908911471522384 22.06179649362633 221.89679972225957 0.8330550650718443 
15.448519487858434 23.10972930057141 232.28456185300624 0.8127111361742855 
15.636227066244418 23.95419154629302 235.3046628745072 0.7906133618859275 
15.994085922800744 24.88119045003417 241.95973713236918 0.7678759214089684 
16.59429119281213 25.925505379335934 254.1248029253331 0.7447578866490472 
17.24208849830334 26.965480239695 267.3848267755167 0.7227487008650613 
17.292686863071204 27.563291760220917 267.78442190130016 0.7025367706944083 
18.052026572931695 28.490719022323898 285.9273073014044 0.6829646428483543 
15.555095008751813 23.719250172321427 236.62596169060586 0.6829646428483543 
epoch: 1, train time every whole data:225.40s
epoch: 1, total time:603.55s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 38.17s
test time on whole data:63.45s
11.898824581891068 17.977383346876906 157.38080603951892 0.8779045961437612 
11.862150172947135 17.945309548597894 153.04713164308498 0.8785811750884855 
12.040631217215557 18.80527422495586 154.43376000022386 0.863524833403688 
12.093317900602168 19.413798319954875 152.04372948808037 0.8513478384098653 
12.31948902790451 20.255885683729698 154.27851551478696 0.8351143688695135 
12.599701548952375 21.073663395710405 158.61007420434422 0.818451544388465 
12.927305492436773 21.970017226581533 163.23304412623898 0.7985490072257927 
13.50821770757845 23.056428236909504 172.19731125099253 0.773650382214433 
14.014919960618501 24.07243683237886 179.64426298994155 0.7485790359850687 
14.381787225444418 24.8758488407731 185.55442045899227 0.7276622509050509 
15.000802482766337 25.856020316045477 194.0151300390226 0.701800765136291 
15.43364830293639 26.605434997413994 203.86638357938628 0.6813126307067233 
13.173399635107806 22.02102804327142 169.0253929919396 0.6813126307067233 
epoch: 2, train time every whole data:225.60s
epoch: 2, total time:908.14s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 38.15s
test time on whole data:63.44s
9.76368596564763 14.317938696378178 95.04113068777998 0.9378829021608891 
10.107205290727219 15.048464453570453 97.58503728218399 0.9306352317584411 
11.647628217448643 17.70270621738354 102.26970994683747 0.9066474932502242 
12.116780525520815 18.33353946046542 107.1557220664138 0.9016336566448532 
12.791477502906472 19.366135683449244 110.91292515071665 0.89160721379882 
13.481752892977395 20.25702566021809 114.4813622179128 0.8836122413905296 
14.600999681575665 21.550884253549082 119.72255806811178 0.8746368401300365 
14.926431524593315 22.060245209647945 118.72575867424942 0.8683028608177885 
15.258901892348456 22.707458513072968 119.11730960200843 0.8577068725448217 
15.752790750459175 23.53031681751348 122.89099530656806 0.8432451332416706 
16.061065542956463 24.34016862850488 123.57593494791672 0.8248214071462024 
16.291159802856793 25.176962268584848 123.20632689677227 0.8028525913749248 
13.566656632501504 20.64194995999753 112.89039223062787 0.8028525913749248 
epoch: 3, train time every whole data:225.98s
epoch: 3, total time:1211.77s
predicting testing set batch 1 / 168, time: 0.38s
predicting testing set batch 101 / 168, time: 38.25s
test time on whole data:63.56s
9.020617378307833 12.561907922267823 108.92817777186279 0.9545650345888586 
9.593107247049396 13.477878557986985 116.86435121336787 0.9472959271073108 
10.120434807850824 14.669655175949558 120.23255998502573 0.9338507326357055 
10.203038886898456 15.030571035983238 119.60539056110113 0.9290346462184914 
10.301927893052582 15.45577857424869 117.38122435246628 0.9222388294092203 
10.442856599971908 15.768913534447478 116.33047017191149 0.9173465676600622 
10.587141738536545 16.092743984279974 114.5024886730811 0.9129635763417558 
10.743704933198812 16.527350045069937 112.42611941491761 0.9067126850806079 
10.917438046769977 16.937727703574552 110.55681971341835 0.9009416149495872 
11.199366032364077 17.473673607711344 110.59943283308107 0.8940887158914455 
11.530249448353574 18.28029918578733 110.96940709340694 0.8815469299955556 
11.981744280714937 19.485440081284512 112.29735749337534 0.8616229358240398 
10.553468941089077 16.089097307809133 114.22448494493071 0.8616229358240398 
epoch: 4, train time every whole data:225.77s
epoch: 4, total time:1515.91s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 38.05s
test time on whole data:63.30s
5.983425397900388 9.765775282883306 54.0479053168969 0.9627243483519963 
6.293228266510454 10.569014725774817 54.02071053913598 0.9559284719947186 
6.725066669013787 11.691335426008974 56.17948542407066 0.9457577076825892 
7.051362628805525 12.227328246843195 59.41120574598284 0.9404652320707696 
7.317214556685604 12.722141353092322 62.55995491422769 0.9353982794268108 
7.46429668324286 12.964804345922424 65.1985679007468 0.9328828311145606 
7.608766853701069 13.155002228229588 69.10512295478635 0.9309247890095943 
7.649738556265513 13.26098372644938 70.99592390678043 0.9297590749272592 
7.692181317246897 13.404029830724527 72.58765888628251 0.9281508858122676 
7.715409630278427 13.541166220275441 72.7631980943523 0.926418452583795 
7.80292145821549 13.907527256676774 72.8359051644358 0.9221706443862464 
8.173895582330562 14.865595344904756 76.13364662887491 0.910502872859861 
7.289792300016381 12.746086204088485 65.4866040098435 0.910502872859861 
epoch: 5, train time every whole data:225.69s
epoch: 5, total time:1818.49s
predicting testing set batch 1 / 168, time: 0.38s
predicting testing set batch 101 / 168, time: 38.36s
test time on whole data:63.82s
6.509197941527182 10.382777864035967 55.58234483793706 0.9601653539569562 
6.857829308792775 11.28855333806169 56.74805458560521 0.9536081965040897 
7.233122406471047 12.284641554109692 58.13098395736284 0.9449255258391737 
7.371907790332937 12.541531700786374 58.686965128141054 0.9425436056700848 
7.482377461119059 12.77988704792089 58.94348942345968 0.9396935873608037 
7.515712496330308 12.828489273926689 58.24341654002669 0.9389245103139301 
7.577322881791682 12.891673940910694 59.731886111024835 0.9378472188855841 
7.574603243511386 12.975480612087411 58.711906243068015 0.9368952226970187 
7.594454367177923 13.093614739569404 58.15474511135873 0.9356235071568176 
7.667353354462042 13.317403824413393 57.559721020530716 0.9334256121852554 
7.775064434898441 13.707034434954302 58.28525383960541 0.9284084590143051 
8.11781271567311 14.695923187805574 60.35992409310852 0.9162662392575567 
7.439729866840658 12.775428548555363 58.26155784710644 0.9162662392575567 
epoch: 6, train time every whole data:225.71s
epoch: 6, total time:2118.76s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 38.02s
test time on whole data:63.26s
7.399948749393395 10.504993797311181 77.95062444941149 0.9640553594388834 
7.633723113610153 11.238522845403272 77.81533798823294 0.957715307215714 
7.650671950943075 11.77289773943423 73.75025178586905 0.9519599448049612 
7.749125450480656 12.075579859934374 73.10815224520294 0.9494050544149546 
7.743489644809376 12.269277654752194 71.3074270740173 0.9478729859918035 
7.86873154875801 12.43575334596801 73.00513051338223 0.946749795639036 
7.9268065900325935 12.520567512596541 73.59296613628047 0.9464539847011961 
8.161118921406405 12.809049770221645 77.20277202616597 0.9448468290783353 
8.387413979301995 13.104950378201174 80.3580400701216 0.9431954080335205 
8.786592787170013 13.679375304967254 86.105047497739 0.9393756624363483 
9.051024974811645 14.307148336140319 88.09345249331545 0.9332594975413596 
9.350725937744079 15.317498328051943 88.3956002034981 0.9210392740576806 
8.142447804038449 12.73212742291832 78.39040342059734 0.9210392740576806 
epoch: 7, train time every whole data:226.03s
epoch: 7, total time:2426.08s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 38.19s
test time on whole data:63.47s
6.604532466690008 9.876393567215645 69.4741876184513 0.9644328184064058 
7.035600318936791 10.846007583943603 71.95233392305974 0.9576715445706353 
7.309756146650611 11.57844892795056 72.7072344358853 0.9510541160377953 
7.431422866883144 12.021878424038013 71.6272262493129 0.9469527492322105 
7.400742240950853 12.122483066677217 70.3758147974878 0.9452799126892723 
7.462820727579366 12.172662944852625 70.95682344007722 0.9442443249607195 
7.423004863746538 12.14968061688186 69.94659915196007 0.9439031218356607 
7.596884416797419 12.335967436086102 72.79230174967434 0.9415867166703554 
7.508463747593659 12.342445887366766 70.9690378457313 0.9409832416599199 
7.592475871771748 12.548702248593486 71.82212385562242 0.9386278945368874 
7.67600773441898 12.965640659820924 70.83044347194351 0.9337345205114157 
8.028541470181418 13.974126917161337 73.78719884727776 0.9218733708295135 
7.422521072683378 12.117047841764283 71.43677731526277 0.9218733708295135 
epoch: 8, train time every whole data:226.14s
epoch: 8, total time:2729.29s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 38.29s
test time on whole data:63.62s
5.96798202502793 9.214302625721142 59.4129280561817 0.9672875969405722 
6.28022249781552 9.960877013502392 59.96676739799693 0.9617966137882072 
6.576454749560124 10.744452803478893 59.909711284414854 0.9551361528922138 
6.704677630628276 10.984121318062469 60.75220066847977 0.9530599061740663 
6.884946176633699 11.403581363198787 61.23378032883794 0.9490647763171189 
6.92711087848609 11.566855762889599 60.885145813283955 0.9472391688192656 
7.005778517812238 11.770440430796082 60.48407195656529 0.9449898373421033 
7.069886764588826 11.909793888671405 60.61754071200697 0.9435879143762638 
7.2076138028118235 12.146895572905374 61.7967847502785 0.9412452924392786 
7.287175916933171 12.377827813242487 61.8468886175381 0.9390178879316105 
7.4852653312224415 12.855622574000641 63.413982857514824 0.9341835904421654 
7.718959310289184 13.667008332713444 64.95540009999378 0.9250194109902854 
6.926339466817444 11.609079605527496 61.27293604924008 0.9250194109902854 
epoch: 9, train time every whole data:225.89s
epoch: 9, total time:3034.23s
predicting testing set batch 1 / 168, time: 0.38s
predicting testing set batch 101 / 168, time: 38.12s
test time on whole data:63.37s
6.992159620571463 10.098004243489576 77.36691870548233 0.9682784757301284 
7.232534178937216 10.781334971878593 75.93949490934484 0.9625155478041875 
7.403300949567585 11.303827336512061 76.74490235901077 0.9565192465863379 
7.4702830444754635 11.768480769223638 75.54376988376961 0.9517623622852083 
7.462415030286882 12.051070633758028 74.64599105445592 0.9476616429943964 
7.397520696426629 12.087412051068805 73.34910894357645 0.9462812016828746 
7.2765704734279915 11.925763518747676 70.14880864257408 0.9469356971865492 
7.241795789616048 11.888604690723977 68.36883279015899 0.9468205961371658 
7.217604664485549 11.96381962595369 66.87700356942237 0.9460703416812715 
7.224640899155181 12.113948745762647 65.56241292801413 0.9446208716950036 
7.26902639508043 12.412542277627884 63.64953774023818 0.9412695020696733 
7.4549171693791125 13.056804556635889 64.79108231751607 0.9333411236562552 
7.303564075950796 11.810338695882809 71.0823227422607 0.9333411236562552 
epoch: 10, train time every whole data:225.89s
epoch: 10, total time:3339.33s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 38.18s
test time on whole data:63.46s
9.15297621891911 12.140868108799275 113.09822594945335 0.9481614335824662 
9.38330536873368 12.907520279509377 112.86433853254094 0.9412480438496128 
9.466245662921578 13.29014948199704 111.8307251249461 0.9369676292942619 
9.512159794501493 13.615786849346387 110.11535125141872 0.934135192504501 
9.424326163636753 13.550844382586833 108.73442422137394 0.934475093804049 
9.49650094037013 13.674673935387109 108.55724311158399 0.9331544130279149 
9.434261067302343 13.690086590592433 106.10631387761455 0.9330766717967806 
9.541109043946676 13.85459729036621 107.55443459918719 0.931115839594507 
9.45178398749367 13.789164881766181 105.7842732857096 0.9306313876713965 
9.568984886416711 13.985062445164738 107.19822550370435 0.9284537958828918 
9.652350783946291 14.252935627487156 106.50454072245286 0.9251908816341702 
9.914530605803828 14.937258054483857 107.20156037412858 0.9157094006896436 
9.499877876999355 13.656511885536133 108.79580491322717 0.9157094006896436 
epoch: 11, train time every whole data:225.73s
epoch: 11, total time:3642.48s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 38.12s
test time on whole data:63.42s
7.626812751440453 10.877340566273014 72.88084573989077 0.9678886485844395 
7.824439060488233 11.341335915659096 76.59024896769904 0.9624755321959869 
8.169705402899238 12.022659461952973 81.5558119802971 0.9563265003703157 
8.295273396635519 12.331982644678899 84.986963111886 0.953464240901396 
8.439817343843014 12.58382003001046 87.48715931023938 0.9515708517629927 
8.529085418327641 12.778130718861302 89.62372439323804 0.9501783412821367 
8.76573854162207 13.076458575923455 94.32085444073027 0.9487683899323657 
8.883718358296594 13.21550875882751 96.0360296644557 0.9484172986197349 
8.824651116736344 13.253010288869131 92.96262739002744 0.947995127464697 
8.875061363127596 13.405231900657103 92.78279072146056 0.9468550095422018 
8.898515951764448 13.66063814766035 91.1272245349075 0.9441086926351621 
9.075942686570787 14.494491684817733 87.20145397924959 0.9354527140343213 
8.517396782645996 12.789601942989902 87.29629762134701 0.9354527140343213 
epoch: 12, train time every whole data:225.90s
epoch: 12, total time:3945.45s
predicting testing set batch 1 / 168, time: 0.38s
predicting testing set batch 101 / 168, time: 38.16s
test time on whole data:63.44s
5.939914929997053 9.166563534261783 57.58410769998223 0.967316077791995 
6.198191173243357 9.844637265011547 56.8587759297854 0.9622279749246044 
6.433215415389989 10.542620871383484 56.06954179663125 0.9566782011733831 
6.4645124090265424 10.703963833324659 55.05289803468223 0.9556479248158033 
6.505656021468344 10.965507971555922 54.87532096121366 0.9535661637791981 
6.57610016049033 11.13442503856117 55.61809992523613 0.9522757899806015 
6.660186685828477 11.315596321455272 56.330770005184014 0.9508444799154374 
6.762513335908666 11.426047322978178 58.08279757797479 0.9496745440409058 
6.770648647634502 11.47469075470081 58.88294223021122 0.9489617674177697 
6.840640012044132 11.63659901907738 60.172160698288366 0.9476084722677675 
6.960178500796627 11.882407483061723 61.587346666502555 0.9457116400289808 
7.108640078000719 12.374525061224821 62.60399614035151 0.9400989573880595 
6.601699780819062 11.071280311283031 57.80989736815899 0.9400989573880595 
epoch: 13, train time every whole data:225.82s
epoch: 13, total time:4250.77s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 38.10s
test time on whole data:63.46s
7.313101853509348 10.208649751881424 85.39961733974715 0.9630061547110239 
7.50294799124747 10.757752772301046 86.42498878366474 0.9588614010215787 
7.7401239948867895 11.33103228385001 87.86391886532351 0.9550336474889083 
7.9000082540572905 11.70423735564632 89.11424619182378 0.9529607991219005 
8.01668778702347 12.043106722368352 89.36300860234627 0.9512810029951324 
8.135961971862002 12.360625481635342 89.55037449140751 0.9501039319156246 
8.459668583137768 12.739612136272537 93.04417783693683 0.9488559684517518 
8.575836214032261 13.014290398461663 92.83013243765299 0.9468406248777408 
8.739052011957291 13.38130886316841 93.77505101762726 0.9434695803797134 
8.798980404175781 13.713370693782561 91.95440254996413 0.9396231783373299 
8.889064308300844 13.928088753707936 91.41260107888306 0.9363090847641635 
9.005503246404722 14.456265924349838 92.04050477910171 0.9276321036325779 
8.256411385049587 12.532987926623038 90.23107980795861 0.9276321036325779 
epoch: 14, train time every whole data:225.84s
epoch: 14, total time:4558.28s
predicting testing set batch 1 / 168, time: 0.38s
predicting testing set batch 101 / 168, time: 38.74s
test time on whole data:64.46s
6.14029240529338 8.927202319318294 71.56199873895439 0.9727395895410328 
6.291507830508547 9.533947880984492 69.60764717883585 0.9682281090185859 
6.467249216464996 10.091800960904534 70.03053043046134 0.9639242370324602 
6.5743790350647995 10.447110405761606 70.15791731672027 0.9612569042550794 
6.626580985471479 10.7183845618452 70.47095117652903 0.9587144705774625 
6.695388830556326 11.038451650007097 70.61229680505295 0.9556631044272357 
6.7139169235002365 11.222991859977695 69.66350229150638 0.9535790501696576 
6.674365458569603 11.30512456781216 66.96001769539556 0.9521437448042935 
6.698586349764681 11.396991467543726 67.00276140875661 0.9512922175572756 
6.665422237063637 11.45009976521463 64.357279643945 0.9504795043903217 
6.755975104040625 11.588989701353999 63.22822866913494 0.9495044686019772 
7.024414185928334 12.2818873598142 64.88893369435684 0.9423041018498571 
6.610673213518887 10.871276660317488 68.21183773949649 0.9423041018498571 
epoch: 15, train time every whole data:228.20s
epoch: 15, total time:4865.84s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 38.40s
test time on whole data:64.02s
5.4469727432090025 8.631538388918688 49.62078496896037 0.97122670703246 
5.679265368978916 9.283733456099807 47.75586040724772 0.966979768779424 
5.988098785294686 10.024803390443244 47.94509477384825 0.9613672574757505 
6.02139052184418 10.166448812107408 46.92078803731915 0.9604313371705977 
6.097665092118489 10.440441096578521 46.91484156606342 0.9583171212119025 
6.0795104493586445 10.481358168913845 46.916776046699695 0.9577920681356112 
6.103914641120464 10.582416744480286 47.267688664861865 0.956858522370606 
6.20910382470157 10.774804995657002 48.973201759265834 0.9547893344582207 
6.269103057039541 11.016275361708534 49.96315719014853 0.9525014282408034 
6.395029750377766 11.29162932482838 51.654530048515255 0.9501819420384071 
6.565620725888578 11.593817331449486 53.740680531588744 0.9475134847280705 
6.804711442065785 12.104371446441169 55.69576650490371 0.9425034053675919 
6.138365533499802 10.572297907727027 49.44743475788521 0.9425034053675919 
epoch: 16, train time every whole data:226.94s
epoch: 16, total time:5171.29s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 38.47s
test time on whole data:63.89s
5.505589712595979 8.562775105599561 51.400524126985225 0.9726411317121242 
5.79218268082804 9.254197481410566 51.97125386973348 0.9687666098076354 
6.060796073030943 9.875466596432318 53.574933762126854 0.9652648564766687 
6.2769158515868115 10.329988148237085 54.71754763704328 0.9632524356556661 
6.454525600815281 10.786946617724514 55.75399592163453 0.96021838258766 
6.530088170702148 11.013597867671605 55.73857099068545 0.9584591897611727 
6.580029955062438 11.105720856451171 55.695277192056324 0.9574939242079162 
6.5567213930988215 11.071067844719874 54.59428318802666 0.9563755673738307 
6.539682743757279 11.107077841116391 54.80591450134795 0.9549009820592776 
6.515184808190098 11.200315044543117 53.65682864829478 0.9530617812733202 
6.582521034152132 11.409419909205774 54.11000337139041 0.9507152880810026 
6.809608284854842 11.885437529441042 56.99494012124063 0.9456876131712197 
6.350320525722901 10.67321664127345 54.41784103024078 0.9456876131712197 
epoch: 17, train time every whole data:227.37s
epoch: 17, total time:5476.07s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 38.48s
test time on whole data:63.91s
5.289106506621632 8.536202893400104 46.01234757176794 0.9738967695397339 
5.549060601768585 9.154256080532143 47.241846737798966 0.9700896270689345 
5.768739837819508 9.660057785221296 48.69820951839058 0.9661928534433577 
5.838150146002093 9.844220637783568 48.93382282089734 0.9651004528523942 
5.911355289826243 10.034791670292668 48.920002881099045 0.9634646385350019 
5.949532959658324 10.15809836806495 48.808122979699334 0.962564967631121 
6.009279960924073 10.30198824792986 49.13959874753039 0.9617028145147427 
6.034340698684883 10.426184183630797 48.38340479386466 0.9610298241739259 
6.0635084438223075 10.56799388915455 48.257441757233636 0.9600984225471264 
6.11942138080035 10.757537738496673 47.93933655877984 0.9587174897137992 
6.203938504601297 10.979039819113309 47.88940908212067 0.9565558271274267 
6.404749126304185 11.491790898224808 48.9427990123164 0.9510444809672935 
5.928431954736123 10.188312470064064 48.26386169074327 0.9510444809672935 
epoch: 18, train time every whole data:227.33s
epoch: 18, total time:5780.83s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 38.49s
test time on whole data:63.92s
5.483880504552889 8.8901042492438 41.755176546039536 0.9734855413102932 
5.723524399421845 9.44552635411893 43.701018129822145 0.9688700524573175 
5.983069807006682 10.075355919899245 45.52514613578531 0.9641240461674064 
6.059954117053091 10.245897110903405 46.669766663065026 0.9627091318861222 
6.149658550948556 10.432325078729535 47.4744371451299 0.961386296718564 
6.200310452832636 10.44838325193102 48.849634398228574 0.9615310753271075 
6.242779640612421 10.483085275000635 50.07025123896497 0.9614189903783481 
6.327006649068479 10.630276905114085 51.26408593377689 0.9605806401278303 
6.376390856713296 10.861677096707702 50.79983684937247 0.9587818751727943 
6.4853120584826485 11.111199968189714 51.54321061702829 0.9570511655289816 
6.636857866905123 11.47669458204751 52.0711177093284 0.9540432234931704 
6.958941642061774 12.28211812098795 52.502041646678364 0.9468955147021776 
6.218973878804953 10.56583664234344 48.51880849010553 0.9468955147021776 
epoch: 19, train time every whole data:227.23s
epoch: 19, total time:6089.17s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 38.39s
test time on whole data:63.91s
8.461868320806822 10.81020137596837 124.43389677137004 0.9718480173546173 
8.740779216645613 11.414345031464135 124.87463868396243 0.9680518563453324 
8.85637450084471 11.766104347863996 124.14415083666049 0.9649025438278993 
9.03537496072672 12.059787669290966 124.6266090969853 0.9635206463086061 
9.110996608853702 12.261232867209484 124.86455521374647 0.961566889796964 
9.077563237983732 12.362684998299567 122.78637901609528 0.9598252307450621 
9.045453010856368 12.426218871174049 120.9262222057269 0.9583117333153626 
9.00026120271549 12.391508323608997 119.85676589691865 0.9577024410973396 
8.996428615130675 12.440720736394102 120.39951112017329 0.9570300202801217 
8.989585879404446 12.48780206886532 120.33249727718778 0.9562788077340183 
9.052896538467989 12.694221176093691 120.90161816087652 0.9540131719172208 
9.184421267699232 13.03350484551976 122.95876453518456 0.9486562409002928 
8.962666946677958 12.192531371625604 122.59213688501731 0.9486562409002928 
epoch: 20, train time every whole data:227.09s
epoch: 20, total time:6399.04s
predicting testing set batch 1 / 168, time: 0.39s
predicting testing set batch 101 / 168, time: 38.65s
test time on whole data:64.46s
6.418375848746394 9.330788326643615 61.828846171146736 0.9748292822332231 
6.489722226774724 9.665436189325654 62.39462618358653 0.9709834133235605 
6.507039123872092 9.954795608623812 62.1486917856225 0.9676500657649721 
6.552097155185362 10.148805812586186 62.34272799381985 0.9656212852165581 
6.644581488292045 10.427050537681668 62.69513470232173 0.9631529520632228 
6.750308842381137 10.678378198307469 63.89327377387186 0.9609093044215384 
6.8612124303911335 10.959299318787952 65.44894380834063 0.9584004414337677 
6.959119516420083 11.104592942581604 67.38578110871988 0.9572790972427261 
6.981189491407665 11.18850740519377 67.4962258092505 0.9565712258296477 
7.0474659364315055 11.274171203788367 68.69320639608702 0.9562268304435253 
7.178277875299773 11.496955791053265 69.42450149653912 0.9549183844243391 
7.325930431574374 11.925019113537628 68.26590550084383 0.9510392878973061 
6.8096100305646905 10.706016844148769 65.16815208224607 0.9510392878973061 
epoch: 21, train time every whole data:227.62s
epoch: 21, total time:6704.47s
predicting testing set batch 1 / 168, time: 0.39s
predicting testing set batch 101 / 168, time: 38.69s
test time on whole data:64.24s
5.710998745975436 9.167020756040118 42.01486277578819 0.9733286012777886 
5.850675602875166 9.553143804096429 44.20154361753147 0.9689064274389816 
6.032028009272236 9.997380379353402 46.94425780055644 0.9646124277057384 
6.074614316518237 10.135415079151203 48.260982693633935 0.9630926002827881 
6.130675152428495 10.375043372618912 49.146905554224965 0.9610456759647458 
6.224904080287254 10.619466769455427 50.764734256699796 0.9594202714016099 
6.428268156037975 10.949214530928757 54.05156761475055 0.9575255587660052 
6.710817361391736 11.415839313006316 57.457293235412024 0.9547952452582991 
6.9394337020303745 11.906925582983982 58.37998586137216 0.9512112061716358 
7.106962023364267 12.250116769408173 58.893597907584784 0.9481111380210755 
7.196970719034406 12.34836948937448 57.78781770917115 0.9468109742387176 
7.370896983460909 12.904332871880191 57.01864219246917 0.9408787866062912 
6.481437071056374 11.028133109207605 52.07684266337612 0.9408787866062912 
epoch: 22, train time every whole data:226.20s
epoch: 22, total time:7009.35s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 38.26s
test time on whole data:63.96s
5.0797734472561675 8.193408014903735 44.483560538768046 0.973799978080371 
5.196368275896332 8.667221502555487 43.31503027162272 0.9706866880050528 
5.328726854559712 9.16631594084892 42.84571532637219 0.9671645374097833 
5.406731314191877 9.37919254857529 42.91234536597834 0.9656112818230014 
5.478825917646537 9.59479179939783 42.79593037513104 0.9639183941974466 
5.534577199485656 9.799622246292556 43.04760576275205 0.9622627548160756 
5.552376980329702 9.843147297838854 42.811255693717506 0.9618522356723451 
5.5849469220343275 9.916070845411502 42.72729269914631 0.9613313076845157 
5.637615037926783 10.07618882186991 43.12794263466333 0.9602109963809655 
5.709913292932406 10.190709899517563 43.48056236046436 0.9594742096147466 
5.777875096013575 10.330063451581331 43.522083441718834 0.9584159808486424 
5.977433888108353 10.749084938677695 44.599900227868126 0.9551198268885733 
5.522097018865119 9.683254821290127 43.30576948988965 0.9551198268885733 
epoch: 23, train time every whole data:226.71s
epoch: 23, total time:7316.82s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 38.50s
test time on whole data:63.89s
6.113529598767957 9.387295526983788 53.33222779743355 0.9735991834533217 
6.256402128003771 9.79171773207578 54.3870719053125 0.969545926517903 
6.411394099583212 10.185956456895155 55.46205059941135 0.9662732279585673 
6.485110711129606 10.404779804756686 56.3254392082049 0.9640143166756423 
6.605724383002688 10.707713808743678 57.78563767212796 0.9614809665473276 
6.706215944022858 10.933028477137322 59.62890081317228 0.9594517233615124 
6.711510965323014 10.969869712522488 60.548699553279675 0.9586610485837679 
6.729929640350565 10.907154061689294 62.43134393619428 0.9587285294701425 
6.739599176884019 10.945107612583532 63.128795291939824 0.9580484305298527 
6.7265331558175445 10.945077953314748 63.908531641229004 0.95744370944032 
6.798187402634713 11.141143814124533 64.46365916165736 0.9554506803652382 
6.927829849101837 11.660735864325984 63.77115056384932 0.9504537916166924 
6.600997254551816 10.681722947592798 59.597789415269176 0.9504537916166924 
epoch: 24, train time every whole data:226.23s
epoch: 24, total time:7621.99s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 38.74s
test time on whole data:64.48s
4.924139248015562 7.923511876479304 42.55591289550995 0.9754935243023389 
5.1784143757673275 8.535927849386042 44.069029601369344 0.9716550026901075 
5.419089303689889 9.094781807842605 46.0913108278136 0.9680301486950097 
5.5519807408955595 9.42112319609151 47.13983746551345 0.9661673223032219 
5.640615751699575 9.679618933254698 47.96186978609907 0.9645750356766625 
5.684978301056507 9.820076892195422 48.14098227605535 0.963495379893268 
5.678255508886567 9.816676249136423 47.81657933132807 0.9632025291928266 
5.677289554720972 9.82978188841896 47.07103857703741 0.9627497524667846 
5.678449754012752 9.920824683703398 46.415697217941116 0.9617424993600486 
5.719949005648238 10.02137753773769 45.82473279926022 0.9612640660120234 
5.842267936674546 10.288872183531007 46.38920247851464 0.9595052412681773 
6.028499688633301 10.715394976608682 47.49205383795192 0.9557406422996777 
5.5853274308084 9.616690140077448 46.41402103587707 0.9557406422996777 
epoch: 25, train time every whole data:228.02s
epoch: 25, total time:7930.47s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 38.49s
test time on whole data:63.93s
6.2349218020202795 9.35637077510724 58.032059795341226 0.9732985434439186 
6.338558302829716 9.868204054037593 56.763378210770554 0.9699449613095253 
6.49126662838053 10.464753950711426 56.54732067172535 0.9665352841677703 
6.5656059889507645 10.76630261718566 56.614618625251204 0.9648376587801925 
6.645666350850804 11.020118909397668 56.8683528517532 0.9630749024989479 
6.646174540635195 11.030233372733779 56.56045214846252 0.9621802824093066 
6.556749988281019 10.968837179511306 54.30011365968287 0.9620009716951416 
6.536231391427147 11.0142073911841 53.08078296590081 0.9611945290082162 
6.537256165385507 11.151680372354676 51.99198004037366 0.9595996934302614 
6.665956557117972 11.412043116948174 53.43354269940078 0.9578728300347735 
6.867709027267736 11.653036267670721 55.740763604397344 0.9559757184400577 
7.089990019957001 11.921792057878118 57.761395441227435 0.9532901807587547 
6.598007230258639 10.90719097104142 55.64123624539358 0.9532901807587547 
epoch: 26, train time every whole data:226.51s
epoch: 26, total time:8238.25s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 38.47s
test time on whole data:63.95s
5.151157485601094 8.334588896018742 44.7615309614099 0.9731814452096053 
5.283210886612077 8.718521657191317 44.37328895636358 0.9702583790439494 
5.421567271083775 9.103426443096586 44.659414953999196 0.9675447258271176 
5.518195019369095 9.377852334925638 45.08202045960987 0.9656336377677722 
5.6207299519981655 9.704067615887634 45.40194709930234 0.9631871009455819 
5.751401113971102 10.062027994982937 46.493610878339595 0.9603007337696888 
5.895020240233898 10.52849795472636 47.585080724622095 0.9563831388892047 
6.021096943480333 10.973454756651385 47.58436805578397 0.9524989501244099 
6.108645379928604 11.360072005324298 48.309237923384046 0.9489117933591212 
6.192797603745949 11.587958509406718 48.97572150181128 0.9467504402439393 
6.244277897846161 11.524016350931351 49.8862311518668 0.9472569036714868 
6.352218751830435 11.671328788986921 51.289506544232246 0.945798038108327 
5.796693212141724 10.309092590429728 47.03349715204129 0.945798038108327 
epoch: 27, train time every whole data:225.99s
epoch: 27, total time:8543.35s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 38.49s
test time on whole data:63.87s
5.424837818326838 8.241703112181945 61.45249398533651 0.975491628258457 
5.7008801929387936 8.910114439266906 62.47363370461218 0.9719631319292453 
5.962417855023514 9.526117134985212 63.81748330597031 0.9689532195701024 
6.082561973184684 9.826266321262397 64.05673558462172 0.9671983168072221 
6.110157464323879 9.993596349862388 63.038927384706646 0.9656535772518138 
6.135963906781268 10.15819584745656 62.52002094653534 0.9640325234529376 
6.19467235852466 10.252804522859645 63.23856963648551 0.962925900644327 
6.2517323906083595 10.347345257643594 63.42912964377071 0.961865276281667 
6.3015472649120134 10.519036118525328 63.92778390415415 0.9602451513249073 
6.439896262866471 10.801315278993307 64.63483691899366 0.9585858678729485 
6.534592969328811 11.029648143745744 64.97847502486643 0.956801522777 
6.724765249941884 11.484869282249315 66.05428040594504 0.9524902451334866 
6.155335475563431 10.127275816511467 63.63519832963127 0.9524902451334866 
epoch: 28, train time every whole data:226.21s
epoch: 28, total time:8848.67s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 38.44s
test time on whole data:63.91s
5.204438750570253 8.330953644547542 45.678047395295366 0.9735710054451057 
5.486657854080993 9.051286147943081 47.52381812811178 0.9681912302193276 
5.733432283079067 9.820714485470932 49.42029128691197 0.9626489270191781 
5.967450979549616 10.472943039505811 51.70902847292719 0.9578794090405951 
6.111162140682697 10.864675036200357 52.77387783673441 0.9547900244036028 
6.192853086143769 10.996150677120253 53.218040748377824 0.9536730697280986 
6.183584367022761 10.945471884270288 52.401235439704564 0.9541120080330895 
6.197435672626595 10.841788698248967 52.48044163896688 0.9550480913678376 
6.1909239720370595 10.793713265029567 51.75594431028963 0.9553109016753574 
6.180435596939161 10.788964508071341 50.6416646113112 0.9553925668402915 
6.2044730755575355 10.860838616704223 50.403126548734036 0.9545567624424882 
6.304284386014191 11.190664825645442 51.18181848137642 0.9513231881765105 
5.996427680358641 10.447721301311537 50.765610121239945 0.9513231881765105 
epoch: 29, train time every whole data:226.00s
epoch: 29, total time:9152.56s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 38.48s
test time on whole data:64.01s
5.465038766312879 8.400874652509614 54.02983591387069 0.9751348351770635 
5.637658411297248 8.91931370545137 54.22447579008757 0.9716253327599981 
5.726057359786198 9.311874828883886 53.434157333021126 0.9686380994258313 
5.805683968212663 9.58846841762612 52.72833834519953 0.9667649391647201 
5.913801479430598 9.857495777710476 52.78587153307974 0.9652574681013584 
6.047988240059393 10.129103688476988 53.55217700006186 0.9639440174494981 
6.189402163169933 10.318972026778171 55.281561634505984 0.9635036647382831 
6.305686641656726 10.48077078097136 56.76474232707548 0.962699408711394 
6.354503290508158 10.654915519033997 58.158378086861305 0.9606910642412708 
6.39193864014042 10.92236097544119 58.15659048488931 0.9578037539637742 
6.432148718558644 11.2221071450782 58.093458409871744 0.9544510040960612 
6.564579486227376 11.714365839285643 58.80937450446403 0.9495508616991306 
6.069540597113353 10.16883533772046 55.50157759006419 0.9495508616991306 
epoch: 30, train time every whole data:228.91s
epoch: 30, total time:9458.76s
predicting testing set batch 1 / 168, time: 0.38s
predicting testing set batch 101 / 168, time: 38.82s
test time on whole data:64.57s
5.146463440631217 8.2387507596826 40.96858718569632 0.9755294148754827 
5.3934028790651825 8.940180674746266 41.88962914542422 0.9713033496456561 
5.617295776147228 9.58456172646732 42.74416522217231 0.9667932232929696 
5.665157496842222 9.749252863728946 42.59577873373439 0.9657412390586401 
5.753422978062618 9.942360832867825 42.855886957907515 0.9645615150655297 
5.8190767704169915 10.070832378988735 43.406376229014896 0.9638349615035556 
5.871062621530785 10.196554761732582 43.7004541691057 0.9631123556610428 
5.960328431368358 10.383080535051048 45.01057059865137 0.9618469348936609 
5.998447641483806 10.568149208927432 45.13760366043534 0.9601166087734336 
6.095685183099777 10.844508830014602 45.77581477002303 0.9578749923690805 
6.202902557648204 11.109993312443244 45.763718005350604 0.9552185808002819 
6.340133992019932 11.479724879954288 45.858542895302975 0.9515032296991585 
5.82194831402636 10.12945818639073 43.80892610156172 0.9515032296991585 
epoch: 31, train time every whole data:227.40s
epoch: 31, total time:9764.74s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 38.86s
test time on whole data:64.79s
5.719319754890111 9.0322158451423 46.85333328766375 0.9755113900487589 
5.745728003857404 9.1983725983412 47.724085451796206 0.9720229376057254 
5.840648759715576 9.50054026236933 49.161442126854645 0.9687464304188242 
5.87712768870029 9.71610859185456 49.5958993837705 0.9663671137784589 
5.961682050961053 9.976200736930501 50.375557377023924 0.9642249112004196 
5.995491596244574 10.176199908460548 50.08757698184613 0.9627000439218866 
5.978864218518331 10.246937515289783 49.008634515659736 0.9621960176920997 
5.954695622800995 10.249714052546201 48.08781086397073 0.9622597075501422 
5.884716640323493 10.264124002256787 46.031742746219 0.9618512511259153 
5.794791479151435 10.213388291161927 44.41533002884091 0.9613521214907634 
5.794168951307536 10.277604555012688 43.810074930302676 0.9601117744153267 
5.888602960081585 10.573240930406454 44.057808105109466 0.9572154369082216 
5.869653143879365 9.96275617144445 47.434106168396426 0.9572154369082216 
epoch: 32, train time every whole data:227.41s
epoch: 32, total time:10070.88s
predicting testing set batch 1 / 168, time: 0.40s
predicting testing set batch 101 / 168, time: 39.03s
test time on whole data:64.86s
4.951171150383104 8.23498954009773 40.82143284687977 0.9743158190166418 
5.13787069918184 8.741921872129089 41.32125882169265 0.9703016867096869 
5.3055416487246205 9.182429051805787 41.83276651072154 0.966932196196883 
5.393876050935035 9.430631840009145 42.008958529858155 0.9650394820039148 
5.472717695622503 9.608282214987875 42.115014083578856 0.9636922048524287 
5.5163461009661185 9.774870990974588 42.04172077425015 0.9624000598639001 
5.541895270134188 9.819946914464817 42.684241435847326 0.962014053048877 
5.566037793591255 9.899727560877395 42.65844406023566 0.9614244217589419 
5.6639334896218925 10.191057941522526 43.1404929230166 0.9592087205941082 
5.848743040150904 10.586725142637034 44.53483665473095 0.9561057280237468 
6.047723250857825 11.034902797887277 45.37466234485839 0.9522595665974568 
6.283402131300525 11.610359012914243 46.73703671236331 0.946891016025201 
5.560771526789151 9.883905906040352 42.93924065679947 0.946891016025201 
epoch: 33, train time every whole data:227.58s
epoch: 33, total time:10377.34s
predicting testing set batch 1 / 168, time: 0.38s
predicting testing set batch 101 / 168, time: 38.63s
test time on whole data:64.33s
5.282356112636393 8.372142350006714 48.44017138486001 0.976010838801897 
5.483459323487083 9.002644261191483 47.73355984505756 0.9725031918793018 
5.6791971375244765 9.543995034180329 47.25139395691429 0.968986711263733 
5.721128255308006 9.736591835120288 46.799716672205804 0.9673419066164843 
5.768094672475592 9.946185363883904 46.047051789465556 0.9652516142514499 
5.8008552040998795 10.106252749192715 45.39071955634536 0.963610293048443 
5.826303268915257 10.20149873042698 44.91127432494878 0.9624819923248564 
5.855878080538152 10.276533098767603 44.835279439186806 0.9618606752674108 
5.86977941639414 10.336539760729401 44.74402905480707 0.9612754032707321 
5.914248550267799 10.444303292286028 44.81215686585 0.9606755085328766 
6.006969495503565 10.62746788123087 45.42770467298734 0.9589433275484052 
6.098938845054421 10.874124785932153 46.118284290138206 0.9564773400759563 
5.775600696850397 9.978674255263142 46.04261317062312 0.9564773400759563 
epoch: 34, train time every whole data:227.89s
epoch: 34, total time:10683.35s
predicting testing set batch 1 / 168, time: 0.38s
predicting testing set batch 101 / 168, time: 38.71s
test time on whole data:64.46s
5.387005486099698 8.61161197477961 43.78109183943372 0.9752454995541373 
5.542313324207423 9.068426606884653 44.131770072182505 0.9717099857874052 
5.702543535070228 9.543799642548827 44.65576607083677 0.9681845166530006 
5.767630847379771 9.766650772720029 44.63458271130392 0.9664190585985343 
5.817278293116222 9.939475234050068 44.760667788221916 0.9649753586578054 
5.855989755814041 10.03847329902577 45.0846167547407 0.9641641190940524 
5.827541535276242 10.022569961477437 44.48950353003766 0.9641345799457461 
5.8357426869271825 9.996312192317204 44.590783364211646 0.9640617397600798 
5.864997871014207 10.047249855497295 44.726489938518824 0.963460785546915 
5.896452083805145 10.144723737677419 45.29725287826679 0.9622813312338385 
6.020992141119376 10.437472088438694 46.394135119621 0.9597400283539244 
6.175407661387405 10.803169578818899 47.85429330559166 0.9568362574941475 
5.807824601768078 9.884002339482633 45.03341511860052 0.9568362574941475 
epoch: 35, train time every whole data:226.46s
epoch: 35, total time:10987.84s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 38.30s
test time on whole data:63.73s
7.355757836010951 9.822902382356993 93.76657882004818 0.9748653250916633 
7.811469079248958 10.571771492421263 97.21955264849706 0.9715555762377797 
8.229199124349936 11.267798505455495 101.14243931643567 0.9680152528034066 
8.53808333397432 11.743235504509926 104.31145623622847 0.9661679925643777 
8.654043842491024 11.993325042370339 105.48118322850442 0.9644609158922947 
8.582527240515196 11.995273569371173 104.52774866321279 0.9635954958139987 
8.45252187860192 11.927797819222468 103.09014991121539 0.9625124447801732 
8.243756284791711 11.768104385435826 99.67307737711592 0.961963947910153 
8.041375468112262 11.662508707745019 96.31676429945735 0.9611731683553671 
7.976078694831093 11.698844710040852 93.76045490272958 0.9602713864556 
7.986530409464206 11.873086584970174 92.06552345283158 0.9581947313514515 
8.055063911484414 12.122213652070295 90.90300025112653 0.9553874726541898 
8.160533925323 11.5556660993013 98.52148935757322 0.9553874726541898 
epoch: 36, train time every whole data:225.70s
epoch: 36, total time:11291.66s
predicting testing set batch 1 / 168, time: 0.39s
predicting testing set batch 101 / 168, time: 38.12s
test time on whole data:63.40s
4.733129993027741 7.7285666462472635 40.0386344326086 0.9771352484575668 
4.958959631465617 8.401400212606442 40.520370160045964 0.9734618897962969 
5.158050923181179 8.941719691099937 41.3322554688348 0.9701593690469781 
5.2862030796201 9.263887488927374 42.006281001329235 0.9681724257026756 
5.393622578123805 9.571576279472177 42.3357727838279 0.9661517045457186 
5.457117774460356 9.738743619462126 42.774551515582836 0.9648467777216487 
5.4929921610877415 9.805079714844721 43.29505346377206 0.9643649564230989 
5.546623069415022 9.86773502568287 44.03925075580796 0.963948671622666 
5.6070810784331515 10.024905376923128 44.56950546385714 0.9629698342692713 
5.686921721034808 10.189673415285528 44.515836135065896 0.9622876541077556 
5.745409140285392 10.352133786923984 44.23247232857271 0.9608799898851367 
5.820255569321884 10.672458831416714 43.87315143519926 0.9577253886110064 
5.4071972266214 9.580598608940505 42.794425811781714 0.9577253886110064 
epoch: 37, train time every whole data:225.39s
epoch: 37, total time:11594.75s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 38.44s
test time on whole data:63.88s
5.019441441418817 8.144383575043896 45.64310598719488 0.9743472007300799 
5.17298119439346 8.806716142893665 44.247749458825204 0.9701825503362841 
5.275204190964028 9.23913624047929 42.69531445827335 0.966740858884256 
5.327510805948858 9.582880646087936 40.93522373847016 0.9640978880609173 
5.393032432417844 9.851233587174567 39.94515799448378 0.9620018898887963 
5.4400947697169215 9.990671438831635 39.4963607160979 0.9610059624516692 
5.453199403313469 9.98722417635769 39.254759673396386 0.9611963793283144 
5.448275752922032 9.866203354395052 39.18186620454753 0.9621726733464327 
5.446772098871958 9.774501696647352 39.41205236671335 0.9628020129107302 
5.51134184890417 9.821076296929741 40.42351348843373 0.9625011014173324 
5.638765244575243 10.123474223259487 41.089473777558844 0.9604044079263124 
5.890928665949052 10.748477829540928 42.68707671333939 0.9554785634279963 
5.418128987449655 9.682623337720887 41.25097382268434 0.9554785634279963 
epoch: 38, train time every whole data:226.19s
epoch: 38, total time:11898.45s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 38.25s
test time on whole data:63.58s
4.94594479121956 8.138500950023236 39.05730683723972 0.9757335836365801 
5.164257994693655 8.76804699218219 39.49835980813047 0.9718099960727903 
5.335814865633133 9.202591779785553 40.64790660104099 0.9683926158317321 
5.4063173053898534 9.36912492462809 41.07845568284183 0.967018429748191 
5.472003777310265 9.5544346078834 41.45603743701701 0.9655071263798904 
5.4878507401618135 9.641110789034135 41.54773247154558 0.9648129333040147 
5.510490804585047 9.703535222144843 41.792553887186614 0.9643412948773266 
5.574658874207321 9.800483062715513 42.223645493802884 0.9636617337702496 
5.649084341631185 10.000924657746165 42.65055280113697 0.9622435799480015 
5.752405865874086 10.271196000761643 42.992750975983476 0.9605925232373537 
5.850078876116028 10.510281379422063 43.06969565122621 0.9590427725499655 
6.026137005444383 10.929310301084236 44.13037685235652 0.9558499848051901 
5.514587103522194 9.684438310635388 41.678781512119365 0.9558499848051901 
epoch: 39, train time every whole data:226.28s
epoch: 39, total time:12202.76s
fine tune the model ... 
epoch: 40, train time every whole data:466.81s
epoch: 40, total time:12669.58s
predicting testing set batch 1 / 168, time: 0.38s
predicting testing set batch 101 / 168, time: 38.61s
test time on whole data:64.09s
4.535394782712216 7.4631107831270596 36.42807198617709 0.9783874063388224 
4.724646998436323 8.024347230799018 36.52369770593277 0.9751289189517844 
4.894871733888881 8.513026136706475 37.09373428451572 0.9721580012505927 
4.991448480790019 8.755539230038668 37.486933344707225 0.9706099760475341 
5.070506347963541 8.969882219988252 37.57770295924311 0.9691458010040729 
5.108178781611329 9.084765919840804 37.484255504625835 0.9683218203197232 
5.120234160642118 9.154979740439236 37.273797035282996 0.9676770180738901 
5.144263201994562 9.250954397857098 37.23867559780627 0.9669370974678935 
5.1790586579493505 9.363325681649659 37.418647878163384 0.9661670906058052 
5.237770089716909 9.484301070804078 37.78771984444678 0.9653880558303968 
5.340362820549156 9.700428286884337 38.490224569048834 0.963826063950628 
5.4753530161206685 10.004585027602047 39.545415242306944 0.9614945617539661 
5.068507422697922 9.006565603206269 37.52907457749831 0.9614945617539661 
epoch: 41, train time every whole data:466.98s
epoch: 41, total time:13215.65s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 38.47s
test time on whole data:64.03s
4.48188421084873 7.435851695591797 33.95189303959179 0.9784803582953427 
4.674093394328427 7.999204216768476 34.36614727440249 0.9752187069137718 
4.837943598061514 8.458703789798186 35.169233641500696 0.9724955179302064 
4.9354166282878404 8.710199630719583 35.756706447453034 0.9709652369234906 
5.028296951521732 8.964524134846243 36.207263003672075 0.969316676515976 
5.085767258830202 9.121413697601296 36.44257044851526 0.9682827692068171 
5.108890426223711 9.191757388677322 36.54257604433887 0.9676622911971668 
5.134309268760689 9.27051674667693 36.60648463056359 0.9670113305437933 
5.154227573064619 9.35115957265609 36.59763926649769 0.9664014824987628 
5.198024236347951 9.435934288013044 36.65888082669368 0.9657762868360216 
5.288887648213344 9.61223510517079 37.01669535331863 0.9644167856588337 
5.425938449547427 9.929848466693002 37.932080231066685 0.9619507315784874 
5.029473303669683 8.982242513844689 36.10401449331387 0.9619507315784874 
epoch: 42, train time every whole data:466.44s
epoch: 42, total time:13762.78s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 38.23s
test time on whole data:63.46s
4.5132374152793915 7.44867349865169 35.039220509689336 0.9785378220253015 
4.729483380477584 8.046191999675667 35.59996555837559 0.97517730875205 
4.922521361081907 8.559487243546496 36.57839867778422 0.9721865812716257 
5.049108333110401 8.859251608483937 37.335926215309094 0.9704523057775352 
5.15464149318101 9.12291097612784 37.78790658539691 0.9687848774533316 
5.21908469869186 9.29099467753892 37.96360021513138 0.967701475167085 
5.234617956472938 9.357732474078107 37.884426113583466 0.9670380187882872 
5.250425693115107 9.422244317449701 37.82368567294799 0.966435899488083 
5.267328011895445 9.509427653627016 37.822593173202016 0.9656901892981837 
5.310163240316162 9.618561043268983 37.92811116940079 0.9648289306868105 
5.399383316126379 9.795298151876404 38.46073078091682 0.9634316343437137 
5.529307412675682 10.093100716820507 39.59746459221932 0.9611859222468971 
5.131608526035322 9.122479168411655 37.485170035699596 0.9611859222468971 
epoch: 43, train time every whole data:457.78s
epoch: 43, total time:14298.95s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 37.73s
test time on whole data:62.73s
4.48117486933572 7.4428130225285996 33.663793901155145 0.9784518767236335 
4.673740409143073 7.99462119549185 34.11825433377114 0.9751323747115375 
4.837427193394635 8.46042284795504 34.85226320944204 0.9722479379328588 
4.938261234191571 8.74235591560817 35.319382244546084 0.9703975302380538 
5.024973922036739 8.978501142041898 35.622330534808846 0.9688001055146824 
5.073510599486674 9.131040991909108 35.7076280813528 0.967780529227683 
5.089052852658412 9.186999968036375 35.711223440157994 0.9673218757757777 
5.1120918053972595 9.251974740986283 35.87051846962181 0.9668534061250698 
5.135251283939815 9.337773177713036 35.945343687415544 0.9662684081830412 
5.182648799882073 9.43900270288938 36.21751568172548 0.9656352286406805 
5.268808168261817 9.620804283851918 36.659550958634014 0.9643162729682035 
5.400649217658467 9.946979390595931 37.62618535961376 0.9618931202702568 
5.018132529615522 8.98655211437212 35.609499928115 0.9618931202702568 
epoch: 44, train time every whole data:458.13s
epoch: 44, total time:14835.57s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 37.77s
test time on whole data:62.89s
4.476556235713707 7.430813825898862 33.490761761068825 0.9785811305654137 
4.675330604094865 7.995093674245341 34.20338020593541 0.9753597806420282 
4.8439963674848 8.461839796863153 35.13834521950433 0.9726305407630883 
4.945190446380699 8.736778049176518 35.6186308261157 0.9708997043898991 
5.040885929921739 8.99902543473137 35.951981487350004 0.9691438330920141 
5.103366244795562 9.17748852482379 36.082227653757 0.9679561664819064 
5.129868817095276 9.25524051364436 36.17160659143973 0.9672975143224122 
5.158412773719986 9.323426089595797 36.39573837620867 0.9668496259991461 
5.184768588799264 9.41305827437114 36.55825989297387 0.966309618166882 
5.237305270823958 9.521366455082156 36.90581138382324 0.965684182331377 
5.324607741281576 9.693249948348436 37.38626846943611 0.9644505358348703 
5.454998153847043 10.008864972976252 38.40219196522632 0.9621336087010343 
5.047940597829872 9.028960828321408 36.02543445970966 0.9621336087010343 
epoch: 45, train time every whole data:457.11s
epoch: 45, total time:15371.47s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 37.66s
test time on whole data:62.56s
4.569907921123143 7.454069632923523 37.681360029201215 0.9785664639073862 
4.78554679307139 8.059155676230795 38.14606866460962 0.9751725529864235 
4.973546094266111 8.549256210900076 38.96740966270483 0.9723295957593759 
5.111787897136697 8.874670255441826 39.798679308883656 0.9704116006695908 
5.221359892112993 9.139627095400987 40.32901465284414 0.9687444396977976 
5.285714501686757 9.328846018429369 40.46296692786439 0.9675325119044019 
5.2999263181535525 9.4032345901858 40.33291205583554 0.9668443436075029 
5.316085822572411 9.462297663194931 40.16702140127762 0.9663722486428417 
5.334803438011852 9.532354294545883 40.0356260678618 0.9659081232235014 
5.389723236547703 9.651617734357941 40.040344033866766 0.9652898303921871 
5.497133466714377 9.849177076250083 40.63554397790586 0.9639443334651472 
5.648789973978541 10.208090057293822 41.842692489195805 0.9613368015002551 
5.202860446281294 9.156553402237055 39.86997089184461 0.9613368015002551 
epoch: 46, train time every whole data:455.43s
epoch: 46, total time:15902.77s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 37.74s
test time on whole data:62.81s
4.483815987899114 7.429903598280059 33.568045710688374 0.9786152937994399 
4.670108786992268 7.989625450242694 34.12197493507379 0.9751857270984224 
4.827610434186113 8.4373484030137 34.87168944165614 0.972392279264697 
4.924445106952348 8.702194439463566 35.32948697842844 0.970707023459602 
5.018999798386183 8.945718097501272 35.72778176447877 0.9691212554549224 
5.077361171690259 9.112108101048534 35.859949933631064 0.9680979930394293 
5.100390039795674 9.190469269870542 35.93105592630506 0.9675737933087124 
5.1268235774359985 9.260451770266725 36.13042343588356 0.9671569712949363 
5.152104496871342 9.35072886452659 36.22219092826368 0.96663356874935 
5.203210999244692 9.461886048039688 36.509278602121356 0.965963056317465 
5.297619271604294 9.669754403809158 36.93654384626816 0.9644109439790338 
5.427164351153232 9.988473344445941 37.8891424694746 0.9619748321522691 
5.02580450185096 8.988274143908592 35.758130952184175 0.9619748321522691 
epoch: 47, train time every whole data:455.99s
epoch: 47, total time:16437.73s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 37.81s
test time on whole data:62.91s
4.497094097534728 7.428189628528165 34.88852663918779 0.9785362612943689 
4.701238860926703 8.008852829899732 35.42335009643093 0.9751897958704087 
4.87674965408802 8.465093824694057 36.298562465347025 0.972541516678675 
4.980778268828349 8.740697340719349 36.867073606030395 0.970874328107791 
5.068462850792734 8.965152074981471 37.295448459454875 0.969436379886815 
5.110813343755162 9.098724825744506 37.44632278599364 0.9685759380120599 
5.120180452412469 9.14501098913141 37.4814578178005 0.9680822107633171 
5.14086956638405 9.215845229309943 37.63760135264646 0.9675539004008847 
5.174145208265215 9.315609623330365 37.882238656656014 0.9669184690650311 
5.238703709748942 9.44387870911873 38.311646992982915 0.9662389860690721 
5.336089105409497 9.641754720601735 38.8691866499556 0.9648589956470915 
5.46635939198432 9.959792151996643 40.000980608194034 0.962495426105498 
5.059290375844183 8.977886835003002 37.36686743184441 0.962495426105498 
epoch: 48, train time every whole data:456.30s
epoch: 48, total time:16971.85s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 37.89s
test time on whole data:62.99s
4.479526513230374 7.3970296691757715 34.528294151255444 0.9787053647261069 
4.689832095347956 7.984785734784598 35.09216105007194 0.9753641388605322 
4.870351151656259 8.482666656670037 35.9636648676614 0.9724935464393544 
4.9864986349450575 8.78198027017922 36.626557874079914 0.970767322659417 
5.087251300756969 9.047444931890052 37.10138179570193 0.9691354740771496 
5.14713604722315 9.228118099751027 37.327700275326855 0.9679997862346774 
5.166904535471848 9.314221724800614 37.414030582231824 0.9672495688393709 
5.187311143772073 9.380072324388907 37.60019934303603 0.9667045072995629 
5.210748091398418 9.46249569126992 37.797333871138335 0.9661162433940277 
5.255835017316928 9.553383825855205 38.01639490042949 0.9655362553649058 
5.33758201487314 9.722064998475021 38.50096717849878 0.9642040510105312 
5.455658576949998 10.031751914152396 39.49781736280919 0.9617582554944037 
5.072886260245181 9.061213726520592 37.12220924309459 0.9617582554944037 
epoch: 49, train time every whole data:456.49s
epoch: 49, total time:17507.63s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 37.82s
test time on whole data:62.91s
4.459890368235499 7.396439698478257 33.46652201731788 0.9787290543957198 
4.655437927352928 7.95402536845254 34.088277930464415 0.975448734343024 
4.824172060126409 8.418347484870514 34.897826545334645 0.9726430694818516 
4.92057978123996 8.688570012551674 35.353478756387894 0.9709243351133864 
5.007350796353218 8.926629405643814 35.70471359837254 0.9693430541713206 
5.056791386840067 9.093644781466505 35.81143317107028 0.9682515122408326 
5.073845234582256 9.165123067700838 35.84762368820403 0.9676574572034077 
5.091864270251228 9.226885280596454 35.99852153647136 0.9672090492505845 
5.111124326582418 9.298454193641856 36.09424235881791 0.9667023401726047 
5.157883236695977 9.390078198733276 36.36357420771872 0.966125014886799 
5.250901393792427 9.596564488774307 36.82744108661662 0.9645978049155156 
5.382158955712021 9.921643371206867 37.819594857337364 0.9621095297673301 
4.999333311480367 8.94900143377757 35.68943823641242 0.9621095297673301 
epoch: 50, train time every whole data:456.52s
epoch: 50, total time:18042.96s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 37.81s
test time on whole data:62.87s
4.479962126367815 7.398964656076579 34.59170941196723 0.9786791112680521 
4.700288196845261 8.003428227769948 35.30793267305783 0.9752136865374856 
4.884085774178858 8.489223775508005 36.06071436909651 0.9723428823424097 
4.987465413625732 8.766042622924944 36.412808471665144 0.9705963057737326 
5.071075252441185 9.00070260793553 36.62599959337508 0.968992715168723 
5.11118549990319 9.151402370396026 36.609907489862884 0.967942326075631 
5.117995901978277 9.22408249805946 36.58250420814834 0.9672974712868884 
5.130618686998357 9.26862906856654 36.68181030231653 0.9669609227337435 
5.151647913670588 9.344882637622133 36.790481675179144 0.9664507787909796 
5.195002527084205 9.445666940213714 36.9130447625286 0.9658306577191166 
5.281391933281191 9.631936409989732 37.22658308663692 0.964414138308264 
5.401442670491596 9.938770260376574 38.10206537062286 0.9620242045525942 
5.042680158072188 8.997975555787546 36.49213064782087 0.9620242045525942 
epoch: 51, train time every whole data:456.69s
epoch: 51, total time:18576.53s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 37.93s
test time on whole data:63.14s
4.473661271887913 7.42115377796812 34.15978365731205 0.9785946391649569 
4.672257929497421 7.990679464323147 34.70662735854001 0.975309578176364 
4.841171410245617 8.439276037690824 35.50717970888181 0.9726821171991651 
4.938383988943551 8.70655542843763 36.08752717544926 0.9710430010285855 
5.0160256803177115 8.905218577257255 36.46529003375227 0.9697236192151355 
5.053614489222496 9.044892664676706 36.5658662098609 0.9687624214560414 
5.064766149819441 9.108822505901733 36.56529778016173 0.9681458836181965 
5.083686835062515 9.16944994529947 36.68839599435924 0.9676696328336948 
5.112245252759406 9.259660055563689 36.90487674379003 0.9671003347970737 
5.168169162965073 9.353128501014478 37.357309400474634 0.9666648523562975 
5.268777473515327 9.552005046279216 37.98774878048213 0.9653258590321177 
5.40500399166199 9.874058241491808 39.1620075628142 0.9630025504533187 
5.008146969658205 8.925957342660025 36.51316048623977 0.9630025504533187 
epoch: 52, train time every whole data:459.60s
epoch: 52, total time:19112.66s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 38.09s
test time on whole data:63.28s
4.448645528615227 7.406967531537551 33.52774536136879 0.9787563495167593 
4.633006157539835 7.935239589643126 34.04652801567837 0.975411628536562 
4.797258584311558 8.38463591550929 34.85062560566731 0.972513086335092 
4.904699523857706 8.669921315154525 35.45485491764377 0.9707047176808907 
5.001185496436663 8.912169099758927 35.959559642582676 0.9691527926825078 
5.05543522299239 9.067745410317727 36.208479439955035 0.9681862163801295 
5.070006891870751 9.116607333699811 36.407766477948755 0.9678213663725709 
5.082496946272342 9.176205704223062 36.53898524825356 0.9674024394674521 
5.1053207757982975 9.25915503865265 36.707378603349994 0.9668541757167856 
5.163191255059735 9.374891016945393 37.16822346143784 0.9661690777327286 
5.260127036184632 9.58040533762775 37.7578712474714 0.9647058475403318 
5.395506226812445 9.914608472294196 38.874288799832215 0.9622069676490549 
4.993073303812632 8.9254834458167 36.12519314581646 0.9622069676490549 
epoch: 53, train time every whole data:459.95s
epoch: 53, total time:19650.70s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 37.94s
test time on whole data:63.12s
4.46472298423918 7.3896826928812684 34.41874640117044 0.978708358531481 
4.669485362075573 7.954566204371561 35.242137372464995 0.9753652429795356 
4.856299862086608 8.454089028881775 36.3157360591228 0.9724566357179691 
4.969717198549101 8.735809087174225 37.038861703670825 0.9707896160549949 
5.056209936099126 8.952447347581725 37.47741676044522 0.9694191521786167 
5.101836356190005 9.092523015315805 37.6222123176972 0.9686048385355532 
5.122030306321219 9.147037926187382 37.81443217081444 0.968255905486552 
5.142472787790958 9.221421771437353 37.827521618782555 0.9678615340010159 
5.175024665211555 9.332528215979627 37.857934616312185 0.9672509033052249 
5.235899263252732 9.471135089561304 38.08506265265861 0.9665351731135163 
5.342384842538611 9.712974441296947 38.52159739666629 0.964825609386744 
5.4768651805982635 10.063959320482168 39.44483439103153 0.9621005564670264 
5.0510790620794115 8.988953214040537 37.30554160688359 0.9621005564670264 
epoch: 54, train time every whole data:460.14s
epoch: 54, total time:20188.79s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 38.03s
test time on whole data:63.30s
4.467715297617646 7.405737534057154 34.15512410845088 0.9786308947753 
4.662373358884115 7.951152140645875 34.78184799913686 0.9753091777804245 
4.842115430578168 8.429768380588055 35.7493909760062 0.9724270815337012 
4.9597947300479115 8.727694307223747 36.49360107502129 0.9706748736497699 
5.0601330539801 8.978975957390661 37.01416342118008 0.9691236457382842 
5.1254915161116825 9.15993077359705 37.30439235908922 0.9680260314896212 
5.153842215688857 9.22235737037404 37.563512837432846 0.9675868551477026 
5.18179538757777 9.293079403854138 37.7716047317328 0.9671450551038615 
5.212720143949033 9.397311472082293 37.968831664692 0.9664673263044401 
5.266350319090033 9.506313918294678 38.10333078041168 0.9658776004942841 
5.365550683920011 9.730925994298534 38.52131224464301 0.9643082737178614 
5.501928010043387 10.08507029961585 39.53158509419429 0.9616878918690367 
5.06665084562406 9.019968513538311 37.07989178295017 0.9616878918690367 
epoch: 55, train time every whole data:460.24s
epoch: 55, total time:20723.69s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 38.02s
test time on whole data:63.17s
4.460904051788482 7.392923778023203 33.18529747220691 0.9788218466831222 
4.644486985030887 7.933077637632914 33.836662059934305 0.9756093888190597 
4.807230249540034 8.400811660897972 34.6146163517128 0.9727680463521923 
4.91158270113718 8.681053029577816 35.07938085760383 0.9710180235631508 
5.0043725458796064 8.927762331187274 35.45576613746484 0.9694118821569117 
5.062039495818917 9.106056079799611 35.61136153295699 0.9682923202463903 
5.0849808562839405 9.18316264162177 35.70094950127351 0.9677073650041278 
5.109688229449317 9.249792545858467 35.93559699409738 0.9672174882691169 
5.140345835643449 9.353713798149625 36.09031707503302 0.9665509596911009 
5.19703172584042 9.473069893822291 36.46079294939707 0.9658305058282114 
5.302707165786183 9.709563029052406 37.056626957277 0.9641128790166622 
5.434491420887705 10.035937295386011 38.0727092642667 0.9616486581170542 
5.013321771923843 8.982688737761606 35.591673989195336 0.9616486581170542 
epoch: 56, train time every whole data:460.16s
epoch: 56, total time:21261.40s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 38.01s
test time on whole data:63.31s
4.480447505239876 7.388967684794782 34.84342658209365 0.9787109863174966 
4.677234628948697 7.9414537255975235 35.4576031749973 0.9754201039701509 
4.847012756949386 8.4075029602919 36.07513057640351 0.9725917258029648 
4.963790948843171 8.704478199527331 36.6787132975928 0.9707865640168389 
5.062029958267306 8.95452384158605 37.1576784194686 0.9692303233762672 
5.115353460069025 9.123676422238773 37.34990148384004 0.9681999485150818 
5.126789244212446 9.189457860623273 37.323691417753125 0.9676636805422447 
5.13760735033076 9.242021913906557 37.34795593745574 0.9672316026332395 
5.149000503524529 9.303968075367866 37.34534356354418 0.9667972762201185 
5.185288130913585 9.384954380430445 37.350567555976575 0.9662652348573647 
5.273315359379481 9.585582518247787 37.84976588584793 0.9647557704942574 
5.3982697807227735 9.91320750623652 38.88561862466579 0.9622690703351863 
5.034678302283419 8.954514303498577 36.972116949254534 0.9622690703351863 
epoch: 57, train time every whole data:460.29s
epoch: 57, total time:21798.73s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 37.97s
test time on whole data:63.23s
4.546212872114407 7.411356442949445 38.04939682366476 0.9786895902525994 
4.757369401403214 7.984160258076627 38.8482515609611 0.9752901489536262 
4.947847087741931 8.473364726403801 39.83449321237658 0.972392387052713 
5.074367176389656 8.762762634547292 40.71671036169575 0.9707149358583056 
5.172027842221132 8.992125579247253 41.2368968045473 0.9693040455202981 
5.21900122562339 9.136520936750172 41.382797376334466 0.9684590023478694 
5.23342311449717 9.194908956212984 41.42867938672959 0.9679994819605107 
5.245245384363003 9.255416474317736 41.29947339467356 0.9675739166909694 
5.265960707350721 9.335927241445194 41.318518252358224 0.9670810687281223 
5.319280876583249 9.452661187432334 41.47444603173297 0.9665561427692897 
5.432846286283496 9.688639849723742 42.125888802934995 0.965019391414755 
5.578280742999268 10.026173984609445 43.32103313851505 0.9625577677324405 
5.149321893130886 9.003279995383108 40.919716385680815 0.9625577677324405 
epoch: 58, train time every whole data:460.64s
epoch: 58, total time:22336.19s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 37.93s
test time on whole data:63.18s
4.503865531125451 7.397227203280044 35.63292073698136 0.9787384486884176 
4.697608719639563 7.9596415857718705 36.101043408812316 0.9754578854066941 
4.867247422075638 8.44593174798022 36.67123298954815 0.9725143719273196 
4.974879306615349 8.732570713620527 37.04249113838626 0.9707454421347483 
5.0666854056866315 8.985307535394668 37.25285764433507 0.9690694553048725 
5.114900297058644 9.149816426526705 37.29585559798075 0.9679912208803 
5.124328122876393 9.194446096096634 37.27742071317321 0.9675395271587072 
5.1387472766335 9.240239337368932 37.328528147089074 0.9671619986594441 
5.16127595328084 9.311992676720356 37.44269632023424 0.966708343105866 
5.216212610888197 9.41057004946747 37.61527245936125 0.9661636217778616 
5.3250481722270555 9.635139600427138 38.19648327295872 0.9646580994453635 
5.473839427722465 9.988957271380634 39.46960398181395 0.9621818748586967 
5.05538652048581 8.981130180169783 37.27720168721214 0.9621818748586967 
epoch: 59, train time every whole data:458.68s
epoch: 59, total time:22871.15s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 37.97s
test time on whole data:63.14s
4.452344944569804 7.400406258451638 33.58061194803808 0.9786676494521337 
4.651674645908198 7.957980660144072 34.2230166737132 0.975409872730741 
4.823437210264613 8.440758192370668 34.935235317347185 0.9725545707378812 
4.928828823438776 8.722644235453988 35.40247710990768 0.9708177760857711 
5.0176273005108545 8.958389242676446 35.77589219585375 0.9692389810550952 
5.072334542437955 9.129396011844479 35.97216970422797 0.9681460743190435 
5.094109740371593 9.201093126599357 36.13917781732338 0.96761005555636 
5.119813022325285 9.280197945798037 36.38405495058029 0.967133522390959 
5.158608525309287 9.386638931103667 36.64652584508421 0.9665359953957329 
5.228699273950324 9.525132283944258 37.099423518806894 0.9658622409834231 
5.332077951697687 9.739269191993188 37.658271581607124 0.9643975713964675 
5.4628573378980345 10.0780009665432 38.66752704193902 0.9618289509366346 
5.028534443223534 9.014173060727577 36.0403661408787 0.9618289509366346 
epoch: 60, train time every whole data:457.68s
epoch: 60, total time:23407.13s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 38.01s
test time on whole data:63.23s
4.452038559706607 7.40830423855385 33.27860878607957 0.9786706384037022 
4.641284238209137 7.955662897763977 33.91770023416537 0.9753571874575028 
4.801719971398702 8.404049903705305 34.61973266555922 0.9725610225603283 
4.895735321151069 8.66896891307937 35.00016441918729 0.9708225465534974 
4.9778032662728595 8.898108247349798 35.29125555113049 0.9692622841597318 
5.019233882636621 9.036423202661037 35.4028598844448 0.9683713703102044 
5.038130284751697 9.10554591449272 35.528278675513484 0.9679097885797406 
5.0614183159919195 9.177348733852813 35.789784962500626 0.9675076917372367 
5.097082437795173 9.2696283129339 36.04323929277486 0.9670466437230868 
5.154927288512861 9.378779613082953 36.32444385503296 0.9665352066713608 
5.2644588016204485 9.616072498301675 36.873987638607055 0.9649723580457179 
5.409425586261035 9.970409461892771 37.966224546252306 0.9623835067906051 
4.984438162859011 8.933495129369813 35.503024254106 0.9623835067906051 
epoch: 61, train time every whole data:458.55s
epoch: 61, total time:23944.30s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 37.88s
test time on whole data:63.05s
4.467309126990217 7.393435991628973 33.97103481990931 0.9786922803113208 
4.672839700347736 7.975737603997203 34.61052978499023 0.975296706226639 
4.85068778336669 8.458771226287354 35.3008360832912 0.9724193080533794 
4.960354550671422 8.7345013175853 35.74010763457988 0.9708105565252384 
5.054042057577364 8.986562308272834 35.99531755621596 0.9692370913203121 
5.1074970281623555 9.175693605064218 35.99681538493887 0.9679949306244067 
5.117857809764151 9.254748965641092 35.879588873109284 0.9672512305341597 
5.126491932810867 9.326443354187713 35.89584528460713 0.9666287705610556 
5.144566367248192 9.401951087943901 35.940717209406614 0.9660222528793738 
5.183820266527269 9.499752319185756 36.14149700571541 0.9653873540120985 
5.276037244410216 9.675351988903593 36.75649865170482 0.9641246058000762 
5.407264408991331 9.991553426983588 37.93274343167511 0.9617712706697888 
5.030730689738984 9.017518800024309 35.846795539018096 0.9617712706697888 
epoch: 62, train time every whole data:457.95s
epoch: 62, total time:24479.69s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 38.04s
test time on whole data:63.38s
4.46029713338168 7.394372392141421 34.30007098259287 0.978690853694703 
4.654705108224751 7.940275323220711 35.0128644838089 0.9754109058418687 
4.8241416738435925 8.416035485678432 35.61817139191651 0.9724965562978157 
4.925558142675216 8.677246815932884 35.968330414212744 0.9708541679610873 
5.011559684282953 8.920785407005525 36.21451788018958 0.969207284242499 
5.063429861176526 9.092690343617578 36.32919283820977 0.9680573869895464 
5.080223044173974 9.156705861069403 36.429847236101715 0.9675341722850749 
5.100092443131708 9.221290051654886 36.70004720938878 0.9670624518157789 
5.1292442622007 9.302959010605695 36.956535633076186 0.9665486017504827 
5.172614724208834 9.406280991259454 37.020459190305424 0.9659137422934804 
5.2657872327002195 9.61189789885186 37.30071424327613 0.964427382479105 
5.394320016264858 9.949947490149357 38.16625405378979 0.9618501270731283 
5.006831110522084 8.95077775020556 36.3347507038802 0.9618501270731283 
epoch: 63, train time every whole data:457.54s
epoch: 63, total time:25015.49s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 37.92s
test time on whole data:63.07s
4.444605149809875 7.37759347100328 33.02086420582157 0.9788691781806913 
4.625599660831722 7.9017359273220835 33.65694008404988 0.9756639821259759 
4.801535117054375 8.394454910804296 34.469852832897764 0.9726437925522429 
4.918000670531137 8.69780810659162 35.02341069722606 0.9707961505230379 
5.024063061943212 8.982907012791188 35.51320927096006 0.968990463639844 
5.083149330204002 9.153979166268867 35.74543191610021 0.968025688807608 
5.1087926913019786 9.225184449145381 35.9571691706991 0.9676005412483057 
5.1354994907934515 9.300933290982828 36.202697497967236 0.9671682415190515 
5.172491920063411 9.400338000534072 36.42753460445217 0.9666228803101239 
5.236708723186111 9.523842397093826 36.81908904740427 0.9660159232983608 
5.3535845408767475 9.768926182744075 37.477882158961194 0.9643079719560814 
5.495950288929057 10.1115489902022 38.57792316830431 0.9616571003517307 
5.033331720460423 9.017712508596036 35.74100128739944 0.9616571003517307 
epoch: 64, train time every whole data:457.29s
epoch: 64, total time:25551.94s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 38.01s
test time on whole data:63.17s
4.478903384261184 7.415057614796379 34.27595039185889 0.9785593328482298 
4.683116274667924 7.993945665943376 34.816369536370615 0.9751016471294705 
4.862598892250637 8.491161609008396 35.39692171657306 0.9720669576063217 
4.974636074565377 8.77322259920936 35.85031863549213 0.9703411334013949 
5.061698176171728 8.992839253147183 36.237526584593496 0.9689293628685544 
5.112048366403816 9.13370737998239 36.42811096193117 0.9680958810131387 
5.135358692829741 9.197364882861327 36.6045694646322 0.9676575957392816 
5.156604629240792 9.251781896912709 36.85161386603593 0.9673409709967621 
5.191669374476366 9.356193042482355 37.04740584236036 0.9667847793817134 
5.2448642337262115 9.485335546988976 37.32902780273745 0.9661245112416658 
5.35230954553908 9.717066192769767 37.9225802173522 0.964553537941649 
5.4818739480940195 10.05209601461958 39.01501356731556 0.962096093204094 
5.06130679935224 9.015792684450858 36.481284820192215 0.962096093204094 
epoch: 65, train time every whole data:457.77s
epoch: 65, total time:26091.31s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 38.08s
test time on whole data:63.29s
4.462408368149372 7.404697076748351 33.17980333491135 0.9786852428725628 
4.653792652406777 7.9699713294308765 33.790879355514306 0.9753057923666761 
4.825802073722277 8.454696295685851 34.52857118619442 0.9723356662255632 
4.920279873439254 8.702452766692156 34.96538636082411 0.970786705733524 
5.0008884716336 8.918257127459611 35.369411085335535 0.9693681085684965 
5.040719959960992 9.058953248272143 35.52679608423042 0.9685091831488394 
5.057479222676414 9.110152980312243 35.677172452282015 0.9681629996683968 
5.080683907124071 9.183539977685362 35.91910142818479 0.9676954919791019 
5.114913309582519 9.300617271859437 36.101485659552026 0.9669850455083526 
5.171126826959064 9.425096028941892 36.39111061156299 0.9663326100559777 
5.281655079979587 9.651078088684441 36.948805131193865 0.9647769763303723 
5.414592606467827 9.980025367847587 37.94964003522857 0.962289731221682 
5.002028529341813 8.956259100021441 35.52901428820901 0.962289731221682 
epoch: 66, train time every whole data:458.79s
epoch: 66, total time:26633.23s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 37.97s
test time on whole data:63.14s
4.451531221053266 7.4053007023917345 33.15171649986727 0.9787078941995281 
4.644539765829141 7.946772782837671 33.966521687978926 0.9753556870600892 
4.819107812448768 8.419119201159003 34.83777952033768 0.972484720872646 
4.921718214278073 8.685945441741142 35.35526277023288 0.9708567087170904 
5.012159483083963 8.932388893666024 35.72868700780704 0.9692455640798564 
5.064607992789795 9.09940436626325 35.93271974200315 0.9681682539915917 
5.090229666464243 9.17941107406731 36.17049124528733 0.9675372097223158 
5.114878973271647 9.276900647289832 36.320869154603486 0.9668013488624343 
5.1398558827831335 9.371466180742571 36.436298017841445 0.9661695923557233 
5.180683583150126 9.472038716503619 36.60374469443134 0.9656059621199677 
5.275990257589356 9.65539963511513 37.02722528901175 0.9643810675653789 
5.403888489336951 9.958428252505616 37.94138628157935 0.9621596354056771 
5.009932611839872 8.977597247908285 35.78939217061377 0.9621596354056771 
epoch: 67, train time every whole data:459.85s
epoch: 67, total time:27172.50s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 38.00s
test time on whole data:63.20s
4.453449457994373 7.397379998197025 33.31583710782246 0.9786926303207869 
4.65006791197235 7.967975417779085 34.00618388841859 0.9752973359726209 
4.822614791747376 8.447682466184249 34.77215537268108 0.9724544167363965 
4.918796900112777 8.69863464804821 35.22279031494061 0.9709440678719267 
4.997257524477338 8.928260143366355 35.475372780184856 0.9694282961162266 
5.038755792249301 9.092615573751278 35.54104698300043 0.9683632613235795 
5.047438275617021 9.14111725406032 35.53405225506655 0.9679445488689515 
5.05831053525855 9.190356874726625 35.697233263305336 0.9676107069003682 
5.083891295367932 9.280154285913621 35.93926651437729 0.9670753157103228 
5.140059742365066 9.401146211956117 36.30628818966288 0.9664330406858772 
5.250049751507691 9.633778982908908 36.96944024879776 0.9648510452925794 
5.384354723483722 9.963547171553783 38.066766529168895 0.9623626761620044 
4.987087225179458 8.954684070283065 35.570537357216274 0.9623626761620044 
epoch: 68, train time every whole data:460.50s
epoch: 68, total time:27710.85s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 37.98s
test time on whole data:63.19s
4.475945985812668 7.399365094961559 34.50671303662095 0.9786553783837697 
4.685415104113841 7.989469277503168 35.242576473086466 0.9752056836193254 
4.870422326866137 8.501315663160163 36.08675262493753 0.9722197404943017 
4.990703876423301 8.780866490053434 36.82595515347432 0.9706976354090723 
5.085356574422872 9.014069724160338 37.342174188729786 0.9693460108498427 
5.138894742503635 9.168839729798082 37.59946274216495 0.9684455216141251 
5.1561884828328 9.228974004918307 37.750961796322215 0.967989752812583 
5.172771901682448 9.297100214006864 37.806798410107255 0.9674668340127495 
5.203661767542135 9.405528138240166 37.92636971390091 0.9667271665330843 
5.265600607260953 9.548714410097741 38.221408381100765 0.9659557545649646 
5.373243245149963 9.78212652072195 38.77790127772106 0.9643248994637655 
5.50335891541276 10.112892058374584 39.84013698982049 0.9618200870375744 
5.076796960835293 9.048442810403037 37.327268282676826 0.9618200870375744 
epoch: 69, train time every whole data:460.11s
epoch: 69, total time:28247.51s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 37.97s
test time on whole data:63.33s
4.466808001510632 7.428862338142397 33.58315762865758 0.9786111810997727 
4.663437874777899 7.985641162490911 34.320748116071286 0.975099936929026 
4.845579715053919 8.466689583365232 35.124526001284735 0.9720922169718179 
4.951305975790482 8.733385466647805 35.60855998251911 0.9704524674465559 
5.028455408927166 8.946358178148081 35.91061050188273 0.9690834584556081 
5.065019862926567 9.082763920604712 35.96499257522834 0.9682052841493871 
5.080198245263078 9.155483395632116 36.01357294320458 0.9676126941610541 
5.089714853010083 9.221090009255374 36.00192198227215 0.9670883144034657 
5.102711924497719 9.295168914862785 36.047509953734476 0.9665502765689468 
5.141734608498642 9.382313099025723 36.18178104109984 0.9660398978157425 
5.2400266881389435 9.586981144811592 36.67195479377266 0.9646276934246076 
5.3660435985471695 9.902642110610769 37.63218124595811 0.9622725187615155 
5.0034197297451914 8.956846121667194 35.755127101225874 0.9622725187615155 
epoch: 70, train time every whole data:461.27s
epoch: 70, total time:28786.12s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 37.97s
test time on whole data:63.16s
4.4646435704775325 7.4173648134143875 33.42721894599664 0.9786307999762873 
4.67027012164027 8.017365306531207 34.18355896218377 0.9751968482709912 
4.860051282244207 8.536202508764143 35.02465890036093 0.9722549079856254 
4.978873668173998 8.833167670477494 35.636578689672014 0.9706011424114196 
5.071254988209299 9.07771441759549 36.044975255668405 0.9690745493119534 
5.117416648316153 9.231620476547603 36.16599256200067 0.9680134803444075 
5.1232126320474185 9.28229585815967 36.139245631368716 0.9674563139577461 
5.127884051055943 9.327363194724134 36.132714972014654 0.9669978541549827 
5.140083472819974 9.385665708851986 36.20453828813795 0.9665800045514805 
5.184682424562592 9.479994716380435 36.41962805628764 0.9660643575143723 
5.287162606105058 9.682794082325811 37.02773689031383 0.9647293964619177 
5.416586387274448 10.009015407643638 38.099547709817664 0.9623590497184583 
5.036843487743908 9.050199809609532 35.8755338995866 0.9623590497184583 
epoch: 71, train time every whole data:461.03s
epoch: 71, total time:29322.97s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 37.88s
test time on whole data:63.01s
4.506417831267199 7.400801173602386 36.0629283785837 0.9787048840257406 
4.724776608441869 8.003513465275892 36.88961720269147 0.9752030744560113 
4.92042766982095 8.522221365858108 37.73900224265552 0.9721651723609066 
5.053877428918777 8.825667075429386 38.54355281167997 0.9704883245444736 
5.1583653075399285 9.09259500879885 39.00707394107092 0.9688802784882091 
5.217572511180704 9.2679715519125 39.19570428749511 0.9678325842751693 
5.238144192075863 9.329986039574992 39.328555296618525 0.9673706108245563 
5.2529732932191076 9.395719696186175 39.312846895356856 0.9669121495139473 
5.2836728939726365 9.49209609996723 39.38777693032737 0.9663441892714517 
5.3391663079575835 9.617396455179565 39.44614281929656 0.965679878526819 
5.455240311704288 9.861436901645526 40.013466631241336 0.9640437336434494 
5.5866841924808766 10.198961636165855 41.0005473122411 0.9614938138360697 
5.144776545714982 9.115501769386888 38.82726843142457 0.9614938138360697 
epoch: 72, train time every whole data:460.61s
epoch: 72, total time:29859.40s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 37.93s
test time on whole data:63.02s
4.463635855225741 7.426403851319849 33.14395175082162 0.9786249324792086 
4.646286217132757 7.972693793039081 33.83787041897753 0.9752557114851674 
4.81394026985454 8.445571701747381 34.65090490636255 0.9723455480523134 
4.918546437199727 8.70525032810529 35.21905579120557 0.9707802684218663 
5.001389703942854 8.926287559874805 35.61634589622521 0.9694032472899675 
5.04358723772464 9.065765547052106 35.77111401014316 0.9685512912249651 
5.0615895908216535 9.119787960409768 35.9104580484274 0.9681091412855113 
5.085166432544395 9.19859568546438 36.04274592856474 0.9675125523057235 
5.114485900489729 9.29624859075649 36.202219738955385 0.966833174752935 
5.167733504032937 9.418009225616686 36.44960998296932 0.9660443303886125 
5.269612768166033 9.63506627272098 36.9159139278802 0.9644911246861555 
5.391963971040078 9.951122571700795 37.810674158612514 0.962069634885118 
4.998161490681257 8.95569778064803 35.63090593637358 0.962069634885118 
epoch: 73, train time every whole data:459.94s
epoch: 73, total time:30397.32s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 37.85s
test time on whole data:62.95s
4.457286343172461 7.4132106257075865 33.02261118818123 0.9786495452314512 
4.65243078031048 7.9779908703973605 33.82160586921372 0.9752452441090158 
4.8255596296997485 8.453680260382315 34.59204349183228 0.9723882308192348 
4.9243772416057965 8.720213208916416 35.01907342625832 0.9707695487905944 
5.005850682553518 8.95531499035374 35.333014033591695 0.9692471909049103 
5.051184838733243 9.115286491642205 35.47617243233691 0.9682358991580619 
5.067089933619927 9.176550320952291 35.64046396725851 0.9678054272547505 
5.0885847101242785 9.25342768136816 35.90748078094153 0.9672937658529368 
5.121117389317424 9.340046241298335 36.19163765090972 0.9667698956142476 
5.175152040690812 9.459304252546849 36.49478020741585 0.9660654969316251 
5.282026233336786 9.678454128655925 37.10009839604968 0.9645387305697504 
5.410277758012658 10.00225322737028 38.15422902682884 0.9621378033946378 
5.005078131764761 8.98918061332721 35.56276840140289 0.9621378033946378 
epoch: 74, train time every whole data:459.62s
epoch: 74, total time:30933.36s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 37.94s
test time on whole data:63.06s
4.458402859518802 7.3986049068538735 33.073163555410076 0.978731079155922 
4.662662589234892 7.99437499240274 33.90516752383599 0.9751634767181127 
4.841353895949037 8.478053745520906 34.69895033364953 0.9721928718791106 
4.950410052746331 8.753247508376315 35.17705078529029 0.970505993665845 
5.031832881245997 8.973737912845651 35.51335799209566 0.9690834746333373 
5.071125264108235 9.116172926529709 35.636379481616984 0.9681997912764484 
5.083268750318074 9.159199065710395 35.72546840105398 0.9678940718590041 
5.099825440862223 9.223648230192119 35.883766940367636 0.9674495225408285 
5.125127071763562 9.313375178001404 36.027583063117284 0.9668654578636282 
5.178475370439139 9.442258815865436 36.24145523797691 0.9660509047521939 
5.279126364551768 9.664614119323094 36.71399301638454 0.9644528124378692 
5.394959893695493 9.967349527350857 37.583194726247484 0.9620929661102632 
5.014714202869462 8.983287027975843 35.51496147811274 0.9620929661102632 
epoch: 75, train time every whole data:459.90s
epoch: 75, total time:31468.15s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 37.84s
test time on whole data:62.94s
4.45242648835446 7.428895818327033 32.671144472115515 0.9785838950969061 
4.638367582384478 7.980095392716833 33.306895369354535 0.9751804678449788 
4.7958869087671365 8.417655391453229 34.037969571737555 0.972427844177061 
4.899780147014629 8.684296015038218 34.61074725511376 0.9707660775072489 
4.988252086398507 8.925165273323076 35.07586814686388 0.9692027193813976 
5.041407830297705 9.090665926497113 35.32397095256077 0.9681447311625815 
5.064618148573705 9.180910493615496 35.507721894354304 0.9674947794977548 
5.083507774238342 9.251651161571923 35.721138192554584 0.9669589908054038 
5.104171627789261 9.31519256257241 35.965506279706574 0.9665681310000607 
5.152872178814752 9.406071137878692 36.3343349803368 0.9660799599169085 
5.256893585280242 9.609437141101374 36.945774638602835 0.9647058016276083 
5.392701348366207 9.950559763811901 38.011311245933534 0.9621741117186802 
4.989240475523285 8.9625479658577 35.29269942104597 0.9621741117186802 
epoch: 76, train time every whole data:458.85s
epoch: 76, total time:32002.62s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 37.80s
test time on whole data:62.89s
4.463347094600074 7.432088397171168 33.313048783733926 0.9785456159361766 
4.656493616099991 7.992027710283835 34.07984141499005 0.9750882268711267 
4.8227723423647335 8.457385887185769 34.82938528947674 0.9722441149430191 
4.923583093239345 8.717737373643317 35.26276548022689 0.9706776135463977 
5.00421724879712 8.93619287462399 35.53413470365436 0.9692882259316197 
5.04792567063273 9.089838606732275 35.61221732800612 0.9683208330941006 
5.064618018320673 9.138711844728581 35.701493858093635 0.9679673540323193 
5.0805414487469225 9.203738717147262 35.82357571024317 0.9675234548222411 
5.110175515712108 9.302236813499958 35.98557695020798 0.9669265193140093 
5.161889064353212 9.421875130648703 36.225742806236276 0.9662598628949625 
5.2751895577615615 9.655260805474265 36.840942735426005 0.9647155618763159 
5.407602417397883 9.974987864991178 37.88867283322933 0.9623370702212963 
5.001529590668863 8.969244302103236 35.591450756466635 0.9623370702212963 
epoch: 77, train time every whole data:458.53s
epoch: 77, total time:32538.09s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 37.82s
test time on whole data:62.94s
4.501491239933798 7.432972775230472 35.69712616178599 0.9784539931864282 
4.70714230284597 8.037773779084153 36.378071107602814 0.9748557598957459 
4.894812380188857 8.53956202586167 37.110956477327925 0.971856538781772 
5.010842129890565 8.827184102364242 37.54168257981219 0.9701712630163987 
5.1022963453867165 9.063912422663282 37.885308197251675 0.9686862266821243 
5.152576534166973 9.214207599330836 38.08847929449306 0.9677243226726626 
5.1756828572235785 9.27146744143724 38.44753020121993 0.9672673915702552 
5.191199709327273 9.324798506598762 38.53885131413464 0.9668510391902019 
5.220888001161383 9.422063364613345 38.80039782242053 0.9662611830931913 
5.281848784417416 9.561919788612682 39.27780200763246 0.965548789286283 
5.393245820456654 9.790274600041837 39.84227928636253 0.9640690603403895 
5.524390452886614 10.120653938183944 40.87232744037902 0.9616865604167448 
5.0963680464904835 9.079046375852425 38.20673503440819 0.9616865604167448 
epoch: 78, train time every whole data:458.58s
epoch: 78, total time:33073.63s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 37.86s
test time on whole data:62.96s
4.495210769077922 7.43039926416191 34.890034100529874 0.9785844378266729 
4.694501821648191 8.016656040776828 35.49836387419694 0.9752030735224425 
4.866490286668063 8.496132819191372 36.124060565838576 0.9723414691127351 
4.97669159570041 8.774506859483099 36.642857443076934 0.9706726814384481 
5.0697331064199975 9.028004772107954 36.990968287800605 0.9690292370836668 
5.121790880644131 9.1986410966619 37.121957491650846 0.9679575648914092 
5.138002697138731 9.256226440215892 37.20780087995052 0.9675355784341088 
5.156067667589091 9.338443635580795 37.3036435142291 0.9669633095073591 
5.187449514256998 9.42886802854234 37.503526310016895 0.9664475347553795 
5.247639274356684 9.562205017842691 37.83645078950054 0.9657463080283353 
5.368154044007893 9.804691262485797 38.549088605215516 0.9641715283656602 
5.505389508199396 10.136653212679583 39.72808205778163 0.9617502032947122 
5.068926763808959 9.068631845805198 37.116403982969175 0.9617502032947122 
epoch: 79, train time every whole data:458.15s
epoch: 79, total time:33612.40s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 37.89s
test time on whole data:62.99s
4.462209842690142 7.398802000199703 34.098022687610666 0.9786746071536196 
4.662320601787486 7.981934804875879 34.87010279502637 0.9752736144749042 
4.849588275661244 8.500109764166671 35.71213187888559 0.9722490269067587 
4.970494801706174 8.796267285743685 36.44857997766974 0.970538753406853 
5.066320442370427 9.037488245414064 36.94369563100362 0.9689670253540481 
5.122965187436627 9.219828130548132 37.206874999507505 0.9677648242364411 
5.144314228611819 9.286170211675122 37.400806486869364 0.9672345833117661 
5.159840920919451 9.357641296007584 37.415532750810996 0.9666902312167298 
5.1765687628549975 9.4166814903175 37.45986928029187 0.9663693256066803 
5.219093073267077 9.518726308595559 37.4479636148378 0.965852829920931 
5.328571555981125 9.732067323070341 37.914218381219065 0.9644991859518046 
5.4597357545553 10.055738622978689 38.902990125202244 0.9621385035071596 
5.051835287320156 9.053869454837361 36.81839936067295 0.9621385035071596 
save parameters to file: experiments/taxi/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention1_spt_trend_adj/epoch_79.params
