total training epoch, fine tune epoch: 30 , 50
batch_size: 4
folder_dir: MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention1_spt_trend
load file: data/bike.npz
ori length: 3001 , percent: 1.0 , scale: 3001
train: torch.Size([3001, 250, 2, 12]) torch.Size([3001, 250, 2, 12]) torch.Size([3001, 250, 2, 12])
val: torch.Size([672, 250, 2, 12]) torch.Size([672, 250, 2, 12]) torch.Size([672, 250, 2, 12])
test: torch.Size([672, 250, 2, 12]) torch.Size([672, 250, 2, 12]) torch.Size([672, 250, 2, 12])
TemporalPositionalEncoding max_len: 12
h_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
en_lookup_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
EncoderDecoder(
  (encoder): Encoder(
    (layers): ModuleList(
      (0): EncoderLayer(
        (self_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (2): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (3): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (feed_forward_gcn): ModuleList(
          (0): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn_cross): spatialAttentionScaledGCN_cross(
          (Theta): Linear(in_features=64, out_features=64, bias=False)
          (SAt_cross): Spatial_Attention_layer_cross(
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (Gate): Linear(in_features=64, out_features=1, bias=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (6): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (7): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (sublayer2): SublayerConnection2(
          (dropout): Dropout(p=0.0, inplace=False)
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): EncoderLayer(
        (self_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (2): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (3): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (feed_forward_gcn): ModuleList(
          (0): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn_cross): spatialAttentionScaledGCN_cross(
          (Theta): Linear(in_features=64, out_features=64, bias=False)
          (SAt_cross): Spatial_Attention_layer_cross(
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (Gate): Linear(in_features=64, out_features=1, bias=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (6): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (7): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (sublayer2): SublayerConnection2(
          (dropout): Dropout(p=0.0, inplace=False)
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): EncoderLayer(
        (self_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (2): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (3): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (feed_forward_gcn): ModuleList(
          (0): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn_cross): spatialAttentionScaledGCN_cross(
          (Theta): Linear(in_features=64, out_features=64, bias=False)
          (SAt_cross): Spatial_Attention_layer_cross(
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (Gate): Linear(in_features=64, out_features=1, bias=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (6): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (7): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (sublayer2): SublayerConnection2(
          (dropout): Dropout(p=0.0, inplace=False)
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): Decoder(
    (layers): ModuleList(
      (0): DecoderLayer(
        (self_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_qc_kc(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_qc_kc(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (src_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (2): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (3): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (feed_forward_gcn): ModuleList(
          (0): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn_cross): spatialAttentionScaledGCN_cross(
          (Theta): Linear(in_features=64, out_features=64, bias=False)
          (SAt_cross): Spatial_Attention_layer_cross(
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (Gate): Linear(in_features=64, out_features=1, bias=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (6): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (7): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (8): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (9): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (sublayer2): SublayerConnection2(
          (dropout): Dropout(p=0.0, inplace=False)
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): DecoderLayer(
        (self_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_qc_kc(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_qc_kc(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (src_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (2): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (3): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (feed_forward_gcn): ModuleList(
          (0): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn_cross): spatialAttentionScaledGCN_cross(
          (Theta): Linear(in_features=64, out_features=64, bias=False)
          (SAt_cross): Spatial_Attention_layer_cross(
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (Gate): Linear(in_features=64, out_features=1, bias=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (6): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (7): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (8): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (9): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (sublayer2): SublayerConnection2(
          (dropout): Dropout(p=0.0, inplace=False)
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): DecoderLayer(
        (self_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_qc_kc(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_qc_kc(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (src_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (2): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (3): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (feed_forward_gcn): ModuleList(
          (0): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn_cross): spatialAttentionScaledGCN_cross(
          (Theta): Linear(in_features=64, out_features=64, bias=False)
          (SAt_cross): Spatial_Attention_layer_cross(
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (Gate): Linear(in_features=64, out_features=1, bias=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (6): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (7): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (8): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (9): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (sublayer2): SublayerConnection2(
          (dropout): Dropout(p=0.0, inplace=False)
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (src_embed): Sequential(
    (0): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (1): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(250, 64)
    )
  )
  (src_embed2): Sequential(
    (0): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (1): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(250, 64)
    )
  )
  (trg_embed): Sequential(
    (0): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (1): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(250, 64)
    )
  )
  (trg_embed2): Sequential(
    (0): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (1): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(250, 64)
    )
  )
  (prediction_generator): Linear(in_features=64, out_features=1, bias=True)
  (prediction_generator2): Linear(in_features=64, out_features=1, bias=True)
)
delete the old one and create params directory experiments/bike/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention1_spt_trend
Net's state_dict:
encoder.layers.0.self_attn.0.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.0.linears.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.0.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.0.linears.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.1.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.1.linears.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.1.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.1.linears.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.2.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.2.linears.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.2.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.2.linears.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.2.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.2.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.2.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.2.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.3.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.3.linears.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.3.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.3.linears.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.3.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.3.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.3.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.3.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.0.feed_forward_gcn.0.Theta.weight 	 torch.Size([64, 64])
encoder.layers.0.feed_forward_gcn.1.Theta.weight 	 torch.Size([64, 64])
encoder.layers.0.feed_forward_gcn_cross.Theta.weight 	 torch.Size([64, 64])
encoder.layers.0.feed_forward_gcn_cross.Gate.weight 	 torch.Size([1, 64])
encoder.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.2.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.2.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.3.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.3.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.4.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.4.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.5.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.5.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.6.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.6.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.7.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.7.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer2.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer2.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer2.norm2.weight 	 torch.Size([64])
encoder.layers.0.sublayer2.norm2.bias 	 torch.Size([64])
encoder.layers.1.self_attn.0.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.0.linears.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.0.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.0.linears.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.1.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.1.linears.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.1.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.1.linears.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.2.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.2.linears.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.2.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.2.linears.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.2.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.2.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.2.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.2.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.3.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.3.linears.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.3.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.3.linears.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.3.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.3.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.3.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.3.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.1.feed_forward_gcn.0.Theta.weight 	 torch.Size([64, 64])
encoder.layers.1.feed_forward_gcn.1.Theta.weight 	 torch.Size([64, 64])
encoder.layers.1.feed_forward_gcn_cross.Theta.weight 	 torch.Size([64, 64])
encoder.layers.1.feed_forward_gcn_cross.Gate.weight 	 torch.Size([1, 64])
encoder.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.2.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.2.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.3.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.3.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.4.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.4.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.5.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.5.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.6.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.6.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.7.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.7.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer2.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer2.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer2.norm2.weight 	 torch.Size([64])
encoder.layers.1.sublayer2.norm2.bias 	 torch.Size([64])
encoder.layers.2.self_attn.0.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.0.linears.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.0.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.0.linears.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.0.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.0.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.0.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.0.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.1.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.1.linears.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.1.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.1.linears.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.1.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.1.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.1.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.1.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.2.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.2.linears.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.2.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.2.linears.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.2.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.2.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.2.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.2.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.3.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.3.linears.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.3.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.3.linears.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.3.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.3.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.3.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.3.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.2.feed_forward_gcn.0.Theta.weight 	 torch.Size([64, 64])
encoder.layers.2.feed_forward_gcn.1.Theta.weight 	 torch.Size([64, 64])
encoder.layers.2.feed_forward_gcn_cross.Theta.weight 	 torch.Size([64, 64])
encoder.layers.2.feed_forward_gcn_cross.Gate.weight 	 torch.Size([1, 64])
encoder.layers.2.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.2.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.2.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.3.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.3.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.4.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.4.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.5.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.5.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.6.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.6.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.7.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.7.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer2.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer2.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer2.norm2.weight 	 torch.Size([64])
encoder.layers.2.sublayer2.norm2.bias 	 torch.Size([64])
encoder.norm.weight 	 torch.Size([64])
encoder.norm.bias 	 torch.Size([64])
encoder.norm2.weight 	 torch.Size([64])
encoder.norm2.bias 	 torch.Size([64])
decoder.layers.0.self_attn.0.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.0.linears.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.0.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.0.linears.1.bias 	 torch.Size([64])
decoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.0.self_attn.1.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.1.linears.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.1.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.1.linears.1.bias 	 torch.Size([64])
decoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.0.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.0.linears.0.bias 	 torch.Size([64])
decoder.layers.0.src_attn.0.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.0.linears.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.0.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.0.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.0.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.0.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.1.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.1.linears.0.bias 	 torch.Size([64])
decoder.layers.0.src_attn.1.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.1.linears.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.1.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.1.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.1.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.1.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.2.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.2.linears.0.bias 	 torch.Size([64])
decoder.layers.0.src_attn.2.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.2.linears.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.2.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.2.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.2.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.2.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.3.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.3.linears.0.bias 	 torch.Size([64])
decoder.layers.0.src_attn.3.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.3.linears.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.3.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.3.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.3.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.3.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.feed_forward_gcn.0.Theta.weight 	 torch.Size([64, 64])
decoder.layers.0.feed_forward_gcn.1.Theta.weight 	 torch.Size([64, 64])
decoder.layers.0.feed_forward_gcn_cross.Theta.weight 	 torch.Size([64, 64])
decoder.layers.0.feed_forward_gcn_cross.Gate.weight 	 torch.Size([1, 64])
decoder.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.3.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.3.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.4.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.4.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.5.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.5.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.6.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.6.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.7.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.7.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.8.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.8.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.9.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.9.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer2.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer2.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer2.norm2.weight 	 torch.Size([64])
decoder.layers.0.sublayer2.norm2.bias 	 torch.Size([64])
decoder.layers.1.self_attn.0.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.0.linears.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.0.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.0.linears.1.bias 	 torch.Size([64])
decoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.1.self_attn.1.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.1.linears.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.1.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.1.linears.1.bias 	 torch.Size([64])
decoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.0.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.0.linears.0.bias 	 torch.Size([64])
decoder.layers.1.src_attn.0.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.0.linears.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.0.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.0.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.0.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.0.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.1.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.1.linears.0.bias 	 torch.Size([64])
decoder.layers.1.src_attn.1.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.1.linears.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.1.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.1.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.1.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.1.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.2.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.2.linears.0.bias 	 torch.Size([64])
decoder.layers.1.src_attn.2.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.2.linears.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.2.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.2.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.2.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.2.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.3.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.3.linears.0.bias 	 torch.Size([64])
decoder.layers.1.src_attn.3.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.3.linears.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.3.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.3.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.3.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.3.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.feed_forward_gcn.0.Theta.weight 	 torch.Size([64, 64])
decoder.layers.1.feed_forward_gcn.1.Theta.weight 	 torch.Size([64, 64])
decoder.layers.1.feed_forward_gcn_cross.Theta.weight 	 torch.Size([64, 64])
decoder.layers.1.feed_forward_gcn_cross.Gate.weight 	 torch.Size([1, 64])
decoder.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.3.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.3.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.4.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.4.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.5.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.5.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.6.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.6.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.7.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.7.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.8.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.8.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.9.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.9.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer2.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer2.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer2.norm2.weight 	 torch.Size([64])
decoder.layers.1.sublayer2.norm2.bias 	 torch.Size([64])
decoder.layers.2.self_attn.0.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.0.linears.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.0.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.0.linears.1.bias 	 torch.Size([64])
decoder.layers.2.self_attn.0.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.self_attn.0.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.0.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.self_attn.0.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.2.self_attn.1.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.1.linears.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.1.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.1.linears.1.bias 	 torch.Size([64])
decoder.layers.2.self_attn.1.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.self_attn.1.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.1.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.self_attn.1.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.0.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.0.linears.0.bias 	 torch.Size([64])
decoder.layers.2.src_attn.0.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.0.linears.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.0.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.0.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.0.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.0.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.1.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.1.linears.0.bias 	 torch.Size([64])
decoder.layers.2.src_attn.1.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.1.linears.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.1.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.1.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.1.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.1.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.2.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.2.linears.0.bias 	 torch.Size([64])
decoder.layers.2.src_attn.2.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.2.linears.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.2.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.2.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.2.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.2.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.3.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.3.linears.0.bias 	 torch.Size([64])
decoder.layers.2.src_attn.3.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.3.linears.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.3.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.3.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.3.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.3.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.feed_forward_gcn.0.Theta.weight 	 torch.Size([64, 64])
decoder.layers.2.feed_forward_gcn.1.Theta.weight 	 torch.Size([64, 64])
decoder.layers.2.feed_forward_gcn_cross.Theta.weight 	 torch.Size([64, 64])
decoder.layers.2.feed_forward_gcn_cross.Gate.weight 	 torch.Size([1, 64])
decoder.layers.2.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.3.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.3.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.4.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.4.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.5.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.5.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.6.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.6.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.7.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.7.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.8.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.8.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.9.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.9.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer2.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer2.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer2.norm2.weight 	 torch.Size([64])
decoder.layers.2.sublayer2.norm2.bias 	 torch.Size([64])
decoder.norm.weight 	 torch.Size([64])
decoder.norm.bias 	 torch.Size([64])
decoder.norm2.weight 	 torch.Size([64])
decoder.norm2.bias 	 torch.Size([64])
src_embed.0.pe 	 torch.Size([1, 1, 12, 64])
src_embed.1.embedding.weight 	 torch.Size([250, 64])
src_embed2.0.pe 	 torch.Size([1, 1, 12, 64])
src_embed2.1.embedding.weight 	 torch.Size([250, 64])
trg_embed.0.pe 	 torch.Size([1, 1, 12, 64])
trg_embed.1.embedding.weight 	 torch.Size([250, 64])
trg_embed2.0.pe 	 torch.Size([1, 1, 12, 64])
trg_embed2.1.embedding.weight 	 torch.Size([250, 64])
prediction_generator.weight 	 torch.Size([1, 64])
prediction_generator.bias 	 torch.Size([1])
prediction_generator2.weight 	 torch.Size([1, 64])
prediction_generator2.bias 	 torch.Size([1])
Net's total params: 1140994
Optimizer's state_dict:
state 	 {}
param_groups 	 [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411]}]
predicting testing set batch 1 / 168, time: 0.67s
predicting testing set batch 101 / 168, time: 35.11s
test time on whole data:58.34s
55.46293306368155 64.57489352045121 2290.168499766279 0.05041419897380896 
51.7485327119704 60.70527187337295 2139.586211342504 0.04706563378116056 
51.50298560603326 59.226136436538 2131.194347269812 0.044852723264311035 
53.175621886159604 60.35711634619009 2200.051062851717 0.040028475423082764 
56.461291548160304 63.034018213259834 2333.597345413626 0.035578671855337377 
58.46508862511894 64.76065124258251 2413.8727274555877 0.031373410046192686 
57.55554663874182 64.0786823146495 2375.431733437515 0.026790470262944906 
55.15701654424057 61.96557866722609 2275.396366736495 0.022690163527379736 
54.06802728563148 60.858102136769666 2228.907444301356 0.019359045933495894 
54.72419599914595 61.60235317192704 2253.356384079626 0.01624933634234481 
55.51493080591925 62.833158287102904 2283.042794774464 0.013496487073368377 
54.8733357572991 62.6770457803474 2255.132903913546 0.01172793784790681 
54.892458872675185 62.245334407177204 2264.9803312009776 0.01172793784790681 
epoch: 0, train time every whole data:209.88s
epoch: 0, total time:279.55s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.50s
test time on whole data:59.08s
2.486189491513673 4.161951637825128 61.88375187644716 0.5541898880049848 
2.529208066397391 4.2510701837071325 63.96756896804921 0.5050528698898786 
2.5729561609988587 4.338893227498364 65.39188176315561 0.45696261022651374 
2.6180782973875423 4.413065022754739 66.80624601438609 0.4077352922521334 
2.655761475595158 4.477262856882174 67.45873139972147 0.3647578295827145 
2.711531678416367 4.534969011286104 69.49337286037685 0.3158933852075556 
2.760709261126905 4.590290061982282 70.88661711466746 0.2773180036373912 
2.8027467522143077 4.635193780461143 71.63432375660466 0.24684607145961932 
2.8587786001284563 4.6906440577973205 73.06783980644995 0.21666119883695073 
2.8955634088070976 4.705967489406501 73.47941632735315 0.19601579336097 
2.936999677064252 4.7096825153897015 74.20546315193849 0.17621336797034706 
2.9894392581205107 4.765298140838106 74.99244831202698 0.15643551899384112 
2.73483017731421 4.526768851240504 69.43921689414348 0.15643551899384112 
epoch: 1, train time every whole data:211.38s
epoch: 1, total time:562.71s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 36.30s
test time on whole data:59.88s
2.304993664377768 4.0880581607797275 60.8174294041173 0.665423098216453 
2.3436956700978 4.169860460314391 62.176186820246414 0.629124149157384 
2.3908337824211587 4.261795876450779 63.0272364394956 0.5842889835559936 
2.4348409578137633 4.337305828797926 64.09029792167256 0.5369733415339916 
2.49050190440725 4.420271266656038 65.50601442880809 0.48874252611423796 
2.558131018374204 4.5070142946611 67.33132369656984 0.44102093360035777 
2.6399608520135462 4.606243087817538 69.74959523795862 0.39362626188403993 
2.71743582538196 4.691247095333135 71.81420754127116 0.35033534312187076 
2.805650391769196 4.779037778826472 74.23629862855562 0.30922531942715853 
2.8715815995150202 4.831973877547363 75.78839347491775 0.27295412556551957 
2.9287142896903235 4.863843061637379 76.79106696538476 0.23936672609565193 
3.0150262994163093 4.933311891472803 78.96453408849439 0.2078812010940514 
2.625113854606525 4.54912117463039 69.19138837463785 0.2078812010940514 
epoch: 2, train time every whole data:211.29s
epoch: 2, total time:846.54s
predicting testing set batch 1 / 168, time: 0.34s
predicting testing set batch 101 / 168, time: 35.47s
test time on whole data:58.98s
2.344240412017153 3.6717449837042326 70.70017896788204 0.6153306731986306 
2.3721277880646467 3.7475848563212057 71.71420069909318 0.5869946729192344 
2.508602913306405 3.973023097183005 70.45453914778777 0.5187364030429249 
2.5495734550374602 4.024437415728845 72.37299730102428 0.4927406255281145 
2.603508168918214 4.0740328540216995 74.58846623662716 0.46772394912206433 
2.659954434978288 4.124688385672515 76.54649555218583 0.4420327684472149 
2.7032068888310876 4.175634149538544 76.70241727082595 0.41836849152932853 
2.746474525360923 4.2364081155201765 75.48994127358361 0.3911408813665672 
2.7771132378548917 4.2842093080945 75.6986661973356 0.3642648742526604 
2.8154560789064993 4.330927724916137 76.41668589775857 0.3359538809769346 
2.8663131065365106 4.380759870985188 77.65351102435096 0.3035737854391372 
2.906492862437009 4.437232775498118 77.75392305285634 0.27028239957896566 
2.654421989354091 4.12807926357546 74.67448071350532 0.27028239957896566 
epoch: 3, train time every whole data:211.38s
epoch: 3, total time:1129.42s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.72s
test time on whole data:59.33s
2.7275512312789933 4.603285976628781 75.77510667191656 0.6455038207375187 
2.79599635357321 4.725192441040868 77.13157364737107 0.6015603886952552 
2.947255929977766 4.969469333444885 81.02334116057484 0.5246104760412971 
2.9846434349274884 5.0298686837662085 81.89857670692975 0.4901747040928451 
3.044276362420725 5.116004334303818 82.84671083149794 0.44829176184308 
3.053697353323212 5.137812518129394 82.39614200162644 0.42914333221717244 
3.0712073261303208 5.151656966598534 82.9662652482947 0.42050867146118676 
3.0852638788264954 5.153330496372983 83.20677935580288 0.4198505402054687 
3.101694353212203 5.154897310675011 83.58670302093289 0.4246709731944447 
3.0974196995855974 5.149078901852236 82.85097719394756 0.42431524146851385 
3.0773004270647433 5.130438798428055 81.44709242916156 0.4167909422595139 
3.106047332930778 5.159116781044834 82.68207400166312 0.40625138803624306 
3.007696140270961 5.043178233943606 81.48439868671207 0.40625138803624306 
epoch: 4, train time every whole data:211.57s
epoch: 4, total time:1412.92s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.57s
test time on whole data:59.19s
2.416178103978258 3.739918904152815 76.58935238316923 0.7235814528888171 
2.4790667056482993 3.840995218816036 77.76054583069693 0.7049277423245979 
2.619553052900093 4.12045914632343 80.10768267193596 0.6650079938853122 
2.6511190980053727 4.183293151227245 80.7530597088442 0.649036459048044 
2.737096313661674 4.332268620125887 82.14758940678223 0.6294208014529786 
2.7685778825542933 4.398005413453311 82.20736421451869 0.6228425537078042 
2.819336538990516 4.460112324822294 83.65486407848375 0.6199788644769821 
2.864503682342668 4.509307928350357 85.19558708400085 0.6209485260964779 
2.89812812921121 4.550859056308398 86.45668633160982 0.6168710837999405 
2.95390644599382 4.60453268295547 88.9010955019408 0.6150092277028478 
3.010439238976953 4.682707594899828 90.53844542172892 0.6007636363280058 
3.0783845047164884 4.778188470077997 92.47078442736122 0.5691214980254651 
2.7746908080816373 4.361065434198656 83.89884590032864 0.5691214980254651 
epoch: 5, train time every whole data:211.89s
epoch: 5, total time:1696.42s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.56s
test time on whole data:59.23s
1.8417889352722006 3.1310995046790446 62.73187492773468 0.7481194442625968 
1.8963952749639394 3.2262143438670976 64.79795968837601 0.7292290028535903 
2.0007624593435653 3.483432443304158 65.27072972563522 0.6859657087800891 
2.0237648197142852 3.5341311819839714 65.05462761283916 0.68097687465547 
2.0619313132725656 3.640645368436933 63.439239977586006 0.6706969833725268 
2.0820455648805947 3.695122992166324 62.2582674746062 0.6694699101931278 
2.129278224321437 3.784966730957801 61.808298457677836 0.6659033063320521 
2.191777001138422 3.875370087494297 62.18584268824421 0.6644930384381991 
2.224404799023643 3.9278645646769323 62.446411955934124 0.6628556079937797 
2.278259218517159 3.9902369600362513 63.889144460040235 0.6620058730236171 
2.316900860843648 4.038169734836027 65.17770208802287 0.6526003392927134 
2.354670275458445 4.10840942481889 66.10285978905209 0.6298017359136412 
2.1168315622291587 3.715118670600594 63.763559267859925 0.6298017359136412 
epoch: 6, train time every whole data:211.65s
epoch: 6, total time:1979.40s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.54s
test time on whole data:59.09s
1.6946134753048065 2.935484341053912 58.96405087890664 0.7710013084989106 
1.7488110082020893 3.034727232761772 61.87389794343194 0.7517861404668258 
1.8158878848092364 3.225171795226883 61.654550587224236 0.7216623573126714 
1.8621485408902878 3.288854272270084 62.53889967789584 0.7098050453951568 
1.9125990095550993 3.4056815456061167 61.51141399506036 0.6922113490166061 
1.9463298887321283 3.4770735541468003 60.74312788517161 0.6817425217433761 
1.972194935127383 3.5436527537690203 59.846447455126416 0.6753815039618749 
2.002139239926246 3.6160667267775493 59.19731852124048 0.6650200107006684 
2.027816061806466 3.6808217703600397 58.997573983375176 0.6584167245401654 
2.0527140725509576 3.7263782026168517 58.53706228453833 0.6522353952056693 
2.094243562481854 3.791302175839848 58.33897332392978 0.6484004471896011 
2.147500049214278 3.8901616216497863 59.47867139062738 0.6228583865419651 
1.939749810716736 3.4798075494535343 60.140109544718676 0.6228583865419651 
epoch: 7, train time every whole data:211.68s
epoch: 7, total time:2262.57s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.61s
test time on whole data:59.23s
2.205544147162299 3.5220591845758262 70.00973951248855 0.7553707117533898 
2.247438665170045 3.592715331790661 71.32728358453294 0.7402033594873667 
2.3414741440326683 3.760117793660027 72.80497486163517 0.7197459865535286 
2.383732214239559 3.8156354590619292 73.91717243353379 0.7085880244853426 
2.431266963184944 3.8921347331296765 74.90343376088111 0.6948304434160755 
2.452082712468913 3.9280992707177225 75.1558756527451 0.6844803240165533 
2.4897291752453894 3.977832335423693 75.85082835217938 0.674342639929473 
2.5055785163105244 4.008800404679518 76.12275796717427 0.6647031723775352 
2.508586629997318 4.016832384275483 76.88928105006117 0.6571654240658525 
2.5052713463097103 4.034374434939294 76.76030443445147 0.6475998203711015 
2.5305461345445366 4.093743550591971 77.15497466652668 0.6422062034610685 
2.5910163612254853 4.201004637242882 78.4949623091551 0.6186423697046678 
2.432688917490949 3.9083315629684203 74.94944064698123 0.6186423697046678 
epoch: 8, train time every whole data:211.68s
epoch: 8, total time:2545.32s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 36.50s
test time on whole data:60.14s
1.7528010751548269 3.085998252521459 56.779861319633206 0.7733222680942072 
1.7952057818906115 3.172648961333469 58.44812378215381 0.7555648117688236 
1.8463126836592954 3.3088765826423012 58.06664800377222 0.7362570928957142 
1.8702520662352797 3.3186978912090823 58.88862967300557 0.7351820658071736 
1.9100287128781812 3.3803972301532257 59.12163751840033 0.7284475210903407 
1.9519310800149328 3.437602782612543 59.39201635198585 0.7208457291104913 
2.0020633472759455 3.5104731359687884 60.23252138854899 0.7127848334419288 
2.0442842889754544 3.580519566437792 60.71101465204754 0.6985839941200319 
2.0801329507913797 3.6558721782752324 61.65425474504996 0.6821257942345488 
2.111078399389539 3.732127326265907 62.261883273072606 0.6641682158893886 
2.14948213185707 3.8186974385827748 62.389894087328514 0.651215749544748 
2.2185198413782885 3.944946379792366 63.55982936670449 0.6192046021692228 
1.9776743632917337 3.5045027552370462 60.12563321378054 0.6192046021692228 
epoch: 9, train time every whole data:211.58s
epoch: 9, total time:2828.81s
predicting testing set batch 1 / 168, time: 0.34s
predicting testing set batch 101 / 168, time: 35.62s
test time on whole data:59.26s
1.9437277932983956 2.946204496727405 67.06403368379867 0.7826378004188814 
1.964967042723582 2.9910874064657773 67.68022873835397 0.7724555166128093 
1.9782684384398161 3.073792399262473 66.10975659553286 0.7576500346542105 
1.9787354122707177 3.0706536709670504 65.50651508005456 0.7571381178306625 
2.0052257120651857 3.114121476602089 64.99033701367503 0.7466942255766292 
2.041174685623142 3.160453454612742 64.95585612243147 0.7343462477314368 
2.0618777903333485 3.2124404212375715 64.12159631460163 0.7208552539365606 
2.0918064944949 3.268840207007347 63.58061475937847 0.7074479379428984 
2.1129642656856173 3.3158788539647963 63.46540984780369 0.6956830436047502 
2.1371098916284916 3.3756147500417013 63.36089148228594 0.682771261518504 
2.1468711700826173 3.4285821277411768 61.64597891516077 0.673956226172133 
2.169071896178116 3.4802025116997704 61.17210150071909 0.6652330084120497 
2.0526500494019944 3.2074387406877674 64.47100822732 0.6652330084120497 
epoch: 10, train time every whole data:211.55s
epoch: 10, total time:3112.40s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.61s
test time on whole data:59.21s
1.8402180735276392 2.95201605637418 63.66026370272348 0.7702081964994628 
1.888125064524068 2.995657827657643 67.02141195560833 0.7578783501738274 
1.9223406582607754 3.0743924562431526 66.5356652293874 0.7437923336864767 
1.9373160688527638 3.0837813102147185 67.42106506683525 0.7399460590232985 
1.9480045816411398 3.108244112815166 66.52160877440801 0.7349341888138395 
1.9557981287573598 3.1433536028328986 65.67816174130911 0.728454248928451 
1.9548058862444901 3.1556173874729985 64.45364746987339 0.7277292461335739 
1.9650424856390094 3.186774136765647 63.6952756326849 0.7253205174398946 
1.9831828204799622 3.2475999282441683 63.233008802036885 0.7181525765405559 
2.0168939699752344 3.3283677027757648 62.898266958036885 0.707118687488305 
2.0782213541594823 3.470153246326573 62.72762508517471 0.6864261872816079 
2.1516609817519785 3.619827542294661 63.553262694065104 0.6531609750249414 
1.9701341728178252 3.202542173046063 64.78320075280665 0.6531609750249414 
epoch: 11, train time every whole data:211.68s
epoch: 11, total time:3396.43s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 35.84s
test time on whole data:59.40s
1.6434224705252618 2.7988679196933073 57.87269826168314 0.7960107363934036 
1.677016820711128 2.8359684390572473 60.120170660321115 0.7905609083980193 
1.697971230068732 2.888419160713536 59.4456050189506 0.7821300578085938 
1.7080713569919268 2.895761135232323 59.24508300574322 0.7824008059223555 
1.7363257972645085 2.949561173075512 58.99558714705627 0.7776024138632193 
1.7725824795784872 3.0228106663744274 58.503021261939296 0.77241222397301 
1.8139502161732386 3.1149708003347816 58.43924855865675 0.7680812689941775 
1.85456766739736 3.210700985965201 58.5507282180059 0.7637597905944001 
1.8990507058779753 3.298393330570391 59.9006578262793 0.7579675729107483 
1.9472363578241674 3.3924289542005517 61.154893550382795 0.7465903433907066 
2.0053849834874273 3.500467761814447 62.539064469093134 0.7320236982827035 
2.0643824658822267 3.6265349778031255 63.224700956001534 0.7074428923656269 
1.8183302126485366 3.1390911507867902 59.83266365380491 0.7074428923656269 
epoch: 12, train time every whole data:211.58s
epoch: 12, total time:3679.61s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.61s
test time on whole data:59.28s
1.7788481359321269 3.0614950192457506 52.78595058815366 0.7986749545950943 
1.7985271489155434 3.0863660244632967 53.93361770099092 0.7913134480988251 
1.855193355505133 3.219039793723432 54.27037689230071 0.7753539223016498 
1.8976822099100266 3.2943980800911263 54.918450802439786 0.7686831575824016 
1.9559763058899413 3.3985290985450325 56.19693904808193 0.759789103809033 
1.9784919049418752 3.4266938856235747 56.631311972388886 0.7598182977250635 
1.9899725975608897 3.434842171709403 57.1502447273989 0.7574895320684012 
1.998470284380196 3.4591978811333974 57.402508765636206 0.7538299924301205 
2.033765616437775 3.5319114139426477 58.78569982046531 0.7457964534107966 
2.0798971007056535 3.641026120099197 59.843297732081865 0.7318227616186767 
2.153581320246238 3.793483536700522 61.28397179289933 0.7100088734042046 
2.2202633081156584 3.9211170374430164 62.0693895754904 0.6851872447092148 
1.9783891073784214 3.4480338630159486 57.10613354664864 0.6851872447092148 
epoch: 13, train time every whole data:212.00s
epoch: 13, total time:3963.08s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.61s
test time on whole data:59.19s
1.7253818128519647 2.797742892090949 54.06634559155975 0.8068726847370713 
1.7645205362440042 2.8571427959370848 54.38775547209712 0.8004220490386086 
1.8012837219826345 2.9660415377050438 53.656219388688406 0.790114049080197 
1.8349078266522183 3.0039879254942843 53.946315014649805 0.783872369097282 
1.8868044751558808 3.1160028301043545 53.358900621649376 0.7684973254247177 
1.9283985040994096 3.183480832183633 52.64466820869143 0.7585727126977995 
1.9478630506609167 3.2153522974205746 52.39816314588994 0.7508420261839706 
1.9599309266255724 3.2284327261591175 52.19729575109297 0.7407326521750138 
1.9714608805539708 3.2618021339972834 52.640036624386354 0.7273680408935569 
1.9907668735975665 3.310662227259307 53.22792827209996 0.7175603348314875 
2.039716882263266 3.4192416170158877 53.72486278828921 0.702856783121052 
2.0974688675365454 3.55362367862241 54.213879811273145 0.682892719888306 
1.912375363185329 3.1667091257544717 53.37183754501299 0.682892719888306 
epoch: 14, train time every whole data:210.72s
epoch: 14, total time:4249.75s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.69s
test time on whole data:59.68s
1.6418893301018647 2.7259684295326916 57.575490636380664 0.8113648708914504 
1.6857073474306437 2.75396478091464 60.33643628738019 0.8050233327161337 
1.712953484283228 2.834450870699065 59.91423634114318 0.7971341953020603 
1.7451987682739716 2.8794290997265133 60.80489637387261 0.7897592810640716 
1.7824572971252104 2.9780069118399397 60.38763513539342 0.7779687193168668 
1.806646980632806 3.0419833924568174 59.36641745692781 0.7733874144799836 
1.8287052171274665 3.1049116051267265 58.94256047726499 0.7709869316266497 
1.8580804698974605 3.181163654814934 58.49086495412404 0.7640804095715173 
1.8914234271417594 3.2500250017005023 59.081983700392925 0.7494420875675123 
1.9197260278102366 3.317054891963874 59.336787421240444 0.7344958153372145 
1.9637273783321005 3.401554897094823 59.88972926598146 0.7214868290829499 
2.0186495396896666 3.515900360234534 60.5048954392876 0.7064499719445179 
1.8212637723205345 3.0919325496959056 59.55265682968918 0.7064499719445179 
epoch: 15, train time every whole data:210.65s
epoch: 15, total time:4532.20s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.82s
test time on whole data:59.48s
1.7291590761373796 2.852741133114079 55.58932791471906 0.8164683921641538 
1.7593455497715622 2.901336788217986 57.69378042827501 0.8024281995073081 
1.7903666144308767 2.969446674799882 58.886327915952364 0.7903293253280067 
1.8034078609567312 2.986794689677387 59.85525451457316 0.7862167953313712 
1.8323256988930738 3.0266055592403154 60.95879135012642 0.7817185020200091 
1.8536335330303937 3.055308374330587 61.303192883249736 0.7805338355902777 
1.8867960998441669 3.1061821435988 62.01276390873103 0.7755797915483192 
1.9143866096460926 3.1674284579168104 62.28918777506024 0.7707479955788143 
1.9636891333147706 3.281497202455362 63.0036623452542 0.7555682708172332 
2.0194337676033554 3.408405624902725 63.74258441478175 0.7375260927839452 
2.078962007806592 3.5481176094816664 64.5937564363443 0.7151281802330579 
2.1421584388893096 3.6915801344099606 65.53303722876609 0.6921245413103688 
1.8978053658603586 3.17638446817264 61.288631010472294 0.6921245413103688 
epoch: 16, train time every whole data:210.01s
epoch: 16, total time:4814.64s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.26s
test time on whole data:58.65s
1.891297723959954 2.8052081461032325 62.30495314430012 0.805222988295655 
1.917748098946753 2.890734874653814 62.664500681724554 0.7880194784396978 
1.9337446245567962 2.9576535255797487 62.2213762132701 0.7767352534085142 
1.948196648948072 2.973250653609478 62.71008356341137 0.7701805564516033 
1.9651819357518994 3.014278379607262 62.85215457925643 0.7585192346246642 
1.9707976001576477 3.051472631947169 62.96474512297087 0.7481284731545427 
1.9650142860062243 3.0831413188536243 61.920918058858184 0.7400996257577009 
1.9674332669314352 3.1166966767370314 60.96411756345383 0.7335145962359587 
1.9652993072118787 3.1710804679285216 60.05485120052801 0.7234197176386176 
1.9798192629692632 3.2413261528790733 59.462908006599605 0.7102424504776434 
2.003064114487863 3.3002672020531443 58.86200410181785 0.7004091535963366 
2.043767476409408 3.397948137042937 58.76571063680559 0.68169989602306 
1.9626136955280995 3.0880165470136403 61.31229288152036 0.68169989602306 
epoch: 17, train time every whole data:209.39s
epoch: 17, total time:5097.03s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.35s
test time on whole data:58.85s
1.7213993168948662 2.6343647028939086 57.87022606847759 0.8222381543618811 
1.7505950308177798 2.6811013898694736 59.13932504537257 0.8138482911528874 
1.7674151880592994 2.727040969546534 59.25571605553718 0.805697471769856 
1.772449570293494 2.7541889689629198 58.52334773858971 0.8049200152416827 
1.8024864336430495 2.86606232344302 57.98175373647998 0.7915352609457219 
1.8461169362516099 2.9762018659634033 57.84632721125944 0.7768264998020395 
1.8796856832571682 3.0552853416709858 57.99736414524483 0.7659789242473882 
1.9140136544770074 3.1187825624627594 57.95249472875247 0.7549478382913506 
1.9322342085739863 3.1571865068403637 57.87686307456434 0.7460393959073229 
1.9400703207092094 3.184191277813267 57.99641072898045 0.7369615137337351 
1.9325233775921875 3.1557166443337583 57.62011855357708 0.7423572198856022 
1.954794343114254 3.194305915145178 58.302056543794635 0.7331573865283105 
1.8511486719736592 2.965821891542942 58.19681532018943 0.7331573865283105 
epoch: 18, train time every whole data:209.73s
epoch: 18, total time:5377.37s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.45s
test time on whole data:58.95s
1.831131266097405 2.697932589809705 66.00644406785685 0.8153047791754287 
1.8335132189046237 2.783515614994851 63.476700691845636 0.797606433614168 
1.8413025660973397 2.89900516401869 59.81997009237083 0.7809296172639619 
1.8611157610079363 3.0207415135451288 57.16572339713992 0.7665635740142942 
1.8942730516911972 3.1303725855774327 55.96752887915598 0.7520833574773487 
1.918851446910983 3.1697911799251606 55.697220583351324 0.7449253485621694 
1.9286879470847724 3.17381438072192 55.626688239692136 0.7440212487324946 
1.9297246334286673 3.1866597254470763 55.37425493665976 0.74311580347012 
1.9219158325556311 3.184245857603233 55.233602574513085 0.7440270643413007 
1.9249432016741483 3.204399333974441 55.82819790186143 0.7396107504782492 
1.9379919882519614 3.2510689069753904 56.93381772817013 0.7323699848543672 
1.9847972569808896 3.3613810809870173 58.27233735908859 0.7115370213086819 
1.9006873475571295 3.0944378168932394 57.95004313416493 0.7115370213086819 
epoch: 19, train time every whole data:209.71s
epoch: 19, total time:5659.55s
predicting testing set batch 1 / 168, time: 0.34s
predicting testing set batch 101 / 168, time: 35.84s
test time on whole data:59.75s
1.7656193673017302 2.6885481745270097 64.2285727646759 0.8287949283017546 
1.7987396424841136 2.7502662549390013 65.69732248264924 0.8194432234003279 
1.821984136278874 2.8141890108492844 66.76152446131827 0.8104398558063565 
1.8419244867101134 2.8546290359217927 67.32055768215031 0.8048961614329593 
1.8737473879675604 2.9255903265080043 67.52436680909653 0.7958846480918639 
1.9054157757037098 3.0082539754878863 67.32825428905343 0.785495330887995 
1.923595355025271 3.0605806925377315 66.78522740221892 0.7798780132668569 
1.9479963962901383 3.1122743650250984 66.31179358705785 0.7748020808299311 
1.964607363116617 3.1507986462149837 65.97480957629696 0.7700532157288761 
1.970170892451668 3.1607859023438434 65.78979685506997 0.7689616850855011 
1.9994552914721093 3.2021585947163476 66.87978036356331 0.7643916146666424 
2.0430842743041437 3.2820077206618463 67.95634862726135 0.7543716114294069 
1.9046950307588373 3.0064707035172478 66.54655036551338 0.7543716114294069 
epoch: 20, train time every whole data:209.95s
epoch: 20, total time:5942.00s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.36s
test time on whole data:58.80s
1.666766974276375 2.67045643980686 58.00740104089541 0.8295258714251857 
1.6782905232054846 2.692622860686706 59.2664717354462 0.8226734286016181 
1.7058488546083903 2.7422589923207745 59.52976298421865 0.8175276280404943 
1.7371379649994807 2.817380206207245 60.04985174458783 0.8084857942076493 
1.7892811393571928 2.9455345394389245 60.753029045709894 0.7952131045557328 
1.8357032957257968 3.0421763984170322 61.45755272384935 0.7849725906709107 
1.8585908695711266 3.0781517997828556 61.92737466711874 0.7794992922462186 
1.8788522344170404 3.110192472867193 62.65266817617903 0.771827294489994 
1.905263471583969 3.1549377034149986 63.41895010010041 0.7628472944967114 
1.9316164085639729 3.2211106448844795 63.93374540288388 0.7509123084437606 
1.9584508524980573 3.2807543569098825 64.29494863401479 0.7413232918551677 
1.9888727944220992 3.3590674874137942 64.75351831526123 0.727320713069385 
1.8278896152690822 3.0179237757023145 61.670562797875405 0.727320713069385 
epoch: 21, train time every whole data:209.90s
epoch: 21, total time:6223.26s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.33s
test time on whole data:58.77s
1.7251606245718543 2.752967589897625 54.114912209624244 0.8214244131012046 
1.7502286041331079 2.8167986935600906 54.48438025824258 0.8087885379797931 
1.7627634658599716 2.816601938377762 54.82089154113786 0.8057094053284125 
1.7498039171726754 2.759549401757365 55.351642846505776 0.8113223733620339 
1.754321462063385 2.74761360603908 56.28105598262163 0.8095811691156344 
1.7675931576914377 2.767539677627036 57.28559917490512 0.8043643688826142 
1.7787067438547632 2.8021320703152637 58.14206978227443 0.7973903928405389 
1.7877422352930796 2.8307458284516 58.43822838371656 0.7911402737357545 
1.7992599213465694 2.855036805690977 58.99512380279484 0.7845092439303446 
1.807029134301114 2.876392937619978 59.52470812351663 0.7794214417615052 
1.8193929280576606 2.917059109910368 59.27086804568411 0.772531848929394 
1.850649306287723 3.0030054380783326 59.15562128780583 0.7583527763320992 
1.7793876250527785 2.829714565942373 57.15554559102566 0.7583527763320992 
epoch: 22, train time every whole data:209.79s
epoch: 22, total time:6504.85s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.26s
test time on whole data:58.68s
1.8849921606029605 2.849168120350101 65.56962107248225 0.8176948229209305 
1.927534172735931 2.918053271943419 67.35281359352618 0.8056886216717349 
1.9907091027940844 3.021958373057232 68.97519581104653 0.7945916475490987 
2.022368677992906 3.088166226275214 69.68047711941949 0.7878474488187276 
2.073398617417241 3.180955833352501 70.95321574886822 0.7782045271233193 
2.1180482157088285 3.254504844102024 72.15602245946658 0.7692697235392572 
2.1578816641544303 3.3132179536554696 73.23127227441934 0.7623117893744323 
2.2000619780175565 3.375333624714646 74.64124108916815 0.7528868691696876 
2.2328909930777514 3.4442090860618495 75.70269156058193 0.738093928986032 
2.2531484572439497 3.47253540810519 76.55896735266514 0.7313047320440901 
2.2599538558990298 3.4722151588197248 77.18185412819668 0.7304893533165489 
2.2864127704462125 3.535325515857293 77.9979043293581 0.7168235985217745 
2.1172833888409066 3.25138755004893 72.50033638224515 0.7168235985217745 
epoch: 23, train time every whole data:209.92s
epoch: 23, total time:6785.98s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.40s
test time on whole data:58.83s
1.6442876621355258 2.703695712445795 57.65162170539535 0.8220254941830523 
1.6907780993062826 2.8085247806707883 58.77250933296081 0.8088011272189063 
1.726613114845185 2.893607633126617 59.62147069614533 0.7972895182359953 
1.754358793792093 2.9499963394155944 60.17260367376069 0.7910757848841298 
1.807499488670379 3.056402667346044 61.22195783004465 0.7774283622018328 
1.8653063397662981 3.1708253095351453 62.203337869054245 0.7601599612169435 
1.9154162025323935 3.281809562579067 63.108867126404135 0.7410001936368821 
1.9602658869262253 3.377657834290709 64.00635258684778 0.7223620950195786 
1.9856907120930651 3.429976444422408 64.55892218161868 0.7106306596895208 
1.985112153762774 3.4012727657244297 64.66920649822495 0.7146405136124521 
1.9605170396451972 3.3200753352467403 64.47147483823495 0.7267327531962139 
1.966503631803695 3.3250329322127747 65.23135752208303 0.7219706406593565 
1.855195760439926 3.1525114513866535 62.1409592129417 0.7219706406593565 
epoch: 24, train time every whole data:209.75s
epoch: 24, total time:7067.39s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.37s
test time on whole data:58.85s
1.6074954271414095 2.6057060105540257 57.46227173976241 0.8335594871565366 
1.635006193213697 2.6688272940763067 58.201346895500095 0.8254766910748704 
1.6565136299603398 2.7080897066733907 57.91307820808176 0.8226467537997061 
1.678080745847807 2.745440362784728 58.19491059604589 0.819172617095116 
1.7053510339915574 2.7930954443007683 58.97441540546669 0.8118501584393254 
1.7282165038356823 2.825383958981021 59.4147149061202 0.8062766295373529 
1.7436795461210643 2.85010302350165 59.865120804905494 0.8021389156035839 
1.7663200508058958 2.891440411608113 60.45446483471424 0.7956980258532197 
1.7920378989423846 2.959123287042269 60.79802211266501 0.7847549875045283 
1.8149848580776404 3.0239895742019303 60.99139325445891 0.7758067255028642 
1.8401915911897306 3.0861157052763835 60.820130084641654 0.7705649707721509 
1.8877868555503943 3.201016693050943 61.23653118247964 0.755522830603639 
1.7379720278898003 2.868256856633177 59.527278729038166 0.755522830603639 
epoch: 25, train time every whole data:209.77s
epoch: 25, total time:7348.71s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.39s
test time on whole data:58.89s
1.6981056817902163 2.730684414065946 56.64138664886891 0.8354431645213335 
1.7292325496113903 2.7911387302124293 57.31075529715366 0.8285745910144685 
1.7556144984652775 2.8186536460386917 58.201228740419474 0.8232536123477205 
1.7756851277669803 2.825606839230494 59.341581286853625 0.8198995172998128 
1.8112656755206131 2.8566342075951496 61.01026945121816 0.8143405982920386 
1.8340596761434738 2.8827569326819327 61.859436094173226 0.8095009050195408 
1.8584468809817696 2.9110043823648937 62.822584555332675 0.8050489150750757 
1.8865648913303656 2.957523432865385 63.619114185833794 0.7996615882015538 
1.9209700430216534 3.018264592435759 64.53826134763226 0.7921154438322014 
1.9460750601316492 3.0626138539853467 65.31952042032054 0.7854496594206928 
1.972368685463532 3.088496203555692 66.21368649046624 0.7839003812572454 
2.021126267396978 3.184592516629207 67.52079639420845 0.770538916001536 
1.8507929198019917 2.930265291327376 62.03342015846731 0.770538916001536 
epoch: 26, train time every whole data:209.88s
epoch: 26, total time:7630.52s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.41s
test time on whole data:58.93s
1.5672136264288177 2.5252430824792866 58.06548767685206 0.8363368532121995 
1.5933162079598044 2.5963775559226834 58.47306038405097 0.8288734787336347 
1.6258558775865073 2.683317448597112 58.2100604334333 0.8210631527739529 
1.644861292729509 2.7208611227457333 58.368098930019485 0.8175738506884163 
1.6767370767536618 2.796090507382913 58.49883068539452 0.8095872834501149 
1.6963726461330162 2.830260770525668 58.368638024713036 0.8072262121319851 
1.7136403772385702 2.860942400047579 58.665234850349215 0.8037719981115523 
1.7355262568728733 2.8943029741372923 59.35917793210764 0.7981639911586067 
1.7678869310652925 2.962209047619303 60.39312715169206 0.7860413147366514 
1.7993014359563766 3.03231106562731 61.32923023286103 0.7734691043832971 
1.8366613770745517 3.1068959918581025 62.272205800799796 0.7629129811940975 
1.8910074385997973 3.2193671208207957 63.49835279276571 0.7452194797308958 
1.7123650453665649 2.8591739235053564 59.62519968386193 0.7452194797308958 
epoch: 27, train time every whole data:210.14s
epoch: 27, total time:7911.37s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.43s
test time on whole data:58.91s
1.5791176657451405 2.588560007372291 55.28479619655571 0.8295367613458586 
1.6026477740124045 2.6423015341706697 55.919229383307226 0.8223035768789838 
1.6195016447818351 2.664844422644232 55.88275844882815 0.821950356722734 
1.630425642252678 2.6907193323646164 56.23023939296608 0.8192986135051451 
1.6483624170853624 2.734315126841879 56.70373848311203 0.8135449362346046 
1.6651341717702648 2.766690414222559 56.873784099079984 0.8106657526700262 
1.6885271157240052 2.8219883404922412 57.14486795646976 0.8057305631649165 
1.7167567082948627 2.880710410952759 57.65653401105847 0.798586305672523 
1.7487321339595532 2.955986682496487 57.930863450733995 0.7894862713420238 
1.7726728068329394 3.0159967557299816 58.12360824363388 0.7819214690871962 
1.8024996225137617 3.0901013977247005 58.43407412247753 0.7738110032568758 
1.8472694032242787 3.2141910177163315 59.06062888709128 0.7533821336061286 
1.6934705921830906 2.8450362710435195 57.10382423895971 0.7533821336061286 
epoch: 28, train time every whole data:209.81s
epoch: 28, total time:8192.35s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.47s
test time on whole data:58.96s
1.5961252795089746 2.626015400151321 54.522812277732 0.829802820010486 
1.630242642663153 2.7177704970318097 54.25227850542035 0.8220361677803713 
1.6563498905325929 2.7494736404794136 53.98625230691718 0.820370727656649 
1.671109064647307 2.757124037024376 54.324200144746385 0.8205622172393949 
1.694612973636371 2.7970836490268827 54.88174206842955 0.8161170210251262 
1.7118842656421698 2.8200963627797107 55.57853879421268 0.8114325246245997 
1.7280103485778506 2.8526905930631488 56.22766890131279 0.804199413497022 
1.7491930698475668 2.8909037450587176 56.957153824391874 0.7962800929330471 
1.7784039617304113 2.9495604771203334 57.45603168922467 0.7878253095024125 
1.8024104062528128 3.012034764255287 57.78477522015759 0.7788549861591015 
1.8257525272761428 3.06921903939203 57.96830468131886 0.7744030441911574 
1.8690587695759855 3.182560609309438 58.605592586874664 0.7580856919643689 
1.726096099990945 2.872809572853244 56.045536463321795 0.7580856919643689 
epoch: 29, train time every whole data:209.66s
epoch: 29, total time:8474.51s
fine tune the model ... 
epoch: 30, train time every whole data:432.78s
epoch: 30, total time:8907.30s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.45s
test time on whole data:58.97s
1.5302967168945996 2.4951333511063023 56.094044600043155 0.8424653115460486 
1.5527387058700302 2.550208665286819 56.47766806519316 0.837069215832458 
1.5738402468224189 2.5914741831842076 56.652371943554044 0.831865181380394 
1.5815298949441916 2.6037536393591743 56.778556466637816 0.8315884440765574 
1.60181065242773 2.6529865221644267 57.06088464770347 0.8260805622850284 
1.6184447762784326 2.6866312289570318 57.15624536991714 0.8223824311510773 
1.6371126766872726 2.729877728122967 57.388537297798756 0.8163405351639749 
1.6587595180087678 2.7634018484176006 57.895357888072716 0.8111726895990304 
1.6867862066261115 2.829681541067554 58.53676468438368 0.800571645312699 
1.7071126320419745 2.8727662504049154 59.192352761036496 0.793295864293217 
1.72564075129763 2.8993113973028977 59.60505344237852 0.7904931971082181 
1.7622661048777046 2.9804534670663947 60.415879498987394 0.7780899289477697 
1.6363615735647388 2.725167673245519 57.77121015907649 0.7780899289477697 
epoch: 31, train time every whole data:433.52s
epoch: 31, total time:9413.47s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.45s
test time on whole data:58.97s
1.5269740627297157 2.4999730762718855 55.559010348689455 0.8440087332311923 
1.5486254917424882 2.5513681522905762 56.03151787597657 0.8389337750562691 
1.5703428974963192 2.5950605951125767 56.22125529630338 0.8337805599794376 
1.5802757132670708 2.610412246383763 56.504084681817446 0.8327069043961758 
1.6034856395841177 2.662435226348263 56.8177476033514 0.8270061697190486 
1.6222089842818677 2.6989550301021654 56.94658919163101 0.8231466586204349 
1.6451256127837335 2.7495864500783904 57.229101480886136 0.8162205248039666 
1.6697537502778605 2.790819417902233 57.79999936119603 0.8097645667977189 
1.6985605620826107 2.8582267001437938 58.41299715144581 0.7989956189031368 
1.7191548777447925 2.9029002955149146 59.02987592368277 0.79098652336783 
1.7349936882980346 2.928431441522508 59.488274229356804 0.7874788420300819 
1.7673741144995605 2.992298398950689 60.36840482565975 0.7772332133951562 
1.640572949565681 2.74097922114476 57.534147217405504 0.7772332133951562 
epoch: 32, train time every whole data:434.67s
epoch: 32, total time:9919.90s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.52s
test time on whole data:59.07s
1.5232126776811976 2.4872486313455164 55.422169094924435 0.8450296262693453 
1.5447186844946728 2.534480370775795 56.003231130008956 0.8399337880030552 
1.5695441840503896 2.5928676690732892 56.00996191250748 0.83361696462354 
1.5844349846153387 2.6262575404346586 56.15682388171428 0.831480741312528 
1.61289217377729 2.6933545123436455 56.37137836711821 0.8252167249293562 
1.6339463048736076 2.7351675242835976 56.423846549911715 0.8215569359313863 
1.6569675733275002 2.78504607246664 56.62870707771187 0.8151478922321822 
1.6811165502346344 2.8256021986543005 57.17103809282145 0.8085628395572105 
1.709017754268877 2.89523099421713 57.86141854185751 0.7966219973594011 
1.7274304053317755 2.934728455346333 58.53943291024707 0.788652127398287 
1.7422989046382054 2.95184125959615 59.20889958523104 0.786132481097827 
1.7760047156322925 3.0159946437954366 60.261991143660076 0.7756600170601333 
1.646798742743815 2.7614999151669473 57.1716426923587 0.7756600170601333 
epoch: 33, train time every whole data:434.31s
epoch: 33, total time:10424.64s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.43s
test time on whole data:58.83s
1.5208364261665515 2.4763675075575944 55.92882423208317 0.8460952371429663 
1.5406145423353605 2.5239728033981437 56.3672917202806 0.840736933304247 
1.5646265983376653 2.578696469571132 56.31886913339139 0.8350637775629542 
1.578500027848585 2.6068577570537346 56.365085597307406 0.8334296062643137 
1.6051235889504176 2.6648557640377497 56.538761800314106 0.8277156948853795 
1.624338979902278 2.703383389103597 56.66556050576199 0.8238745839616796 
1.6459046200355958 2.7460381356342816 56.98571767849428 0.818052159571602 
1.6663437922690951 2.778236995954957 57.644381142526136 0.812432848094827 
1.694063058463679 2.844913431221362 58.53477655701944 0.8008540340981264 
1.7099903897707838 2.8832195241165075 59.2455620312912 0.7935040295385787 
1.7234054348910492 2.897988009892483 59.86995230699994 0.7919504445890145 
1.7532913929882148 2.95454819310594 60.72420277333123 0.78371436832699 
1.6355865709966064 2.7256720672521597 57.599155858194415 0.78371436832699 
epoch: 34, train time every whole data:434.38s
epoch: 34, total time:10929.21s
predicting testing set batch 1 / 168, time: 0.34s
predicting testing set batch 101 / 168, time: 35.38s
test time on whole data:58.86s
1.5185521422889794 2.485944965450221 55.28309156529252 0.8460256320237692 
1.5409800520080719 2.5377828354732976 55.69860239124932 0.8406748929106562 
1.5667464256689307 2.5943906190472523 55.759987244558864 0.8347655005409006 
1.5822263186509233 2.6218779957073126 55.87630515075105 0.8333631894051332 
1.6089441215610576 2.6795147614170465 56.15413014357041 0.8277332285088432 
1.6302943194989292 2.727043699248376 56.374936165568066 0.8226946100803232 
1.6546730390249618 2.775877210559232 56.72180927290859 0.8163489203051252 
1.6790286431668238 2.819142174399006 57.35618592428293 0.8093708873269984 
1.7071574519140025 2.8887682522343363 58.186987880265384 0.797062330375349 
1.723433524337464 2.9229017868069924 58.88326843975944 0.7900561605429687 
1.7354132510384634 2.93735416653381 59.535842343926525 0.7875003235492097 
1.7643757900914976 2.994956369926202 60.489599424127995 0.7776481863855762 
1.6426520899375088 2.753499963826883 57.19347718822757 0.7776481863855762 
epoch: 35, train time every whole data:433.06s
epoch: 35, total time:11434.10s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.49s
test time on whole data:58.97s
1.5200357712460237 2.482212611301183 55.491533476073386 0.8470349094453891 
1.5419928599651902 2.536067374725402 56.0068382061845 0.8409198962524614 
1.568161811446771 2.588888148951392 56.1602833825105 0.8351397607813116 
1.581313595167317 2.6106261333496033 56.402188120271205 0.8335114345578947 
1.6070914963836826 2.6679778662044358 56.68602335483071 0.8273770079589483 
1.6261884701856013 2.7055563287011117 56.85233140932372 0.8237100831290151 
1.649617785064947 2.753797419818184 57.09849425351704 0.8177297706649109 
1.6726468043759288 2.795088309305198 57.59532563653653 0.8114691281577544 
1.7012222908929522 2.868999466185619 58.427655623246686 0.7987211857914053 
1.7169312834296198 2.904253591492052 59.15156546567025 0.7912753487272843 
1.7286561929915278 2.916392465587317 59.98124974983274 0.7886763283678645 
1.75625194006972 2.96887810148054 61.09403583542997 0.7793733519479462 
1.63917585843494 2.737550862796196 57.579042139383 0.7793733519479462 
epoch: 36, train time every whole data:434.72s
epoch: 36, total time:11940.79s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.52s
test time on whole data:59.07s
1.5149887672576698 2.4658957421522336 55.83731890640825 0.8469179121662385 
1.536507043928795 2.5180250155358714 56.305448385841906 0.8412432868608197 
1.5599073532290224 2.5669027988775324 56.36436417026971 0.8358098610296759 
1.5727548729395937 2.5918520379277084 56.42943168242544 0.8343835238458063 
1.5969075128240955 2.648169302902489 56.529811001182765 0.8290371248278356 
1.6176669841350189 2.6923492845219297 56.68526483289431 0.8243818953473119 
1.6392276244361308 2.7396700381535175 56.96126462907084 0.8180896183332473 
1.6612156868054575 2.7758488829889454 57.51626261043216 0.8121813066230011 
1.687588313581954 2.841690264188191 58.23447719565612 0.801139414371429 
1.7051102809609757 2.8828522624806125 58.72140275901151 0.793688153893736 
1.7205383162521535 2.9055047904758102 59.220197567408306 0.7908095231520096 
1.7490394478985773 2.9633329674116653 59.92948620367484 0.7821651426255316 
1.630121017020787 2.72044411370292 57.394624019670474 0.7821651426255316 
epoch: 37, train time every whole data:434.45s
epoch: 37, total time:12445.78s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.60s
test time on whole data:59.24s
1.5143766016687843 2.4725509804182946 55.731075908238516 0.8471206580995557 
1.5350637998643908 2.5212497513400502 56.0828182603327 0.8419561479606928 
1.5605088498722761 2.5747871861078444 56.127756553225204 0.8362762493947442 
1.5748191116225152 2.60118425384475 56.19833861042862 0.8346893446855213 
1.600234919881182 2.6574640102568003 56.30608606493811 0.8293214298253553 
1.620145521801231 2.699310211235556 56.40268183231913 0.824955232681164 
1.640378195914839 2.740935866953614 56.644953627858484 0.8191521886658855 
1.659429924249915 2.7704112331439994 57.21158202147972 0.8135746739875108 
1.6815543805979014 2.825819639879639 57.97791431626208 0.8031157776847077 
1.6933335726232757 2.8495681912475868 58.61203448825998 0.7974572560057467 
1.7025060568450108 2.8623242641169733 59.19525875110986 0.7951895829837555 
1.7242666927255867 2.90463277337618 59.867898646621754 0.7889944270613302 
1.6255514689722423 2.7101242729838044 57.19659678405097 0.7889944270613302 
epoch: 38, train time every whole data:434.23s
epoch: 38, total time:12951.46s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.42s
test time on whole data:58.91s
1.5180879938712433 2.4641439079182548 56.70653639495688 0.8466125582441983 
1.5399663220017794 2.514537689427374 56.98033082335289 0.8413442526045554 
1.5645402080512472 2.5713518841857006 57.007163824035324 0.8354294127068211 
1.5784953906792438 2.6023830147599085 56.946809083580355 0.8338733254803418 
1.6039972640924334 2.659338945092117 57.065894683769756 0.8287112137419677 
1.6245753035962227 2.6996330858061395 57.21122224361124 0.8248374400330104 
1.6477105474468499 2.7472049762907447 57.492837376257846 0.8187942097195565 
1.6716255867875047 2.790072201421712 58.0538609611045 0.8121043578800242 
1.6999760698615796 2.8602066437685005 58.752040449380594 0.8012092860352565 
1.7187073719997314 2.903927390867939 59.23923684640043 0.7941355345097698 
1.736490294939528 2.935217707280531 59.743953139141695 0.7901853684585823 
1.767872145364061 2.9999680278439516 60.51892207295456 0.7804587745631116 
1.6393370415576187 2.7340412829999 57.97662619341292 0.7804587745631116 
epoch: 39, train time every whole data:434.53s
epoch: 39, total time:13457.12s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.47s
test time on whole data:59.01s
1.5109399870061981 2.448407994717263 56.792713646965254 0.8475333886863201 
1.5324164545756012 2.506808312223704 56.97450199925657 0.8410689761947051 
1.556496938854722 2.5616629223224536 56.889232015131505 0.8352304519973072 
1.5705035425891125 2.591478478681474 56.91769011661957 0.8330214939510994 
1.5942157722260093 2.6448110733566406 57.05089010276038 0.8272872893836087 
1.6122791842074977 2.679606353735833 57.14638120352653 0.8234956253292997 
1.6337062853205773 2.7245294166870204 57.412022170336726 0.8172646835505678 
1.6562362203639711 2.7618183586069898 58.02509010405077 0.8111350849237549 
1.6834660630697118 2.828574882396572 58.86582587167779 0.8000396181330964 
1.7005767007320232 2.869838032134404 59.542319496858134 0.7925861324748182 
1.7157637644949413 2.8923013853305783 60.26440005033532 0.7891865243066915 
1.7434757281001658 2.946913670995126 61.161037150896014 0.7806270000357797 
1.6258397201283776 2.7090773022201984 58.08690767578888 0.7806270000357797 
epoch: 40, train time every whole data:434.75s
epoch: 40, total time:13964.70s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.46s
test time on whole data:58.98s
1.5078376288321755 2.4517559676456626 56.15553082743641 0.8481955461263295 
1.528663663782002 2.5031010614922042 56.56583796952614 0.8420582748141201 
1.551170783726055 2.5465304382613976 56.69524615054078 0.8372972016046417 
1.563597458608005 2.5674941596223375 56.836077891038606 0.8358005511783646 
1.586417963215283 2.6201746340459717 56.97475168709708 0.8301527430661986 
1.6055479370706849 2.66005343705619 56.99229370413723 0.8259470053326868 
1.6278137361326566 2.708283500845348 57.10382780269973 0.8197914234683473 
1.6507599645210873 2.750616590427731 57.48412309107871 0.8133132140417497 
1.6738079060151108 2.8094804882203652 58.04659824911552 0.803764124905955 
1.6849809086092171 2.8362150049096635 58.47569378899974 0.7985328984482563 
1.6941469191973586 2.843886509127927 59.06336937080354 0.7971820653299503 
1.7169545447034318 2.889545760782218 59.913929117570255 0.7897657463055944 
1.615974951201089 2.685917249892109 57.52565811626634 0.7897657463055944 
epoch: 41, train time every whole data:434.53s
epoch: 41, total time:14470.59s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.59s
test time on whole data:59.18s
1.5159916156219053 2.480492167893548 55.54961851219401 0.8481096560425004 
1.539270745825732 2.5345995275456037 55.9661720942391 0.8423692539189152 
1.563404120780971 2.5830657909235852 56.237899401551196 0.836557698432525 
1.5761835038068572 2.6021324851193763 56.475745519442796 0.8351829067731967 
1.598689618394932 2.651117872594396 56.75132269515362 0.8295959296345907 
1.6181254544786754 2.68584636965404 56.95656269980076 0.8256035514787815 
1.6395112549062996 2.729799475800248 57.305586941928254 0.819478270273524 
1.6630508770961314 2.7741916749707785 57.88178247411334 0.812331112330741 
1.6914391281405197 2.8480367130978905 58.64309012954128 0.8005469344750585 
1.708636365522054 2.885136171764032 59.20304581303654 0.7943260171726663 
1.7247719388906622 2.9065675867493654 59.825017961149165 0.7915286481604317 
1.7533445140947366 2.9658187200992834 60.6151031960352 0.7822678668753794 
1.632701594796623 2.724733006787188 57.61766070414554 0.7822678668753794 
epoch: 42, train time every whole data:434.28s
epoch: 42, total time:14975.61s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.53s
test time on whole data:59.09s
1.5102359558866314 2.4570754132783517 55.61115973408051 0.8479087777100333 
1.5313796904104806 2.506387457019896 56.102387370067234 0.8418029451553461 
1.5542584612489279 2.5532328188596343 56.18749904412134 0.8365630600880274 
1.5682837790174498 2.580005708582025 56.266207409907274 0.8345747421252904 
1.5922446555031375 2.6329769520919606 56.32268076861864 0.8294255675565472 
1.6122330662713698 2.672400027972176 56.30815998908217 0.8257429103362102 
1.6366890257806295 2.725670748528328 56.50203006319826 0.8191043138937486 
1.660381882150347 2.7699178953644603 56.972026097465786 0.8124986290222392 
1.6890427058648674 2.8433533243713067 57.619868123680796 0.8008628746587029 
1.7043732794780462 2.87514035967742 57.99607332568962 0.7955427713657361 
1.719430870849462 2.900753074054588 58.54010761280484 0.791909496908138 
1.7439677524931196 2.951914365966548 59.28211454924093 0.7841535175172858 
1.6268767604128724 2.710318211741229 56.97591098838958 0.7841535175172858 
epoch: 43, train time every whole data:435.28s
epoch: 43, total time:15481.91s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.36s
test time on whole data:58.84s
1.5101462950545053 2.4617623705834326 56.25778765627677 0.846931884497484 
1.5337019065387902 2.518485192025596 56.583051685321216 0.84053555039746 
1.559999722376998 2.5730573821847744 56.619014972298565 0.8347034956852996 
1.5740136158075184 2.596535248742252 56.83428675215296 0.8330192777283448 
1.5979592056866025 2.64877385391435 57.10741061595526 0.8274539717902688 
1.6162161420227161 2.6806298625244804 57.31695363553185 0.8240391829986301 
1.637248395291024 2.7234112537298536 57.67794193022768 0.8179078689350011 
1.659099508412005 2.7587591901568267 58.30780608775225 0.8117988584283314 
1.6867228445645777 2.8245280605848975 59.15165903531372 0.8007432337928334 
1.7020336249539896 2.861010122311971 59.685377762122904 0.7942556352890294 
1.7159432027343484 2.8865692258764653 60.213395290774685 0.7905422019366578 
1.7402869345677927 2.9393960808921746 60.836958744066294 0.7826200919411779 
1.627780949834239 2.710025071194748 58.04938197116475 0.7826200919411779 
epoch: 44, train time every whole data:432.74s
epoch: 44, total time:15986.68s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.44s
test time on whole data:58.90s
1.50746343545252 2.4518612960678423 56.02004055486891 0.8483714946590616 
1.5257883641757959 2.490857175668314 56.5068593594114 0.8439024666183933 
1.5482604876381478 2.5395229148746705 56.67988468729622 0.8384562844241742 
1.5609815936184355 2.5639279117654525 56.951773005829324 0.8361822354713393 
1.5850436021988945 2.617194360987256 57.28296565515778 0.8299823062544022 
1.6033742565396463 2.6528127859180355 57.47569279657433 0.8259455303722101 
1.627750803857687 2.705738565431398 57.8462527685837 0.8186367093698423 
1.652287289218977 2.7497260131859274 58.386677535263466 0.8119501041433741 
1.6832549090745548 2.8304085135711863 59.103760591103146 0.7992731640648507 
1.7010545649563096 2.870199010375472 59.591518271514964 0.7927280849077601 
1.7154160758114996 2.8958251507304884 60.188444521288176 0.7889019379498907 
1.7404051688703752 2.9494641386409994 61.05560389346518 0.7801159257366757 
1.6209233792844036 2.6978761602198973 58.09087009484599 0.7801159257366757 
epoch: 45, train time every whole data:432.52s
epoch: 45, total time:16491.17s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.50s
test time on whole data:59.05s
1.511596852561725 2.4518583741249573 55.73300147557686 0.8489997200330769 
1.5337224262117275 2.5018572940160735 56.04534254061443 0.8436885317002747 
1.5572492394445552 2.551741133445541 56.066930680540075 0.8378708518076528 
1.570013205132669 2.5751013341104723 56.1617426513054 0.836068706693143 
1.5920163027846388 2.6232422672487226 56.264503744581916 0.8311992508349971 
1.609992111604927 2.656495241854959 56.277120550310286 0.8276295592130324 
1.6303077648526856 2.699629072259949 56.45734898374756 0.8215866028798428 
1.6515417120090374 2.7381143359236835 56.941736646672844 0.8152281375204463 
1.6792304286641024 2.8092434033994684 57.69318788039549 0.8039824240140259 
1.6954454424369725 2.8452186253286103 58.26485124427619 0.7979431298290175 
1.708983032773293 2.8634316354882876 58.9249441819578 0.7955323032794667 
1.7362422263846689 2.9196769479853897 59.71212881399336 0.786946076561157 
1.6230283954050835 2.690228228293349 57.04529378087828 0.786946076561157 
epoch: 46, train time every whole data:432.66s
epoch: 46, total time:16996.42s
predicting testing set batch 1 / 168, time: 0.34s
predicting testing set batch 101 / 168, time: 35.39s
test time on whole data:58.91s
1.507628037647566 2.4563477242894978 56.01791220759533 0.8484201882598261 
1.531264695728641 2.5100764093367287 56.324940912890895 0.8425062868833222 
1.5572107969345967 2.5673734496627465 56.301107718054524 0.8361226355060326 
1.5716749230019216 2.5939844432410095 56.30758119988465 0.8343295921320311 
1.5944390386369611 2.6426172291722887 56.36055308553948 0.8298493726020967 
1.6114028374988232 2.674369165290412 56.36409397942308 0.8268389965930572 
1.6318849378159004 2.7156816104331756 56.67630949814518 0.8209536091193395 
1.6527257450964479 2.7552624966795367 57.29449321591126 0.8136931800461491 
1.6797427379248575 2.8218059071204 58.1940649124546 0.8021691554248261 
1.6977253849724574 2.859236949374063 58.88576902871009 0.7953207443379193 
1.711959351643033 2.8822662084419384 59.5753863055322 0.7920534380817033 
1.7389407917274429 2.9380763493497857 60.3598366393014 0.7835631505919695 
1.623883273219054 2.7054565137457076 57.388568461284784 0.7835631505919695 
epoch: 47, train time every whole data:432.18s
epoch: 47, total time:17500.91s
predicting testing set batch 1 / 168, time: 0.34s
predicting testing set batch 101 / 168, time: 35.43s
test time on whole data:58.88s
1.5070502942224875 2.4568429766786446 55.7060295092883 0.848595801169606 
1.530829133447703 2.5151956190650577 56.017375196510955 0.842095468733895 
1.5558648550079337 2.570797642809247 55.98982466689794 0.835904044093882 
1.568541620240946 2.590294712220933 56.03088169341872 0.8351041837089243 
1.591226595388814 2.640860794787727 56.1577583251212 0.8299771943970253 
1.6073082909803127 2.6677649894233566 56.2408612035711 0.8274645459189673 
1.6274023816056018 2.7083514155135804 56.53635204235346 0.8216639366674007 
1.6478095415133451 2.7419432738694676 57.11615039674248 0.8156207164174505 
1.6737207726061876 2.808569200251712 57.96053398310603 0.8038806947653734 
1.6871109472413859 2.8358227875347732 58.59945292372495 0.7984976781825597 
1.6983162124401756 2.852177358248469 59.27495245769063 0.7960619721887316 
1.7225572476478381 2.9003469985290615 60.039840518297936 0.7889221233964999 
1.6181448243618943 2.694165454329206 57.139233755048245 0.7889221233964999 
epoch: 48, train time every whole data:432.59s
epoch: 48, total time:18005.53s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.44s
test time on whole data:58.96s
1.503974433443376 2.449132737461589 55.59999371265055 0.8493128981697107 
1.528280911265296 2.5122461589762177 55.67339123454887 0.8428625185277131 
1.5535925611312547 2.5654271162697486 55.6196789366443 0.8377199506140576 
1.5677848418734612 2.594089573675902 55.70333905512257 0.8356919926544308 
1.5905792454459837 2.6449325105950123 55.83987259766761 0.8309356270027735 
1.6072133003097204 2.6759626823793203 55.92962388112163 0.8280507122706853 
1.628181686440128 2.7190821783917474 56.32056989385876 0.8218294799074343 
1.648862954015888 2.7517601289648232 56.969891145365125 0.8157983192125993 
1.6766547069163726 2.8209082361892097 57.86341059446828 0.8039833169357491 
1.690753341211272 2.850346935615986 58.4856199425832 0.798342513482583 
1.7022341669969083 2.8645866014891483 59.19180264703772 0.7960963517488118 
1.7253029331421212 2.9101086762477153 60.02694030324046 0.7889621143134575 
1.6186179235159819 2.700292804074205 56.935415065635254 0.7889621143134575 
epoch: 49, train time every whole data:432.84s
epoch: 49, total time:18509.62s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.42s
test time on whole data:58.86s
1.50433885439778 2.4452017160236568 56.07610162555366 0.8491330619231766 
1.5273714987469749 2.4995996451238653 56.36837098424223 0.843195023079977 
1.5528931596492905 2.5551936017982317 56.43249585015337 0.8370843883624016 
1.5659361409584858 2.5817829031417956 56.495627612301206 0.8350839880956042 
1.5888800250467445 2.6307780032436208 56.67740890130406 0.830134455912167 
1.6061741675727423 2.6632869446650957 56.79586763655619 0.8264786985414533 
1.6267768587762756 2.707162501897717 57.14900444332473 0.8199513439491838 
1.6462167062637885 2.7368706985498226 57.677370839531314 0.8150079920381595 
1.6727681959571228 2.80643599866336 58.37645835994635 0.8039698223591997 
1.6883776206700576 2.8430199673053567 58.81001853625475 0.7978578585880978 
1.6993989308873811 2.8560669180222718 59.330635823352594 0.7962059957676699 
1.722631391726523 2.904856910163008 60.07497609701857 0.7886650250517119 
1.6168136292210973 2.689626133586284 57.52209170626421 0.7886650250517119 
epoch: 50, train time every whole data:432.47s
epoch: 50, total time:19012.20s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.58s
test time on whole data:59.19s
1.5054825534228946 2.4583181525750506 55.23638618130041 0.8492947928647244 
1.5301226086374373 2.517602189575857 55.56632686585192 0.8432052899603611 
1.5568737725685573 2.575682441771243 55.577147002488815 0.8372998884906162 
1.5730336344312168 2.6039987700178986 55.67866213481077 0.8355072518500328 
1.5991197518294766 2.6638499516529968 55.82536309511177 0.829828634277383 
1.6207242959627792 2.7045108880878606 55.92914784824345 0.8263184077948985 
1.644416338321886 2.7559998485838233 56.238755299726805 0.8193832557692717 
1.6663763724687908 2.796184009685045 56.880357273902426 0.8120146483080066 
1.6919799262783712 2.8608771754228335 57.73414234259198 0.8008461880382365 
1.7074576875561227 2.8926102765709327 58.42054024703799 0.7947788816107877 
1.7199194286550794 2.9071892007674927 59.19001467108834 0.7923553639964347 
1.744908101946825 2.959067709350375 60.036097885384564 0.784058581729513 
1.6300345393399531 2.7291771902904287 56.85948473903507 0.784058581729513 
epoch: 51, train time every whole data:433.04s
epoch: 51, total time:19517.89s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.48s
test time on whole data:59.00s
1.5037095119200115 2.4494113273350653 55.745213815344854 0.8495541992019049 
1.5258799468677136 2.4994172912758006 56.20995352838608 0.8434995782055792 
1.5500518390510587 2.549860063922233 56.42217700383979 0.8374946559827766 
1.563862752637604 2.5781120570085228 56.66196084979214 0.8346686085829033 
1.5875450679846994 2.633119187444126 56.87845828579493 0.8291308491319751 
1.6066727466644453 2.6672464633360673 56.99373149671246 0.8262161000170438 
1.6305792286237257 2.7181935635848555 57.30101904817079 0.8199019325597342 
1.6577313356070469 2.768486526094864 57.86029242687114 0.8127744453896686 
1.6885928407319422 2.8477005036787095 58.562833528837224 0.8009526125830326 
1.7070265046037911 2.8893347145742587 58.98810093565252 0.7942016066042142 
1.7234410158669842 2.9168248722381707 59.65854056340629 0.790088666270521 
1.750617389884733 2.9720631349774553 60.53979468529758 0.7810288772956455 
1.6246425150369797 2.7125394756163956 57.65191305131272 0.7810288772956455 
epoch: 52, train time every whole data:434.54s
epoch: 52, total time:20023.08s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.53s
test time on whole data:59.11s
1.5169913568368092 2.4663150785906383 55.7811158525356 0.8493762072991844 
1.5427747386499706 2.5225492881259806 56.17261707696015 0.8431063564941408 
1.5669690360255717 2.574038405778134 56.304955835979186 0.837776020985183 
1.5830910687879438 2.602048203766336 56.517516400085945 0.8356039908431485 
1.608861254937858 2.6550816453087496 56.719049549966314 0.8303829475670672 
1.6283447462749623 2.687642512564024 56.8911411122185 0.8273023282938538 
1.649698437987605 2.7306582975059963 57.31222516440207 0.8212314265139321 
1.6707760584883038 2.768512468075041 57.97355027772665 0.8147402665145005 
1.6990756796275577 2.841878449174516 58.85989120853825 0.8028142653038014 
1.7151152596148174 2.8801710573073374 59.44975010431 0.7962604182319623 
1.7289103643922579 2.898908492485052 60.1027486302705 0.7939225270706376 
1.7563391926724108 2.9536508950998397 60.9139921680441 0.7857713695721015 
1.6389122661913391 2.719309239593064 57.74996245897741 0.7857713695721015 
epoch: 53, train time every whole data:434.59s
epoch: 53, total time:20529.21s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 35.52s
test time on whole data:59.07s
1.5048497156888423 2.4538920643376914 55.61530045646011 0.8494089800949522 
1.5290645721553868 2.508536974068416 55.88938316490588 0.8438736689491607 
1.5526289732170602 2.558624032732536 55.99603461810392 0.8380274208419789 
1.5652603244753998 2.5811471063374225 56.21651147665059 0.8361046795038731 
1.5877981448365996 2.6338101428137946 56.378075706229744 0.8307103025628332 
1.6066583826093093 2.6693015970167986 56.47897421240483 0.8271288396990832 
1.6300780074120986 2.7180752131875865 56.798492993298396 0.8206370605666697 
1.654856698187955 2.7629012399928987 57.3649020336748 0.8134190138108243 
1.6845400035306812 2.8395138356742304 58.152525303324765 0.8007763099929125 
1.6995027774647766 2.874770120770927 58.726971192362384 0.7940126201717995 
1.7091250664323923 2.8831402682676135 59.42697591967504 0.7922711802201446 
1.730868680202269 2.9239505982036214 60.295204855521646 0.7851736892127649 
1.6212692788510643 2.7048726298932393 57.27835147706573 0.7851736892127649 
epoch: 54, train time every whole data:434.42s
epoch: 54, total time:21035.27s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.58s
test time on whole data:59.05s
1.5027472755079645 2.4375406189686406 56.22400118811341 0.849487867702263 
1.524977956270799 2.492100615692871 56.52830522785991 0.8434411899554587 
1.550024546625536 2.548830799390429 56.54020259547845 0.8373729989446694 
1.5640485252008018 2.5780021024046125 56.63844786657671 0.8352142647594349 
1.5866384186634706 2.6302765236874337 56.77410674526237 0.8298917354258764 
1.6043794581504272 2.660399153811159 56.8666378608212 0.8269320955658306 
1.6254526428435707 2.7047796735435465 57.1677006026899 0.8208722064714883 
1.6482106013260782 2.7472946987987177 57.717132020090546 0.813991973851445 
1.6762153649980291 2.822038434243203 58.39170319034791 0.802177901592751 
1.6941717870100623 2.8648880315397744 58.85611922808109 0.7950365675838137 
1.7080239988096235 2.886858670771906 59.417372606051934 0.7918440187740966 
1.731931810956005 2.9383122857856616 60.14232827313055 0.7837052123492789 
1.618068532196864 2.6971197439169647 57.60539909896375 0.7837052123492789 
epoch: 55, train time every whole data:434.92s
epoch: 55, total time:21541.57s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.59s
test time on whole data:59.16s
1.507577142543115 2.450663575088164 55.50173133231784 0.8490341543560606 
1.5288849192083414 2.495912328760942 56.12440454934843 0.8433841676195706 
1.5524639556684665 2.544663885007023 56.29819848503037 0.8377622267436853 
1.564700122785178 2.567765142335509 56.47393936162251 0.8359131278118491 
1.587529379718538 2.6173240806046616 56.67717040672153 0.8307050819019902 
1.6064433712479436 2.6521623416748956 56.806684544783316 0.8272701258649622 
1.6291082884459092 2.699299181551189 57.15611534901955 0.8211327756094978 
1.650288229221212 2.73771248017162 57.70014009899395 0.814989298818254 
1.6774919117980946 2.8085151406000737 58.423765213739486 0.8036411357382132 
1.691375710383501 2.8426556076780543 58.829358453071 0.7977675320362541 
1.7003001107444897 2.8549182073397605 59.2746941448518 0.7960941551536039 
1.721290724962861 2.8972307674736006 59.92498660534358 0.789640966327381 
1.6181211555606374 2.6845646890998003 57.43266984742535 0.789640966327381 
epoch: 56, train time every whole data:434.57s
epoch: 56, total time:22047.50s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.49s
test time on whole data:58.98s
1.513617297053337 2.474018872908441 55.448091425398175 0.8488573363121736 
1.5376508431493172 2.5237502416481625 55.99855510276491 0.8427372567637961 
1.5620634561881779 2.5716170461262386 56.36426756119579 0.8367553490617866 
1.5752668770172944 2.593008069591791 56.596293280954015 0.8350101081847304 
1.599591601675465 2.6476032234556564 56.7638244141634 0.8295656327969144 
1.6190989777644476 2.682195430039735 56.85747703235591 0.8266588831304108 
1.6448301030104713 2.7345298566744063 57.204171480993296 0.8204320941256336 
1.6702251578847922 2.7786636495624113 57.79536217693882 0.8139385113434573 
1.7009531154081758 2.859013355844178 58.57363420020767 0.8010439692682362 
1.7190105721609046 2.90366357068251 59.110787192143555 0.7930764844158547 
1.7306461410972156 2.9183525798443872 59.760781793400966 0.7906011081904166 
1.7522199956387103 2.9620121217028785 60.554525788997026 0.7832779003383356 
1.6354311781706925 2.725269210017713 57.585726310731914 0.7832779003383356 
epoch: 57, train time every whole data:434.83s
epoch: 57, total time:22552.16s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.56s
test time on whole data:59.15s
1.5050472943751763 2.4503357026765644 55.97542757906792 0.8486894373364607 
1.5289275158397144 2.5063025386147313 56.32126585514142 0.8425375287080282 
1.5537492798839119 2.560931337559756 56.35308575206233 0.8364925808909373 
1.5663663584461347 2.5848399952223184 56.46150409448493 0.8347800236637596 
1.5896380528467042 2.636852879759322 56.63484652920071 0.8294893385981582 
1.6084748105313629 2.6709511143370355 56.78241475836463 0.826068445568614 
1.6314719906702992 2.7181120966096897 57.162460189025154 0.8197067549329075 
1.654409173562768 2.756769359404663 57.77183901014992 0.8131368340275159 
1.6826475164722652 2.8312214929167228 58.52263614016567 0.8007785129893777 
1.6981650431425799 2.868296655685789 59.036855378549106 0.7940123717706649 
1.7078830552522448 2.880414400716146 59.67744064991523 0.7918958933098409 
1.7283897404401962 2.9193756335432304 60.507328996010514 0.7853521535633576 
1.6212641526219465 2.702819982280652 57.60066331691066 0.7853521535633576 
epoch: 58, train time every whole data:434.34s
epoch: 58, total time:23057.78s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.47s
test time on whole data:58.94s
1.5043518931685635 2.442470945403758 55.800735615480825 0.8491253320525202 
1.5276324922092082 2.498865169923449 56.09424713025193 0.8429081773566343 
1.554950039719187 2.562088519682444 55.97874785289315 0.8363298461450207 
1.5704619697257876 2.5977316313726653 56.01887837372884 0.8335533327195985 
1.5948122049280042 2.650162444737621 56.13941644042978 0.828921531906114 
1.6148083297357496 2.683948372034152 56.30078185853302 0.8257906027488923 
1.638628837217976 2.7323357365221788 56.69807149978979 0.8192395895844278 
1.661517154673203 2.7708494356589886 57.2993701023888 0.812991583464178 
1.6885738087924465 2.842161018335168 58.025874986067215 0.8012306100984332 
1.704245299742158 2.8755130795801533 58.55923857795096 0.7951431017856553 
1.7154672291004764 2.8934367077267202 59.13229864868163 0.7922265079600511 
1.7373102868882317 2.9391888577763865 59.857808068031495 0.7849623936055661 
1.6260632954917493 2.7118561530129286 57.15885405707299 0.7849623936055661 
epoch: 59, train time every whole data:433.10s
epoch: 59, total time:23561.24s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 35.42s
test time on whole data:58.86s
1.5031196056104132 2.4348309111901907 56.01558647666709 0.8497144842965201 
1.5245752774468135 2.4847068532098415 56.38644336978206 0.8437590493688016 
1.5475754279413572 2.534612878037832 56.29770599552387 0.8382961063905888 
1.5607378023092946 2.5636191910757207 56.23797743592088 0.8363053636857017 
1.5851008368782877 2.618317669579469 56.24549788416976 0.8313809298543693 
1.6050827875314724 2.659443041699658 56.25522878280407 0.8276491978803834 
1.6275381422065909 2.7104800809020166 56.49011446625366 0.8211618501484467 
1.648969818157011 2.7485753120661074 56.981850234892676 0.8152106163244787 
1.6758450010991877 2.8202658321533747 57.584911017172246 0.8039466442778009 
1.6924441020055008 2.8546605578860613 58.04373269791462 0.7982736755036648 
1.7048623630059438 2.873431925252238 58.59158370950186 0.7958577769663261 
1.7302528544585443 2.924075528880926 59.302171286846296 0.7885278053291382 
1.6171753348875348 2.6900740963959526 57.03611274532341 0.7885278053291382 
epoch: 60, train time every whole data:435.22s
epoch: 60, total time:24068.05s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.51s
test time on whole data:59.05s
1.5028551023567007 2.4480944185001916 55.42650507798372 0.850139010597258 
1.5274034934844822 2.5036025184785404 55.85019380746841 0.8437802261000141 
1.5526008688446489 2.557400998205734 55.88778288906514 0.8380022343744816 
1.567649986901631 2.5898349951361626 55.97293725235271 0.8354315629220629 
1.5914979725355902 2.6395450553568662 56.09289812914293 0.8310527094236695 
1.610781491944655 2.6764477600256598 56.251907004184076 0.8271556591649087 
1.6322569595908836 2.721183119160438 56.656155170732035 0.8208552574051634 
1.6538981987238817 2.756831984826321 57.325414432927516 0.8144926483864171 
1.6796580218380939 2.825827642830691 58.16559604161492 0.802784084966072 
1.6967138327171227 2.863151027495116 58.823928306412284 0.7960797960328119 
1.7089785820602306 2.8814300502989503 59.513214690398975 0.7933854884294694 
1.7333564932595584 2.9319162166340904 60.242922589325254 0.7858687440369609 
1.6214709170214565 2.7037932521029604 57.18419735888198 0.7858687440369609 
epoch: 61, train time every whole data:434.65s
epoch: 61, total time:24573.49s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 36.05s
test time on whole data:60.09s
1.5023011984345283 2.445388097383748 56.01815356624207 0.8496977720635153 
1.5277114143856756 2.50395889621937 56.43382853942238 0.8429623246313134 
1.5540034035727204 2.562727127248331 56.48877444347685 0.8366384037171708 
1.5711541567843939 2.599127301328357 56.60788184994326 0.8337404199803637 
1.596949402200058 2.65190163199232 56.76829424685368 0.8289799166808635 
1.6180800864417992 2.6919711421408397 56.951114860775775 0.8248894484091464 
1.6411342015773767 2.7397898374339413 57.239256115446956 0.8185439831691241 
1.6630057117687982 2.77501593915856 57.730753249742584 0.812722531895308 
1.6874897672096711 2.841327684403898 58.317668225991795 0.8018414024758607 
1.7010116223588232 2.8711334303216094 58.775118993367016 0.7961437913321966 
1.7120865294411778 2.8863432718866355 59.48350283300231 0.7931239123737669 
1.7348532393369824 2.93241283085842 60.41385074260668 0.7850026195347867 
1.6258150611260005 2.7127137634421046 57.60241447326185 0.7850026195347867 
epoch: 62, train time every whole data:435.00s
epoch: 62, total time:25080.43s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.43s
test time on whole data:58.95s
1.5004720035214865 2.44398672700001 55.696660834257905 0.8501668391721985 
1.525432947345965 2.5029286086345968 56.04097445186845 0.8438782692692757 
1.549918739518062 2.560131037394644 56.08663247555786 0.837811401798459 
1.5651827188545748 2.5901492387445186 56.38451115705049 0.835256465350862 
1.5887495350932614 2.6378762476252238 56.65630255068468 0.8307173985913139 
1.6091117735109515 2.6752873977168994 56.92317725069217 0.8266720456404589 
1.6319321184249684 2.7232997118942417 57.29232826819677 0.819851584739145 
1.6545981799796046 2.764691059715961 57.87154043324071 0.8127584492349726 
1.6805461490166684 2.8327944822429454 58.59275435454039 0.8012226278008822 
1.695331338653607 2.8641985054317223 59.24330934167745 0.7948776602488277 
1.7047666083869657 2.8773291707570827 59.987282206837456 0.7919336822156328 
1.7255372396466278 2.916786193946413 60.86840207463795 0.7850939011773601 
1.6192982793293953 2.703259159470721 57.63707245176156 0.7850939011773601 
epoch: 63, train time every whole data:432.60s
epoch: 63, total time:25584.54s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.61s
test time on whole data:59.20s
1.4995684418575395 2.434234322717742 55.88997557754749 0.8502046667435963 
1.523493976748859 2.491471535307664 56.30441796841351 0.8435085731886428 
1.5486913466213181 2.5483243715090964 56.3487488033586 0.8374565191423324 
1.5644741106211606 2.5788025768126097 56.47798325838972 0.8349160383396692 
1.5890556592587382 2.6312885762274982 56.629479109853065 0.8296822911446508 
1.608276341118894 2.6665809465816874 56.817596817056746 0.826161895041802 
1.631374261689949 2.7135557304816644 57.31299255691249 0.8195399649418333 
1.6529065822002789 2.7507379590109884 58.03420939719436 0.8130139393968013 
1.6780781116266512 2.8142379988910644 58.92278554908894 0.802323504169343 
1.6927330797536386 2.848173424480286 59.567202897940675 0.7961330501090487 
1.7037357310502834 2.864876199748348 60.23773289150315 0.7933270480184718 
1.724177346098902 2.907662699092243 60.90229348211267 0.7866503113627124 
1.6180470823871844 2.691583020907876 57.787201002040476 0.7866503113627124 
epoch: 64, train time every whole data:433.71s
epoch: 64, total time:26090.65s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.39s
test time on whole data:58.87s
1.504592950620999 2.4634160706395263 55.12346179315134 0.8496854144126316 
1.5310396010954643 2.5239857383277022 55.51173820623252 0.8429639876345548 
1.5538776936432612 2.568114381782152 55.725426791489205 0.8373666621253274 
1.5665656434666542 2.590062027065436 55.93956945721206 0.8352929701613027 
1.5880724925449383 2.6360522668474693 56.14973020983529 0.8304562861450904 
1.6029362211907725 2.661013154067066 56.29653329181171 0.8280110790586032 
1.6228819968498178 2.6988906021697012 56.70831126542629 0.8230380644566487 
1.6455356918953892 2.7400680743685175 57.27134270824771 0.8168111483897145 
1.6743596180409548 2.8118537629841494 57.89169149328579 0.8063946827476618 
1.692714363449741 2.855992615367538 58.26608963655973 0.7997613130044794 
1.707728289812005 2.8820485215148812 58.72945257239009 0.7967168251477961 
1.7357057379203007 2.9423377209334047 59.438839555950175 0.7880187325726841 
1.6188341917108582 2.7017135298499024 56.92108668197022 0.7880187325726841 
epoch: 65, train time every whole data:433.54s
epoch: 65, total time:26596.47s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.45s
test time on whole data:58.94s
1.5004068703626594 2.4422788065059846 55.53605835303508 0.8503873542837069 
1.5236414141972505 2.4937146957319367 55.996785955216346 0.8442239712474143 
1.5481452967677976 2.5465477401509915 56.18061555078827 0.8380294738826177 
1.5633019643260078 2.5786921803893104 56.34632633168673 0.8351343945704108 
1.587460497224792 2.6337575958916264 56.492868272786524 0.829682150959386 
1.6086271534608234 2.673813629533606 56.66742024553455 0.8258755274773788 
1.6342635726249288 2.7263854632076026 57.03036573128794 0.8194013534192041 
1.6599796930422919 2.7728167862795505 57.58449209055436 0.8123819760626915 
1.6888469144293063 2.8466089310087956 58.22307419492524 0.8007104800307787 
1.7064308998181175 2.8845199750829473 58.616893269120276 0.7945519469329421 
1.7177205112388447 2.9016776240516724 59.08832255518224 0.7922358561205869 
1.7398248848840594 2.9510614898313827 59.75259448340683 0.7844676500223208 
1.6232208060314066 2.7092077774013923 57.29305293554173 0.7844676500223208 
epoch: 66, train time every whole data:433.58s
epoch: 66, total time:27103.22s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.50s
test time on whole data:59.04s
1.5024671388994015 2.454802732167478 55.36357334056075 0.8498636754175477 
1.5285086335185027 2.5156194264907867 55.71786115186496 0.8432616680133131 
1.5526797915366257 2.5630197489472915 55.915808149406246 0.8378863945911659 
1.5657214873421583 2.585489771459813 56.14932326876346 0.8358996227912305 
1.5882780323673396 2.634177400261125 56.31535544018086 0.8309947630721134 
1.607272734009173 2.6702363386457777 56.453380570817544 0.8275104363021852 
1.6297858300605523 2.717025111211536 56.79212390562082 0.8214707573480567 
1.6512401279203948 2.7550569283562916 57.31661269627229 0.8155353263933887 
1.6765366639888712 2.8199925190201984 57.91331674598563 0.8052222166578168 
1.6916504661558818 2.8565943353886274 58.309855434136246 0.7989059985061212 
1.7017628925412538 2.870010942119279 58.785169159329506 0.7968515205019381 
1.7238756076232309 2.9173653197293654 59.47303354657013 0.7894158732550235 
1.6183149504969487 2.7004677708881775 57.042184273171856 0.7894158732550235 
epoch: 67, train time every whole data:433.76s
epoch: 67, total time:27608.55s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.41s
test time on whole data:58.96s
1.5003663275138075 2.440326404881782 55.775548547354425 0.8498040474059635 
1.5272310538879108 2.5066218142857943 55.970159102155016 0.8429164118779064 
1.5545163129832418 2.567845040375281 55.98388611318216 0.8364980998598716 
1.5700398102042576 2.6007671263156316 56.08818708631878 0.8337168862078531 
1.5938116715370367 2.6483433125594544 56.26401410480016 0.8291228795748949 
1.6150809154909636 2.6878345108935875 56.464992394159594 0.8247811632988795 
1.640027864510637 2.739870181897105 56.83860293280457 0.8175137893827807 
1.663119861997043 2.7824267724831846 57.386546962322846 0.8103289916801505 
1.688715921577687 2.8494212140140407 57.96509920448488 0.7992385458620068 
1.7041774801738738 2.8821622250589662 58.42616369869484 0.7935029724987193 
1.7133557741742227 2.891765070501996 59.0348954337896 0.7919963755328787 
1.734222926867771 2.935570242402201 59.80792976189724 0.7851123883909096 
1.6253888267432044 2.71552735690836 57.16723369739939 0.7851123883909096 
epoch: 68, train time every whole data:433.81s
epoch: 68, total time:28114.14s
predicting testing set batch 1 / 168, time: 0.34s
predicting testing set batch 101 / 168, time: 35.41s
test time on whole data:58.89s
1.498487144163854 2.428868986464479 56.21428339584252 0.850591265004401 
1.520681834380453 2.481519704131845 56.599893614976246 0.8443360419844939 
1.5445786656950202 2.5321773061081854 56.71956886558724 0.8384557620635403 
1.5572076984001768 2.5585841822963666 56.88491006324008 0.8359297282086182 
1.5789607022488046 2.606344087588112 57.007452171514615 0.8308648426219711 
1.597463231687567 2.6426773141005198 57.09893120711731 0.8272788980864709 
1.621698276195675 2.693242323703351 57.47173132425216 0.8208619016496423 
1.6453611981372038 2.735950428814832 58.01814463834174 0.8146262143595381 
1.672707402902611 2.8060566826253326 58.6653006872805 0.8036887435180048 
1.68893086196154 2.844632956510336 59.09241439759112 0.7971484012205827 
1.6967340478541417 2.8562267037122355 59.522139645532704 0.795354059747856 
1.7163201463199442 2.897498721433403 60.13891476461921 0.7888202696443705 
1.6115942674955825 2.6778534930430475 57.78620411081663 0.7888202696443705 
epoch: 69, train time every whole data:433.74s
epoch: 69, total time:28620.08s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.47s
test time on whole data:59.00s
1.5033890225011854 2.4526520773098954 55.087790905187404 0.8503665616818317 
1.5266254926324778 2.505072243225865 55.66209842244577 0.844023587646273 
1.5485174970845914 2.547663152561499 55.98966521519616 0.8385529024940223 
1.5612799227275842 2.569719346701909 56.31304475224589 0.8362499214352292 
1.5835414627653857 2.618977462575717 56.57312743044326 0.8307715977984751 
1.6017159657553726 2.653535752722453 56.781031437284135 0.8272070717462752 
1.626577706232667 2.7051552415608655 57.236353418250495 0.8202814505501637 
1.6504843943498675 2.7490569421286692 57.848338692605004 0.8133969614067663 
1.6791134296228134 2.821352910300433 58.519132706563134 0.8019109983146985 
1.6968310541103462 2.8646854170810476 58.9355745015693 0.794582105845102 
1.7073723806337053 2.8790930028014854 59.421096179676255 0.7922891067863447 
1.7280737324019984 2.924521828385333 59.986602366915776 0.7851480671203684 
1.6177935050681662 2.6951942931678285 57.362904724762785 0.7851480671203684 
epoch: 70, train time every whole data:433.35s
epoch: 70, total time:29126.68s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.38s
test time on whole data:58.86s
1.5012227972103727 2.43146193554173 56.26365130311874 0.8505240241514124 
1.525313995134529 2.488876829652693 56.45132189449632 0.8439983513143487 
1.550096504197234 2.5433975530730213 56.33738783186958 0.8383446174795038 
1.5667823787024688 2.580702376643472 56.311096379370774 0.8354225690106851 
1.5925014925587568 2.6414211558014076 56.3163825484996 0.8295275791223251 
1.612344619439915 2.676151970786148 56.38614790188146 0.8263503040052764 
1.6344206692771543 2.7196927601183636 56.779255152048925 0.8205398931515968 
1.6538307899756446 2.7534881200332877 57.37063895407542 0.814589720990137 
1.6775927903322236 2.813400143673664 58.06184764248295 0.804416359885404 
1.691318946798731 2.8453454460181646 58.653231059691414 0.7983937180037532 
1.7012167099324011 2.8607542532213217 59.33577852240916 0.7955903692770675 
1.722729952327286 2.903114278801382 60.13851387555076 0.7888126615219542 
1.619114303823893 2.6922099039842036 57.36716230591854 0.7888126615219542 
epoch: 71, train time every whole data:432.82s
epoch: 71, total time:29631.27s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.47s
test time on whole data:58.99s
1.4994502422137275 2.4389317616784303 55.87947584284441 0.8507149884923412 
1.525514816548498 2.5010302048453528 56.23819022631557 0.843590308438848 
1.550325217217473 2.555537650888958 56.330420607539324 0.837485530993233 
1.565960243462718 2.5883891954555454 56.38205781860239 0.8350737684643724 
1.5929657523255973 2.646622262510398 56.50510643314494 0.8297073405036144 
1.616253730637243 2.690843233278764 56.68328994418016 0.8256237824847448 
1.6415317122506066 2.7437483355362398 57.0146166974839 0.8190773268051595 
1.6644531347548501 2.7863533014547803 57.54215604311263 0.8125237514575504 
1.6897437820335228 2.851907872260669 58.13537476099029 0.8018985410697971 
1.70495651473034 2.884226657999884 58.608479217787824 0.7961142153093315 
1.7153565662750707 2.899804343328709 59.24318025441346 0.7932903779347148 
1.7363867426856998 2.9444413126058477 60.039694135976376 0.7858412831183933 
1.6252415379279457 2.715725496855703 57.38356690758939 0.7858412831183933 
epoch: 72, train time every whole data:433.66s
epoch: 72, total time:30136.49s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.41s
test time on whole data:58.86s
1.5008388939881254 2.4511719053493723 55.3425609255251 0.8502095174000334 
1.527771936418134 2.512507694340174 55.82296608479316 0.8434917513380634 
1.5540703085794867 2.569839540520599 56.036218540134676 0.8368525800191602 
1.5703114469659825 2.604532729906165 56.30361831479116 0.8333511432968683 
1.5935983935876616 2.6493883265379985 56.53235019844256 0.8289167298860688 
1.613994645249542 2.685888709532309 56.82063456632819 0.8249609231349057 
1.6373257469146378 2.7336304777824134 57.27209341979949 0.8180981322128562 
1.658868495146877 2.772708954073309 57.865536529359794 0.8111515493188963 
1.6837568316800253 2.8373397188645733 58.537186103230354 0.7999698374545131 
1.6982088631643426 2.8716011602458535 59.05349686390278 0.7935721724472775 
1.7068768636231266 2.8817255587220725 59.67368621519654 0.7914966923099366 
1.7264092484987563 2.92163429831353 60.50039551929384 0.7846443524236077 
1.6226693061513915 2.7116936727711067 57.48014586055883 0.7846443524236077 
epoch: 73, train time every whole data:434.93s
epoch: 73, total time:30643.77s
predicting testing set batch 1 / 168, time: 0.34s
predicting testing set batch 101 / 168, time: 35.48s
test time on whole data:59.04s
1.5024687416099367 2.4331147982120127 56.2926409830518 0.8496713925677791 
1.5283187102810258 2.4949213699214052 56.7104332194196 0.8426153028473022 
1.5544320069629523 2.5566231839303746 56.72036498015307 0.8356802943071772 
1.5701697441259665 2.591149719177439 56.68449663449239 0.8328239792106776 
1.5937105128963789 2.6419837188414 56.69650207254274 0.8278439728952772 
1.6138978624851221 2.678287888841702 56.81021803588019 0.8241476547311833 
1.6349372747261963 2.7227830515104685 57.1228483563965 0.8177263780345685 
1.653835872053834 2.7520496045334957 57.691478647389246 0.8123054331885461 
1.6766018864544374 2.807764992264038 58.31531745788482 0.8028522807818383 
1.692261554957944 2.8447337752274717 58.8161579976186 0.7962561492674047 
1.70138735884499 2.8594612251849796 59.31901921933268 0.793928617020116 
1.7220141878127164 2.9044096997941655 59.877853036495075 0.7872139543017315 
1.6203363094342917 2.694498353111011 57.58816615333031 0.7872139543017315 
epoch: 74, train time every whole data:434.84s
epoch: 74, total time:31150.20s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.52s
test time on whole data:59.07s
1.5000574145762338 2.4492153486173946 55.73010733389925 0.8496472334289094 
1.5269953948444732 2.5135071993073685 56.13776855238666 0.8423966429704682 
1.5515676399722163 2.563056954617152 56.2613159480275 0.8370840967715558 
1.5648575305512087 2.58874900260555 56.414199664377854 0.8349471228697831 
1.5863783731794074 2.6359078749033547 56.46058497471873 0.8304490587143141 
1.604866349732326 2.6689530708831994 56.57245255758115 0.8275257596505315 
1.6287524681359176 2.717841588768114 56.94360822585304 0.8213842922234598 
1.6515568512751766 2.759673952627611 57.49055679269717 0.8148429392854774 
1.6792201861034015 2.8298695009834467 58.18086249969794 0.8034478137360855 
1.6967963261081882 2.8695185310413236 58.699577548141036 0.7965511500108199 
1.7061638199883913 2.8802907934171236 59.241229673584684 0.7947080811616898 
1.7279317200727584 2.9218450161592426 59.919441425837185 0.7882532064754859 
1.6187620062116415 2.7039568538172394 57.337707444172906 0.7882532064754859 
epoch: 75, train time every whole data:435.36s
epoch: 75, total time:31655.60s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.48s
test time on whole data:59.01s
1.499697806383971 2.4391751127756205 55.66212066150955 0.8506084220334398 
1.5243801439136622 2.4942668248395736 56.2460148501487 0.8439259021088229 
1.547051560662687 2.5438612416051063 56.45108392655895 0.8380693923386456 
1.560465467219906 2.5752782913430834 56.55451441641275 0.8353135712241043 
1.5839777820632748 2.6262029807735128 56.55543669403189 0.8308785589291859 
1.6045554320715545 2.6646232274345243 56.60426467566085 0.8275971820660277 
1.628677792946675 2.713171125033713 56.90978602839307 0.8214871269302912 
1.6508232076010179 2.7526058341767725 57.404140234252345 0.8152319138983151 
1.6750228395862061 2.8115181171318926 58.02521776760295 0.805604959509737 
1.6900228937019905 2.8469546340154337 58.52245020620332 0.7990241340024246 
1.7003120700414514 2.8628752224263363 59.12346578748052 0.7961966439774615 
1.7217375582492067 2.907218784217028 59.78922552104413 0.7893541534875868 
1.6155603795368003 2.6905279283804235 57.32070312450831 0.7893541534875868 
epoch: 76, train time every whole data:435.02s
epoch: 76, total time:32161.77s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.53s
test time on whole data:59.03s
1.5011209462022497 2.451429033423725 55.13852024278668 0.8501251095334715 
1.5273716129185189 2.50768824737704 55.597729944546856 0.8436221564704771 
1.55217786286656 2.561943528412827 55.78026413942021 0.8372703573313686 
1.5664839331366653 2.591462479658898 55.93979136410635 0.834710012728229 
1.589468076355578 2.6401987139434984 56.065416026353596 0.830148333775233 
1.6095485429734524 2.6780222773822953 56.26676734710267 0.8264009528439541 
1.6327553595339968 2.7241748413209836 56.70617656875151 0.8203377650591617 
1.6560074778285232 2.7672990786321146 57.31718529504213 0.8135510328329457 
1.6843627388642302 2.8404251774600824 57.97294323085907 0.8023448775705089 
1.7030696079740744 2.887927842138015 58.437443989352204 0.7944456297998295 
1.715167753375091 2.905660227425119 58.9565526851095 0.7917633595766349 
1.7377611831667878 2.9549907904071797 59.62017833877541 0.783836410387015 
1.6229412579329774 2.713880013635574 56.983320699857096 0.783836410387015 
epoch: 77, train time every whole data:435.14s
epoch: 77, total time:32667.68s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.52s
test time on whole data:59.02s
1.5024624034545073 2.460214382268911 55.30248368704391 0.8494995764507511 
1.5309873556789189 2.5279238531383363 55.73962812998518 0.8417397595347644 
1.5558349141936216 2.5790400607092283 55.95020867554125 0.8356879218759914 
1.5684994472282983 2.600140571197321 56.071048192439974 0.8341452015094148 
1.5905754740629345 2.6463364723827825 56.23221742981801 0.8292577318146913 
1.6091661108090054 2.681942704716353 56.45867672804796 0.8252323458776541 
1.630223361451977 2.7237907684513645 56.92594258607423 0.8194355688897433 
1.6521471077298657 2.7578641822649366 57.532402304381414 0.8139099504752337 
1.6787168049873518 2.8204325037768805 58.25659079805272 0.8039880969887722 
1.6956035912902583 2.863238952609479 58.814366058366886 0.7965097628954344 
1.7064072704621192 2.877812210393293 59.44080192198447 0.7939087381501887 
1.7264643966634536 2.9197662755649287 60.21309899844319 0.7871088743538394 
1.620590686501026 2.708563762457877 57.244867715605515 0.7871088743538394 
epoch: 78, train time every whole data:434.98s
epoch: 78, total time:33173.51s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.50s
test time on whole data:59.07s
1.5004534001279446 2.445665272128952 55.1944187094947 0.8506727850259855 
1.5276098294118863 2.5105253910338923 55.54830005127306 0.8437609422922584 
1.5521349737239736 2.5623713109150743 55.70968849657615 0.8377803299764536 
1.5662712575416302 2.5895603090297694 55.916139995399085 0.8353859574952813 
1.5896737381248247 2.6395919136345087 56.14833822086982 0.830207266916122 
1.6084763558891024 2.6727143246278295 56.44179798524319 0.826232123537812 
1.629535613258591 2.715250508175874 56.94275909633926 0.8198038541124684 
1.6510505861264786 2.753311066430889 57.60389766416599 0.8131108945581472 
1.6756231572127769 2.812278468005031 58.35285879469823 0.8033694222695581 
1.6922490462852375 2.8511052133543577 58.928821016581814 0.7964194408712697 
1.7020186472100516 2.865565989557894 59.54069496966893 0.7937598775480081 
1.7236585173486245 2.909548923983403 60.25668261589355 0.7865741421220708 
1.61822959352176 2.6977520684588354 57.215452234646115 0.7865741421220708 
epoch: 79, train time every whole data:435.09s
epoch: 79, total time:33679.32s
predicting testing set batch 1 / 168, time: 0.34s
predicting testing set batch 101 / 168, time: 35.51s
test time on whole data:59.03s
1.4978159421666393 2.4279558913955603 56.31562280296109 0.8509102635047898 
1.5214558986535385 2.48419777922054 56.65237757428869 0.8442713127917735 
1.5455017975775436 2.537591177264213 56.84951041071544 0.8379166969484345 
1.5602453071312712 2.571122013489076 56.88205092693991 0.8349675639537808 
1.5847955155430273 2.6208708905946763 56.98150080551295 0.8303033972724061 
1.6073416716921187 2.664757664313609 57.124065603837494 0.8259946541846457 
1.633516493445085 2.7186043234893877 57.47219527494218 0.8192615959808238 
1.6576042224640648 2.7628061189477573 57.9934359004715 0.8125464347458148 
1.6842436204090536 2.8312011569946356 58.62166340396963 0.8013406355381776 
1.7022294828378197 2.8725360367667934 59.16876343278161 0.7941006965956389 
1.7124559265284667 2.8890884010027773 59.80387905999612 0.7911121251959411 
1.734846174335196 2.935599630547706 60.574200644101836 0.7835887271401915 
1.620171004398652 2.6978662991160127 57.87000354916634 0.7835887271401915 
