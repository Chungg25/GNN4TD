CUDA: True cuda:0
Read configuration file: configurations/bike.conf
total training epoch, fine tune epoch: 100 , 50
batch_size: 4
folder_dir: MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_adj
load file: data/bike.npz
ori length: 3001 , percent: 1.0 , scale: 3001
train: torch.Size([3001, 250, 2, 12]) torch.Size([3001, 250, 2, 12]) torch.Size([3001, 250, 2, 12])
val: torch.Size([672, 250, 2, 12]) torch.Size([672, 250, 2, 12]) torch.Size([672, 250, 2, 12])
test: torch.Size([672, 250, 2, 12]) torch.Size([672, 250, 2, 12]) torch.Size([672, 250, 2, 12])
TemporalPositionalEncoding max_len: 12
h_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
en_lookup_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
EncoderDecoder(
  (encoder): Encoder(
    (layers): ModuleList(
      (0): EncoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): selfAdaptiveGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn2): PositionWiseGCNFeedForward(
          (gcn): selfAdaptiveGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (tcn2): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (1): EncoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): selfAdaptiveGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn2): PositionWiseGCNFeedForward(
          (gcn): selfAdaptiveGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (tcn2): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (2): EncoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): selfAdaptiveGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn2): PositionWiseGCNFeedForward(
          (gcn): selfAdaptiveGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (tcn2): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (3): EncoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): selfAdaptiveGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn2): PositionWiseGCNFeedForward(
          (gcn): selfAdaptiveGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (tcn2): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): Decoder(
    (layers): ModuleList(
      (0): DecoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): selfAdaptiveGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (1): DecoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): selfAdaptiveGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (2): DecoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): selfAdaptiveGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (3): DecoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): selfAdaptiveGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (decoder2): Decoder(
    (layers): ModuleList(
      (0): DecoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): selfAdaptiveGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (1): DecoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): selfAdaptiveGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (2): DecoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): selfAdaptiveGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (3): DecoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): selfAdaptiveGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (src_embed): Sequential(
    (0): Linear(in_features=1, out_features=64, bias=True)
    (1): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (2): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(250, 64)
    )
  )
  (src_embed2): Sequential(
    (0): Linear(in_features=1, out_features=64, bias=True)
    (1): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (2): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(250, 64)
    )
  )
  (trg_embed): Sequential(
    (0): Linear(in_features=1, out_features=64, bias=True)
    (1): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (2): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(250, 64)
    )
  )
  (trg_embed2): Sequential(
    (0): Linear(in_features=1, out_features=64, bias=True)
    (1): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (2): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(250, 64)
    )
  )
  (prediction_generator): Linear(in_features=64, out_features=1, bias=True)
  (prediction_generator2): Linear(in_features=64, out_features=1, bias=True)
)
delete the old one and create params directory experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_adj
Net's state_dict:
encoder.layers.0.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.linears.2.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.linears.2.bias 	 torch.Size([64])
encoder.layers.0.self_attn.linears.3.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.linears.3.bias 	 torch.Size([64])
encoder.layers.0.feed_forward_gcn.gcn.nodevec1 	 torch.Size([250, 10])
encoder.layers.0.feed_forward_gcn.gcn.nodevec2 	 torch.Size([10, 250])
encoder.layers.0.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.0.feed_forward_gcn2.gcn.nodevec1 	 torch.Size([250, 10])
encoder.layers.0.feed_forward_gcn2.gcn.nodevec2 	 torch.Size([10, 250])
encoder.layers.0.feed_forward_gcn2.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.0.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.tcn.filter_convs.bias 	 torch.Size([64])
encoder.layers.0.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.tcn.gate_convs.bias 	 torch.Size([64])
encoder.layers.0.tcn2.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.tcn2.filter_convs.bias 	 torch.Size([64])
encoder.layers.0.tcn2.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.tcn2.gate_convs.bias 	 torch.Size([64])
encoder.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.2.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.2.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.3.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.3.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.4.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.4.norm.bias 	 torch.Size([64])
encoder.layers.1.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.linears.2.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.linears.2.bias 	 torch.Size([64])
encoder.layers.1.self_attn.linears.3.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.linears.3.bias 	 torch.Size([64])
encoder.layers.1.feed_forward_gcn.gcn.nodevec1 	 torch.Size([250, 10])
encoder.layers.1.feed_forward_gcn.gcn.nodevec2 	 torch.Size([10, 250])
encoder.layers.1.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.1.feed_forward_gcn2.gcn.nodevec1 	 torch.Size([250, 10])
encoder.layers.1.feed_forward_gcn2.gcn.nodevec2 	 torch.Size([10, 250])
encoder.layers.1.feed_forward_gcn2.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.1.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.tcn.filter_convs.bias 	 torch.Size([64])
encoder.layers.1.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.tcn.gate_convs.bias 	 torch.Size([64])
encoder.layers.1.tcn2.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.tcn2.filter_convs.bias 	 torch.Size([64])
encoder.layers.1.tcn2.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.tcn2.gate_convs.bias 	 torch.Size([64])
encoder.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.2.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.2.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.3.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.3.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.4.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.4.norm.bias 	 torch.Size([64])
encoder.layers.2.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.linears.2.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.linears.2.bias 	 torch.Size([64])
encoder.layers.2.self_attn.linears.3.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.linears.3.bias 	 torch.Size([64])
encoder.layers.2.feed_forward_gcn.gcn.nodevec1 	 torch.Size([250, 10])
encoder.layers.2.feed_forward_gcn.gcn.nodevec2 	 torch.Size([10, 250])
encoder.layers.2.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.2.feed_forward_gcn2.gcn.nodevec1 	 torch.Size([250, 10])
encoder.layers.2.feed_forward_gcn2.gcn.nodevec2 	 torch.Size([10, 250])
encoder.layers.2.feed_forward_gcn2.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.2.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.tcn.filter_convs.bias 	 torch.Size([64])
encoder.layers.2.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.tcn.gate_convs.bias 	 torch.Size([64])
encoder.layers.2.tcn2.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.tcn2.filter_convs.bias 	 torch.Size([64])
encoder.layers.2.tcn2.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.tcn2.gate_convs.bias 	 torch.Size([64])
encoder.layers.2.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.2.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.2.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.3.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.3.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.4.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.4.norm.bias 	 torch.Size([64])
encoder.layers.3.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.3.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.3.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.3.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.3.self_attn.linears.2.weight 	 torch.Size([64, 64])
encoder.layers.3.self_attn.linears.2.bias 	 torch.Size([64])
encoder.layers.3.self_attn.linears.3.weight 	 torch.Size([64, 64])
encoder.layers.3.self_attn.linears.3.bias 	 torch.Size([64])
encoder.layers.3.feed_forward_gcn.gcn.nodevec1 	 torch.Size([250, 10])
encoder.layers.3.feed_forward_gcn.gcn.nodevec2 	 torch.Size([10, 250])
encoder.layers.3.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.3.feed_forward_gcn2.gcn.nodevec1 	 torch.Size([250, 10])
encoder.layers.3.feed_forward_gcn2.gcn.nodevec2 	 torch.Size([10, 250])
encoder.layers.3.feed_forward_gcn2.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.3.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.3.tcn.filter_convs.bias 	 torch.Size([64])
encoder.layers.3.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.3.tcn.gate_convs.bias 	 torch.Size([64])
encoder.layers.3.tcn2.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.3.tcn2.filter_convs.bias 	 torch.Size([64])
encoder.layers.3.tcn2.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.3.tcn2.gate_convs.bias 	 torch.Size([64])
encoder.layers.3.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.3.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.3.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.3.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.3.sublayer.2.norm.weight 	 torch.Size([64])
encoder.layers.3.sublayer.2.norm.bias 	 torch.Size([64])
encoder.layers.3.sublayer.3.norm.weight 	 torch.Size([64])
encoder.layers.3.sublayer.3.norm.bias 	 torch.Size([64])
encoder.layers.3.sublayer.4.norm.weight 	 torch.Size([64])
encoder.layers.3.sublayer.4.norm.bias 	 torch.Size([64])
encoder.norm.weight 	 torch.Size([64])
encoder.norm.bias 	 torch.Size([64])
encoder.norm2.weight 	 torch.Size([64])
encoder.norm2.bias 	 torch.Size([64])
decoder.layers.0.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.0.self_attn.linears.2.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.linears.2.bias 	 torch.Size([64])
decoder.layers.0.self_attn.linears.3.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.linears.3.bias 	 torch.Size([64])
decoder.layers.0.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.0.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.linears.2.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.linears.2.bias 	 torch.Size([64])
decoder.layers.0.src_attn.linears.3.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.linears.3.bias 	 torch.Size([64])
decoder.layers.0.feed_forward_gcn.gcn.nodevec1 	 torch.Size([250, 10])
decoder.layers.0.feed_forward_gcn.gcn.nodevec2 	 torch.Size([10, 250])
decoder.layers.0.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.0.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.tcn.filter_convs.bias 	 torch.Size([64])
decoder.layers.0.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.tcn.gate_convs.bias 	 torch.Size([64])
decoder.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.3.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.3.norm.bias 	 torch.Size([64])
decoder.layers.1.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.1.self_attn.linears.2.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.linears.2.bias 	 torch.Size([64])
decoder.layers.1.self_attn.linears.3.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.linears.3.bias 	 torch.Size([64])
decoder.layers.1.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.1.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.linears.2.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.linears.2.bias 	 torch.Size([64])
decoder.layers.1.src_attn.linears.3.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.linears.3.bias 	 torch.Size([64])
decoder.layers.1.feed_forward_gcn.gcn.nodevec1 	 torch.Size([250, 10])
decoder.layers.1.feed_forward_gcn.gcn.nodevec2 	 torch.Size([10, 250])
decoder.layers.1.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.1.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.tcn.filter_convs.bias 	 torch.Size([64])
decoder.layers.1.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.tcn.gate_convs.bias 	 torch.Size([64])
decoder.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.3.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.3.norm.bias 	 torch.Size([64])
decoder.layers.2.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.2.self_attn.linears.2.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.linears.2.bias 	 torch.Size([64])
decoder.layers.2.self_attn.linears.3.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.linears.3.bias 	 torch.Size([64])
decoder.layers.2.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.2.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.linears.2.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.linears.2.bias 	 torch.Size([64])
decoder.layers.2.src_attn.linears.3.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.linears.3.bias 	 torch.Size([64])
decoder.layers.2.feed_forward_gcn.gcn.nodevec1 	 torch.Size([250, 10])
decoder.layers.2.feed_forward_gcn.gcn.nodevec2 	 torch.Size([10, 250])
decoder.layers.2.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.2.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.tcn.filter_convs.bias 	 torch.Size([64])
decoder.layers.2.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.tcn.gate_convs.bias 	 torch.Size([64])
decoder.layers.2.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.3.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.3.norm.bias 	 torch.Size([64])
decoder.layers.3.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.3.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.3.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.3.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.3.self_attn.linears.2.weight 	 torch.Size([64, 64])
decoder.layers.3.self_attn.linears.2.bias 	 torch.Size([64])
decoder.layers.3.self_attn.linears.3.weight 	 torch.Size([64, 64])
decoder.layers.3.self_attn.linears.3.bias 	 torch.Size([64])
decoder.layers.3.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.3.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.3.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.3.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.3.src_attn.linears.2.weight 	 torch.Size([64, 64])
decoder.layers.3.src_attn.linears.2.bias 	 torch.Size([64])
decoder.layers.3.src_attn.linears.3.weight 	 torch.Size([64, 64])
decoder.layers.3.src_attn.linears.3.bias 	 torch.Size([64])
decoder.layers.3.feed_forward_gcn.gcn.nodevec1 	 torch.Size([250, 10])
decoder.layers.3.feed_forward_gcn.gcn.nodevec2 	 torch.Size([10, 250])
decoder.layers.3.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.3.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.3.tcn.filter_convs.bias 	 torch.Size([64])
decoder.layers.3.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.3.tcn.gate_convs.bias 	 torch.Size([64])
decoder.layers.3.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.3.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.3.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.3.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.3.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.3.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.3.sublayer.3.norm.weight 	 torch.Size([64])
decoder.layers.3.sublayer.3.norm.bias 	 torch.Size([64])
decoder.norm.weight 	 torch.Size([64])
decoder.norm.bias 	 torch.Size([64])
decoder2.layers.0.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder2.layers.0.self_attn.linears.0.bias 	 torch.Size([64])
decoder2.layers.0.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder2.layers.0.self_attn.linears.1.bias 	 torch.Size([64])
decoder2.layers.0.self_attn.linears.2.weight 	 torch.Size([64, 64])
decoder2.layers.0.self_attn.linears.2.bias 	 torch.Size([64])
decoder2.layers.0.self_attn.linears.3.weight 	 torch.Size([64, 64])
decoder2.layers.0.self_attn.linears.3.bias 	 torch.Size([64])
decoder2.layers.0.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder2.layers.0.src_attn.linears.0.bias 	 torch.Size([64])
decoder2.layers.0.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder2.layers.0.src_attn.linears.1.bias 	 torch.Size([64])
decoder2.layers.0.src_attn.linears.2.weight 	 torch.Size([64, 64])
decoder2.layers.0.src_attn.linears.2.bias 	 torch.Size([64])
decoder2.layers.0.src_attn.linears.3.weight 	 torch.Size([64, 64])
decoder2.layers.0.src_attn.linears.3.bias 	 torch.Size([64])
decoder2.layers.0.feed_forward_gcn.gcn.nodevec1 	 torch.Size([250, 10])
decoder2.layers.0.feed_forward_gcn.gcn.nodevec2 	 torch.Size([10, 250])
decoder2.layers.0.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder2.layers.0.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder2.layers.0.tcn.filter_convs.bias 	 torch.Size([64])
decoder2.layers.0.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder2.layers.0.tcn.gate_convs.bias 	 torch.Size([64])
decoder2.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
decoder2.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
decoder2.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
decoder2.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
decoder2.layers.0.sublayer.2.norm.weight 	 torch.Size([64])
decoder2.layers.0.sublayer.2.norm.bias 	 torch.Size([64])
decoder2.layers.0.sublayer.3.norm.weight 	 torch.Size([64])
decoder2.layers.0.sublayer.3.norm.bias 	 torch.Size([64])
decoder2.layers.1.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder2.layers.1.self_attn.linears.0.bias 	 torch.Size([64])
decoder2.layers.1.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder2.layers.1.self_attn.linears.1.bias 	 torch.Size([64])
decoder2.layers.1.self_attn.linears.2.weight 	 torch.Size([64, 64])
decoder2.layers.1.self_attn.linears.2.bias 	 torch.Size([64])
decoder2.layers.1.self_attn.linears.3.weight 	 torch.Size([64, 64])
decoder2.layers.1.self_attn.linears.3.bias 	 torch.Size([64])
decoder2.layers.1.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder2.layers.1.src_attn.linears.0.bias 	 torch.Size([64])
decoder2.layers.1.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder2.layers.1.src_attn.linears.1.bias 	 torch.Size([64])
decoder2.layers.1.src_attn.linears.2.weight 	 torch.Size([64, 64])
decoder2.layers.1.src_attn.linears.2.bias 	 torch.Size([64])
decoder2.layers.1.src_attn.linears.3.weight 	 torch.Size([64, 64])
decoder2.layers.1.src_attn.linears.3.bias 	 torch.Size([64])
decoder2.layers.1.feed_forward_gcn.gcn.nodevec1 	 torch.Size([250, 10])
decoder2.layers.1.feed_forward_gcn.gcn.nodevec2 	 torch.Size([10, 250])
decoder2.layers.1.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder2.layers.1.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder2.layers.1.tcn.filter_convs.bias 	 torch.Size([64])
decoder2.layers.1.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder2.layers.1.tcn.gate_convs.bias 	 torch.Size([64])
decoder2.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
decoder2.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
decoder2.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
decoder2.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
decoder2.layers.1.sublayer.2.norm.weight 	 torch.Size([64])
decoder2.layers.1.sublayer.2.norm.bias 	 torch.Size([64])
decoder2.layers.1.sublayer.3.norm.weight 	 torch.Size([64])
decoder2.layers.1.sublayer.3.norm.bias 	 torch.Size([64])
decoder2.layers.2.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder2.layers.2.self_attn.linears.0.bias 	 torch.Size([64])
decoder2.layers.2.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder2.layers.2.self_attn.linears.1.bias 	 torch.Size([64])
decoder2.layers.2.self_attn.linears.2.weight 	 torch.Size([64, 64])
decoder2.layers.2.self_attn.linears.2.bias 	 torch.Size([64])
decoder2.layers.2.self_attn.linears.3.weight 	 torch.Size([64, 64])
decoder2.layers.2.self_attn.linears.3.bias 	 torch.Size([64])
decoder2.layers.2.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder2.layers.2.src_attn.linears.0.bias 	 torch.Size([64])
decoder2.layers.2.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder2.layers.2.src_attn.linears.1.bias 	 torch.Size([64])
decoder2.layers.2.src_attn.linears.2.weight 	 torch.Size([64, 64])
decoder2.layers.2.src_attn.linears.2.bias 	 torch.Size([64])
decoder2.layers.2.src_attn.linears.3.weight 	 torch.Size([64, 64])
decoder2.layers.2.src_attn.linears.3.bias 	 torch.Size([64])
decoder2.layers.2.feed_forward_gcn.gcn.nodevec1 	 torch.Size([250, 10])
decoder2.layers.2.feed_forward_gcn.gcn.nodevec2 	 torch.Size([10, 250])
decoder2.layers.2.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder2.layers.2.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder2.layers.2.tcn.filter_convs.bias 	 torch.Size([64])
decoder2.layers.2.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder2.layers.2.tcn.gate_convs.bias 	 torch.Size([64])
decoder2.layers.2.sublayer.0.norm.weight 	 torch.Size([64])
decoder2.layers.2.sublayer.0.norm.bias 	 torch.Size([64])
decoder2.layers.2.sublayer.1.norm.weight 	 torch.Size([64])
decoder2.layers.2.sublayer.1.norm.bias 	 torch.Size([64])
decoder2.layers.2.sublayer.2.norm.weight 	 torch.Size([64])
decoder2.layers.2.sublayer.2.norm.bias 	 torch.Size([64])
decoder2.layers.2.sublayer.3.norm.weight 	 torch.Size([64])
decoder2.layers.2.sublayer.3.norm.bias 	 torch.Size([64])
decoder2.layers.3.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder2.layers.3.self_attn.linears.0.bias 	 torch.Size([64])
decoder2.layers.3.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder2.layers.3.self_attn.linears.1.bias 	 torch.Size([64])
decoder2.layers.3.self_attn.linears.2.weight 	 torch.Size([64, 64])
decoder2.layers.3.self_attn.linears.2.bias 	 torch.Size([64])
decoder2.layers.3.self_attn.linears.3.weight 	 torch.Size([64, 64])
decoder2.layers.3.self_attn.linears.3.bias 	 torch.Size([64])
decoder2.layers.3.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder2.layers.3.src_attn.linears.0.bias 	 torch.Size([64])
decoder2.layers.3.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder2.layers.3.src_attn.linears.1.bias 	 torch.Size([64])
decoder2.layers.3.src_attn.linears.2.weight 	 torch.Size([64, 64])
decoder2.layers.3.src_attn.linears.2.bias 	 torch.Size([64])
decoder2.layers.3.src_attn.linears.3.weight 	 torch.Size([64, 64])
decoder2.layers.3.src_attn.linears.3.bias 	 torch.Size([64])
decoder2.layers.3.feed_forward_gcn.gcn.nodevec1 	 torch.Size([250, 10])
decoder2.layers.3.feed_forward_gcn.gcn.nodevec2 	 torch.Size([10, 250])
decoder2.layers.3.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder2.layers.3.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder2.layers.3.tcn.filter_convs.bias 	 torch.Size([64])
decoder2.layers.3.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder2.layers.3.tcn.gate_convs.bias 	 torch.Size([64])
decoder2.layers.3.sublayer.0.norm.weight 	 torch.Size([64])
decoder2.layers.3.sublayer.0.norm.bias 	 torch.Size([64])
decoder2.layers.3.sublayer.1.norm.weight 	 torch.Size([64])
decoder2.layers.3.sublayer.1.norm.bias 	 torch.Size([64])
decoder2.layers.3.sublayer.2.norm.weight 	 torch.Size([64])
decoder2.layers.3.sublayer.2.norm.bias 	 torch.Size([64])
decoder2.layers.3.sublayer.3.norm.weight 	 torch.Size([64])
decoder2.layers.3.sublayer.3.norm.bias 	 torch.Size([64])
decoder2.norm.weight 	 torch.Size([64])
decoder2.norm.bias 	 torch.Size([64])
src_embed.0.weight 	 torch.Size([64, 1])
src_embed.0.bias 	 torch.Size([64])
src_embed.1.pe 	 torch.Size([1, 1, 12, 64])
src_embed.2.embedding.weight 	 torch.Size([250, 64])
src_embed2.0.weight 	 torch.Size([64, 1])
src_embed2.0.bias 	 torch.Size([64])
src_embed2.1.pe 	 torch.Size([1, 1, 12, 64])
src_embed2.2.embedding.weight 	 torch.Size([250, 64])
trg_embed.0.weight 	 torch.Size([64, 1])
trg_embed.0.bias 	 torch.Size([64])
trg_embed.1.pe 	 torch.Size([1, 1, 12, 64])
trg_embed.2.embedding.weight 	 torch.Size([250, 64])
trg_embed2.0.weight 	 torch.Size([64, 1])
trg_embed2.0.bias 	 torch.Size([64])
trg_embed2.1.pe 	 torch.Size([1, 1, 12, 64])
trg_embed2.2.embedding.weight 	 torch.Size([250, 64])
prediction_generator.weight 	 torch.Size([1, 64])
prediction_generator.bias 	 torch.Size([1])
prediction_generator2.weight 	 torch.Size([1, 64])
prediction_generator2.bias 	 torch.Size([1])
Net's total params: 948482
Optimizer's state_dict:
state 	 {}
param_groups 	 [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399]}]
validation batch 1 / 168, loss: 1.21
validation batch 101 / 168, loss: 1.27
validation cost time: 43.8949s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_adj/epoch_0.params
epoch: 0, learning rate 0.001000
epoch: 0, train time every whole data:161.78s
epoch: 0, total time:205.85s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.14
validation cost time: 44.4588s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_adj/epoch_1.params
epoch: 1, learning rate 0.001000
epoch: 1, train time every whole data:162.66s
epoch: 1, total time:413.09s
validation batch 1 / 168, loss: 0.09
validation batch 101 / 168, loss: 0.08
validation cost time: 44.4851s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_adj/epoch_2.params
epoch: 2, learning rate 0.001000
epoch: 2, train time every whole data:162.63s
epoch: 2, total time:620.30s
validation batch 1 / 168, loss: 0.08
validation batch 101 / 168, loss: 0.04
validation cost time: 44.7766s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_adj/epoch_3.params
epoch: 3, learning rate 0.001000
epoch: 3, train time every whole data:162.36s
epoch: 3, total time:827.60s
validation batch 1 / 168, loss: 0.10
validation batch 101 / 168, loss: 0.03
validation cost time: 44.5033s
epoch: 4, learning rate 0.001000
epoch: 4, train time every whole data:162.75s
epoch: 4, total time:1034.86s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.07
validation cost time: 44.7985s
epoch: 5, learning rate 0.001000
epoch: 5, train time every whole data:161.98s
epoch: 5, total time:1241.64s
validation batch 1 / 168, loss: 0.07
validation batch 101 / 168, loss: 0.03
validation cost time: 44.8159s
epoch: 6, learning rate 0.001000
epoch: 6, train time every whole data:161.91s
epoch: 6, total time:1448.37s
validation batch 1 / 168, loss: 0.16
validation batch 101 / 168, loss: 0.12
validation cost time: 44.6804s
epoch: 7, learning rate 0.001000
epoch: 7, train time every whole data:162.28s
epoch: 7, total time:1655.34s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.08
validation cost time: 44.5106s
epoch: 8, learning rate 0.001000
epoch: 8, train time every whole data:161.21s
epoch: 8, total time:1861.06s
validation batch 1 / 168, loss: 0.10
validation batch 101 / 168, loss: 0.03
validation cost time: 44.4224s
epoch: 9, learning rate 0.001000
epoch: 9, train time every whole data:161.63s
epoch: 9, total time:2067.12s
validation batch 1 / 168, loss: 0.10
validation batch 101 / 168, loss: 0.04
validation cost time: 44.6287s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_adj/epoch_10.params
epoch: 10, learning rate 0.001000
epoch: 10, train time every whole data:161.95s
epoch: 10, total time:2273.85s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.04
validation cost time: 44.7450s
epoch: 11, learning rate 0.001000
epoch: 11, train time every whole data:161.91s
epoch: 11, total time:2480.51s
validation batch 1 / 168, loss: 0.09
validation batch 101 / 168, loss: 0.04
validation cost time: 44.6766s
epoch: 12, learning rate 0.001000
epoch: 12, train time every whole data:161.86s
epoch: 12, total time:2687.05s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.04
validation cost time: 44.6703s
epoch: 13, learning rate 0.001000
epoch: 13, train time every whole data:161.69s
epoch: 13, total time:2893.42s
validation batch 1 / 168, loss: 0.09
validation batch 101 / 168, loss: 0.03
validation cost time: 44.6216s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_adj/epoch_14.params
epoch: 14, learning rate 0.001000
epoch: 14, train time every whole data:162.46s
epoch: 14, total time:3100.62s
validation batch 1 / 168, loss: 0.10
validation batch 101 / 168, loss: 0.04
validation cost time: 44.7547s
epoch: 15, learning rate 0.001000
epoch: 15, train time every whole data:161.94s
epoch: 15, total time:3307.32s
validation batch 1 / 168, loss: 0.10
validation batch 101 / 168, loss: 0.06
validation cost time: 44.4594s
epoch: 16, learning rate 0.001000
epoch: 16, train time every whole data:161.83s
epoch: 16, total time:3513.62s
validation batch 1 / 168, loss: 0.07
validation batch 101 / 168, loss: 0.05
validation cost time: 44.4370s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_adj/epoch_17.params
epoch: 17, learning rate 0.001000
epoch: 17, train time every whole data:162.53s
epoch: 17, total time:3720.72s
validation batch 1 / 168, loss: 0.10
validation batch 101 / 168, loss: 0.04
validation cost time: 44.7525s
epoch: 18, learning rate 0.001000
epoch: 18, train time every whole data:162.62s
epoch: 18, total time:3928.10s
validation batch 1 / 168, loss: 0.07
validation batch 101 / 168, loss: 0.04
validation cost time: 44.6974s
epoch: 19, learning rate 0.001000
epoch: 19, train time every whole data:162.63s
epoch: 19, total time:4135.42s
validation batch 1 / 168, loss: 0.07
validation batch 101 / 168, loss: 0.03
validation cost time: 44.5019s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_adj/epoch_20.params
epoch: 20, learning rate 0.001000
epoch: 20, train time every whole data:162.91s
epoch: 20, total time:4343.01s
validation batch 1 / 168, loss: 0.10
validation batch 101 / 168, loss: 0.05
validation cost time: 44.6016s
epoch: 21, learning rate 0.001000
epoch: 21, train time every whole data:163.08s
epoch: 21, total time:4550.69s
validation batch 1 / 168, loss: 0.08
validation batch 101 / 168, loss: 0.02
validation cost time: 44.7548s
epoch: 22, learning rate 0.001000
epoch: 22, train time every whole data:162.77s
epoch: 22, total time:4758.22s
validation batch 1 / 168, loss: 0.07
validation batch 101 / 168, loss: 0.03
validation cost time: 44.6715s
epoch: 23, learning rate 0.001000
epoch: 23, train time every whole data:162.64s
epoch: 23, total time:4965.53s
validation batch 1 / 168, loss: 0.08
validation batch 101 / 168, loss: 0.02
validation cost time: 44.8300s
epoch: 24, learning rate 0.001000
epoch: 24, train time every whole data:162.77s
epoch: 24, total time:5173.13s
validation batch 1 / 168, loss: 0.07
validation batch 101 / 168, loss: 0.03
validation cost time: 44.8072s
epoch: 25, learning rate 0.001000
epoch: 25, train time every whole data:162.62s
epoch: 25, total time:5380.57s
validation batch 1 / 168, loss: 0.09
validation batch 101 / 168, loss: 0.03
validation cost time: 44.8239s
epoch: 26, learning rate 0.001000
epoch: 26, train time every whole data:163.02s
epoch: 26, total time:5588.42s
validation batch 1 / 168, loss: 0.09
validation batch 101 / 168, loss: 0.02
validation cost time: 44.6770s
epoch: 27, learning rate 0.001000
epoch: 27, train time every whole data:162.81s
epoch: 27, total time:5795.91s
validation batch 1 / 168, loss: 0.09
validation batch 101 / 168, loss: 0.02
validation cost time: 44.7063s
epoch: 28, learning rate 0.001000
epoch: 28, train time every whole data:162.90s
epoch: 28, total time:6003.52s
validation batch 1 / 168, loss: 0.09
validation batch 101 / 168, loss: 0.02
validation cost time: 44.8414s
epoch: 29, learning rate 0.001000
epoch: 29, train time every whole data:162.67s
epoch: 29, total time:6211.04s
validation batch 1 / 168, loss: 0.07
validation batch 101 / 168, loss: 0.02
validation cost time: 44.6289s
epoch: 30, learning rate 0.001000
epoch: 30, train time every whole data:162.80s
epoch: 30, total time:6418.47s
validation batch 1 / 168, loss: 0.10
validation batch 101 / 168, loss: 0.04
validation cost time: 44.8453s
epoch: 31, learning rate 0.001000
epoch: 31, train time every whole data:162.87s
epoch: 31, total time:6626.19s
validation batch 1 / 168, loss: 0.07
validation batch 101 / 168, loss: 0.02
validation cost time: 44.7818s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_adj/epoch_32.params
epoch: 32, learning rate 0.001000
epoch: 32, train time every whole data:162.92s
epoch: 32, total time:6834.14s
validation batch 1 / 168, loss: 0.09
validation batch 101 / 168, loss: 0.02
validation cost time: 44.7915s
epoch: 33, learning rate 0.001000
epoch: 33, train time every whole data:163.05s
epoch: 33, total time:7041.99s
validation batch 1 / 168, loss: 0.09
validation batch 101 / 168, loss: 0.02
validation cost time: 44.6812s
epoch: 34, learning rate 0.001000
epoch: 34, train time every whole data:162.66s
epoch: 34, total time:7249.33s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 44.5746s
epoch: 35, learning rate 0.001000
epoch: 35, train time every whole data:162.84s
epoch: 35, total time:7456.75s
validation batch 1 / 168, loss: 0.08
validation batch 101 / 168, loss: 0.02
validation cost time: 44.6812s
epoch: 36, learning rate 0.001000
epoch: 36, train time every whole data:162.50s
epoch: 36, total time:7663.93s
validation batch 1 / 168, loss: 0.10
validation batch 101 / 168, loss: 0.02
validation cost time: 44.7098s
epoch: 37, learning rate 0.001000
epoch: 37, train time every whole data:162.58s
epoch: 37, total time:7871.22s
validation batch 1 / 168, loss: 0.09
validation batch 101 / 168, loss: 0.02
validation cost time: 44.7185s
epoch: 38, learning rate 0.001000
epoch: 38, train time every whole data:162.66s
epoch: 38, total time:8078.60s
validation batch 1 / 168, loss: 0.10
validation batch 101 / 168, loss: 0.02
validation cost time: 44.8112s
epoch: 39, learning rate 0.001000
epoch: 39, train time every whole data:162.97s
epoch: 39, total time:8286.38s
validation batch 1 / 168, loss: 0.07
validation batch 101 / 168, loss: 0.02
validation cost time: 44.6849s
epoch: 40, learning rate 0.001000
epoch: 40, train time every whole data:162.73s
epoch: 40, total time:8493.80s
validation batch 1 / 168, loss: 0.09
validation batch 101 / 168, loss: 0.02
validation cost time: 44.7834s
epoch: 41, learning rate 0.001000
epoch: 41, train time every whole data:162.84s
epoch: 41, total time:8701.43s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 44.7415s
epoch: 42, learning rate 0.001000
epoch: 42, train time every whole data:162.27s
epoch: 42, total time:8908.44s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 44.7587s
epoch: 43, learning rate 0.001000
epoch: 43, train time every whole data:162.68s
epoch: 43, total time:9115.89s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 44.7832s
epoch: 44, learning rate 0.001000
epoch: 44, train time every whole data:162.60s
epoch: 44, total time:9323.27s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 44.7346s
epoch: 45, learning rate 0.001000
epoch: 45, train time every whole data:162.21s
epoch: 45, total time:9530.22s
validation batch 1 / 168, loss: 0.10
validation batch 101 / 168, loss: 0.02
validation cost time: 44.6916s
epoch: 46, learning rate 0.001000
epoch: 46, train time every whole data:161.92s
epoch: 46, total time:9736.84s
validation batch 1 / 168, loss: 0.10
validation batch 101 / 168, loss: 0.02
validation cost time: 44.5556s
epoch: 47, learning rate 0.001000
epoch: 47, train time every whole data:161.18s
epoch: 47, total time:9942.58s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 44.5094s
epoch: 48, learning rate 0.001000
epoch: 48, train time every whole data:161.78s
epoch: 48, total time:10148.87s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 44.7268s
epoch: 49, learning rate 0.001000
epoch: 49, train time every whole data:162.05s
epoch: 49, total time:10355.65s
validation batch 1 / 168, loss: 0.10
validation batch 101 / 168, loss: 0.02
validation cost time: 44.6549s
epoch: 50, learning rate 0.001000
epoch: 50, train time every whole data:162.15s
epoch: 50, total time:10562.46s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 44.7417s
epoch: 51, learning rate 0.001000
epoch: 51, train time every whole data:162.79s
epoch: 51, total time:10769.99s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.01
validation cost time: 44.8147s
epoch: 52, learning rate 0.001000
epoch: 52, train time every whole data:162.35s
epoch: 52, total time:10977.16s
validation batch 1 / 168, loss: 0.10
validation batch 101 / 168, loss: 0.02
validation cost time: 44.7878s
epoch: 53, learning rate 0.001000
epoch: 53, train time every whole data:162.58s
epoch: 53, total time:11184.53s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 44.6457s
epoch: 54, learning rate 0.001000
epoch: 54, train time every whole data:162.34s
epoch: 54, total time:11391.52s
validation batch 1 / 168, loss: 0.10
validation batch 101 / 168, loss: 0.02
validation cost time: 44.7469s
epoch: 55, learning rate 0.001000
epoch: 55, train time every whole data:162.28s
epoch: 55, total time:11598.55s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 45.0274s
epoch: 56, learning rate 0.001000
epoch: 56, train time every whole data:162.01s
epoch: 56, total time:11805.60s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 45.1836s
epoch: 57, learning rate 0.001000
epoch: 57, train time every whole data:161.92s
epoch: 57, total time:12012.71s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 45.1565s
epoch: 58, learning rate 0.001000
epoch: 58, train time every whole data:162.35s
epoch: 58, total time:12220.22s
validation batch 1 / 168, loss: 0.10
validation batch 101 / 168, loss: 0.02
validation cost time: 44.3893s
epoch: 59, learning rate 0.001000
epoch: 59, train time every whole data:162.43s
epoch: 59, total time:12427.04s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 44.7529s
epoch: 60, learning rate 0.001000
epoch: 60, train time every whole data:162.51s
epoch: 60, total time:12634.31s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 45.0122s
epoch: 61, learning rate 0.001000
epoch: 61, train time every whole data:162.46s
epoch: 61, total time:12841.78s
validation batch 1 / 168, loss: 0.10
validation batch 101 / 168, loss: 0.02
validation cost time: 44.6189s
epoch: 62, learning rate 0.001000
epoch: 62, train time every whole data:162.30s
epoch: 62, total time:13048.70s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.03
validation cost time: 44.7227s
epoch: 63, learning rate 0.001000
epoch: 63, train time every whole data:162.33s
epoch: 63, total time:13255.76s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 44.7849s
epoch: 64, learning rate 0.001000
epoch: 64, train time every whole data:162.07s
epoch: 64, total time:13462.62s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 44.7903s
epoch: 65, learning rate 0.001000
epoch: 65, train time every whole data:162.48s
epoch: 65, total time:13669.89s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 44.6562s
epoch: 66, learning rate 0.001000
epoch: 66, train time every whole data:162.46s
epoch: 66, total time:13877.01s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 44.6483s
epoch: 67, learning rate 0.001000
epoch: 67, train time every whole data:162.60s
epoch: 67, total time:14084.26s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 44.5937s
epoch: 68, learning rate 0.001000
epoch: 68, train time every whole data:162.57s
epoch: 68, total time:14291.42s
validation batch 1 / 168, loss: 0.15
validation batch 101 / 168, loss: 0.02
validation cost time: 44.7169s
epoch: 69, learning rate 0.001000
epoch: 69, train time every whole data:162.39s
epoch: 69, total time:14498.53s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 44.7016s
epoch: 70, learning rate 0.001000
epoch: 70, train time every whole data:162.43s
epoch: 70, total time:14705.67s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.03
validation cost time: 44.8312s
epoch: 71, learning rate 0.001000
epoch: 71, train time every whole data:162.61s
epoch: 71, total time:14913.11s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 44.8395s
epoch: 72, learning rate 0.001000
epoch: 72, train time every whole data:162.42s
epoch: 72, total time:15120.37s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 44.9254s
epoch: 73, learning rate 0.001000
epoch: 73, train time every whole data:162.42s
epoch: 73, total time:15327.72s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 44.7857s
epoch: 74, learning rate 0.001000
epoch: 74, train time every whole data:162.25s
epoch: 74, total time:15534.77s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 44.7540s
epoch: 75, learning rate 0.001000
epoch: 75, train time every whole data:162.55s
epoch: 75, total time:15742.08s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 44.7569s
epoch: 76, learning rate 0.001000
epoch: 76, train time every whole data:162.09s
epoch: 76, total time:15948.93s
validation batch 1 / 168, loss: 0.15
validation batch 101 / 168, loss: 0.02
validation cost time: 44.7918s
epoch: 77, learning rate 0.001000
epoch: 77, train time every whole data:162.01s
epoch: 77, total time:16155.74s
validation batch 1 / 168, loss: 0.14
validation batch 101 / 168, loss: 0.02
validation cost time: 44.7536s
epoch: 78, learning rate 0.001000
epoch: 78, train time every whole data:161.62s
epoch: 78, total time:16362.12s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 44.4073s
epoch: 79, learning rate 0.001000
epoch: 79, train time every whole data:161.09s
epoch: 79, total time:16567.61s
validation batch 1 / 168, loss: 0.14
validation batch 101 / 168, loss: 0.02
validation cost time: 44.6225s
epoch: 80, learning rate 0.001000
epoch: 80, train time every whole data:160.89s
epoch: 80, total time:16773.13s
validation batch 1 / 168, loss: 0.14
validation batch 101 / 168, loss: 0.02
validation cost time: 44.5314s
epoch: 81, learning rate 0.001000
epoch: 81, train time every whole data:160.98s
epoch: 81, total time:16978.66s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 44.3953s
epoch: 82, learning rate 0.001000
epoch: 82, train time every whole data:161.76s
epoch: 82, total time:17184.82s
validation batch 1 / 168, loss: 0.14
validation batch 101 / 168, loss: 0.02
validation cost time: 44.6658s
epoch: 83, learning rate 0.001000
epoch: 83, train time every whole data:162.40s
epoch: 83, total time:17391.89s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 44.7453s
epoch: 84, learning rate 0.001000
epoch: 84, train time every whole data:162.66s
epoch: 84, total time:17599.30s
validation batch 1 / 168, loss: 0.15
validation batch 101 / 168, loss: 0.02
validation cost time: 44.7054s
epoch: 85, learning rate 0.001000
epoch: 85, train time every whole data:162.48s
epoch: 85, total time:17806.49s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 44.7656s
epoch: 86, learning rate 0.001000
epoch: 86, train time every whole data:162.32s
epoch: 86, total time:18013.58s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 44.7574s
epoch: 87, learning rate 0.001000
epoch: 87, train time every whole data:162.55s
epoch: 87, total time:18220.89s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 44.7181s
epoch: 88, learning rate 0.001000
epoch: 88, train time every whole data:162.48s
epoch: 88, total time:18428.09s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 44.8979s
epoch: 89, learning rate 0.001000
epoch: 89, train time every whole data:162.40s
epoch: 89, total time:18635.39s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 44.6664s
epoch: 90, learning rate 0.001000
epoch: 90, train time every whole data:162.65s
epoch: 90, total time:18842.71s
validation batch 1 / 168, loss: 0.14
validation batch 101 / 168, loss: 0.02
validation cost time: 44.7038s
epoch: 91, learning rate 0.001000
epoch: 91, train time every whole data:162.43s
epoch: 91, total time:19049.85s
validation batch 1 / 168, loss: 0.15
validation batch 101 / 168, loss: 0.02
validation cost time: 44.7880s
epoch: 92, learning rate 0.001000
epoch: 92, train time every whole data:162.57s
epoch: 92, total time:19257.22s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 44.8153s
epoch: 93, learning rate 0.001000
epoch: 93, train time every whole data:161.96s
epoch: 93, total time:19463.99s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 44.5919s
epoch: 94, learning rate 0.001000
epoch: 94, train time every whole data:162.39s
epoch: 94, total time:19670.98s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 44.8250s
epoch: 95, learning rate 0.001000
epoch: 95, train time every whole data:162.49s
epoch: 95, total time:19878.30s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 44.9068s
epoch: 96, learning rate 0.001000
epoch: 96, train time every whole data:162.33s
epoch: 96, total time:20085.54s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 44.9043s
epoch: 97, learning rate 0.001000
epoch: 97, train time every whole data:162.58s
epoch: 97, total time:20293.03s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 44.6033s
epoch: 98, learning rate 0.001000
epoch: 98, train time every whole data:162.44s
epoch: 98, total time:20500.08s
validation batch 1 / 168, loss: 0.14
validation batch 101 / 168, loss: 0.02
validation cost time: 44.5705s
epoch: 99, learning rate 0.001000
epoch: 99, train time every whole data:162.64s
epoch: 99, total time:20707.29s
best epoch: 32
apply the best val model on the test data set ...
load weight from: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_adj/epoch_32.params
predicting testing set batch 1 / 168, time: 0.27s
predicting testing set batch 101 / 168, time: 26.86s
test time on whole data:44.71s
input: (672, 250, 12, 2)
prediction: (672, 250, 12, 2)
data_target_tensor: (672, 250, 12, 2)
current epoch: 32, predict 0 points
MAE: 1.56
RMSE: 2.54
MAPE: 52.93
PCC: 0.84
current epoch: 32, predict 1 points
MAE: 1.72
RMSE: 2.85
MAPE: 59.97
PCC: 0.79
current epoch: 32, predict 2 points
MAE: 1.87
RMSE: 3.19
MAPE: 66.95
PCC: 0.74
current epoch: 32, predict 3 points
MAE: 2.03
RMSE: 3.51
MAPE: 73.55
PCC: 0.70
current epoch: 32, predict 4 points
MAE: 2.17
RMSE: 3.80
MAPE: 78.89
PCC: 0.65
current epoch: 32, predict 5 points
MAE: 2.29
RMSE: 4.04
MAPE: 83.16
PCC: 0.60
current epoch: 32, predict 6 points
MAE: 2.40
RMSE: 4.24
MAPE: 86.46
PCC: 0.56
current epoch: 32, predict 7 points
MAE: 2.43
RMSE: 4.28
MAPE: 86.99
PCC: 0.54
current epoch: 32, predict 8 points
MAE: 2.42
RMSE: 4.23
MAPE: 85.65
PCC: 0.54
current epoch: 32, predict 9 points
MAE: 2.41
RMSE: 4.17
MAPE: 84.44
PCC: 0.54
current epoch: 32, predict 10 points
MAE: 2.39
RMSE: 4.08
MAPE: 82.73
PCC: 0.55
current epoch: 32, predict 11 points
MAE: 2.35
RMSE: 3.98
MAPE: 79.56
PCC: 0.56
all MAE: 2.17
all RMSE: 3.79
all MAPE: 76.77
all PCC: 0.56
1.5620265744998165 2.543914054404547 52.93412340910625 0.841239936724077 
1.7221715500097545 2.8530003200472773 59.9721334444713 0.7899479711910189 
1.8745833411813668 3.187747527215935 66.94573239615234 0.7426161658058827 
2.0251308273521387 3.508081411803609 73.54987270022778 0.6956127683034745 
2.165528911370163 3.796336206149269 78.89285482605976 0.6474584031404365 
2.2932385451848663 4.043826490810099 83.16353498511772 0.6001162979272513 
2.3958000476341694 4.237871215921136 86.46498383280998 0.5572632340856097 
2.4296122076842224 4.279703398535614 86.9943853922476 0.5375606105269429 
2.422114056892427 4.2317592070650125 85.64704429060032 0.5357563566874504 
2.4139489848201294 4.174081281802659 84.4413383198392 0.5399213753024963 
2.391455405515042 4.082546838777229 82.7251964797525 0.546685859882232 
2.350642993011379 3.976568956587867 79.556879101992 0.5584188844714039 
2.170521120429623 3.785175291213416 76.77461751200971 0.5584188844714039 
fine tune the model ... 
epoch: 100, learning rate 0.000100
epoch: 100, train time every whole data:341.49s
epoch: 100, total time:21104.94s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 44.7748s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_adj/epoch_100.params
epoch: 101, learning rate 0.000100
epoch: 101, train time every whole data:341.38s
epoch: 101, total time:21491.20s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 44.6930s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_adj/epoch_101.params
epoch: 102, learning rate 0.000100
epoch: 102, train time every whole data:341.42s
epoch: 102, total time:21877.44s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 44.8201s
epoch: 103, learning rate 0.000100
epoch: 103, train time every whole data:341.45s
epoch: 103, total time:22263.71s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 44.7985s
epoch: 104, learning rate 0.000100
epoch: 104, train time every whole data:341.52s
epoch: 104, total time:22650.04s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 44.9350s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_adj/epoch_104.params
epoch: 105, learning rate 0.000100
epoch: 105, train time every whole data:340.38s
epoch: 105, total time:23035.48s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 44.6489s
epoch: 106, learning rate 0.000100
epoch: 106, train time every whole data:336.88s
epoch: 106, total time:23417.01s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 44.4686s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_adj/epoch_106.params
epoch: 107, learning rate 0.000100
epoch: 107, train time every whole data:338.21s
epoch: 107, total time:23799.78s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 44.4419s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_adj/epoch_107.params
epoch: 108, learning rate 0.000100
epoch: 108, train time every whole data:339.77s
epoch: 108, total time:24184.09s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 44.7303s
epoch: 109, learning rate 0.000100
epoch: 109, train time every whole data:341.30s
epoch: 109, total time:24570.12s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 44.9658s
epoch: 110, learning rate 0.000100
epoch: 110, train time every whole data:341.39s
epoch: 110, total time:24956.48s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 44.8200s
epoch: 111, learning rate 0.000100
epoch: 111, train time every whole data:340.38s
epoch: 111, total time:25341.69s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 44.9485s
epoch: 112, learning rate 0.000100
epoch: 112, train time every whole data:341.33s
epoch: 112, total time:25727.97s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 44.8346s
epoch: 113, learning rate 0.000100
epoch: 113, train time every whole data:341.21s
epoch: 113, total time:26114.02s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 44.8222s
epoch: 114, learning rate 0.000100
epoch: 114, train time every whole data:341.38s
epoch: 114, total time:26500.22s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 44.9330s
epoch: 115, learning rate 0.000100
epoch: 115, train time every whole data:341.41s
epoch: 115, total time:26886.57s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 44.8861s
epoch: 116, learning rate 0.000100
epoch: 116, train time every whole data:340.92s
epoch: 116, total time:27272.38s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 44.7476s
epoch: 117, learning rate 0.000100
epoch: 117, train time every whole data:341.04s
epoch: 117, total time:27658.18s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 44.8963s
epoch: 118, learning rate 0.000100
epoch: 118, train time every whole data:340.86s
epoch: 118, total time:28043.94s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 44.9872s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_adj/epoch_118.params
epoch: 119, learning rate 0.000100
epoch: 119, train time every whole data:341.37s
epoch: 119, total time:28430.42s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 44.8005s
epoch: 120, learning rate 0.000100
epoch: 120, train time every whole data:341.52s
epoch: 120, total time:28816.75s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 44.8344s
epoch: 121, learning rate 0.000100
epoch: 121, train time every whole data:341.61s
epoch: 121, total time:29203.20s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 44.8382s
epoch: 122, learning rate 0.000100
epoch: 122, train time every whole data:340.81s
epoch: 122, total time:29588.85s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 44.6657s
epoch: 123, learning rate 0.000100
epoch: 123, train time every whole data:339.27s
epoch: 123, total time:29972.78s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 44.7854s
epoch: 124, learning rate 0.000100
epoch: 124, train time every whole data:339.61s
epoch: 124, total time:30357.18s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 44.6460s
epoch: 125, learning rate 0.000100
epoch: 125, train time every whole data:339.67s
epoch: 125, total time:30741.51s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 44.7646s
epoch: 126, learning rate 0.000100
epoch: 126, train time every whole data:339.19s
epoch: 126, total time:31125.47s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 44.8363s
epoch: 127, learning rate 0.000100
epoch: 127, train time every whole data:339.69s
epoch: 127, total time:31510.00s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 44.7350s
epoch: 128, learning rate 0.000100
epoch: 128, train time every whole data:340.29s
epoch: 128, total time:31895.03s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 45.0281s
epoch: 129, learning rate 0.000100
epoch: 129, train time every whole data:340.90s
epoch: 129, total time:32280.97s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 44.5067s
epoch: 130, learning rate 0.000100
epoch: 130, train time every whole data:341.42s
epoch: 130, total time:32666.90s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 44.9408s
epoch: 131, learning rate 0.000100
epoch: 131, train time every whole data:341.08s
epoch: 131, total time:33052.93s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 44.5257s
epoch: 132, learning rate 0.000100
epoch: 132, train time every whole data:341.75s
epoch: 132, total time:33439.21s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 44.7388s
epoch: 133, learning rate 0.000100
epoch: 133, train time every whole data:341.07s
epoch: 133, total time:33825.02s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 44.8134s
epoch: 134, learning rate 0.000100
epoch: 134, train time every whole data:340.84s
epoch: 134, total time:34210.68s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 44.6186s
epoch: 135, learning rate 0.000100
epoch: 135, train time every whole data:341.11s
epoch: 135, total time:34596.41s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 44.7892s
epoch: 136, learning rate 0.000100
epoch: 136, train time every whole data:341.23s
epoch: 136, total time:34982.44s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 44.8174s
epoch: 137, learning rate 0.000100
epoch: 137, train time every whole data:340.84s
epoch: 137, total time:35368.10s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 44.8231s
epoch: 138, learning rate 0.000100
epoch: 138, train time every whole data:340.00s
epoch: 138, total time:35752.93s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 44.7842s
epoch: 139, learning rate 0.000100
epoch: 139, train time every whole data:339.72s
epoch: 139, total time:36137.44s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 45.0483s
epoch: 140, learning rate 0.000100
epoch: 140, train time every whole data:340.67s
epoch: 140, total time:36523.17s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 44.7874s
epoch: 141, learning rate 0.000100
epoch: 141, train time every whole data:339.47s
epoch: 141, total time:36907.43s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 44.8033s
epoch: 142, learning rate 0.000100
epoch: 142, train time every whole data:340.08s
epoch: 142, total time:37292.32s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 44.8281s
epoch: 143, learning rate 0.000100
epoch: 143, train time every whole data:340.75s
epoch: 143, total time:37677.90s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 44.8397s
epoch: 144, learning rate 0.000100
epoch: 144, train time every whole data:339.73s
epoch: 144, total time:38062.47s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 44.5568s
epoch: 145, learning rate 0.000100
epoch: 145, train time every whole data:340.43s
epoch: 145, total time:38447.46s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 44.7050s
epoch: 146, learning rate 0.000100
epoch: 146, train time every whole data:339.65s
epoch: 146, total time:38831.82s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 44.7454s
epoch: 147, learning rate 0.000100
epoch: 147, train time every whole data:341.12s
epoch: 147, total time:39217.69s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 44.8467s
epoch: 148, learning rate 0.000100
epoch: 148, train time every whole data:341.37s
epoch: 148, total time:39603.91s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 44.8197s
epoch: 149, learning rate 0.000100
epoch: 149, train time every whole data:341.54s
epoch: 149, total time:39990.28s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 44.5504s
best epoch: 118
apply the best val model on the test data set ...
load weight from: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_adj/epoch_118.params
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 26.87s
test time on whole data:44.72s
input: (672, 250, 12, 2)
prediction: (672, 250, 12, 2)
data_target_tensor: (672, 250, 12, 2)
current epoch: 118, predict 0 points
MAE: 1.47
RMSE: 2.39
MAPE: 54.50
PCC: 0.86
current epoch: 118, predict 1 points
MAE: 1.54
RMSE: 2.53
MAPE: 56.37
PCC: 0.84
current epoch: 118, predict 2 points
MAE: 1.57
RMSE: 2.59
MAPE: 57.15
PCC: 0.83
current epoch: 118, predict 3 points
MAE: 1.59
RMSE: 2.65
MAPE: 57.67
PCC: 0.83
current epoch: 118, predict 4 points
MAE: 1.62
RMSE: 2.70
MAPE: 58.11
PCC: 0.82
current epoch: 118, predict 5 points
MAE: 1.66
RMSE: 2.78
MAPE: 58.53
PCC: 0.81
current epoch: 118, predict 6 points
MAE: 1.69
RMSE: 2.84
MAPE: 59.19
PCC: 0.80
current epoch: 118, predict 7 points
MAE: 1.72
RMSE: 2.91
MAPE: 59.76
PCC: 0.79
current epoch: 118, predict 8 points
MAE: 1.75
RMSE: 2.98
MAPE: 60.43
PCC: 0.78
current epoch: 118, predict 9 points
MAE: 1.78
RMSE: 3.04
MAPE: 61.24
PCC: 0.77
current epoch: 118, predict 10 points
MAE: 1.80
RMSE: 3.09
MAPE: 61.80
PCC: 0.76
current epoch: 118, predict 11 points
MAE: 1.83
RMSE: 3.14
MAPE: 62.13
PCC: 0.75
all MAE: 1.67
all RMSE: 2.81
all MAPE: 58.91
all PCC: 0.75
1.465084085297549 2.3888690539920177 54.500113647152936 0.8577996497763857 
1.5385683498292098 2.525942755087812 56.37367677750634 0.8406680691886156 
1.5700287529830599 2.594292554211932 57.14655587548353 0.8318232152415028 
1.593140118215854 2.6458388562500494 57.67220970849788 0.8257118357074099 
1.6234658999022629 2.703268287486077 58.10786833107865 0.8195040015875479 
1.6558633303306998 2.7751002550288515 58.5281669574835 0.810427896196882 
1.6883867157820966 2.844998230776917 59.19135649869002 0.8000391713847869 
1.7189482964125595 2.913980104875598 59.760648483857636 0.7890522409542808 
1.74715277323384 2.976617142942124 60.4272862637118 0.7780730992822912 
1.7765437918502305 3.0422113533801634 61.239050994094015 0.7659383785791218 
1.801571317740849 3.0860062487824154 61.801784983548224 0.7586269837411315 
1.8297754344264312 3.1384303547890253 62.12804780600375 0.7516685134393685 
1.667377405500387 2.8121835274863143 58.90652263372409 0.7516685134393685 
