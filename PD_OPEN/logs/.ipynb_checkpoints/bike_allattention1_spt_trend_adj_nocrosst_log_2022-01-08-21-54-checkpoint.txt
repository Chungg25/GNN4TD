total training epoch, fine tune epoch: 40 , 40
batch_size: 4
folder_dir: MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention1_spt_trend_adj_nocrosst
load file: data/bike.npz
ori length: 3001 , percent: 1.0 , scale: 3001
train: torch.Size([3001, 250, 2, 12]) torch.Size([3001, 250, 2, 12]) torch.Size([3001, 250, 2, 12])
val: torch.Size([672, 250, 2, 12]) torch.Size([672, 250, 2, 12]) torch.Size([672, 250, 2, 12])
test: torch.Size([672, 250, 2, 12]) torch.Size([672, 250, 2, 12]) torch.Size([672, 250, 2, 12])
TemporalPositionalEncoding max_len: 12
h_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
en_lookup_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
EncoderDecoder(
  (encoder): Encoder(
    (layers): ModuleList(
      (0): EncoderLayer(
        (self_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (2): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (3): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (feed_forward_gcn): ModuleList(
          (0): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn_cross): spatialAttentionScaledGCN_cross(
          (Theta1): Linear(in_features=64, out_features=64, bias=False)
          (Theta2): Linear(in_features=64, out_features=64, bias=False)
          (SAt_cross): Spatial_Attention_layer_cross(
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (6): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (7): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (sublayer2): SublayerConnection2(
          (dropout): Dropout(p=0.0, inplace=False)
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): EncoderLayer(
        (self_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (2): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (3): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (feed_forward_gcn): ModuleList(
          (0): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn_cross): spatialAttentionScaledGCN_cross(
          (Theta1): Linear(in_features=64, out_features=64, bias=False)
          (Theta2): Linear(in_features=64, out_features=64, bias=False)
          (SAt_cross): Spatial_Attention_layer_cross(
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (6): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (7): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (sublayer2): SublayerConnection2(
          (dropout): Dropout(p=0.0, inplace=False)
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): EncoderLayer(
        (self_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (2): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (3): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (feed_forward_gcn): ModuleList(
          (0): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn_cross): spatialAttentionScaledGCN_cross(
          (Theta1): Linear(in_features=64, out_features=64, bias=False)
          (Theta2): Linear(in_features=64, out_features=64, bias=False)
          (SAt_cross): Spatial_Attention_layer_cross(
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (6): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (7): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (sublayer2): SublayerConnection2(
          (dropout): Dropout(p=0.0, inplace=False)
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): Decoder(
    (layers): ModuleList(
      (0): DecoderLayer(
        (self_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_qc_kc(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_qc_kc(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (src_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (2): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (3): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (feed_forward_gcn): ModuleList(
          (0): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn_cross): spatialAttentionScaledGCN_cross(
          (Theta1): Linear(in_features=64, out_features=64, bias=False)
          (Theta2): Linear(in_features=64, out_features=64, bias=False)
          (SAt_cross): Spatial_Attention_layer_cross(
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (6): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (7): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (8): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (9): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (sublayer2): SublayerConnection2(
          (dropout): Dropout(p=0.0, inplace=False)
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): DecoderLayer(
        (self_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_qc_kc(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_qc_kc(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (src_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (2): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (3): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (feed_forward_gcn): ModuleList(
          (0): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn_cross): spatialAttentionScaledGCN_cross(
          (Theta1): Linear(in_features=64, out_features=64, bias=False)
          (Theta2): Linear(in_features=64, out_features=64, bias=False)
          (SAt_cross): Spatial_Attention_layer_cross(
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (6): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (7): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (8): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (9): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (sublayer2): SublayerConnection2(
          (dropout): Dropout(p=0.0, inplace=False)
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): DecoderLayer(
        (self_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_qc_kc(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_qc_kc(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (src_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (2): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (3): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (feed_forward_gcn): ModuleList(
          (0): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn_cross): spatialAttentionScaledGCN_cross(
          (Theta1): Linear(in_features=64, out_features=64, bias=False)
          (Theta2): Linear(in_features=64, out_features=64, bias=False)
          (SAt_cross): Spatial_Attention_layer_cross(
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (6): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (7): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (8): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (9): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (sublayer2): SublayerConnection2(
          (dropout): Dropout(p=0.0, inplace=False)
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (src_embed): Sequential(
    (0): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (1): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(250, 64)
    )
  )
  (src_embed2): Sequential(
    (0): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (1): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(250, 64)
    )
  )
  (trg_embed): Sequential(
    (0): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (1): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(250, 64)
    )
  )
  (trg_embed2): Sequential(
    (0): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (1): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(250, 64)
    )
  )
  (prediction_generator): Linear(in_features=64, out_features=1, bias=True)
  (prediction_generator2): Linear(in_features=64, out_features=1, bias=True)
)
create params directory experiments/bike/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention1_spt_trend_adj_nocrosst
Net's state_dict:
encoder.layers.0.self_attn.0.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.0.linears.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.0.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.0.linears.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.1.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.1.linears.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.1.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.1.linears.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.2.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.2.linears.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.2.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.2.linears.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.2.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.2.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.2.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.2.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.3.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.3.linears.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.3.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.3.linears.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.3.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.3.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.3.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.3.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.0.feed_forward_gcn.0.Theta.weight 	 torch.Size([64, 64])
encoder.layers.0.feed_forward_gcn.1.Theta.weight 	 torch.Size([64, 64])
encoder.layers.0.feed_forward_gcn_cross.Theta1.weight 	 torch.Size([64, 64])
encoder.layers.0.feed_forward_gcn_cross.Theta2.weight 	 torch.Size([64, 64])
encoder.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.2.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.2.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.3.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.3.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.4.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.4.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.5.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.5.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.6.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.6.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.7.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.7.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer2.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer2.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer2.norm2.weight 	 torch.Size([64])
encoder.layers.0.sublayer2.norm2.bias 	 torch.Size([64])
encoder.layers.1.self_attn.0.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.0.linears.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.0.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.0.linears.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.1.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.1.linears.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.1.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.1.linears.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.2.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.2.linears.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.2.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.2.linears.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.2.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.2.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.2.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.2.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.3.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.3.linears.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.3.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.3.linears.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.3.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.3.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.3.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.3.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.1.feed_forward_gcn.0.Theta.weight 	 torch.Size([64, 64])
encoder.layers.1.feed_forward_gcn.1.Theta.weight 	 torch.Size([64, 64])
encoder.layers.1.feed_forward_gcn_cross.Theta1.weight 	 torch.Size([64, 64])
encoder.layers.1.feed_forward_gcn_cross.Theta2.weight 	 torch.Size([64, 64])
encoder.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.2.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.2.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.3.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.3.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.4.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.4.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.5.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.5.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.6.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.6.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.7.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.7.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer2.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer2.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer2.norm2.weight 	 torch.Size([64])
encoder.layers.1.sublayer2.norm2.bias 	 torch.Size([64])
encoder.layers.2.self_attn.0.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.0.linears.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.0.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.0.linears.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.0.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.0.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.0.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.0.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.1.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.1.linears.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.1.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.1.linears.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.1.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.1.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.1.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.1.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.2.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.2.linears.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.2.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.2.linears.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.2.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.2.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.2.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.2.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.3.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.3.linears.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.3.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.3.linears.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.3.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.3.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.3.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.3.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.2.feed_forward_gcn.0.Theta.weight 	 torch.Size([64, 64])
encoder.layers.2.feed_forward_gcn.1.Theta.weight 	 torch.Size([64, 64])
encoder.layers.2.feed_forward_gcn_cross.Theta1.weight 	 torch.Size([64, 64])
encoder.layers.2.feed_forward_gcn_cross.Theta2.weight 	 torch.Size([64, 64])
encoder.layers.2.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.2.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.2.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.3.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.3.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.4.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.4.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.5.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.5.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.6.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.6.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.7.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.7.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer2.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer2.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer2.norm2.weight 	 torch.Size([64])
encoder.layers.2.sublayer2.norm2.bias 	 torch.Size([64])
encoder.norm.weight 	 torch.Size([64])
encoder.norm.bias 	 torch.Size([64])
encoder.norm2.weight 	 torch.Size([64])
encoder.norm2.bias 	 torch.Size([64])
decoder.layers.0.self_attn.0.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.0.linears.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.0.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.0.linears.1.bias 	 torch.Size([64])
decoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.0.self_attn.1.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.1.linears.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.1.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.1.linears.1.bias 	 torch.Size([64])
decoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.0.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.0.linears.0.bias 	 torch.Size([64])
decoder.layers.0.src_attn.0.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.0.linears.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.0.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.0.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.0.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.0.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.1.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.1.linears.0.bias 	 torch.Size([64])
decoder.layers.0.src_attn.1.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.1.linears.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.1.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.1.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.1.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.1.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.2.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.2.linears.0.bias 	 torch.Size([64])
decoder.layers.0.src_attn.2.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.2.linears.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.2.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.2.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.2.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.2.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.3.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.3.linears.0.bias 	 torch.Size([64])
decoder.layers.0.src_attn.3.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.3.linears.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.3.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.3.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.3.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.3.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.feed_forward_gcn.0.Theta.weight 	 torch.Size([64, 64])
decoder.layers.0.feed_forward_gcn.1.Theta.weight 	 torch.Size([64, 64])
decoder.layers.0.feed_forward_gcn_cross.Theta1.weight 	 torch.Size([64, 64])
decoder.layers.0.feed_forward_gcn_cross.Theta2.weight 	 torch.Size([64, 64])
decoder.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.3.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.3.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.4.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.4.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.5.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.5.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.6.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.6.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.7.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.7.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.8.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.8.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.9.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.9.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer2.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer2.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer2.norm2.weight 	 torch.Size([64])
decoder.layers.0.sublayer2.norm2.bias 	 torch.Size([64])
decoder.layers.1.self_attn.0.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.0.linears.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.0.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.0.linears.1.bias 	 torch.Size([64])
decoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.1.self_attn.1.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.1.linears.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.1.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.1.linears.1.bias 	 torch.Size([64])
decoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.0.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.0.linears.0.bias 	 torch.Size([64])
decoder.layers.1.src_attn.0.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.0.linears.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.0.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.0.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.0.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.0.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.1.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.1.linears.0.bias 	 torch.Size([64])
decoder.layers.1.src_attn.1.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.1.linears.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.1.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.1.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.1.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.1.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.2.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.2.linears.0.bias 	 torch.Size([64])
decoder.layers.1.src_attn.2.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.2.linears.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.2.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.2.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.2.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.2.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.3.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.3.linears.0.bias 	 torch.Size([64])
decoder.layers.1.src_attn.3.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.3.linears.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.3.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.3.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.3.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.3.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.feed_forward_gcn.0.Theta.weight 	 torch.Size([64, 64])
decoder.layers.1.feed_forward_gcn.1.Theta.weight 	 torch.Size([64, 64])
decoder.layers.1.feed_forward_gcn_cross.Theta1.weight 	 torch.Size([64, 64])
decoder.layers.1.feed_forward_gcn_cross.Theta2.weight 	 torch.Size([64, 64])
decoder.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.3.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.3.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.4.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.4.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.5.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.5.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.6.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.6.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.7.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.7.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.8.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.8.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.9.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.9.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer2.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer2.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer2.norm2.weight 	 torch.Size([64])
decoder.layers.1.sublayer2.norm2.bias 	 torch.Size([64])
decoder.layers.2.self_attn.0.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.0.linears.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.0.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.0.linears.1.bias 	 torch.Size([64])
decoder.layers.2.self_attn.0.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.self_attn.0.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.0.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.self_attn.0.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.2.self_attn.1.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.1.linears.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.1.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.1.linears.1.bias 	 torch.Size([64])
decoder.layers.2.self_attn.1.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.self_attn.1.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.1.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.self_attn.1.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.0.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.0.linears.0.bias 	 torch.Size([64])
decoder.layers.2.src_attn.0.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.0.linears.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.0.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.0.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.0.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.0.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.1.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.1.linears.0.bias 	 torch.Size([64])
decoder.layers.2.src_attn.1.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.1.linears.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.1.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.1.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.1.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.1.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.2.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.2.linears.0.bias 	 torch.Size([64])
decoder.layers.2.src_attn.2.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.2.linears.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.2.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.2.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.2.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.2.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.3.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.3.linears.0.bias 	 torch.Size([64])
decoder.layers.2.src_attn.3.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.3.linears.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.3.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.3.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.3.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.3.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.feed_forward_gcn.0.Theta.weight 	 torch.Size([64, 64])
decoder.layers.2.feed_forward_gcn.1.Theta.weight 	 torch.Size([64, 64])
decoder.layers.2.feed_forward_gcn_cross.Theta1.weight 	 torch.Size([64, 64])
decoder.layers.2.feed_forward_gcn_cross.Theta2.weight 	 torch.Size([64, 64])
decoder.layers.2.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.3.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.3.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.4.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.4.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.5.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.5.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.6.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.6.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.7.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.7.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.8.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.8.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.9.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.9.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer2.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer2.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer2.norm2.weight 	 torch.Size([64])
decoder.layers.2.sublayer2.norm2.bias 	 torch.Size([64])
decoder.norm.weight 	 torch.Size([64])
decoder.norm.bias 	 torch.Size([64])
decoder.norm2.weight 	 torch.Size([64])
decoder.norm2.bias 	 torch.Size([64])
src_embed.0.pe 	 torch.Size([1, 1, 12, 64])
src_embed.1.embedding.weight 	 torch.Size([250, 64])
src_embed2.0.pe 	 torch.Size([1, 1, 12, 64])
src_embed2.1.embedding.weight 	 torch.Size([250, 64])
trg_embed.0.pe 	 torch.Size([1, 1, 12, 64])
trg_embed.1.embedding.weight 	 torch.Size([250, 64])
trg_embed2.0.pe 	 torch.Size([1, 1, 12, 64])
trg_embed2.1.embedding.weight 	 torch.Size([250, 64])
prediction_generator.weight 	 torch.Size([1, 64])
prediction_generator.bias 	 torch.Size([1])
prediction_generator2.weight 	 torch.Size([1, 64])
prediction_generator2.bias 	 torch.Size([1])
Net's total params: 1165186
Optimizer's state_dict:
state 	 {}
param_groups 	 [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411]}]
predicting testing set batch 1 / 168, time: 0.63s
predicting testing set batch 101 / 168, time: 27.23s
test time on whole data:44.96s
72.44026044585654 74.44437307009049 2977.701462566532 0.003897561089343129 
70.01482405289946 72.70519857270871 2878.3848501192556 0.0024587873428018833 
59.84603396924896 64.6125334172407 2464.3428508755383 0.0006902544328464473 
47.776955918245285 56.08543517138229 1968.331131774291 0.00023593360171518158 
40.370760140289775 51.16863787920416 1651.8218246982594 0.0005254165187588759 
39.145189396352016 50.03028355079425 1595.4335254897057 0.0015240575134827907 
39.86540952411214 51.14413717212319 1626.5360896294196 0.0026492873499100087 
42.58276760482291 53.6132111063681 1745.5309327463763 0.003511426589127941 
45.06930141829655 55.156614128214756 1852.8560873014567 0.003652057915780612 
43.85278678104379 53.7349245997405 1803.0963490473268 0.0030236378822672875 
39.930532460842635 50.1949376347781 1637.419681861498 0.0022954834512944433 
36.82338574144005 46.95140654112935 1504.2530409473454 0.002137882984815182 
48.14318395445417 57.31011006302637 1975.4505796919343 0.002137882984815182 
epoch: 0, train time every whole data:149.60s
epoch: 0, total time:205.03s
predicting testing set batch 1 / 168, time: 0.27s
predicting testing set batch 101 / 168, time: 27.37s
test time on whole data:45.56s
3.2829001436134178 4.447809591242983 105.25304894306973 0.3041851078086913 
3.2940198953690096 4.473777081173596 105.49379799450016 0.28532013282899527 
3.2960382519468134 4.494413119733501 104.99443747630653 0.2655620497984504 
3.2537509749772116 4.488068823704379 101.81210986391724 0.2538841330300489 
3.2372802890107213 4.499429134886851 100.03437522800233 0.2373046223990391 
3.193331633904062 4.491356982043819 96.65334027098346 0.2295104236005973 
3.21738642511437 4.521034411647485 97.37715781265435 0.209241686103277 
3.1770181954220114 4.5366022252565195 93.19182585919651 0.1893473193811465 
3.1682284616998264 4.5569116958331195 91.42380437513341 0.17400991592098264 
3.2124083793064844 4.589889907851759 93.32928251422157 0.15887514048450224 
3.195313632591849 4.589645002016255 91.19490450695908 0.15451511264300788 
3.1993134058447823 4.596795783295433 90.53844395423978 0.14928288726491812 
3.22724914073338 4.524063170594255 97.60771447976997 0.14928288726491812 
epoch: 1, train time every whole data:150.64s
epoch: 1, total time:410.97s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 27.50s
test time on whole data:45.67s
2.7925434340792044 4.35478697706621 78.13908418971182 0.3550897555345028 
2.8407153858975285 4.418589019152866 79.91198475295752 0.3280275225387075 
2.872125162230893 4.459452179164805 79.75142091876018 0.29929377849864147 
2.9112372774015225 4.510712261883686 81.02861937786078 0.2747391612444865 
2.947802228585773 4.555836037034061 81.98383420226337 0.2518169933633643 
2.9449574389441735 4.586890032451886 80.37553598184691 0.23647245726952648 
2.973749912695161 4.618950333601766 80.71004766385403 0.21573536684903274 
2.980022471673698 4.6645992318421 79.47472918231206 0.19846539553395617 
2.997236743411759 4.7031729716550625 79.0855426814424 0.18265281983262616 
3.0291808691518827 4.723144667907747 79.72770449156522 0.16855867675969324 
3.041006511939601 4.740043224957445 78.9501493652193 0.16023537598989096 
3.0637694895048404 4.753044879140736 78.98361714541664 0.15181007079374043 
2.94952891045967 4.592540189268703 79.8435179893209 0.15181007079374043 
epoch: 2, train time every whole data:150.71s
epoch: 2, total time:617.03s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 27.27s
test time on whole data:45.44s
2.7746119414307175 4.613257942995292 76.5991291443755 0.48388973870595126 
2.837099346052678 4.696513715888423 78.43373385172447 0.4539222227408154 
2.8802283900511405 4.779129627061198 78.59555843157182 0.4271550540800572 
2.925892814490944 4.836781114734699 79.66168515956612 0.4054325458712652 
2.9579581942154713 4.884949605984366 79.47292629900264 0.3886724781764066 
3.007650289506341 4.946205381493598 79.93140876201231 0.37745035359241297 
3.0028689595781977 4.952929851167546 78.49090890446496 0.36066709003224506 
3.0350118848122656 5.008972322658182 78.492403836571 0.3462016758156008 
3.036834062029386 5.040831293215583 77.35948293521957 0.32927661319193047 
3.024785976737383 5.0423406184537605 76.11734578742286 0.3144008232139555 
3.049681766639597 5.066770562944818 76.71268404196525 0.3030388319461207 
3.0697829988569554 5.080905101291869 77.57608663172947 0.29167892890280633 
2.9668672187000897 4.914653762558279 78.1202607873936 0.29167892890280633 
epoch: 3, train time every whole data:150.57s
epoch: 3, total time:822.59s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 27.55s
test time on whole data:45.58s
2.267284100843416 4.078648578267207 57.17400115667009 0.6293725315388783 
2.349258426709633 4.209951415918609 59.15501854484017 0.5980629584417806 
2.4355604196410803 4.3629848982937895 60.77872806507637 0.5654265841056061 
2.495410037899922 4.450426703284602 62.506855384633575 0.5311279819854697 
2.570835640062445 4.551076516772528 64.36627847311284 0.5002088347543889 
2.6674180877245077 4.667174504882558 67.04443022523527 0.47070151592879844 
2.709404028664831 4.720181972097326 67.85653017463585 0.44840543502381475 
2.7829146022719464 4.804973643877728 70.57207136147811 0.4210882859840569 
2.8435012779673117 4.864173532702137 72.93872626585744 0.39296913478924284 
2.8848888530104997 4.905800453129095 74.33869161011842 0.367092746625693 
2.9405139076927944 4.960579753641213 76.24345906661709 0.34247916857155175 
2.9689149255965437 4.980646072854805 76.95577460581464 0.32535914445936426 
2.659658692340411 4.638650613230655 67.49459298827846 0.32535914445936426 
epoch: 4, train time every whole data:150.42s
epoch: 4, total time:1029.35s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 27.78s
test time on whole data:45.65s
2.0761721770092847 3.757857514026222 56.68845744833055 0.647349012777753 
2.123125878417953 3.8423798176253805 57.55243631998137 0.6271948540710054 
2.168192034244626 3.9505594684135548 57.74585197379919 0.6098134787956219 
2.2066572639342574 4.016828074145563 58.396393285392456 0.5899403543681304 
2.244457805537397 4.078657596020382 58.642849621385054 0.5767781618328802 
2.283948271263568 4.126471409083534 59.33696438935678 0.5702049770676716 
2.3166525076986955 4.144654852853009 59.80844031307273 0.563006562454303 
2.3587915786824944 4.178888080744115 61.00599276634935 0.5525501831594934 
2.4014884981761377 4.210269816710824 62.66430033208239 0.5390737103997846 
2.4486664366702593 4.254755609794876 64.28623956889223 0.524179411387211 
2.5080327574922037 4.319869422988681 66.20496475253617 0.5040159271192785 
2.561108138898476 4.381590844342635 67.5767804595537 0.4761228866321519 
2.3081077790021127 4.109142393827887 60.825975149444425 0.4761228866321519 
epoch: 5, train time every whole data:150.43s
epoch: 5, total time:1235.26s
predicting testing set batch 1 / 168, time: 0.28s
predicting testing set batch 101 / 168, time: 27.43s
test time on whole data:45.51s
1.8996791196010474 3.5045791404267312 56.320091624284544 0.7018612448584666 
1.9489518517952058 3.5569454005331287 59.066541497901234 0.6866471859982258 
2.010951966398085 3.680438980355084 59.20069404253243 0.6663490266990623 
2.061280203252587 3.7637383661797847 60.27199426449914 0.6519370593256818 
2.112511442753974 3.847222001049709 60.7200550917134 0.6412366635056111 
2.155284534602027 3.903613106317606 61.271087764885856 0.6338793037396069 
2.1798779252719664 3.9308662915804637 61.803951524099574 0.6292816759470538 
2.202909902809188 3.948984915643536 62.02798026205754 0.6243036978594073 
2.20947047398674 3.948193098149867 61.68432560236686 0.6164203789659393 
2.204838239308979 3.9219689789621506 61.38865264532944 0.61013777496887 
2.228417947002997 3.9642296123815544 61.75475585749022 0.5989042530441515 
2.278229143637188 4.047616358410708 62.78957800269945 0.5737655037687942 
2.124366895868332 3.838393557241476 60.6917350599791 0.5737655037687942 
epoch: 6, train time every whole data:150.32s
epoch: 6, total time:1441.44s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 27.12s
test time on whole data:45.21s
1.9885369934099062 3.588374933762453 52.71059593192368 0.7135044615483123 
2.020989267630857 3.6467933517321285 54.981626336246784 0.7073417456788993 
2.083464854548552 3.767710656629637 57.930944954795294 0.6996415909184043 
2.1411837606647364 3.847933372288951 60.127122859901775 0.6925136962672813 
2.2020536944184097 3.9110278833324914 62.29992254626049 0.6829608918206224 
2.2727929498312904 3.9425078603379142 65.60280441250353 0.6783757082277594 
2.3274464408663946 3.9779361255721337 68.00769337633233 0.6725381746948913 
2.3751494859184716 4.027918700282387 69.5836997916363 0.667599799269498 
2.425589419754577 4.088930553508645 71.15255282581349 0.6591509292407618 
2.482764728547739 4.155721239568595 72.87784828644286 0.6515230011368389 
2.5655688151616958 4.249359282866951 75.24358361336651 0.6408076269324613 
2.621412345463676 4.338696919552964 76.50642034723666 0.6147403914243751 
2.2922460630180255 3.9679560315570406 65.58584904387061 0.6147403914243751 
epoch: 7, train time every whole data:150.54s
epoch: 7, total time:1648.26s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 27.60s
test time on whole data:45.68s
1.795572625579135 3.1502482572816715 54.23177927492543 0.7469039720925976 
1.8126769492054091 3.167361330265244 55.04209189355906 0.7405157748852423 
1.8605712800703589 3.280036561991128 54.57914219274434 0.7295610595239365 
1.8955470215206345 3.339594797244725 55.411877992750355 0.7194594224980051 
1.9271726305349064 3.3785763418870696 55.548035089209854 0.712738216010612 
1.932463422233771 3.3846894508981213 56.09988192822887 0.7085278396739454 
1.9556686586113203 3.4110187615612677 56.231123184911525 0.6973745448636841 
1.97557969317328 3.4459719510713653 56.425848037121305 0.6869942668555468 
1.9920058534634966 3.477660896909863 56.51537645645024 0.6776988181422984 
2.003517376841445 3.5031287109370837 56.5136156541442 0.6739746043060181 
2.0301949792895466 3.558184585558299 57.03079322830165 0.6662956265627835 
2.0884727404537125 3.669450995973958 58.469213604715975 0.6400456216324207 
1.9391202692480847 3.4002454792395573 56.00828926304842 0.6400456216324207 
epoch: 8, train time every whole data:150.72s
epoch: 8, total time:1854.94s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 27.04s
test time on whole data:45.46s
1.7873484877224657 3.2048583985831387 55.05011619228455 0.7512808364866138 
1.8028268632494977 3.1958413549765847 56.81119627984981 0.749767313665433 
1.8212361011122842 3.231570180308661 57.24154364295945 0.744516206343326 
1.8580485107023268 3.2693743731485063 58.154182656196994 0.7382716263374177 
1.901341175182767 3.332545805892467 58.83816306212055 0.7266140498463541 
1.9467868729151254 3.4182068820439757 59.45438750368059 0.7133433513198526 
2.00833671264652 3.5452571305605036 59.96304448305695 0.6904470377484695 
2.062395497480496 3.657866354208994 61.177150696453374 0.6693077541157143 
2.1024847620832956 3.7378495794783593 62.5654708462178 0.6571309940588701 
2.128259760934416 3.7898245701130544 62.574113392265886 0.6459193398140293 
2.1548112057875843 3.8333902231961416 62.55084663332469 0.6397194587769697 
2.2053173332031637 3.917736969417554 63.179353478719534 0.6185002375096614 
1.981599440251662 3.5205709939694945 59.79678234972492 0.6185002375096614 
epoch: 9, train time every whole data:151.62s
epoch: 9, total time:2061.55s
predicting testing set batch 1 / 168, time: 0.27s
predicting testing set batch 101 / 168, time: 27.37s
test time on whole data:45.79s
1.839631852706096 3.201764691384422 52.71720949350473 0.7595860915880555 
1.834166283202402 3.173072285595512 52.86031933187629 0.7609871697784953 
1.8584608651663044 3.226324220703652 52.82157724624225 0.7598074769452283 
1.8687675739312988 3.2298184137807597 53.37116072658055 0.757061374649319 
1.8797715268468573 3.2370829180293104 53.788277376211326 0.752323335009699 
1.8911702613480212 3.243044500125896 54.03029132264032 0.7457415910762737 
1.913949642347438 3.26329833030824 54.93983889094493 0.7320286475182973 
1.934619016135821 3.3053043661581376 56.07544738025735 0.7154628378820178 
1.9658316597828553 3.370985902260948 57.204916049585854 0.6965679341490009 
1.9937456053114895 3.4338867016299366 57.68295747816629 0.6836579755016623 
2.0205690988134593 3.49337636691025 58.056684043789794 0.675420302004524 
2.0705094676834666 3.603847433658501 58.98510509515158 0.6523125393053767 
1.9225994044396257 3.317595701007034 55.211268211187694 0.6523125393053767 
epoch: 10, train time every whole data:150.65s
epoch: 10, total time:2268.27s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 27.48s
test time on whole data:45.96s
1.8228956762823676 3.1813223111194024 57.12118047442966 0.745972905038823 
1.8245692459637566 3.12071065642679 59.04110287786699 0.7464428832244401 
1.844213095293602 3.155436443083734 59.411743864436005 0.7439787261091798 
1.8541739372432764 3.169044834697821 60.26182313853688 0.7404735144324364 
1.8622244464066766 3.1838587925275625 59.31373017110268 0.7424671682412771 
1.8686931170907226 3.2049216099022857 58.74608571570429 0.7411472439742082 
1.8968409729974256 3.279907598166784 58.039813061730214 0.7337410412524524 
1.9451802834715872 3.3640861454344977 58.59924791479531 0.7219531075532629 
2.001074901816923 3.448351126009113 59.55998670491681 0.7076356202105868 
2.0429314576165662 3.543317459277485 60.19133914004695 0.693775943288157 
2.1206614489436504 3.709202857225765 61.56837358467002 0.6723423206163 
2.2153750368740766 3.8918331117122085 63.634737459375 0.6405227619879834 
1.941569468333386 3.362704698264457 59.624138192319535 0.6405227619879834 
epoch: 11, train time every whole data:150.51s
epoch: 11, total time:2475.14s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 27.25s
test time on whole data:45.48s
1.8267698399199261 3.272033492263319 55.02285202497502 0.7642387410796271 
1.8595594078124102 3.287546471653666 55.45541160496115 0.7665664416725471 
1.9184895523987888 3.399101839739467 55.34874586951708 0.758829488756209 
1.9436683482178265 3.405002280162199 56.02912318294754 0.7584736369241245 
1.9776724890027018 3.4520448334839173 57.0505573262145 0.744864486596944 
2.000233865159076 3.473993800864828 57.78204534079801 0.7372633019709495 
2.01016124705376 3.474058879675728 58.582972322300606 0.7328807766872831 
2.01182097689018 3.4691082000904063 59.854879468371394 0.7314412683824841 
2.042813505097869 3.5239391202344654 61.70648720721083 0.7223588306000431 
2.0651684635744565 3.5597309204718157 62.9046038617308 0.7205314484008556 
2.12166068775739 3.62807673896539 64.91270886579487 0.7146643347071947 
2.200479617468658 3.7649283986156776 66.85713914653361 0.689757088701878 
1.998208166696087 3.4782490794774708 59.292489564396355 0.689757088701878 
epoch: 12, train time every whole data:150.67s
epoch: 12, total time:2682.10s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 27.22s
test time on whole data:45.53s
1.7679381038273374 2.901995070009674 62.35764269184192 0.7735989208754869 
1.7671155397374894 2.87379428482362 62.2374540096237 0.7789418790498716 
1.7786981002691955 2.895789578547388 60.69425878203445 0.7753607562336553 
1.7968011074725183 2.9072198045254996 61.552755394132966 0.7730851837383508 
1.817567193789585 2.92348225608061 62.16849672976051 0.7702922471238485 
1.8330859432490987 2.9498758892848964 61.083465504372526 0.7656682175057288 
1.8521956732668692 3.023240674095337 60.13782411727574 0.752791605379401 
1.8542676259520507 3.037232006233918 58.90787851314111 0.7515942431649438 
1.8568841646707483 3.0438777737630147 58.12329124463807 0.7523465076680806 
1.8544273221144187 3.0467447830071563 57.69758347108795 0.7543784099758785 
1.8755344175181927 3.0902786058580953 57.886302513005404 0.7475710667736502 
1.9199411932113801 3.1810435602678018 58.65978986769276 0.7318897557610381 
1.8312046987565738 2.990927637852348 60.1254708964152 0.7318897557610381 
epoch: 13, train time every whole data:150.71s
epoch: 13, total time:2890.33s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 27.47s
test time on whole data:45.86s
1.7112365851103373 2.8853354769624713 58.840514078892134 0.7823219581037661 
1.729773120538376 2.8813419239547415 59.292957777444656 0.784580210084688 
1.7733185082509049 3.01251792811896 57.60411589692155 0.7757451677709635 
1.8234676438947874 3.1277726525569363 57.90946550568006 0.7647801418513938 
1.8878933317136197 3.2542877708377307 58.32289482448934 0.7517869718908052 
1.9513375537776876 3.3814288169992897 58.98729337498032 0.7326348132768415 
1.9980742122496344 3.486463922263455 59.149561463835866 0.7140197729727158 
2.0273870851871156 3.5314753804226044 59.43704921402448 0.7047395465155541 
2.054615302087473 3.5867898400840987 59.46031061774746 0.6928282134046146 
2.068290134789156 3.6079613760829123 59.67275285780761 0.6893886987693677 
2.0917927333668227 3.6186518962047023 60.24504852709946 0.6901286861600731 
2.126290363339441 3.6803709534595197 60.77915922034737 0.6806673337892156 
1.936956381192113 3.3498623785602826 59.14179630345554 0.6806673337892156 
epoch: 14, train time every whole data:150.82s
epoch: 14, total time:3097.26s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 27.73s
test time on whole data:45.63s
1.7284677283726633 3.0527506951372896 52.64752579670521 0.7899366264080367 
1.7343248995239182 3.0234661624677823 52.357600213142916 0.7957189494894257 
1.7905523908508143 3.1151953820417146 52.22317423875553 0.793363153709392 
1.8152339472736987 3.152292021388194 52.77512933630736 0.7937680357587482 
1.8590616650421705 3.231280154277225 53.8212101875858 0.7872475521238068 
1.9132351008933037 3.3258781134811692 54.909129426828706 0.7805754796967319 
1.9499904715098617 3.3998872927353503 55.443677726836725 0.7716293844085894 
1.9714603903038161 3.436626219164276 55.959246650726925 0.7669269008485052 
1.9802113718729288 3.4509653046973754 56.439569497371124 0.7631488743250499 
2.003829669575606 3.487746175717467 56.81737857060586 0.7580609318957608 
2.0356121578256468 3.5314983868882566 57.59542622413822 0.7534067373071933 
2.0830941940343806 3.6291855668738897 58.61072560180974 0.7376354619139227 
1.9054228322565674 3.325285644236912 54.96676931834609 0.7376354619139227 
epoch: 15, train time every whole data:151.04s
epoch: 15, total time:3304.57s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 27.26s
test time on whole data:45.66s
1.7919424947783174 2.842988928736342 61.86250061948668 0.7849239064973258 
1.7993296229824247 2.8248499338857047 63.10937497266583 0.7892638439518496 
1.7955719904208645 2.82675794449137 61.12219986987799 0.7872379690559612 
1.7855689125124898 2.8312570516268045 58.94621627795118 0.7874075618570867 
1.8121914804168044 2.912150909671162 57.70866668722173 0.7774567125287466 
1.8546055235996666 3.0088464880402856 56.823171642864864 0.7631850232197548 
1.8991276140336302 3.098282588441397 56.74533948276053 0.7456561602476841 
1.93065415691336 3.1642237832462845 56.621100507750775 0.7324233477776414 
1.9565708780405777 3.228875061616266 56.078460238124364 0.7204246894635692 
1.9733075614984015 3.267646547663913 55.88686161579799 0.7131063763730471 
1.979282101921471 3.2867188644030407 55.37037429634908 0.7114391713142899 
1.998679402548465 3.324660937805538 55.42829693183769 0.7046917144671749 
1.881402644972206 3.0574148501851846 57.975064886325654 0.7046917144671749 
epoch: 16, train time every whole data:150.74s
epoch: 16, total time:3511.57s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 27.35s
test time on whole data:45.43s
1.7139598418122957 2.8398106591319334 58.02048380102038 0.790528727263555 
1.7208937687546546 2.8207105809373823 58.21846855501717 0.795233452724076 
1.7522214389700619 2.89651022371927 57.21796710394184 0.7893720935432849 
1.7754599870869092 2.942824876114083 57.46844890773689 0.7867037416019946 
1.8149672301067483 3.0136553235141412 57.665226427465065 0.7800004847205803 
1.8531883547623598 3.0921575431764596 57.923472339674994 0.7689878329593849 
1.8846465260067156 3.1677678910448455 58.33274704548621 0.752075068339358 
1.8968339780147765 3.184893937653321 58.87810521952872 0.7450539307938433 
1.907331153573912 3.193693058313798 59.4639437504218 0.7402707840442456 
1.9280338196945155 3.2059869695523315 60.813876157232535 0.7339287486570014 
1.9497011909111448 3.245824489765236 62.15980068005812 0.724751171553497 
1.9896353598095122 3.329326308562778 63.25079591965357 0.7074146636283086 
1.8489060541253004 3.0820799262569203 59.117852105531284 0.7074146636283086 
epoch: 17, train time every whole data:150.61s
epoch: 17, total time:3719.14s
predicting testing set batch 1 / 168, time: 0.27s
predicting testing set batch 101 / 168, time: 27.47s
test time on whole data:45.54s
1.6495247529001817 2.759714918251058 56.86931349251506 0.8084185501223262 
1.6558246946247916 2.7356503739348668 57.34873647833787 0.8122710772858704 
1.68307503552726 2.8128277029339555 56.52835648650038 0.8065067441845477 
1.6987829692859557 2.8495745076377004 56.29320383464511 0.8030125755897801 
1.725068905961478 2.8862738032762323 56.49120266430939 0.7975201874677348 
1.7457691615244284 2.911073361068732 56.87075441275068 0.791288847482344 
1.7794056458792515 2.9557917275344283 58.06495655513078 0.7796201779112354 
1.7960604054047948 2.960804827287212 58.81456141249055 0.7766395885352597 
1.8178229620644735 2.9962120630712334 59.26886450723457 0.7733980389605375 
1.8421795437992328 3.05431086445037 59.267196599856234 0.7659313188911885 
1.8809524453780835 3.1377326417995755 59.71997487990072 0.757023311087262 
1.9353731176885112 3.24833154740158 60.106388944533585 0.7439042649992993 
1.7674866366698703 2.945943596132113 57.970359909370636 0.7439042649992993 
epoch: 18, train time every whole data:151.13s
epoch: 18, total time:3926.26s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 27.41s
test time on whole data:45.50s
1.9955147052134963 3.2090056141913483 63.244426694775925 0.8143335081412493 
2.003770283081436 3.2030070421552956 64.53215246776611 0.8070721942404011 
2.0146543417705134 3.1964655828702266 65.51195568932917 0.7993760028641128 
2.033236805279695 3.2143058742168082 66.42917741101468 0.7959751018927499 
2.0926000940424525 3.3201789252199547 67.54874066083096 0.7867760593942871 
2.1438795577360406 3.43111711152264 68.15778355413217 0.7732096466822272 
2.193340738924575 3.536612458348293 68.78015198530979 0.7582192526320713 
2.2418574124077955 3.612984910968112 69.60178322830583 0.7505537413597 
2.2928203482108103 3.7086278227323435 70.72949449575712 0.7349030704765662 
2.3213070180546493 3.7730290947631135 71.46178825897616 0.7217535885345302 
2.360837668711497 3.838741191938822 72.47514718166555 0.7097055119195992 
2.3858433383043325 3.8983214786077673 72.80322036424884 0.6958376293119063 
2.1733051926447744 3.5045931666187315 68.43982554582298 0.6958376293119063 
epoch: 19, train time every whole data:150.61s
epoch: 19, total time:4133.53s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 27.38s
test time on whole data:45.90s
1.6772522334209865 2.7945651329772305 56.57440160973641 0.8173120682116419 
1.6921751926437552 2.7945852810600655 57.369046643345655 0.8169934896798225 
1.7154716812636526 2.8361951243776895 57.53914978504824 0.8120294629535466 
1.731997195459991 2.8683293073638256 58.40296616172873 0.8062945831790952 
1.776576787550712 2.947638515850994 59.695518162487005 0.797901439388195 
1.8277130974714777 3.0436877160765445 60.43282443579289 0.7880781035116242 
1.8794100884430642 3.1765721780769685 60.899874639447546 0.7680234241930776 
1.9116191566480059 3.255285512194918 61.17245099253822 0.7551276773028706 
1.954235652345898 3.347924803442409 61.92845027411342 0.7412394718010462 
1.9893207095480923 3.4267762533570063 62.503796616445925 0.7281456580027565 
2.025194086620052 3.4955103669650356 63.0638671006285 0.7167247887628067 
2.0511577425527254 3.5501161075690595 63.26496407518659 0.7061006945978408 
1.8526769686640343 3.139851805937869 60.23740838676736 0.7061006945978408 
epoch: 20, train time every whole data:151.11s
epoch: 20, total time:4339.84s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 27.51s
test time on whole data:46.07s
1.6593576676708957 2.6682020661785746 57.28758557679251 0.8230797087961769 
1.6820815856097533 2.706535601360962 57.23074821537807 0.8210580981233645 
1.72355080564054 2.8252220413647597 56.2566640898502 0.8138010944713014 
1.7674642418366635 2.921898362150934 56.678649783684065 0.8056981581350124 
1.7973336827658295 2.974835795769815 56.97480126805444 0.8014857275193109 
1.8009234541207553 2.9794532715341315 56.912639619933515 0.7989724417612798 
1.8047403635353383 2.967075247161926 57.489031581645555 0.7928678492831217 
1.807234657702524 2.9354794201798646 58.911738429156635 0.7878707074234222 
1.8192697589442666 2.9430587414012708 60.608322838777816 0.782814593740863 
1.840530566726412 2.9826328891016205 61.57643875541907 0.7757837086641068 
1.87364137514042 3.0581475121850104 62.26517095677874 0.7664698241196886 
1.9189411957637363 3.1635993861020273 62.428191876326956 0.7537277109729773 
1.791255779621428 2.93015489629437 58.718435655550515 0.7537277109729773 
epoch: 21, train time every whole data:151.20s
epoch: 21, total time:4547.73s
predicting testing set batch 1 / 168, time: 0.27s
predicting testing set batch 101 / 168, time: 27.37s
test time on whole data:45.58s
1.6504275986706571 2.657712619624998 55.35850374275905 0.8192754342219526 
1.6555119410459662 2.655715046040842 55.717999958096996 0.8188217954510872 
1.6764061056735615 2.7080033521229905 55.277482589573246 0.8122250012308053 
1.6870722316961204 2.7301078321153285 55.53289212354454 0.8094368556811439 
1.7165231239216492 2.7909782651209363 55.65899497581931 0.8028526054269688 
1.7559050848186015 2.8760323201631977 56.12922562104449 0.7905595623119079 
1.8031734893960611 2.9918447643817627 56.57280580963915 0.7712792991133779 
1.8405662073474378 3.073073531362799 56.82585625098473 0.7575687680109731 
1.8678319875462246 3.1390309206726714 56.91955777833082 0.7466081171057569 
1.8785537512434558 3.1647546469716112 56.883895887972734 0.7411284508275959 
1.8941529367985648 3.185879042349122 56.852105729006766 0.7395827940464781 
1.919307023742724 3.2326281416274516 56.94463569711136 0.7321024755264688 
1.7787859568250854 2.9414843812503784 56.22286852870136 0.7321024755264688 
epoch: 22, train time every whole data:151.02s
epoch: 22, total time:4755.94s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 26.95s
test time on whole data:45.14s
1.7292208533017408 2.6746819943393265 64.77612262927825 0.8126135749951896 
1.7113441714385436 2.65837470886136 62.496126148249076 0.8144699677601005 
1.7188355803759325 2.708252332600789 60.757259876333414 0.8084086100798709 
1.7451662305146456 2.7751261717937052 60.90420723908168 0.8003811672146449 
1.7914835323418181 2.892680734593681 61.11364286671389 0.7853939505350265 
1.8501235109071823 3.028141611892515 61.266647842986174 0.7665184332942501 
1.9045905651263892 3.166636737756981 60.97453326682055 0.7462349050920258 
1.9446475487601544 3.250844092329005 61.2103464916146 0.7316692941831291 
1.9699307676145719 3.319435572928992 60.96331979643813 0.7213058888589137 
1.9762785737135757 3.3333767022377123 60.64011868496601 0.7182640153854063 
1.9925680281615683 3.353977384674417 60.55076877067073 0.7157096081767365 
2.0085437989170174 3.390644798581082 60.41510162546426 0.7098266048190907 
1.8618944300977616 3.058667248361281 61.33897237674565 0.7098266048190907 
epoch: 23, train time every whole data:151.25s
epoch: 23, total time:4962.78s
predicting testing set batch 1 / 168, time: 0.27s
predicting testing set batch 101 / 168, time: 27.14s
test time on whole data:45.53s
1.6522775729189494 2.6477308923408365 57.69106020369592 0.8267219474922869 
1.672440085372311 2.66227060689984 58.42085441534426 0.8253630059752841 
1.6913214400259866 2.7067599633219412 57.89247680612861 0.8217527143638339 
1.7101571167363296 2.7464782828063283 58.18268833073949 0.8173833003008654 
1.7437820173643883 2.832861380681833 58.36129534595672 0.8093218788367382 
1.7700512929172034 2.903368400140575 58.558062509692924 0.8030168385433333 
1.7977692698861163 2.9650747616113815 58.73335082529886 0.7956135668635644 
1.8176629555355757 2.9957977822457695 58.816886849695805 0.7925763582997011 
1.8453678815093424 3.064303897551512 58.93694678752305 0.7842844435882091 
1.8649725729309554 3.1235733513672455 58.6909419897401 0.7753919691089703 
1.8913382968086572 3.1917558303117293 58.70484881960931 0.7662954984114232 
1.9208202866997037 3.2520908249347817 58.97958612867809 0.7558024401138737 
1.7814967323921267 2.931140980269885 58.4974391479411 0.7558024401138737 
epoch: 24, train time every whole data:150.96s
epoch: 24, total time:5168.79s
predicting testing set batch 1 / 168, time: 0.27s
predicting testing set batch 101 / 168, time: 27.41s
test time on whole data:45.57s
1.638676036479661 2.6282475939154515 56.68596266240438 0.8198008019111116 
1.6485965316230875 2.6844086535360328 55.75322811657141 0.8155295588372135 
1.687443558257694 2.7910442537570006 54.88163075304789 0.8080715667879634 
1.7242264159760836 2.870615898344509 54.98773365689678 0.8013321536118443 
1.760476584701666 2.940627095957974 55.37454063369312 0.7942543979119244 
1.7859986435085358 2.9945100799192836 56.127584860470634 0.7842366262455045 
1.8238277619698395 3.0826176125726006 56.636527953862604 0.7666781020580294 
1.856880068840459 3.149820306425798 56.94750521010881 0.7542085502343983 
1.8870258505524447 3.221336614881649 57.25066543992708 0.742437682553788 
1.9086901552833262 3.2813875260034178 57.368817832256966 0.7292977536093854 
1.9411485548191483 3.350021069986356 57.68718717679011 0.7193073154102358 
1.9673193805893616 3.3984780954169063 57.86026201280566 0.7136811213453899 
1.8025257952167757 3.0427397845426554 56.463516463906416 0.7136811213453899 
epoch: 25, train time every whole data:150.77s
epoch: 25, total time:5374.79s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 27.46s
test time on whole data:45.45s
1.6291690966910017 2.721754258452941 53.83775489908666 0.8237418421492986 
1.64198141389828 2.72228251620391 54.28654302503156 0.8208636162307149 
1.6802943372392938 2.8042385349186136 54.54410516918653 0.8098302921388685 
1.7090251522361346 2.8634527899777633 54.586169098352656 0.8050486103580105 
1.7510823134018019 2.95538450420579 54.45793455695369 0.7974956146375731 
1.7930248553607435 3.0425782805419512 54.47292643142793 0.7940007015229466 
1.8501008450638148 3.1664820986523434 54.42646631337752 0.7831594234406387 
1.8796536517344593 3.210338544192454 54.584268897007895 0.7794401816935259 
1.9030248554944993 3.2532809996801997 55.04999974640177 0.7752705008227974 
1.9212657043039798 3.2905703647189877 55.82008945787615 0.7703192887640764 
1.9487881405067053 3.3363828401310296 57.03762854217366 0.7633321099408995 
1.9795816542213516 3.394965417911677 58.2525386325459 0.7570733092578411 
1.8072493350126722 3.072394259445894 55.11307917946448 0.7570733092578411 
epoch: 26, train time every whole data:150.83s
epoch: 26, total time:5580.56s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 27.10s
test time on whole data:45.10s
1.66479851861236 2.8281188666440102 54.804817825588025 0.821147467686187 
1.6871396871000706 2.8720214108585895 55.513379585378395 0.8178563723546045 
1.7141914861010654 2.9234035661220554 55.05109372771167 0.8164947250063627 
1.7233561671658286 2.9394970272196512 55.297118182119554 0.8132634157531146 
1.7430084866431674 2.9703706085033925 55.77576428263696 0.8075939050196693 
1.7520833763687738 2.9653587965508015 56.29422496514691 0.8065632017457219 
1.773982315158915 2.998254124620036 57.1637378778877 0.7982124761455427 
1.7913458015478794 3.0219628040621673 57.95007494947011 0.7907025508984977 
1.8239229739416567 3.083306798736948 58.91522470163045 0.7812102009591281 
1.8514021467037853 3.125617831420451 59.71044218003676 0.7754273668555507 
1.8848194632613589 3.1773559164857006 60.79851516897592 0.7682580366613893 
1.9044213522427849 3.219249775359372 61.42629044060834 0.7604141244139916 
1.7762059812373039 3.0125759077605765 57.391839734080584 0.7604141244139916 
epoch: 27, train time every whole data:151.18s
epoch: 27, total time:5786.40s
predicting testing set batch 1 / 168, time: 0.27s
predicting testing set batch 101 / 168, time: 27.41s
test time on whole data:45.47s
1.5964227987346904 2.627874501869996 57.71438190002113 0.8283665873196064 
1.6091557682933553 2.6358988984843648 58.383790042518925 0.8272408343499364 
1.6354726586774702 2.6891181260273673 57.83571010249597 0.8238529623708865 
1.6572835794845153 2.748854950396838 58.150172548567404 0.8161875883797746 
1.6858228344006376 2.8064992102794504 58.47128250370904 0.8093878760260595 
1.7110075218996832 2.8440729994921212 59.081295054778806 0.8047262256750334 
1.7409094682646293 2.8947626413068486 59.82238878543464 0.79678559151463 
1.763763260338278 2.925744958714803 60.67627931615077 0.7900882882491793 
1.7858947404320573 2.9633444376072693 61.80567421612555 0.7827965602057809 
1.8062254527846262 3.000758887676611 62.72032868281475 0.7762293003550366 
1.8395489411031207 3.0601310739242096 63.78962109401558 0.76740893566594 
1.8775599532196565 3.147501220709396 64.53301545622988 0.7532952750445634 
1.7257555814693932 2.8665193887532774 60.24877921933817 0.7532952750445634 
epoch: 28, train time every whole data:151.04s
epoch: 28, total time:5992.48s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 27.20s
test time on whole data:45.50s
1.6737663872052162 2.807684328028988 54.648367376415244 0.8255656212428515 
1.6773979979286946 2.7986355451334735 55.60245761428392 0.8224008153913701 
1.69748075722699 2.8173479346780588 56.66323964360146 0.8171938744106946 
1.699726333259383 2.822157087221049 57.68916545656987 0.8106636740166618 
1.7179097314187812 2.850619462557205 59.076830892735984 0.8037777419716718 
1.7306245253759303 2.8658594035005107 60.23524901949234 0.7994015004014254 
1.7541965926191105 2.909568776504804 61.32655473369603 0.7921802576934476 
1.7794582237213672 2.96558725927177 61.86095188873719 0.7841297558214836 
1.8143329655730298 3.0467208501790894 62.340136819110626 0.7732076656076886 
1.831507840486598 3.11298475045671 61.98350336967925 0.761426554604688 
1.8524196809462847 3.16778893518289 61.81234208321319 0.7532500633363479 
1.8780881983159732 3.228106050638498 61.939992052065286 0.7443551781453076 
1.7589091028397799 2.953044887856825 59.59839751333846 0.7443551781453076 
epoch: 29, train time every whole data:150.74s
epoch: 29, total time:6198.97s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 27.36s
test time on whole data:45.71s
1.583860465589556 2.562455932635908 58.09183037950327 0.8304539784257025 
1.5887955511766707 2.573103743955744 57.99941081405474 0.8294773977751425 
1.6128454454029422 2.6589744610412565 55.67219151223036 0.8248208668339451 
1.6319086477674898 2.7138030946206766 55.74288364472903 0.8193432441454056 
1.6552556975014685 2.7561030155005395 56.015090633566146 0.8150272809962765 
1.6734226023772998 2.7851684776849215 56.52817670543882 0.8097497764172543 
1.690038756550334 2.818359258667748 56.97774943707293 0.8026763474182237 
1.704893916488226 2.8461121872818094 57.60034653549951 0.7954799311409932 
1.7220450720305422 2.8825702086120657 58.19386371952193 0.7895522186149587 
1.737556444792964 2.9156280426920125 58.415994697450365 0.7844139151668171 
1.7590683095872934 2.955997697111981 58.5777426207721 0.7803706188116067 
1.788172048335274 3.0194966692048384 58.94422193204565 0.77292649682944 
1.678988579800005 2.794101926244756 57.396656618533584 0.77292649682944 
epoch: 30, train time every whole data:150.93s
epoch: 30, total time:6405.86s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 27.04s
test time on whole data:45.19s
1.6941083799643175 2.7888789212014484 56.02795246751526 0.8305989801637427 
1.7126460437861581 2.825191359291597 56.51349904640982 0.8275207012349479 
1.738316574915534 2.8755865861796592 57.09082124523501 0.8216964702003852 
1.7656951925749225 2.9252487638860103 57.7702894962515 0.8161816484252642 
1.816431118320851 3.030207750290128 58.594638491952935 0.8059027827536802 
1.8710774584095038 3.155159647926544 59.3528854366277 0.7926660959724718 
1.9138294090290686 3.2576136122289334 59.96508785526359 0.7787177516088661 
1.9431502019937728 3.296236588012301 60.86879243406405 0.7695389444979336 
1.9714694164203745 3.34633567286055 61.842555374086515 0.7581684841855307 
1.9885681088202234 3.38433477362971 62.06785454534249 0.7485620350555982 
2.017604419740006 3.444247760845277 62.531706969229006 0.7401735998889997 
2.0452301565418463 3.512683270857524 62.876573198133414 0.7290760421169852 
1.8731772067097148 3.1629826983196243 59.62536049431411 0.7290760421169852 
epoch: 31, train time every whole data:150.70s
epoch: 31, total time:6612.42s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 27.27s
test time on whole data:45.58s
1.6132858580693248 2.6285094163632428 56.35959567250167 0.8341587708995906 
1.6469935363720924 2.6826221336207428 56.97389829444906 0.8299087421072724 
1.692421302325669 2.778286430837531 57.25281889558187 0.8221504739715121 
1.7323862518177677 2.865129678410113 58.03574427844092 0.8114982084945688 
1.7812949589451863 2.9515852528396396 59.0235440796924 0.8030043188534314 
1.8195139140646372 3.0179801673062316 60.0913961717034 0.7938856996933092 
1.85320589813457 3.0732812425676066 61.24688970026112 0.7849036083067313 
1.8700869243102414 3.0866226138431623 62.12911241879689 0.7809776928209339 
1.8917647378126248 3.1202344898188423 63.065452689061765 0.7743661857357832 
1.9019307327730848 3.145794411609405 63.358370337944024 0.7694653222948985 
1.9218363054015983 3.181007630538947 63.93639354678635 0.7640777199434006 
1.9344509190096564 3.219144653117231 64.28510371867286 0.756534284480649 
1.8049309449197044 2.985231858326821 60.48002573948287 0.756534284480649 
epoch: 32, train time every whole data:150.88s
epoch: 32, total time:6817.50s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 27.34s
test time on whole data:45.31s
1.6703881054325473 2.7689991166715076 53.916605071425906 0.8245515141039977 
1.6786677221807518 2.7626784017463764 54.714843762553386 0.8240349329868519 
1.6894964127797811 2.773046902777916 55.24513132669851 0.8205563536746283 
1.706328244118907 2.8082229308751154 55.4685695288557 0.8172197425580497 
1.7417654433151086 2.8899866181353295 55.707520944188225 0.8117613798851661 
1.7737961466465855 2.959411730361743 56.30914466175865 0.8061974851601137 
1.8164773812285138 3.0422315594057427 57.093730387758946 0.795046919765541 
1.8402247100169105 3.0774671083888516 57.78097085997517 0.787230633606994 
1.8575396497092609 3.1042745664773728 58.42278091021807 0.7819678626467282 
1.864659229133633 3.1198053895531164 58.65163972359832 0.7790758952351461 
1.8816633598610226 3.1519882852015506 59.27435004996167 0.7742276340073646 
1.8983338209277107 3.204306538312432 59.803478063906304 0.7654625711656607 
1.7849450187792277 2.9760724553714613 56.86583566106622 0.7654625711656607 
epoch: 33, train time every whole data:151.00s
epoch: 33, total time:7022.92s
predicting testing set batch 1 / 168, time: 0.28s
predicting testing set batch 101 / 168, time: 27.73s
test time on whole data:46.00s
1.582126463302012 2.564617382269762 55.859956711317835 0.8331935485398961 
1.6032230771426113 2.6214620312304064 55.53675622086608 0.8284167125123099 
1.6421678690141333 2.721799262606173 54.889464679702925 0.8190225367045799 
1.6635825785708036 2.76889460261811 54.61259372652512 0.8139524568024119 
1.694183207407239 2.8242884373880006 54.649215775230395 0.8096316390428944 
1.727313212750657 2.890739156931475 54.70676659780375 0.8032726927630478 
1.7655574262724922 2.9589745863551604 54.94676640201187 0.7923805238797778 
1.78800205227777 2.9892303032213525 55.344785410530925 0.7847440954921124 
1.8093346468894078 3.027244172485978 56.17077395453952 0.7749486140759678 
1.8254705864230083 3.0645752560918798 56.5870716863717 0.768460269548981 
1.850615081228582 3.1054376385718236 57.20382404944458 0.7613219955348485 
1.8858010584173635 3.1749202856233505 57.70398616513128 0.7499558992781752 
1.7364481049746734 2.898677730614845 55.68436017360371 0.7499558992781752 
epoch: 34, train time every whole data:151.33s
epoch: 34, total time:7229.96s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 27.33s
test time on whole data:45.42s
1.801018145524675 2.892657585047253 58.23582079015066 0.8325263546921048 
1.8198933855641102 2.9205510427265278 58.847863592212256 0.8272018116973102 
1.8372534833979748 2.935524431878082 59.50466347038882 0.8230613885686217 
1.847122966754738 2.9404310087127152 60.57731507113802 0.8174238116664443 
1.87432227791491 2.980986493889366 61.88378504646298 0.8106777189632453 
1.9015361373129167 3.023446781323006 62.978652690911844 0.8058815667858688 
1.9314011524456243 3.093330970801508 63.98702662434527 0.7949117001755033 
1.954814803051984 3.1440145892605296 64.81064017400304 0.7862595210681002 
1.9888673607643161 3.209221435804691 65.98699800415972 0.7749840250432348 
2.026391900152855 3.2815881021218365 66.8668686775557 0.7640253260163553 
2.0650491830141595 3.348822512389131 68.01753352546768 0.7530401773413509 
2.105298982037054 3.4293803700570265 68.92475251753093 0.7402963552407718 
1.9294141481612765 3.1048986066554805 63.38536177561258 0.7402963552407718 
epoch: 35, train time every whole data:150.97s
epoch: 35, total time:7435.80s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 27.78s
test time on whole data:46.04s
1.5903692603202626 2.647058227542091 55.884975386624326 0.8302685021928449 
1.615259168342643 2.6963139378302903 56.25588098416069 0.8261676792227204 
1.6382670253678446 2.74042691989291 56.3578042093882 0.8217527842387173 
1.6445938123208248 2.7495295500885057 56.3683001230766 0.8209633588749147 
1.6735662301981022 2.8034568197177845 56.73792274852518 0.8150088857194715 
1.703848433958544 2.8603110347898753 57.161456093642684 0.808162181535252 
1.7537367571687237 2.9656487409970502 57.97213516962242 0.7947443583427807 
1.7841332651690713 3.0176045773248323 58.68389581555339 0.7871563495373511 
1.8151988369762189 3.0688550348556625 59.679870814220024 0.7784728661316993 
1.8388901428502231 3.116090807129013 59.995810074349954 0.7730729003469023 
1.8651132072926986 3.171606734698256 60.33694272631851 0.7694095593867301 
1.9015618491061919 3.2573643688077403 60.499800208712415 0.7633379498009754 
1.7353781657559457 2.9309560842161817 57.99466081258943 0.7633379498009754 
epoch: 36, train time every whole data:150.83s
epoch: 36, total time:7642.85s
predicting testing set batch 1 / 168, time: 0.27s
predicting testing set batch 101 / 168, time: 27.16s
test time on whole data:45.34s
1.6143977802447265 2.5516510341235206 57.10835583757342 0.8345912633834353 
1.6403689782063344 2.5936259639338473 57.69088999614732 0.8301778034936779 
1.659753027140828 2.629794118894459 58.0980607183211 0.825020243742737 
1.671250274308558 2.6510090748540835 58.56343409011796 0.8208640079616256 
1.6982087403919903 2.6884937458789566 59.27615842896732 0.815869826455053 
1.7285296317898624 2.750518329925942 59.91674826078158 0.8076961924027978 
1.7850637077773432 2.8793560515474463 60.98546748833186 0.7889553695779218 
1.8322574325607468 2.980900962183033 61.793984322820684 0.7724230015342253 
1.8635871902657228 3.0383177806900226 62.53613532775684 0.7616043691904879 
1.8882634700875551 3.094365290084489 62.78166218476785 0.7522243219884674 
1.9131493595225648 3.1472160417105304 62.8518263502727 0.743651529107894 
1.9356822170830732 3.1974487968494842 63.21834043702902 0.7348873028880498 
1.7692093174482755 2.8589977190863674 60.40188380090776 0.7348873028880498 
epoch: 37, train time every whole data:151.00s
epoch: 37, total time:7850.13s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 27.30s
test time on whole data:45.50s
1.5777426162901378 2.596979719569226 54.056420313926004 0.8334783937505611 
1.5870061360405137 2.600988543138696 54.945787947789185 0.8301471991709153 
1.6076120290571736 2.648961803782291 54.3560395356915 0.826925077117165 
1.6303323618013943 2.703937557308981 54.116903903013124 0.823498349790272 
1.6630743686266776 2.774143275841222 54.344440595319156 0.8183991760133201 
1.692270859799747 2.837340327420259 54.915217926917435 0.8118038304596572 
1.7272475022403966 2.9087729520629964 55.72252431871111 0.8015423224309137 
1.7540586385223127 2.9624895095003505 56.45799295132338 0.792439222279695 
1.7803902908645215 3.0100544461726066 57.2173716794188 0.7854944109723304 
1.8054027146395473 3.0695883355924924 57.538379473562095 0.7797881821033054 
1.836833976025826 3.130523766126794 58.25328840634852 0.7738155978567259 
1.8791998084850077 3.21518202403431 58.81775479035996 0.766533624027336 
1.711764275199438 2.878682743649957 55.89525981121373 0.766533624027336 
epoch: 38, train time every whole data:151.25s
epoch: 38, total time:8057.87s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 27.82s
test time on whole data:45.84s
1.5893122173789003 2.6495608429311757 53.942522482987954 0.8341884155144688 
1.6186120977877152 2.7095605336585633 53.712775001038295 0.8302163663386525 
1.6577328460692826 2.7918718288152458 53.35213006816766 0.8255227579466703 
1.693079127045437 2.864835700579355 53.338247181004874 0.8208594817778335 
1.7316970741090676 2.930687817473821 53.9509964969877 0.8144614594668462 
1.7501455066056832 2.9475970759970966 54.78166635327588 0.809310626491755 
1.7727829719974348 2.9894196059558578 55.898064378254375 0.7992966585464961 
1.7865621694264313 3.008614987515465 56.94833246043625 0.7911519735711939 
1.7938898947981319 3.0198075073148867 58.124648074805776 0.7853951484631186 
1.8062256436709847 3.0484799598533066 58.54990089912734 0.7817626529127154 
1.8350193217143063 3.109387992728433 59.04703176657786 0.7768026558370996 
1.8765467831494198 3.2045277198130924 59.41555808556424 0.769749986023647 
1.7426338044793996 2.943624965052009 55.92194619920052 0.769749986023647 
epoch: 39, train time every whole data:150.98s
epoch: 39, total time:8265.01s
fine tune the model ... 
epoch: 40, train time every whole data:324.70s
epoch: 40, total time:8589.72s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 27.31s
test time on whole data:45.34s
1.5317504781530726 2.505601894949885 55.82320960328043 0.8425645139852377 
1.552086731773136 2.5492870085768504 56.142068748314514 0.8388680941407289 
1.5779672678563565 2.6069218834357555 56.13489919337423 0.8340220923374729 
1.6009814222322865 2.657495050286305 56.48861087245894 0.8278911406758743 
1.6332838268547007 2.7190648399447572 57.009114150855325 0.8215583461557878 
1.6614279770475946 2.768467454268952 57.74893123809988 0.8160882880112261 
1.7019592952071023 2.8545943787160204 58.59899934186459 0.8045274559244795 
1.7347397301738994 2.927971861954955 59.25954430207866 0.7931643527523874 
1.7665241669380949 2.9915541083252677 60.23588935307432 0.7822289324575388 
1.7935502904762648 3.05194504073349 60.67296538638337 0.7723319364324945 
1.8205446410572068 3.1036660682082653 61.154776187319214 0.7646629198910617 
1.8431070757151715 3.1468583868030486 61.49873754811301 0.7585197334601832 
1.6848269086237406 2.8315765040802283 58.39742793259758 0.7585197334601832 
epoch: 41, train time every whole data:320.06s
epoch: 41, total time:8964.78s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 26.89s
test time on whole data:44.70s
1.5292623937135297 2.505113651089825 55.66224388161851 0.8422019423067393 
1.5486756685511873 2.5480718825752233 55.99048768298517 0.8387009313525412 
1.5742890143555899 2.6080189297337513 55.84178480628796 0.8339392508106768 
1.5984907477414678 2.66388578154141 55.963200876235966 0.828587599500223 
1.6326228489990213 2.733113287602291 56.27348300162417 0.8222556344336045 
1.6628592529098192 2.7871508540065193 56.96967979570891 0.8158195013867464 
1.6989579685960143 2.86510215230191 57.78410002146994 0.804096673335086 
1.7254725175924777 2.9189209830962537 58.52795067805614 0.79414495183205 
1.7508247266314214 2.9642295259660196 59.582429374358625 0.7848852019450125 
1.772910761069329 3.011565542420276 60.0829302068111 0.7762663274178848 
1.7947075014551659 3.049315570436178 60.66246685558055 0.7699308389796414 
1.8123622585974988 3.0818540839323307 61.04486019969537 0.7651171807740994 
1.6751196383510436 2.8178845025242185 57.86557409110175 0.7651171807740994 
epoch: 42, train time every whole data:319.39s
epoch: 42, total time:9337.81s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 26.85s
test time on whole data:44.73s
1.5259667707055453 2.490839041076194 56.17784273539614 0.8429248764061559 
1.5458616295628071 2.5395324649046676 56.27781378494873 0.8387104109972848 
1.5724840166808238 2.6038750410942733 56.06801304253272 0.8332426560211919 
1.5960045971361299 2.6569085690412604 56.23731418649108 0.8275260252922696 
1.6267275608420548 2.7156834568801953 56.65768224578469 0.8212274796522496 
1.654175228422153 2.7637945251181306 57.39164861930012 0.8153656126359796 
1.6916366599721036 2.8432860413015684 58.2792655301559 0.804126816040594 
1.7226389319651894 2.9095361192871754 59.043139324066296 0.7934038685194436 
1.752990290600008 2.968373578611498 60.01943029961292 0.7833729046925402 
1.777036870973096 3.02262238058574 60.39202561908058 0.7746818294540874 
1.8010582847811636 3.0667099116962175 60.8410884421135 0.7682387343176442 
1.8222094801634194 3.1065954567620135 61.210513604433714 0.762951805980854 
1.6740658601503746 2.8145327938541054 58.21642115542905 0.762951805980854 
epoch: 43, train time every whole data:319.52s
epoch: 43, total time:9712.55s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 26.78s
test time on whole data:44.55s
1.5277065505937983 2.4937342884285942 55.943883095278665 0.8428722847453508 
1.5466036289846081 2.5403409098821728 56.04708018434293 0.838727832803903 
1.5711059298191574 2.599906881634573 55.83950770504329 0.8336007093201573 
1.5949791571657572 2.6520367279887234 56.03742768778716 0.8281577004274783 
1.627273851185505 2.717030326338908 56.41621191915216 0.8214223477671471 
1.6574380135885662 2.772322970659967 57.18722064835927 0.8149455223106313 
1.6982626154758924 2.85961115866826 58.13563120766548 0.8032999046544165 
1.734553910192723 2.9359088166975686 58.97373046302713 0.7914916577427418 
1.7682926155454701 3.0008701039997043 60.001132929585154 0.780541143800241 
1.7928616664292556 3.057437032814344 60.436550262438224 0.7712257144714635 
1.8175921638924628 3.102927276914508 60.94021129409284 0.7646158548759566 
1.838803128451641 3.1426690669990838 61.36703262550992 0.759350485792304 
1.6812894359437365 2.8311877864733574 58.11058123154537 0.759350485792304 
epoch: 44, train time every whole data:319.12s
epoch: 44, total time:10087.45s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 26.82s
test time on whole data:44.61s
1.5252756323338088 2.498535752345663 55.73782170647935 0.8437227869568177 
1.5438861980985494 2.537991212800559 56.16190460321915 0.8400147284400142 
1.569008959007139 2.5951866813905116 56.1252792681927 0.8349788268074647 
1.589336877402273 2.638230740170367 56.364619733148466 0.8299775254457732 
1.61940555400561 2.6969317859614854 56.74053024784441 0.8236198368160172 
1.6474161951930395 2.7484551861883535 57.420600051105986 0.8177372074665039 
1.685681598337722 2.832052722561895 58.24912267019594 0.8067080195381916 
1.7170036725046203 2.898294333306043 59.01089101788223 0.7964190809290499 
1.7464061165732288 2.9532836304465166 59.917982149894925 0.7869767295150857 
1.76972828327891 3.0071652043066344 60.217674466669216 0.778231923102376 
1.792973438022392 3.053660695404244 60.501214813582784 0.7718980564883601 
1.8141055421992427 3.0951619866109006 60.769759803796155 0.7672624339005699 
1.6683523389130446 2.803230478988809 58.1015548682534 0.7672624339005699 
epoch: 45, train time every whole data:319.63s
epoch: 45, total time:10463.56s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 26.82s
test time on whole data:44.62s
1.5286094780738155 2.493635867371044 56.3029250228612 0.8433615165075747 
1.549700159774295 2.5407491579211072 56.43198257635815 0.8395636207694006 
1.574852685679726 2.597705906127629 56.35077519544571 0.8347144006207424 
1.5966403144108399 2.647018830427833 56.5603773456547 0.829388370601888 
1.6286233687333407 2.708272879164042 56.9514937238925 0.8229239754444897 
1.6574637439885131 2.7579112692571317 57.714995647145216 0.8168822623908922 
1.6960354147615533 2.8398728278419436 58.63389015958348 0.8057580152528877 
1.729404414404361 2.910602237533733 59.45820102152135 0.7950424795322953 
1.7608311199629236 2.9691681629954836 60.458772051523525 0.785327422418789 
1.785178495487553 3.023923773382878 60.89105604809427 0.7762745508949214 
1.8094877728755985 3.0721643559211285 61.26802523109004 0.7693566266442426 
1.8314643332758653 3.112737378016137 61.637232378723304 0.7645790990499264 
1.679024275119032 2.8135551767013496 58.55508977040726 0.7645790990499264 
epoch: 46, train time every whole data:319.43s
epoch: 46, total time:10838.35s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 26.82s
test time on whole data:44.62s
1.5312142008331027 2.504832209004816 55.896213116531094 0.8439904581164934 
1.553411225309773 2.549310216156081 56.33948759860271 0.8396989469634151 
1.5804647265496177 2.6067963202831255 56.38725330982864 0.8346637539406739 
1.6037599553955453 2.6562156730623943 56.62523179873492 0.8294459205107384 
1.6377679981492637 2.72144605862231 57.018274711137316 0.822681921624859 
1.6673797305319458 2.7734254680083934 57.71810026402683 0.8165755442275491 
1.7040425092969977 2.8546004173886677 58.54848966683422 0.8051880041875104 
1.7335352784733156 2.918138547389829 59.267505608270895 0.7950198013868796 
1.7611775293137346 2.9679898865806544 60.16733326606351 0.7865169915079512 
1.7837462640050799 3.0214945527278 60.54419772779559 0.777564131688216 
1.807502126621792 3.069666602376599 60.94501450828267 0.7705725851297353 
1.8302209534876581 3.113593191345458 61.39842916230447 0.7649630439228755 
1.6828518748306522 2.820197662132686 58.40473647824943 0.7649630439228755 
epoch: 47, train time every whole data:319.59s
epoch: 47, total time:11214.01s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 26.88s
test time on whole data:44.70s
1.5223921141520675 2.492132060225792 55.639096533336804 0.8436514586001882 
1.5410564241441234 2.5343269910232733 56.01135281005226 0.8398801875249171 
1.5646186969266052 2.586445645096582 55.96225441993167 0.8354863665226578 
1.5847479762261112 2.6321610968219504 56.14160260906543 0.830436616606018 
1.614222861691511 2.688503490828285 56.54052898342279 0.8240796537508458 
1.6409562632252594 2.736907198031795 57.27289929504566 0.8179388917528521 
1.6776154651460016 2.8153007082303394 58.112277146977995 0.8074826624705413 
1.7112848170361525 2.8849213505235713 58.89006822329211 0.7969032845588014 
1.7430202152122345 2.946714336977965 59.78782987109958 0.7866579679719887 
1.769190330127254 3.0060207474733365 60.15399282506967 0.776926899293355 
1.7935920721879672 3.0556583520564464 60.45606666419353 0.7698703309674424 
1.8162836303709164 3.0998780504372245 60.796583611227405 0.764415758557505 
1.6649150722038504 2.7970890811560083 57.980486244339914 0.764415758557505 
epoch: 48, train time every whole data:319.43s
epoch: 48, total time:11589.46s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 26.82s
test time on whole data:44.62s
1.5233477173909722 2.494047123761501 55.53467660282924 0.8439337501638258 
1.5445193486722808 2.5441332044113736 55.881726972006284 0.8389007902919183 
1.5695850795189894 2.599112238279222 55.80054615406096 0.8338789997801035 
1.5919418467173263 2.646656937979737 55.90658055441793 0.8287447341123649 
1.6232049571152423 2.7045687747169542 56.20660351101486 0.8226897480647498 
1.6519227180777207 2.75674167653803 56.911412344723075 0.816059449876543 
1.6875512064441685 2.834414642637587 57.848452416163354 0.8043477523600749 
1.716874605869963 2.8934461447773554 58.6898284302254 0.7937887058264061 
1.7440897010881453 2.9415081031922754 59.6847250033851 0.7848711624969579 
1.7664312303578038 2.989941567410961 60.14634489259363 0.7764365641357673 
1.7868665608500263 3.029341074499611 60.48242229253624 0.7706782171987658 
1.8045770832500643 3.0631995298478083 60.775892144020446 0.7666899385957653 
1.6675760046127253 2.7977019629556326 57.8225427275159 0.7666899385957653 
epoch: 49, train time every whole data:319.38s
epoch: 49, total time:11962.54s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 26.83s
test time on whole data:44.63s
1.522972026426345 2.4945429070554335 55.808826332550424 0.8433909108429886 
1.5432914036239187 2.544437698796243 56.14801086786566 0.8386489384957497 
1.568022204884195 2.599794886274211 56.10605679792731 0.8336238370874003 
1.5895905349006256 2.648596703143148 56.29142847693005 0.8283037416836787 
1.6208769114604664 2.708907871397208 56.63100732017649 0.8222836600642022 
1.6506143072369908 2.760847722260406 57.3289328938114 0.8163955436123643 
1.6902785337224957 2.8462558062093892 58.26857712732245 0.8049090868809746 
1.72392837664893 2.9171696266348777 59.15856905863276 0.7934630527691305 
1.7546648736189874 2.9718256970394736 60.19919784837838 0.7840116928965756 
1.7777336160362298 3.023147284553736 60.65912453198944 0.7750156298969562 
1.7994564620768208 3.0680977402882883 60.94748199172662 0.7681722614899648 
1.820296321927082 3.1103442336871905 61.27789065993979 0.7625551620752303 
1.6718104643802572 2.8151532031230317 58.23553887092249 0.7625551620752303 
epoch: 50, train time every whole data:319.52s
epoch: 50, total time:12337.14s
predicting testing set batch 1 / 168, time: 0.27s
predicting testing set batch 101 / 168, time: 26.87s
test time on whole data:44.67s
1.525789258221608 2.510222613099922 55.24096930228093 0.8437690798617968 
1.547312930575439 2.554725254107531 55.82774234293554 0.8390546390307596 
1.5715636753486026 2.6047592941738142 55.87765940703567 0.8343702064540907 
1.5934934199747763 2.6524175659408424 56.158098212055584 0.8291574187526876 
1.6257782638897853 2.7123954459064654 56.590032289661764 0.8231612362054889 
1.6553714429737911 2.765807376585397 57.34542308288768 0.8171979083619048 
1.6922663847804957 2.843672854452468 58.3053341873771 0.806682823911675 
1.7216625898274638 2.90802573030015 59.195081180495066 0.7961785503172851 
1.7510821472292855 2.9618514412700923 60.1948228910379 0.786864776179367 
1.773121575247851 3.012208179642574 60.58335400332798 0.7783509504329714 
1.7947249596567736 3.0564433787794956 60.84274843372325 0.7719642102464674 
1.8157764820581568 3.097440663193495 61.15594061276619 0.7668128947775193 
1.672328594148669 2.813357186913945 58.10988884562899 0.7668128947775193 
epoch: 51, train time every whole data:319.43s
epoch: 51, total time:12711.86s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 26.86s
test time on whole data:44.66s
1.5198020042809879 2.4868716781192663 56.00951450120012 0.8439191586922847 
1.5414374982810446 2.5393668152885165 56.22767315708782 0.8386796177433467 
1.56619018785212 2.5927667695999927 56.122454779646866 0.8338948413826133 
1.5876191126545447 2.6400333282113744 56.29448785272738 0.8285660826004573 
1.6185092853831926 2.6995077448043836 56.669325117899774 0.8220381691732845 
1.6477435832304792 2.752228642637521 57.36059027732801 0.8158678293012934 
1.687259696108511 2.8391135336719713 58.245567774945705 0.804308330300814 
1.7209937393640478 2.911503347202289 59.07401635804125 0.7933166338160865 
1.7527319467952032 2.972228249423903 59.95222785786205 0.7834249115783904 
1.7755598974521494 3.024011702551229 60.247710138914044 0.7749729749628775 
1.7968064899637053 3.0688115074991487 60.47263870849719 0.7687938021186843 
1.816228399317623 3.108806155470956 60.814218132513865 0.7637704365801069 
1.6692401533903007 2.8104821553988644 58.12430528116293 0.7637704365801069 
epoch: 52, train time every whole data:319.57s
epoch: 52, total time:13085.70s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 26.87s
test time on whole data:44.72s
1.5285644517615438 2.5182780561922757 54.71828281707124 0.8433953003038475 
1.5499769742274214 2.5652227463923807 55.254608114308986 0.8380441010888278 
1.575219950379715 2.615847274165312 55.3887291169689 0.8333293607047805 
1.5968852890290852 2.663393258710128 55.67601186077442 0.827709866589383 
1.6271345088177671 2.719156037704045 56.15680363064281 0.8215992320670401 
1.654683449924879 2.7665534722292744 56.98263663776477 0.8157819727745241 
1.6923394450184313 2.8500889574092922 58.01707161281037 0.8039557222262541 
1.7238456241678268 2.917141402224881 58.961331282422925 0.7927661304851525 
1.7533902912020152 2.9711422391221967 59.97376217262102 0.7831583216893723 
1.7757544810609627 3.024149539733051 60.38053958386186 0.773945969086096 
1.797313800576897 3.0676444490422257 60.602375459258575 0.767968246287423 
1.8179427472808887 3.109556104714817 60.872762036631435 0.7629872554691439 
1.6744209177872862 2.82240603172318 57.74887227831 0.7629872554691439 
epoch: 53, train time every whole data:320.01s
epoch: 53, total time:13460.15s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 26.84s
test time on whole data:44.64s
1.5278157049427252 2.510448912972354 55.55720851494532 0.8438272572091156 
1.5496049442297468 2.55888821367213 55.89068205126837 0.8387322673998924 
1.5750388487051463 2.611898756604583 55.856949631323495 0.8341552150335109 
1.5976486237959138 2.6611429511788804 56.026280267125095 0.8291891449926558 
1.6302109819330453 2.721768953325381 56.418524524737 0.8231423136280887 
1.6601193778031462 2.7740113020168313 57.180831835489954 0.8170693586273454 
1.6979612201833654 2.8552473258643207 58.14429244574201 0.8060462171737026 
1.7272272471923913 2.9165557099767914 59.068887573441685 0.7957739550398993 
1.7558807543565829 2.969763133648077 60.08572000266727 0.7861903312597321 
1.7756915404369966 3.013807301422094 60.49218542084584 0.7782403040188686 
1.7949945115915367 3.0540111556728466 60.73280402675834 0.7721888704192971 
1.8137968843195234 3.092249969043125 61.051361576019815 0.7671046032325798 
1.67549921995751 2.8182054060228094 58.0422603908524 0.7671046032325798 
epoch: 54, train time every whole data:319.51s
epoch: 54, total time:13834.83s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 26.98s
test time on whole data:44.87s
1.5186705225502983 2.4784675854032963 56.3283816277962 0.8441576663621042 
1.5394181672379907 2.5306046018354884 56.20655989782399 0.839632625735467 
1.5638586337218683 2.585442901532521 56.0550046571769 0.834886887781529 
1.5873300983927967 2.638740447240794 56.17094025169544 0.8293723700342939 
1.619559574119924 2.7015659180270504 56.5302654290905 0.8226844642193647 
1.649793341502902 2.755547911283238 57.22983109230334 0.8165112083832603 
1.6890485757163594 2.8432092013793886 58.1176539074832 0.8048864193808971 
1.7219838776572474 2.912303963213233 58.97046559546073 0.7939218721737847 
1.7525116870833473 2.968680588686953 59.8327613488085 0.7844323509946329 
1.7748191820923238 3.0216040986134907 60.145219804208125 0.7754774961166558 
1.7960836241208016 3.063662266057614 60.33335643279708 0.7696483331129805 
1.8165978693144307 3.1043893682440036 60.69233235660607 0.7644893751142398 
1.6691395961258575 2.8079870993594644 58.05116306669148 0.7644893751142398 
epoch: 55, train time every whole data:319.40s
epoch: 55, total time:14208.62s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 26.88s
test time on whole data:44.71s
1.522037010370798 2.503601039625716 55.30635455286268 0.843871003467704 
1.545845898524725 2.5592619123940823 55.62942644350994 0.8384641177342906 
1.5691626549529 2.6053195129146425 55.72804154555563 0.8337151351770336 
1.5901685831394223 2.6498063537037764 56.02678399847262 0.8286151684158493 
1.6207786538314428 2.7087150844360837 56.44986779281691 0.8222954039935362 
1.6519593656252893 2.7647881982469666 57.1591769808572 0.8158572986850882 
1.6917771674211004 2.8561506551538938 58.033312653293166 0.8035606651624234 
1.7235595922281168 2.923283008654892 58.867821921262234 0.7925037059655083 
1.7526547889882433 2.9771954171284927 59.80373809247064 0.7824471996778324 
1.7728839729453127 3.0229421499481584 60.20715976824834 0.7738168521868396 
1.7922180612545815 3.0604666916190557 60.44534126074925 0.7680811033749124 
1.809109141740948 3.094914870874455 60.73750715221574 0.7632220009080951 
1.6701795742519068 2.817478197253204 57.86632526099176 0.7632220009080951 
epoch: 56, train time every whole data:319.71s
epoch: 56, total time:14583.53s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 26.90s
test time on whole data:44.74s
1.5190634924003943 2.4920033424936676 55.513685326813736 0.8437552497173392 
1.5427715791178247 2.5479803742025244 55.641628999743055 0.838612210709742 
1.568042772625972 2.602824318987264 55.595684859588545 0.8337176048984217 
1.5900382844859824 2.6503029630357156 55.81512079177179 0.8285854714680312 
1.6209726144297136 2.710272890209552 56.275026334043844 0.8222513156466221 
1.6502176755644558 2.7627705377571963 57.0556356147634 0.8162335921996842 
1.6891553704505342 2.848570400037877 58.08423837642744 0.8046979546929707 
1.7216582056048015 2.9150280770518417 59.075687105444366 0.7939969276385558 
1.7536206567556198 2.975747080567865 60.1056034377706 0.7837441848832994 
1.776630761916971 3.0267165389399553 60.539138312209126 0.7751917522016848 
1.7993256528690635 3.0739525940188646 60.82406047619442 0.7684059362594864 
1.8206714291691426 3.1172333916494726 61.19240372744864 0.7627349264348807 
1.6710140412825396 2.8177076873804623 57.97661533711017 0.7627349264348807 
epoch: 57, train time every whole data:319.36s
epoch: 57, total time:14957.30s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 26.83s
test time on whole data:44.62s
1.5213818385011206 2.5029468800046675 55.23520457191451 0.8447903119410656 
1.5477328472221714 2.5660805759070615 55.421977456502624 0.8394684061390211 
1.5752929896139318 2.6257899439814603 55.43853825843528 0.8338700489540934 
1.5970254447368817 2.670722932818031 55.72668034134317 0.8283738636439852 
1.6265829356993948 2.7249878570561172 56.20912641554159 0.8222550075144551 
1.6544813594290366 2.7741251205989044 56.98599312203372 0.8161140801325443 
1.6919184104032106 2.8582868969745525 58.00009015643541 0.8042064533057137 
1.720552868589404 2.9158105663703022 58.992608211625566 0.7937339879507621 
1.7476206048570042 2.963185112079955 60.03778867610852 0.7843203272699996 
1.7674115025397568 3.0083131259413722 60.523750182959404 0.7756146384644783 
1.7846723720582114 3.0405851484702016 60.73639853190886 0.7707612681669092 
1.8000665668482405 3.0708965463964075 60.97238694111948 0.7671853662415367 
1.6695616450415303 2.816263899005672 57.85683744956934 0.7671853662415367 
epoch: 58, train time every whole data:319.39s
epoch: 58, total time:15330.81s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 26.86s
test time on whole data:44.69s
1.5194728323650502 2.475496010429176 55.988397331818206 0.844736289884698 
1.5391275333069443 2.521910093492211 56.18682791293236 0.839826988202523 
1.561202982838842 2.5725887142986594 56.00863860073808 0.8348167586135244 
1.5841214575312499 2.625921846368796 56.0733777658665 0.8292753431448924 
1.615441572652154 2.691058951285642 56.32394883220023 0.8228438280147342 
1.645909123578508 2.747460705973706 56.960471053492746 0.8167616083737229 
1.6846268837654166 2.8350915415488984 57.87005908461214 0.8052965470653187 
1.7166017921324819 2.9021633828326294 58.6975094414692 0.794266991756065 
1.7458923988014106 2.9555523598253473 59.61257629168127 0.7848118182371013 
1.7663150705450348 3.003864802659019 59.99829506295266 0.7762815299620922 
1.7861360952872782 3.042682993974399 60.242604916189414 0.7711510556891772 
1.804879374607333 3.0801154420487693 60.55666292493452 0.7668271019158671 
1.6641439264509752 2.7951736477923617 57.87671131776466 0.7668271019158671 
epoch: 59, train time every whole data:319.31s
epoch: 59, total time:15706.34s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 26.92s
test time on whole data:44.79s
1.5201838451960967 2.4938464885954983 55.85396390163635 0.8434714412956811 
1.5436842205632655 2.5489499843744547 55.89820248339469 0.8386040538832887 
1.568143277650167 2.6019949049320363 55.842788622797315 0.8337024632245726 
1.5903272128066137 2.649932696872822 56.0969407583113 0.8282897343206123 
1.6202111615601573 2.705622182980631 56.58027297513658 0.8219059208115733 
1.6475360978459497 2.752634556502571 57.392079176064414 0.8158130389079152 
1.68436968453805 2.8338130463635185 58.431321589725 0.8044083761316114 
1.7162710837429123 2.9005880326094458 59.3974472448697 0.7935484456048068 
1.7479088468879815 2.959504707806492 60.355750220277216 0.783727344532133 
1.770984097110285 3.015145913215659 60.69711991102802 0.7744706354696419 
1.793257946346576 3.0605725877249523 60.8229619772657 0.7682764028760246 
1.813947864287311 3.1048294926324274 61.05172355170383 0.7629263497316562 
1.6680687782112804 2.809315998700874 58.201833539309554 0.7629263497316562 
epoch: 60, train time every whole data:319.63s
epoch: 60, total time:16081.16s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 26.82s
test time on whole data:44.60s
1.5270043880156285 2.504995245988169 55.38683617189134 0.844095582761997 
1.55276160522914 2.5628775243499327 55.78475010474756 0.8381096405777169 
1.5822562191672622 2.6254242915485815 55.78188856375469 0.8328467275999278 
1.6077091124354905 2.6795937411785715 56.026891949568515 0.8275235732667993 
1.6410279035310127 2.7413335184500944 56.56420770111914 0.8213746483732562 
1.67119177992296 2.793470200811656 57.440413640622765 0.8149304188571114 
1.7099598368170361 2.8783080973318866 58.608333454388415 0.8026243321930384 
1.7402405495438724 2.941965959168704 59.67445569121875 0.791363218676886 
1.7700029580109709 2.994202247482908 60.72339582119278 0.7818670369970886 
1.7914096073070984 3.045086971678678 61.19780891159105 0.7725309146779542 
1.8122107776037994 3.0896870851855907 61.455856825103204 0.7656505746204859 
1.8309581385541351 3.1265171791035544 61.78845993570332 0.7609866785333317 
1.6863944063448673 2.8392150010381934 58.36957843489754 0.7609866785333317 
epoch: 61, train time every whole data:319.63s
epoch: 61, total time:16455.15s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 26.84s
test time on whole data:44.66s
1.518430666060586 2.4928877214965364 56.04256203151859 0.844161460525637 
1.5418762777597599 2.5445386817812645 56.367927740217695 0.838786476304372 
1.5662242130944062 2.594546260339471 56.35810836276984 0.8340217799791179 
1.588060234355962 2.641824245780452 56.49971722000194 0.8290414846430231 
1.6200274215505592 2.7051413090229435 56.849711352369724 0.8224618848495134 
1.6503491202148475 2.762448347121031 57.55116393494269 0.8156500241691135 
1.6881700095964507 2.8448540704853227 58.51515306844151 0.8046652145999555 
1.718319498072334 2.9074423996743324 59.36074690250349 0.7947194458660541 
1.7476145172339996 2.9614785013064813 60.22247699174428 0.7854178154022976 
1.7693535138883938 3.012590707752053 60.56397621164763 0.7765054080568633 
1.7917627433515375 3.0590988468141327 60.726466204371896 0.7701858716861675 
1.8126392919007865 3.102041489830657 60.98166144326706 0.7651393146044003 
1.6677356255899687 2.809540341187567 58.336745799437196 0.7651393146044003 
epoch: 62, train time every whole data:319.64s
epoch: 62, total time:16828.89s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 26.92s
test time on whole data:44.77s
1.5207886502169783 2.50100055439793 55.66501590457863 0.8427225316649417 
1.5445115646148722 2.5521361792668493 55.84582120901911 0.8377203591909411 
1.5708548743929713 2.610009647565689 55.834230936947925 0.8323366401547179 
1.5941247646031635 2.661061668956193 56.06492792220594 0.8269543767868476 
1.6251613398102067 2.716993827502927 56.56165701376021 0.8213162663029159 
1.6553891486931769 2.770229325532518 57.365166713556924 0.8151958985449625 
1.694860756816786 2.855316837252864 58.435674573710884 0.8037906002214883 
1.7258672165977103 2.921315089286254 59.38592850738662 0.7929966778509657 
1.7557665650958107 2.975022535455958 60.36217506852356 0.7836286956770306 
1.7774738661918257 3.027344529541273 60.76922289878811 0.7743771559515915 
1.7999423295456385 3.0718756137658136 61.01231939107527 0.767841962784485 
1.817866187423911 3.1045652775134416 61.283045091799394 0.7638154815585498 
1.6735506053335876 2.8209818594997724 58.2155554896195 0.7638154815585498 
epoch: 63, train time every whole data:319.69s
epoch: 63, total time:17203.42s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 26.92s
test time on whole data:44.81s
1.5193325089333314 2.4896334731296004 55.52285668400728 0.8445274140289352 
1.5415373050545653 2.537943844705742 55.76095972213201 0.8401299490460683 
1.5656715318848866 2.5934495301063554 55.80642359022786 0.8348482239150535 
1.5883123359446014 2.6424853510251753 55.99612872643487 0.8297356924502856 
1.6199245630339498 2.703767115050869 56.39859806960706 0.8232274518222985 
1.6502321604359895 2.7582933523102513 57.097206553903604 0.8167959474093858 
1.688903835962837 2.8465277585332216 58.05866626414019 0.8049499617626168 
1.7205769612082236 2.9137738160178372 58.996299184828494 0.7940006587831987 
1.7521729387538951 2.9711143352545535 60.00992699025039 0.7840027992903085 
1.773984023839679 3.019694238594874 60.50915561998153 0.7750877138693273 
1.796400246660979 3.0631568092439374 60.86900906617703 0.768376889688427 
1.8151338018625087 3.100405075631541 61.26530098120849 0.7632078926675135 
1.669348517797954 2.8107086147538314 58.02432951107785 0.7632078926675135 
epoch: 64, train time every whole data:319.40s
epoch: 64, total time:17578.82s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 26.86s
test time on whole data:44.77s
1.5248435552679889 2.5133436263734077 54.69593004787261 0.8434104245756127 
1.5506174673937438 2.566671692733502 55.07191753355146 0.838297445970685 
1.5761975881754464 2.6213545525446813 55.202129178161066 0.8326127662434204 
1.5998911320958287 2.669764558555818 55.436510608828414 0.8275308748794874 
1.6319553760660015 2.7308755750199842 55.77850260909089 0.8216634784117851 
1.6646448569116847 2.7889497519215367 56.45603147667877 0.8153222300727545 
1.7033690513442492 2.8770291001093 57.43827398797999 0.80315413161643 
1.7308154063611514 2.9324628949755667 58.34655566919965 0.7928420996227742 
1.755709230815637 2.972683366913647 59.31053223475471 0.7845624936815798 
1.7723834703605446 3.011606596299742 59.76006127388622 0.7765562623968845 
1.7895005930881238 3.04520020529931 59.95247581666538 0.7712168592642283 
1.8050879607966082 3.0760798071686164 60.181523738582165 0.7673075156645439 
1.6754179740564172 2.823392336213559 57.302652883359116 0.7673075156645439 
epoch: 65, train time every whole data:319.38s
epoch: 65, total time:17953.23s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 26.89s
test time on whole data:44.74s
1.5155932021694525 2.474475176807445 56.06880116996148 0.8448749777474744 
1.537761561176784 2.5220943792723283 56.39205730362734 0.83962037424847 
1.5602194164840593 2.5735214813289695 56.410685551067786 0.8339278577979208 
1.5812100534233309 2.6162357486931285 56.573527469987575 0.829221657299202 
1.6098439585086668 2.6740114114336686 56.85061086020392 0.8230748184877252 
1.638803446607753 2.7286390642290295 57.40186849715819 0.8170753806257418 
1.677553061944477 2.8197450224790512 58.21078900598037 0.8056049629465659 
1.7098001648186751 2.8890653808399827 59.012472971542316 0.795212078721895 
1.7384780394102313 2.942710858367746 59.86935870882173 0.7861806602341399 
1.7581349661610133 2.988728239039898 60.286505994664054 0.7777543750862684 
1.7768665104346084 3.027200114317536 60.48746694200868 0.771706550487931 
1.7923394729573103 3.057489790224594 60.74352280043161 0.7677747769560201 
1.6580503211746969 2.7831245441097634 58.19240282722178 0.7677747769560201 
epoch: 66, train time every whole data:319.51s
epoch: 66, total time:18327.33s
predicting testing set batch 1 / 168, time: 0.27s
predicting testing set batch 101 / 168, time: 26.96s
test time on whole data:44.82s
1.5191544413310254 2.4695705001867987 56.01422552871808 0.8446476576545103 
1.5398878319617362 2.5121646679123306 56.250285812982746 0.8403385214495251 
1.5603832966152225 2.5595546397222675 56.22956902845817 0.835405036134696 
1.5833206854993922 2.610515419272579 56.31070810094045 0.8299860274292065 
1.614863280786024 2.6753773450245872 56.61136790355143 0.8227951705865894 
1.644914227534795 2.7299823584632916 57.20391472277219 0.8162977411443237 
1.6832235683368608 2.8160436863618608 58.11079260780364 0.8042920670751722 
1.7143828028517643 2.882399793698006 58.99039628908125 0.7929576227406601 
1.7437137144013708 2.9353546479600388 59.944188409502694 0.7834714010083476 
1.7626167658664995 2.9796199650874486 60.3877594740235 0.7754083650870471 
1.7812769078689494 3.016485498144366 60.636927564660795 0.769466634672465 
1.7964107283899295 3.0486208169129023 60.9339355029549 0.7650263398997308 
1.662012354286964 2.7765739440835233 58.13544250978943 0.7650263398997308 
epoch: 67, train time every whole data:319.44s
epoch: 67, total time:18701.97s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 26.93s
test time on whole data:44.79s
1.5184505685063168 2.484899680575117 56.20149881798162 0.8434862778617752 
1.542797140884701 2.5361679019321404 56.25877289671898 0.8385161629948674 
1.567238475719112 2.5935877129894536 56.05953539711641 0.8332473102786878 
1.5920935146400617 2.6481212684877016 56.08509403594355 0.8284263437243103 
1.6257825720265862 2.7164687514265378 56.46876687067562 0.8218560664087765 
1.6573922572268085 2.77396841308054 57.23854130824536 0.8154478657958054 
1.69657291234941 2.859151059679289 58.39120958938111 0.8039499874370414 
1.7279467060557079 2.924419856626262 59.468436981579906 0.7928708155640084 
1.7580832186262345 2.9767126153128283 60.5260854897256 0.7834994243780418 
1.7782443024815016 3.022560311169582 60.931630191673534 0.7755295075970441 
1.7990860537611657 3.065628763465347 61.119044150483205 0.7694380300214113 
1.8192350725777269 3.1091258175145087 61.40904550168238 0.7640155246717157 
1.6735768995712776 2.8167450028709546 58.346589179953945 0.7640155246717157 
epoch: 68, train time every whole data:319.34s
epoch: 68, total time:19076.67s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 26.97s
test time on whole data:44.84s
1.5208779732341922 2.489337111697822 55.26069523587706 0.8441515915965372 
1.545667339992665 2.5410365030250124 55.43348500871416 0.8393300016132773 
1.5693197425395429 2.59444664798034 55.40316047834963 0.8334842181970109 
1.5934660574996933 2.646250141963202 55.50382464055785 0.8283127071099059 
1.6244148582432065 2.7089737314273092 55.816631978184574 0.8219962661076533 
1.654978952086309 2.7641356887785853 56.41141490086154 0.8160090967773836 
1.6939433304903408 2.8527356843579255 57.31758506503153 0.8041725405262371 
1.7258577444591514 2.9206474786337777 58.23898761626041 0.7926784585861718 
1.7554084429457073 2.975261389999215 59.181945624413935 0.7827249818036155 
1.7760635613868279 3.0219845064129753 59.61455300616948 0.7740084171304038 
1.7964630537369244 3.0641031575105533 59.81037561280066 0.7678526557650813 
1.8132264074739068 3.0980495526239604 60.043414834622766 0.7642075034082947 
1.6724739553407055 2.8137450760720975 57.336442856706945 0.7642075034082947 
epoch: 69, train time every whole data:319.23s
epoch: 69, total time:19450.36s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 26.82s
test time on whole data:44.61s
1.5194995470186252 2.502397969092276 55.20948792459367 0.8441637397629362 
1.544863927499879 2.55645816432881 55.57506922631492 0.8388767888050477 
1.5691202251622898 2.609762055783666 55.67142966447869 0.8334190401858098 
1.591608323171114 2.6586896037378107 55.855474120898705 0.8283074969224572 
1.622443488735617 2.717175500445508 56.30979937894141 0.8220945593274017 
1.6509423075156908 2.7685615740614993 57.037197893923356 0.8156922409822818 
1.6862690392549904 2.848278213398129 58.029775396250415 0.8041820559264284 
1.7139954614356339 2.9065400283941103 58.94451049088359 0.7938918551275234 
1.740137730126757 2.9503175158445534 59.8305364572605 0.7860460480125911 
1.7595107341677483 2.9924845033299876 60.2428349050472 0.7786713676061252 
1.7808838289835092 3.037110582582019 60.4608198618585 0.7722353354982128 
1.8006096277620998 3.0776578496921467 60.76785079063689 0.7672899730386155 
1.6649903534028294 2.8083351744294416 57.82801641846114 0.7672899730386155 
epoch: 70, train time every whole data:319.50s
epoch: 70, total time:19825.34s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 26.89s
test time on whole data:44.75s
1.5149332605448684 2.479121940168388 56.133560766311376 0.8441645135499535 
1.5379788639972962 2.5339691549371683 56.1246749169615 0.8391637313423634 
1.5608142659098265 2.5835320463124534 56.00414373621815 0.8346408252768548 
1.5827608302663125 2.630158571644447 56.09000306765998 0.8300334157842133 
1.6118723703745221 2.6879118290550057 56.434892714113936 0.8238743508851276 
1.641356242379706 2.743272472982212 57.148117537879784 0.8170658794185047 
1.6783565392886244 2.8273862749776386 58.161823005713174 0.8056260035474794 
1.7098064832076252 2.894285633705968 59.15149688768218 0.7945850700819186 
1.7394608826733948 2.946852961051938 60.14700031597455 0.7853062854735618 
1.7589667113702745 2.9894602332207034 60.63956040657761 0.7772353550235582 
1.7777632100438434 3.0263914840614965 60.91997919306483 0.7711344038675365 
1.7939346239710492 3.0577918772365975 61.28171923898942 0.766762120181914 
1.6590003570022787 2.790023670707271 58.186526240213865 0.766762120181914 
epoch: 71, train time every whole data:319.22s
epoch: 71, total time:20199.45s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 26.90s
test time on whole data:44.73s
1.5197796169859135 2.5042688786856315 55.23525216849416 0.8436220158600805 
1.5456165595172593 2.5616441963868515 55.45817797131185 0.8383324902828859 
1.5705460821229609 2.6144969368496835 55.509057437902484 0.8334386148328251 
1.5928977650648781 2.6610975252328335 55.719398721233425 0.8284806394845806 
1.6232193289205787 2.7198701991733687 56.16235367002044 0.8222066640856661 
1.6531657073547443 2.7739859732254137 56.841307369706726 0.8164640098507493 
1.6919485185292682 2.860034478815006 57.85170561855435 0.8053426537262095 
1.72340039922909 2.923489270477275 58.77449514462151 0.7951228605346969 
1.7541990463558939 2.979990280553301 59.65951202105426 0.7856194580595551 
1.7761719208647986 3.030638407511094 60.01469011135935 0.7768553938781847 
1.80008054019901 3.082555816012607 60.181134431637695 0.7692846595467365 
1.8197568247915201 3.121621412968044 60.44096528286411 0.7645991962573047 
1.6725651924946596 2.826680599305025 57.654118037220826 0.7645991962573047 
epoch: 72, train time every whole data:319.77s
epoch: 72, total time:20573.29s
predicting testing set batch 1 / 168, time: 0.27s
predicting testing set batch 101 / 168, time: 27.05s
test time on whole data:44.98s
1.51503685789848 2.4814982974085558 55.99536369907714 0.8441571246903814 
1.5383938875428091 2.5286473980864725 56.21370734811266 0.839292730615384 
1.5614895592555404 2.5811218404982323 56.139827729854986 0.8338858842133057 
1.5829447190284374 2.6253908730270217 56.24758370445995 0.8291052746981412 
1.611621955908569 2.6811977612348254 56.575786519060436 0.8230519286322697 
1.641676764357214 2.734487034644505 57.19949409670847 0.816949300337422 
1.6793165565382335 2.8220736974710725 58.08769858447559 0.805369853806111 
1.7122319309377954 2.892708813526541 58.96110907994804 0.7945696732817671 
1.7444809448656937 2.9521757639067925 59.887633743936064 0.7847296952772623 
1.7664964729344383 3.000562263692776 60.32236342295011 0.7761608295920254 
1.7862992896141396 3.041773593239597 60.50307588061178 0.7696377039169332 
1.8021032313069418 3.0713456617507267 60.78550406317701 0.7654923504247225 
1.6618410141823576 2.7914919856688925 58.07669821096116 0.7654923504247225 
epoch: 73, train time every whole data:323.66s
epoch: 73, total time:20952.19s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 26.97s
test time on whole data:44.88s
1.5184633523128217 2.506596618600072 55.36942496085045 0.8435883784861709 
1.5458415350484707 2.5665905108185885 55.63233793547738 0.837721354765423 
1.5712852762963267 2.621491682259145 55.677761791492685 0.8322487389254581 
1.5950556203620065 2.669395917080413 55.81447703291784 0.8276536546514305 
1.626746690529709 2.73089492681055 56.20903140817632 0.8212879304613023 
1.6578699200372433 2.7868703692304173 56.89999813630562 0.8148717704909119 
1.6961947084179236 2.873421903048343 57.90182260016723 0.8032274438335004 
1.7259983824894187 2.9356784247987115 58.83476347077189 0.7925685026166769 
1.7536805803382858 2.98309830106424 59.7942321336661 0.7836985983286416 
1.7725830249424492 3.0260514879103324 60.292497895164544 0.7753361833815925 
1.792993257692882 3.0665110758257157 60.57675488344047 0.7691624585637613 
1.8112499780040234 3.1016021394357915 60.92668860112037 0.7648618099481795 
1.67233019387263 2.829116330744352 57.827598811959156 0.7648618099481795 
epoch: 74, train time every whole data:323.12s
epoch: 74, total time:21331.34s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 27.07s
test time on whole data:44.95s
1.5163584057976092 2.483982828204592 56.057071054666906 0.8439339411883877 
1.5420076931628974 2.542338696059799 56.11833824518755 0.8379822777602245 
1.5652494278487172 2.59307769249391 56.151149119264076 0.832771650534231 
1.5877433433703014 2.6429156874338715 56.28807859149694 0.8276950830127529 
1.6182994869890668 2.703958351333036 56.69190337690384 0.8216557553650269 
1.6506018939037763 2.7606013169379127 57.39207492553868 0.815700838284016 
1.690631438740396 2.847479354438254 58.41478204999115 0.8046785562231722 
1.72426514457929 2.918099686345916 59.39689366443791 0.7936105867480717 
1.7571197928449227 2.9779116452053707 60.41258184789048 0.7838147122369639 
1.7790937273533394 3.027378544123598 60.89650983997639 0.7751473775968875 
1.8005584528490546 3.0713332060096206 61.11315410591659 0.76840158802243 
1.819245942219116 3.106623177132497 61.4383941820127 0.7637496351274903 
1.6709312291382072 2.813888778301642 58.364361235615604 0.7637496351274903 
epoch: 75, train time every whole data:325.19s
epoch: 75, total time:21712.02s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 27.04s
test time on whole data:44.98s
1.5174813301965062 2.4953956198552123 55.7570204076281 0.8438880673828992 
1.5433298589966837 2.5474269484522734 55.918174409465436 0.838908839192166 
1.5688607451888246 2.6023809990068725 55.948999883335226 0.8336473876213492 
1.5955065862077864 2.6623685180840715 56.02716448207213 0.8279322662070426 
1.6307288696709132 2.7331651727592603 56.39680055542149 0.8212457172208596 
1.6644773186744146 2.793748908030001 57.092486221066984 0.8150888178174361 
1.7036026798001536 2.878815187905832 58.159880213937555 0.8040784281592402 
1.734211896496958 2.9415431912319883 59.153185864314516 0.7933996251858647 
1.7636207867854585 2.9949669922795157 60.1768631334714 0.7835980138258497 
1.7821113809490843 3.0358643854459 60.649723063400586 0.7755931240186911 
1.8007947937273199 3.0759639088163047 60.79261255174555 0.7693674258685592 
1.8180135166619327 3.1115485501081896 61.027348334707696 0.7653133286651784 
1.6768949802796695 2.8302244110340693 58.09180417805979 0.7653133286651784 
epoch: 76, train time every whole data:321.39s
epoch: 76, total time:22088.61s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 27.01s
test time on whole data:44.92s
1.5171514804947765 2.499998766255622 55.27595923402286 0.8443138962519934 
1.5439083036858412 2.5561680036601517 55.49832338944529 0.8389796842461463 
1.5670211134219454 2.6045710454210957 55.632343897790435 0.833825848023979 
1.5877758440214786 2.646418020129871 55.917149927105534 0.8289866706897941 
1.6161367130374447 2.6991739079106982 56.526594530126516 0.8227666640396124 
1.6451038283751833 2.7502857484347967 57.391598734071096 0.8162007995298448 
1.6799985197324838 2.8282436212903694 58.48807430649309 0.8051019681137629 
1.7094399685435706 2.889452286300639 59.4650083566888 0.7944566355563543 
1.7355385585437928 2.932589482308029 60.404813840859276 0.7864869227231392 
1.752574089520744 2.9716959636699216 60.81867847113379 0.779066729740689 
1.7691938480452767 3.0062187483526333 60.98517275450107 0.7734339418552154 
1.782814735909303 3.033295176572511 61.225464387454466 0.7699045129085926 
1.6588880836109867 2.7904316288717976 58.13589717139654 0.7699045129085926 
epoch: 77, train time every whole data:321.20s
epoch: 77, total time:22466.13s
predicting testing set batch 1 / 168, time: 0.27s
predicting testing set batch 101 / 168, time: 27.00s
test time on whole data:44.90s
1.5151440310343391 2.4869578195132593 56.038479512607076 0.8435410031551305 
1.5402084239866762 2.5433123979866616 56.272696867462955 0.8375498938080856 
1.5625399887481084 2.590219531360489 56.30448958772873 0.8327104630069846 
1.5836805331839159 2.6327336624434197 56.353796894061034 0.8286389035877381 
1.6132052571381486 2.6922958186263553 56.616294089786365 0.8225920030525521 
1.6441437547982094 2.749454108830684 57.20601494006176 0.8160684257345434 
1.6813473918162996 2.8340907561592075 58.136798148500255 0.8044206892080684 
1.7132755536169169 2.9017013934235116 59.06019908333644 0.7928535588529085 
1.7413272650328775 2.949090603396354 60.01663938862922 0.7844820812347246 
1.7616444781833285 2.995523560214189 60.46387705264203 0.7762521471294994 
1.7809510904227694 3.0366880356049966 60.592126461902716 0.770038937242471 
1.7964921698492198 3.0703476212683967 60.77866382155474 0.7657813757726425 
1.6611633281509008 2.796912322811693 58.15344231159082 0.7657813757726425 
epoch: 78, train time every whole data:320.90s
epoch: 78, total time:22845.83s
predicting testing set batch 1 / 168, time: 0.26s
predicting testing set batch 101 / 168, time: 26.99s
test time on whole data:44.92s
1.5152582863838013 2.489766089295945 55.71666710163177 0.8444711673837199 
1.5402234772327579 2.5413843297084737 55.90125123608285 0.8396444844427202 
1.5655750115316007 2.5983927776257145 55.841883712078165 0.8342760097195357 
1.5899034269414842 2.6501365369019156 55.89967004874844 0.8292527152677025 
1.621658617130259 2.711490159912271 56.19971462651306 0.82322167315267 
1.6539170521979354 2.7694551409388186 56.8470987045784 0.8168627660335354 
1.6916203614343845 2.8551103102710935 57.82255948809081 0.8054153500648692 
1.722842566254593 2.921490705229425 58.74498946574743 0.794288938265798 
1.7511823594214484 2.972602402053512 59.70270120782343 0.7849297196744595 
1.7724560453473102 3.019446433867779 60.289553743454725 0.7760999580131853 
1.794555654323438 3.0657609417365994 60.625975540266886 0.7687964479073975 
1.8118638508813012 3.0998007280332436 60.938904745824765 0.7645280200468155 
1.6692547257566928 2.8151722591514683 57.877689659701815 0.7645280200468155 
epoch: 79, train time every whole data:321.39s
epoch: 79, total time:23222.62s
predicting testing set batch 1 / 168, time: 0.27s
predicting testing set batch 101 / 168, time: 26.97s
test time on whole data:44.87s
1.5185125589947261 2.4842261019088587 55.53923122876919 0.8441457137243078 
1.5442916206756518 2.538736327202573 55.67121239529709 0.8385932222804235 
1.5682471990987126 2.5944500720534243 55.606187941880094 0.8329369932845184 
1.5919160081996095 2.6470687468875425 55.64625764987139 0.8279291020303894 
1.6215788144036418 2.707592901052914 55.980333717155176 0.8220475603552139 
1.6515696636307984 2.7638678446898597 56.65953425600749 0.8159177494787345 
1.6880163708894202 2.846695411753563 57.67471413386569 0.8049737310900277 
1.7184269846374436 2.908773033023671 58.59282731977407 0.7943484981812455 
1.7470654487780162 2.960094607126824 59.51937712568841 0.7851812713805193 
1.7677228429952547 3.006991123166659 59.97941306604767 0.7765599376621762 
1.7885187316145748 3.0490107070396877 60.17690008773795 0.7701813514013538 
1.8059309190235855 3.086152320603319 60.41663820076124 0.7655060748418684 
1.6676497635784528 2.806455710096953 57.621992603077686 0.7655060748418684 
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention1_spt_trend_adj_nocrosst/epoch_79.params
