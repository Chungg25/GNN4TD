CUDA: True cuda:0
Read configuration file: configurations/bike.conf
total training epoch, fine tune epoch: 100 , 50
batch_size: 4
folder_dir: MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_0.55
load file: data/bike.npz
ori length: 3001 , percent: 1.0 , scale: 3001
train: torch.Size([3001, 250, 2, 12]) torch.Size([3001, 250, 2, 12]) torch.Size([3001, 250, 2, 12])
val: torch.Size([672, 250, 2, 12]) torch.Size([672, 250, 2, 12]) torch.Size([672, 250, 2, 12])
test: torch.Size([672, 250, 2, 12]) torch.Size([672, 250, 2, 12]) torch.Size([672, 250, 2, 12])
TemporalPositionalEncoding max_len: 12
h_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
en_lookup_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
EncoderDecoder(
  (encoder): Encoder(
    (layers): ModuleList(
      (0): EncoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn2): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (tcn2): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (1): EncoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn2): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (tcn2): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (2): EncoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn2): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (tcn2): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (3): EncoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn2): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (tcn2): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): Decoder(
    (layers): ModuleList(
      (0): DecoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (1): DecoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (2): DecoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (3): DecoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (decoder2): Decoder(
    (layers): ModuleList(
      (0): DecoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (1): DecoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (2): DecoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (3): DecoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (src_embed): Sequential(
    (0): Linear(in_features=1, out_features=64, bias=True)
    (1): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (2): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(250, 64)
    )
  )
  (src_embed2): Sequential(
    (0): Linear(in_features=1, out_features=64, bias=True)
    (1): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (2): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(250, 64)
    )
  )
  (trg_embed): Sequential(
    (0): Linear(in_features=1, out_features=64, bias=True)
    (1): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (2): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(250, 64)
    )
  )
  (trg_embed2): Sequential(
    (0): Linear(in_features=1, out_features=64, bias=True)
    (1): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (2): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(250, 64)
    )
  )
  (prediction_generator): Linear(in_features=64, out_features=1, bias=True)
  (prediction_generator2): Linear(in_features=64, out_features=1, bias=True)
)
create params directory experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_0.55
Net's state_dict:
encoder.layers.0.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.linears.2.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.linears.2.bias 	 torch.Size([64])
encoder.layers.0.self_attn.linears.3.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.linears.3.bias 	 torch.Size([64])
encoder.layers.0.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.0.feed_forward_gcn2.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.0.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.tcn.filter_convs.bias 	 torch.Size([64])
encoder.layers.0.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.tcn.gate_convs.bias 	 torch.Size([64])
encoder.layers.0.tcn2.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.tcn2.filter_convs.bias 	 torch.Size([64])
encoder.layers.0.tcn2.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.tcn2.gate_convs.bias 	 torch.Size([64])
encoder.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.2.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.2.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.3.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.3.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.4.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.4.norm.bias 	 torch.Size([64])
encoder.layers.1.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.linears.2.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.linears.2.bias 	 torch.Size([64])
encoder.layers.1.self_attn.linears.3.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.linears.3.bias 	 torch.Size([64])
encoder.layers.1.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.1.feed_forward_gcn2.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.1.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.tcn.filter_convs.bias 	 torch.Size([64])
encoder.layers.1.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.tcn.gate_convs.bias 	 torch.Size([64])
encoder.layers.1.tcn2.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.tcn2.filter_convs.bias 	 torch.Size([64])
encoder.layers.1.tcn2.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.tcn2.gate_convs.bias 	 torch.Size([64])
encoder.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.2.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.2.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.3.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.3.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.4.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.4.norm.bias 	 torch.Size([64])
encoder.layers.2.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.linears.2.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.linears.2.bias 	 torch.Size([64])
encoder.layers.2.self_attn.linears.3.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.linears.3.bias 	 torch.Size([64])
encoder.layers.2.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.2.feed_forward_gcn2.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.2.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.tcn.filter_convs.bias 	 torch.Size([64])
encoder.layers.2.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.tcn.gate_convs.bias 	 torch.Size([64])
encoder.layers.2.tcn2.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.tcn2.filter_convs.bias 	 torch.Size([64])
encoder.layers.2.tcn2.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.tcn2.gate_convs.bias 	 torch.Size([64])
encoder.layers.2.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.2.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.2.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.3.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.3.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.4.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.4.norm.bias 	 torch.Size([64])
encoder.layers.3.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.3.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.3.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.3.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.3.self_attn.linears.2.weight 	 torch.Size([64, 64])
encoder.layers.3.self_attn.linears.2.bias 	 torch.Size([64])
encoder.layers.3.self_attn.linears.3.weight 	 torch.Size([64, 64])
encoder.layers.3.self_attn.linears.3.bias 	 torch.Size([64])
encoder.layers.3.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.3.feed_forward_gcn2.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.3.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.3.tcn.filter_convs.bias 	 torch.Size([64])
encoder.layers.3.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.3.tcn.gate_convs.bias 	 torch.Size([64])
encoder.layers.3.tcn2.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.3.tcn2.filter_convs.bias 	 torch.Size([64])
encoder.layers.3.tcn2.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.3.tcn2.gate_convs.bias 	 torch.Size([64])
encoder.layers.3.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.3.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.3.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.3.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.3.sublayer.2.norm.weight 	 torch.Size([64])
encoder.layers.3.sublayer.2.norm.bias 	 torch.Size([64])
encoder.layers.3.sublayer.3.norm.weight 	 torch.Size([64])
encoder.layers.3.sublayer.3.norm.bias 	 torch.Size([64])
encoder.layers.3.sublayer.4.norm.weight 	 torch.Size([64])
encoder.layers.3.sublayer.4.norm.bias 	 torch.Size([64])
encoder.norm.weight 	 torch.Size([64])
encoder.norm.bias 	 torch.Size([64])
encoder.norm2.weight 	 torch.Size([64])
encoder.norm2.bias 	 torch.Size([64])
decoder.layers.0.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.0.self_attn.linears.2.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.linears.2.bias 	 torch.Size([64])
decoder.layers.0.self_attn.linears.3.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.linears.3.bias 	 torch.Size([64])
decoder.layers.0.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.0.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.linears.2.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.linears.2.bias 	 torch.Size([64])
decoder.layers.0.src_attn.linears.3.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.linears.3.bias 	 torch.Size([64])
decoder.layers.0.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.0.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.tcn.filter_convs.bias 	 torch.Size([64])
decoder.layers.0.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.tcn.gate_convs.bias 	 torch.Size([64])
decoder.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.3.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.3.norm.bias 	 torch.Size([64])
decoder.layers.1.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.1.self_attn.linears.2.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.linears.2.bias 	 torch.Size([64])
decoder.layers.1.self_attn.linears.3.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.linears.3.bias 	 torch.Size([64])
decoder.layers.1.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.1.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.linears.2.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.linears.2.bias 	 torch.Size([64])
decoder.layers.1.src_attn.linears.3.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.linears.3.bias 	 torch.Size([64])
decoder.layers.1.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.1.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.tcn.filter_convs.bias 	 torch.Size([64])
decoder.layers.1.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.tcn.gate_convs.bias 	 torch.Size([64])
decoder.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.3.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.3.norm.bias 	 torch.Size([64])
decoder.layers.2.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.2.self_attn.linears.2.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.linears.2.bias 	 torch.Size([64])
decoder.layers.2.self_attn.linears.3.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.linears.3.bias 	 torch.Size([64])
decoder.layers.2.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.2.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.linears.2.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.linears.2.bias 	 torch.Size([64])
decoder.layers.2.src_attn.linears.3.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.linears.3.bias 	 torch.Size([64])
decoder.layers.2.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.2.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.tcn.filter_convs.bias 	 torch.Size([64])
decoder.layers.2.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.tcn.gate_convs.bias 	 torch.Size([64])
decoder.layers.2.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.3.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.3.norm.bias 	 torch.Size([64])
decoder.layers.3.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.3.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.3.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.3.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.3.self_attn.linears.2.weight 	 torch.Size([64, 64])
decoder.layers.3.self_attn.linears.2.bias 	 torch.Size([64])
decoder.layers.3.self_attn.linears.3.weight 	 torch.Size([64, 64])
decoder.layers.3.self_attn.linears.3.bias 	 torch.Size([64])
decoder.layers.3.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.3.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.3.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.3.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.3.src_attn.linears.2.weight 	 torch.Size([64, 64])
decoder.layers.3.src_attn.linears.2.bias 	 torch.Size([64])
decoder.layers.3.src_attn.linears.3.weight 	 torch.Size([64, 64])
decoder.layers.3.src_attn.linears.3.bias 	 torch.Size([64])
decoder.layers.3.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.3.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.3.tcn.filter_convs.bias 	 torch.Size([64])
decoder.layers.3.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.3.tcn.gate_convs.bias 	 torch.Size([64])
decoder.layers.3.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.3.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.3.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.3.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.3.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.3.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.3.sublayer.3.norm.weight 	 torch.Size([64])
decoder.layers.3.sublayer.3.norm.bias 	 torch.Size([64])
decoder.norm.weight 	 torch.Size([64])
decoder.norm.bias 	 torch.Size([64])
decoder2.layers.0.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder2.layers.0.self_attn.linears.0.bias 	 torch.Size([64])
decoder2.layers.0.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder2.layers.0.self_attn.linears.1.bias 	 torch.Size([64])
decoder2.layers.0.self_attn.linears.2.weight 	 torch.Size([64, 64])
decoder2.layers.0.self_attn.linears.2.bias 	 torch.Size([64])
decoder2.layers.0.self_attn.linears.3.weight 	 torch.Size([64, 64])
decoder2.layers.0.self_attn.linears.3.bias 	 torch.Size([64])
decoder2.layers.0.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder2.layers.0.src_attn.linears.0.bias 	 torch.Size([64])
decoder2.layers.0.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder2.layers.0.src_attn.linears.1.bias 	 torch.Size([64])
decoder2.layers.0.src_attn.linears.2.weight 	 torch.Size([64, 64])
decoder2.layers.0.src_attn.linears.2.bias 	 torch.Size([64])
decoder2.layers.0.src_attn.linears.3.weight 	 torch.Size([64, 64])
decoder2.layers.0.src_attn.linears.3.bias 	 torch.Size([64])
decoder2.layers.0.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder2.layers.0.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder2.layers.0.tcn.filter_convs.bias 	 torch.Size([64])
decoder2.layers.0.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder2.layers.0.tcn.gate_convs.bias 	 torch.Size([64])
decoder2.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
decoder2.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
decoder2.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
decoder2.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
decoder2.layers.0.sublayer.2.norm.weight 	 torch.Size([64])
decoder2.layers.0.sublayer.2.norm.bias 	 torch.Size([64])
decoder2.layers.0.sublayer.3.norm.weight 	 torch.Size([64])
decoder2.layers.0.sublayer.3.norm.bias 	 torch.Size([64])
decoder2.layers.1.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder2.layers.1.self_attn.linears.0.bias 	 torch.Size([64])
decoder2.layers.1.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder2.layers.1.self_attn.linears.1.bias 	 torch.Size([64])
decoder2.layers.1.self_attn.linears.2.weight 	 torch.Size([64, 64])
decoder2.layers.1.self_attn.linears.2.bias 	 torch.Size([64])
decoder2.layers.1.self_attn.linears.3.weight 	 torch.Size([64, 64])
decoder2.layers.1.self_attn.linears.3.bias 	 torch.Size([64])
decoder2.layers.1.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder2.layers.1.src_attn.linears.0.bias 	 torch.Size([64])
decoder2.layers.1.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder2.layers.1.src_attn.linears.1.bias 	 torch.Size([64])
decoder2.layers.1.src_attn.linears.2.weight 	 torch.Size([64, 64])
decoder2.layers.1.src_attn.linears.2.bias 	 torch.Size([64])
decoder2.layers.1.src_attn.linears.3.weight 	 torch.Size([64, 64])
decoder2.layers.1.src_attn.linears.3.bias 	 torch.Size([64])
decoder2.layers.1.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder2.layers.1.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder2.layers.1.tcn.filter_convs.bias 	 torch.Size([64])
decoder2.layers.1.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder2.layers.1.tcn.gate_convs.bias 	 torch.Size([64])
decoder2.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
decoder2.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
decoder2.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
decoder2.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
decoder2.layers.1.sublayer.2.norm.weight 	 torch.Size([64])
decoder2.layers.1.sublayer.2.norm.bias 	 torch.Size([64])
decoder2.layers.1.sublayer.3.norm.weight 	 torch.Size([64])
decoder2.layers.1.sublayer.3.norm.bias 	 torch.Size([64])
decoder2.layers.2.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder2.layers.2.self_attn.linears.0.bias 	 torch.Size([64])
decoder2.layers.2.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder2.layers.2.self_attn.linears.1.bias 	 torch.Size([64])
decoder2.layers.2.self_attn.linears.2.weight 	 torch.Size([64, 64])
decoder2.layers.2.self_attn.linears.2.bias 	 torch.Size([64])
decoder2.layers.2.self_attn.linears.3.weight 	 torch.Size([64, 64])
decoder2.layers.2.self_attn.linears.3.bias 	 torch.Size([64])
decoder2.layers.2.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder2.layers.2.src_attn.linears.0.bias 	 torch.Size([64])
decoder2.layers.2.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder2.layers.2.src_attn.linears.1.bias 	 torch.Size([64])
decoder2.layers.2.src_attn.linears.2.weight 	 torch.Size([64, 64])
decoder2.layers.2.src_attn.linears.2.bias 	 torch.Size([64])
decoder2.layers.2.src_attn.linears.3.weight 	 torch.Size([64, 64])
decoder2.layers.2.src_attn.linears.3.bias 	 torch.Size([64])
decoder2.layers.2.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder2.layers.2.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder2.layers.2.tcn.filter_convs.bias 	 torch.Size([64])
decoder2.layers.2.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder2.layers.2.tcn.gate_convs.bias 	 torch.Size([64])
decoder2.layers.2.sublayer.0.norm.weight 	 torch.Size([64])
decoder2.layers.2.sublayer.0.norm.bias 	 torch.Size([64])
decoder2.layers.2.sublayer.1.norm.weight 	 torch.Size([64])
decoder2.layers.2.sublayer.1.norm.bias 	 torch.Size([64])
decoder2.layers.2.sublayer.2.norm.weight 	 torch.Size([64])
decoder2.layers.2.sublayer.2.norm.bias 	 torch.Size([64])
decoder2.layers.2.sublayer.3.norm.weight 	 torch.Size([64])
decoder2.layers.2.sublayer.3.norm.bias 	 torch.Size([64])
decoder2.layers.3.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder2.layers.3.self_attn.linears.0.bias 	 torch.Size([64])
decoder2.layers.3.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder2.layers.3.self_attn.linears.1.bias 	 torch.Size([64])
decoder2.layers.3.self_attn.linears.2.weight 	 torch.Size([64, 64])
decoder2.layers.3.self_attn.linears.2.bias 	 torch.Size([64])
decoder2.layers.3.self_attn.linears.3.weight 	 torch.Size([64, 64])
decoder2.layers.3.self_attn.linears.3.bias 	 torch.Size([64])
decoder2.layers.3.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder2.layers.3.src_attn.linears.0.bias 	 torch.Size([64])
decoder2.layers.3.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder2.layers.3.src_attn.linears.1.bias 	 torch.Size([64])
decoder2.layers.3.src_attn.linears.2.weight 	 torch.Size([64, 64])
decoder2.layers.3.src_attn.linears.2.bias 	 torch.Size([64])
decoder2.layers.3.src_attn.linears.3.weight 	 torch.Size([64, 64])
decoder2.layers.3.src_attn.linears.3.bias 	 torch.Size([64])
decoder2.layers.3.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder2.layers.3.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder2.layers.3.tcn.filter_convs.bias 	 torch.Size([64])
decoder2.layers.3.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder2.layers.3.tcn.gate_convs.bias 	 torch.Size([64])
decoder2.layers.3.sublayer.0.norm.weight 	 torch.Size([64])
decoder2.layers.3.sublayer.0.norm.bias 	 torch.Size([64])
decoder2.layers.3.sublayer.1.norm.weight 	 torch.Size([64])
decoder2.layers.3.sublayer.1.norm.bias 	 torch.Size([64])
decoder2.layers.3.sublayer.2.norm.weight 	 torch.Size([64])
decoder2.layers.3.sublayer.2.norm.bias 	 torch.Size([64])
decoder2.layers.3.sublayer.3.norm.weight 	 torch.Size([64])
decoder2.layers.3.sublayer.3.norm.bias 	 torch.Size([64])
decoder2.norm.weight 	 torch.Size([64])
decoder2.norm.bias 	 torch.Size([64])
src_embed.0.weight 	 torch.Size([64, 1])
src_embed.0.bias 	 torch.Size([64])
src_embed.1.pe 	 torch.Size([1, 1, 12, 64])
src_embed.2.embedding.weight 	 torch.Size([250, 64])
src_embed2.0.weight 	 torch.Size([64, 1])
src_embed2.0.bias 	 torch.Size([64])
src_embed2.1.pe 	 torch.Size([1, 1, 12, 64])
src_embed2.2.embedding.weight 	 torch.Size([250, 64])
trg_embed.0.weight 	 torch.Size([64, 1])
trg_embed.0.bias 	 torch.Size([64])
trg_embed.1.pe 	 torch.Size([1, 1, 12, 64])
trg_embed.2.embedding.weight 	 torch.Size([250, 64])
trg_embed2.0.weight 	 torch.Size([64, 1])
trg_embed2.0.bias 	 torch.Size([64])
trg_embed2.1.pe 	 torch.Size([1, 1, 12, 64])
trg_embed2.2.embedding.weight 	 torch.Size([250, 64])
prediction_generator.weight 	 torch.Size([1, 64])
prediction_generator.bias 	 torch.Size([1])
prediction_generator2.weight 	 torch.Size([1, 64])
prediction_generator2.bias 	 torch.Size([1])
Net's total params: 868482
Optimizer's state_dict:
state 	 {}
param_groups 	 [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367]}]
validation batch 1 / 168, loss: 1.54
validation batch 101 / 168, loss: 1.58
validation cost time: 52.9075s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_0.55/epoch_0.params
epoch: 0, learning rate 0.001000
epoch: 0, train time every whole data:181.07s
epoch: 0, total time:234.13s
validation batch 1 / 168, loss: 0.05
validation batch 101 / 168, loss: 0.05
validation cost time: 53.4129s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_0.55/epoch_1.params
epoch: 1, learning rate 0.001000
epoch: 1, train time every whole data:182.09s
epoch: 1, total time:469.78s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.09
validation cost time: 53.6307s
epoch: 2, learning rate 0.001000
epoch: 2, train time every whole data:182.28s
epoch: 2, total time:705.69s
validation batch 1 / 168, loss: 0.17
validation batch 101 / 168, loss: 0.16
validation cost time: 53.4209s
epoch: 3, learning rate 0.001000
epoch: 3, train time every whole data:182.05s
epoch: 3, total time:941.17s
validation batch 1 / 168, loss: 0.08
validation batch 101 / 168, loss: 0.03
validation cost time: 53.5347s
epoch: 4, learning rate 0.001000
epoch: 4, train time every whole data:182.33s
epoch: 4, total time:1177.05s
validation batch 1 / 168, loss: 0.10
validation batch 101 / 168, loss: 0.04
validation cost time: 53.5937s
epoch: 5, learning rate 0.001000
epoch: 5, train time every whole data:182.56s
epoch: 5, total time:1413.21s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.06
validation cost time: 53.7106s
epoch: 6, learning rate 0.001000
epoch: 6, train time every whole data:182.67s
epoch: 6, total time:1649.59s
validation batch 1 / 168, loss: 0.08
validation batch 101 / 168, loss: 0.04
validation cost time: 53.7489s
epoch: 7, learning rate 0.001000
epoch: 7, train time every whole data:182.27s
epoch: 7, total time:1885.62s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.06
validation cost time: 53.5183s
epoch: 8, learning rate 0.001000
epoch: 8, train time every whole data:181.97s
epoch: 8, total time:2121.11s
validation batch 1 / 168, loss: 0.09
validation batch 101 / 168, loss: 0.02
validation cost time: 53.4890s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_0.55/epoch_9.params
epoch: 9, learning rate 0.001000
epoch: 9, train time every whole data:182.25s
epoch: 9, total time:2356.98s
validation batch 1 / 168, loss: 0.05
validation batch 101 / 168, loss: 0.02
validation cost time: 53.6688s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_0.55/epoch_10.params
epoch: 10, learning rate 0.001000
epoch: 10, train time every whole data:182.59s
epoch: 10, total time:2593.36s
validation batch 1 / 168, loss: 0.09
validation batch 101 / 168, loss: 0.04
validation cost time: 53.4561s
epoch: 11, learning rate 0.001000
epoch: 11, train time every whole data:182.32s
epoch: 11, total time:2829.14s
validation batch 1 / 168, loss: 0.09
validation batch 101 / 168, loss: 0.03
validation cost time: 53.5152s
epoch: 12, learning rate 0.001000
epoch: 12, train time every whole data:182.29s
epoch: 12, total time:3064.95s
validation batch 1 / 168, loss: 0.07
validation batch 101 / 168, loss: 0.02
validation cost time: 53.4955s
epoch: 13, learning rate 0.001000
epoch: 13, train time every whole data:182.66s
epoch: 13, total time:3301.11s
validation batch 1 / 168, loss: 0.06
validation batch 101 / 168, loss: 0.02
validation cost time: 53.6894s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_0.55/epoch_14.params
epoch: 14, learning rate 0.001000
epoch: 14, train time every whole data:182.00s
epoch: 14, total time:3536.92s
validation batch 1 / 168, loss: 0.07
validation batch 101 / 168, loss: 0.03
validation cost time: 53.3298s
epoch: 15, learning rate 0.001000
epoch: 15, train time every whole data:182.35s
epoch: 15, total time:3772.61s
validation batch 1 / 168, loss: 0.06
validation batch 101 / 168, loss: 0.03
validation cost time: 53.7342s
epoch: 16, learning rate 0.001000
epoch: 16, train time every whole data:182.68s
epoch: 16, total time:4009.03s
validation batch 1 / 168, loss: 0.06
validation batch 101 / 168, loss: 0.03
validation cost time: 53.7932s
epoch: 17, learning rate 0.001000
epoch: 17, train time every whole data:182.26s
epoch: 17, total time:4245.08s
validation batch 1 / 168, loss: 0.08
validation batch 101 / 168, loss: 0.04
validation cost time: 53.5054s
epoch: 18, learning rate 0.001000
epoch: 18, train time every whole data:182.16s
epoch: 18, total time:4480.75s
validation batch 1 / 168, loss: 0.09
validation batch 101 / 168, loss: 0.04
validation cost time: 53.5816s
epoch: 19, learning rate 0.001000
epoch: 19, train time every whole data:182.65s
epoch: 19, total time:4716.99s
validation batch 1 / 168, loss: 0.08
validation batch 101 / 168, loss: 0.02
validation cost time: 53.7756s
epoch: 20, learning rate 0.001000
epoch: 20, train time every whole data:182.64s
epoch: 20, total time:4953.40s
validation batch 1 / 168, loss: 0.08
validation batch 101 / 168, loss: 0.02
validation cost time: 53.4467s
epoch: 21, learning rate 0.001000
epoch: 21, train time every whole data:182.10s
epoch: 21, total time:5188.95s
validation batch 1 / 168, loss: 0.09
validation batch 101 / 168, loss: 0.04
validation cost time: 53.5637s
epoch: 22, learning rate 0.001000
epoch: 22, train time every whole data:182.01s
epoch: 22, total time:5424.53s
validation batch 1 / 168, loss: 0.09
validation batch 101 / 168, loss: 0.02
validation cost time: 53.5206s
epoch: 23, learning rate 0.001000
epoch: 23, train time every whole data:182.59s
epoch: 23, total time:5660.65s
validation batch 1 / 168, loss: 0.08
validation batch 101 / 168, loss: 0.02
validation cost time: 53.6045s
epoch: 24, learning rate 0.001000
epoch: 24, train time every whole data:182.67s
epoch: 24, total time:5896.93s
validation batch 1 / 168, loss: 0.08
validation batch 101 / 168, loss: 0.02
validation cost time: 53.6276s
epoch: 25, learning rate 0.001000
epoch: 25, train time every whole data:182.69s
epoch: 25, total time:6133.25s
validation batch 1 / 168, loss: 0.08
validation batch 101 / 168, loss: 0.02
validation cost time: 53.5514s
epoch: 26, learning rate 0.001000
epoch: 26, train time every whole data:182.49s
epoch: 26, total time:6369.29s
validation batch 1 / 168, loss: 0.06
validation batch 101 / 168, loss: 0.02
validation cost time: 53.3772s
epoch: 27, learning rate 0.001000
epoch: 27, train time every whole data:181.89s
epoch: 27, total time:6604.56s
validation batch 1 / 168, loss: 0.07
validation batch 101 / 168, loss: 0.02
validation cost time: 53.5228s
epoch: 28, learning rate 0.001000
epoch: 28, train time every whole data:182.54s
epoch: 28, total time:6840.63s
validation batch 1 / 168, loss: 0.08
validation batch 101 / 168, loss: 0.02
validation cost time: 53.4600s
epoch: 29, learning rate 0.001000
epoch: 29, train time every whole data:182.68s
epoch: 29, total time:7076.77s
validation batch 1 / 168, loss: 0.07
validation batch 101 / 168, loss: 0.02
validation cost time: 53.6107s
epoch: 30, learning rate 0.001000
epoch: 30, train time every whole data:182.47s
epoch: 30, total time:7312.86s
validation batch 1 / 168, loss: 0.08
validation batch 101 / 168, loss: 0.02
validation cost time: 53.6562s
epoch: 31, learning rate 0.001000
epoch: 31, train time every whole data:182.56s
epoch: 31, total time:7549.08s
validation batch 1 / 168, loss: 0.09
validation batch 101 / 168, loss: 0.02
validation cost time: 53.6981s
epoch: 32, learning rate 0.001000
epoch: 32, train time every whole data:182.71s
epoch: 32, total time:7785.50s
validation batch 1 / 168, loss: 0.09
validation batch 101 / 168, loss: 0.02
validation cost time: 53.8829s
epoch: 33, learning rate 0.001000
epoch: 33, train time every whole data:182.71s
epoch: 33, total time:8022.09s
validation batch 1 / 168, loss: 0.08
validation batch 101 / 168, loss: 0.02
validation cost time: 53.5754s
epoch: 34, learning rate 0.001000
epoch: 34, train time every whole data:182.68s
epoch: 34, total time:8258.35s
validation batch 1 / 168, loss: 0.08
validation batch 101 / 168, loss: 0.02
validation cost time: 53.7885s
epoch: 35, learning rate 0.001000
epoch: 35, train time every whole data:182.66s
epoch: 35, total time:8494.80s
validation batch 1 / 168, loss: 0.10
validation batch 101 / 168, loss: 0.02
validation cost time: 53.6539s
epoch: 36, learning rate 0.001000
epoch: 36, train time every whole data:182.61s
epoch: 36, total time:8731.07s
validation batch 1 / 168, loss: 0.10
validation batch 101 / 168, loss: 0.02
validation cost time: 53.6899s
epoch: 37, learning rate 0.001000
epoch: 37, train time every whole data:182.60s
epoch: 37, total time:8967.36s
validation batch 1 / 168, loss: 0.09
validation batch 101 / 168, loss: 0.02
validation cost time: 53.6809s
epoch: 38, learning rate 0.001000
epoch: 38, train time every whole data:182.65s
epoch: 38, total time:9203.69s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 53.6334s
epoch: 39, learning rate 0.001000
epoch: 39, train time every whole data:182.64s
epoch: 39, total time:9439.97s
validation batch 1 / 168, loss: 0.08
validation batch 101 / 168, loss: 0.02
validation cost time: 53.5562s
epoch: 40, learning rate 0.001000
epoch: 40, train time every whole data:182.56s
epoch: 40, total time:9676.10s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 53.6164s
epoch: 41, learning rate 0.001000
epoch: 41, train time every whole data:182.65s
epoch: 41, total time:9912.37s
validation batch 1 / 168, loss: 0.09
validation batch 101 / 168, loss: 0.02
validation cost time: 53.7730s
epoch: 42, learning rate 0.001000
epoch: 42, train time every whole data:182.65s
epoch: 42, total time:10148.79s
validation batch 1 / 168, loss: 0.09
validation batch 101 / 168, loss: 0.02
validation cost time: 53.8130s
epoch: 43, learning rate 0.001000
epoch: 43, train time every whole data:182.60s
epoch: 43, total time:10385.21s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 53.4952s
epoch: 44, learning rate 0.001000
epoch: 44, train time every whole data:182.44s
epoch: 44, total time:10621.15s
validation batch 1 / 168, loss: 0.10
validation batch 101 / 168, loss: 0.02
validation cost time: 53.5508s
epoch: 45, learning rate 0.001000
epoch: 45, train time every whole data:182.30s
epoch: 45, total time:10857.01s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 53.5185s
epoch: 46, learning rate 0.001000
epoch: 46, train time every whole data:182.55s
epoch: 46, total time:11093.08s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 53.6196s
epoch: 47, learning rate 0.001000
epoch: 47, train time every whole data:182.63s
epoch: 47, total time:11329.34s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 53.4727s
epoch: 48, learning rate 0.001000
epoch: 48, train time every whole data:182.39s
epoch: 48, total time:11565.21s
validation batch 1 / 168, loss: 0.09
validation batch 101 / 168, loss: 0.02
validation cost time: 53.5986s
epoch: 49, learning rate 0.001000
epoch: 49, train time every whole data:182.62s
epoch: 49, total time:11801.43s
validation batch 1 / 168, loss: 0.10
validation batch 101 / 168, loss: 0.02
validation cost time: 53.6680s
epoch: 50, learning rate 0.001000
epoch: 50, train time every whole data:182.68s
epoch: 50, total time:12037.79s
validation batch 1 / 168, loss: 0.10
validation batch 101 / 168, loss: 0.02
validation cost time: 53.7052s
epoch: 51, learning rate 0.001000
epoch: 51, train time every whole data:182.67s
epoch: 51, total time:12274.17s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 53.6370s
epoch: 52, learning rate 0.001000
epoch: 52, train time every whole data:182.68s
epoch: 52, total time:12510.49s
validation batch 1 / 168, loss: 0.09
validation batch 101 / 168, loss: 0.02
validation cost time: 53.8080s
epoch: 53, learning rate 0.001000
epoch: 53, train time every whole data:182.66s
epoch: 53, total time:12746.97s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 53.5778s
epoch: 54, learning rate 0.001000
epoch: 54, train time every whole data:182.67s
epoch: 54, total time:12983.22s
validation batch 1 / 168, loss: 0.14
validation batch 101 / 168, loss: 0.02
validation cost time: 53.5810s
epoch: 55, learning rate 0.001000
epoch: 55, train time every whole data:182.66s
epoch: 55, total time:13219.47s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 53.6433s
epoch: 56, learning rate 0.001000
epoch: 56, train time every whole data:182.65s
epoch: 56, total time:13455.77s
validation batch 1 / 168, loss: 0.10
validation batch 101 / 168, loss: 0.02
validation cost time: 53.7726s
epoch: 57, learning rate 0.001000
epoch: 57, train time every whole data:182.66s
epoch: 57, total time:13692.21s
validation batch 1 / 168, loss: 0.10
validation batch 101 / 168, loss: 0.02
validation cost time: 53.7736s
epoch: 58, learning rate 0.001000
epoch: 58, train time every whole data:182.60s
epoch: 58, total time:13928.59s
validation batch 1 / 168, loss: 0.14
validation batch 101 / 168, loss: 0.02
validation cost time: 53.6755s
epoch: 59, learning rate 0.001000
epoch: 59, train time every whole data:182.45s
epoch: 59, total time:14164.72s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 53.6424s
epoch: 60, learning rate 0.001000
epoch: 60, train time every whole data:182.54s
epoch: 60, total time:14400.90s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 53.5049s
epoch: 61, learning rate 0.001000
epoch: 61, train time every whole data:182.57s
epoch: 61, total time:14636.99s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 53.4805s
epoch: 62, learning rate 0.001000
epoch: 62, train time every whole data:182.59s
epoch: 62, total time:14873.06s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 53.8285s
epoch: 63, learning rate 0.001000
epoch: 63, train time every whole data:182.72s
epoch: 63, total time:15109.62s
validation batch 1 / 168, loss: 0.09
validation batch 101 / 168, loss: 0.02
validation cost time: 53.7065s
epoch: 64, learning rate 0.001000
epoch: 64, train time every whole data:182.69s
epoch: 64, total time:15346.01s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 53.7914s
epoch: 65, learning rate 0.001000
epoch: 65, train time every whole data:182.48s
epoch: 65, total time:15582.29s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 53.5323s
epoch: 66, learning rate 0.001000
epoch: 66, train time every whole data:182.34s
epoch: 66, total time:15818.18s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 53.5997s
epoch: 67, learning rate 0.001000
epoch: 67, train time every whole data:182.36s
epoch: 67, total time:16054.14s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 53.6821s
epoch: 68, learning rate 0.001000
epoch: 68, train time every whole data:182.35s
epoch: 68, total time:16290.18s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 53.5629s
epoch: 69, learning rate 0.001000
epoch: 69, train time every whole data:182.31s
epoch: 69, total time:16526.05s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 53.6299s
epoch: 70, learning rate 0.001000
epoch: 70, train time every whole data:182.29s
epoch: 70, total time:16761.98s
validation batch 1 / 168, loss: 0.10
validation batch 101 / 168, loss: 0.02
validation cost time: 53.6397s
epoch: 71, learning rate 0.001000
epoch: 71, train time every whole data:182.29s
epoch: 71, total time:16997.92s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 53.5617s
epoch: 72, learning rate 0.001000
epoch: 72, train time every whole data:182.80s
epoch: 72, total time:17234.28s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 53.6471s
epoch: 73, learning rate 0.001000
epoch: 73, train time every whole data:182.69s
epoch: 73, total time:17470.62s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 53.5067s
epoch: 74, learning rate 0.001000
epoch: 74, train time every whole data:182.57s
epoch: 74, total time:17706.70s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 53.6840s
epoch: 75, learning rate 0.001000
epoch: 75, train time every whole data:182.71s
epoch: 75, total time:17943.10s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 53.7815s
epoch: 76, learning rate 0.001000
epoch: 76, train time every whole data:182.61s
epoch: 76, total time:18179.49s
validation batch 1 / 168, loss: 0.15
validation batch 101 / 168, loss: 0.02
validation cost time: 53.6512s
epoch: 77, learning rate 0.001000
epoch: 77, train time every whole data:182.42s
epoch: 77, total time:18415.57s
validation batch 1 / 168, loss: 0.14
validation batch 101 / 168, loss: 0.02
validation cost time: 53.6278s
epoch: 78, learning rate 0.001000
epoch: 78, train time every whole data:182.74s
epoch: 78, total time:18651.94s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 53.6222s
epoch: 79, learning rate 0.001000
epoch: 79, train time every whole data:182.74s
epoch: 79, total time:18888.31s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 53.7465s
epoch: 80, learning rate 0.001000
epoch: 80, train time every whole data:182.68s
epoch: 80, total time:19124.74s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 53.8229s
epoch: 81, learning rate 0.001000
epoch: 81, train time every whole data:182.72s
epoch: 81, total time:19361.28s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 53.6075s
epoch: 82, learning rate 0.001000
epoch: 82, train time every whole data:182.63s
epoch: 82, total time:19597.52s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 53.6588s
epoch: 83, learning rate 0.001000
epoch: 83, train time every whole data:182.61s
epoch: 83, total time:19833.79s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 53.5359s
epoch: 84, learning rate 0.001000
epoch: 84, train time every whole data:182.77s
epoch: 84, total time:20070.10s
validation batch 1 / 168, loss: 0.15
validation batch 101 / 168, loss: 0.02
validation cost time: 53.7867s
epoch: 85, learning rate 0.001000
epoch: 85, train time every whole data:182.87s
epoch: 85, total time:20306.76s
validation batch 1 / 168, loss: 0.10
validation batch 101 / 168, loss: 0.02
validation cost time: 53.7076s
epoch: 86, learning rate 0.001000
epoch: 86, train time every whole data:182.68s
epoch: 86, total time:20543.15s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 53.6804s
epoch: 87, learning rate 0.001000
epoch: 87, train time every whole data:182.80s
epoch: 87, total time:20779.63s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 53.8250s
epoch: 88, learning rate 0.001000
epoch: 88, train time every whole data:182.84s
epoch: 88, total time:21016.30s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 53.6262s
epoch: 89, learning rate 0.001000
epoch: 89, train time every whole data:182.66s
epoch: 89, total time:21252.59s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 53.5917s
epoch: 90, learning rate 0.001000
epoch: 90, train time every whole data:182.78s
epoch: 90, total time:21488.96s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 53.6468s
epoch: 91, learning rate 0.001000
epoch: 91, train time every whole data:182.82s
epoch: 91, total time:21725.43s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 53.4876s
epoch: 92, learning rate 0.001000
epoch: 92, train time every whole data:182.60s
epoch: 92, total time:21961.53s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 53.4763s
epoch: 93, learning rate 0.001000
epoch: 93, train time every whole data:182.65s
epoch: 93, total time:22197.66s
validation batch 1 / 168, loss: 0.14
validation batch 101 / 168, loss: 0.02
validation cost time: 53.6613s
epoch: 94, learning rate 0.001000
epoch: 94, train time every whole data:182.65s
epoch: 94, total time:22433.98s
validation batch 1 / 168, loss: 0.16
validation batch 101 / 168, loss: 0.02
validation cost time: 53.5417s
epoch: 95, learning rate 0.001000
epoch: 95, train time every whole data:182.60s
epoch: 95, total time:22670.12s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 53.5922s
epoch: 96, learning rate 0.001000
epoch: 96, train time every whole data:182.67s
epoch: 96, total time:22906.39s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 53.5944s
epoch: 97, learning rate 0.001000
epoch: 97, train time every whole data:182.62s
epoch: 97, total time:23142.62s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 53.6157s
epoch: 98, learning rate 0.001000
epoch: 98, train time every whole data:182.49s
epoch: 98, total time:23378.72s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 53.4760s
epoch: 99, learning rate 0.001000
epoch: 99, train time every whole data:182.66s
epoch: 99, total time:23614.86s
best epoch: 14
apply the best val model on the test data set ...
load weight from: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_0.55/epoch_14.params
predicting testing set batch 1 / 168, time: 0.32s
predicting testing set batch 101 / 168, time: 32.24s
test time on whole data:53.66s
input: (672, 250, 12, 2)
prediction: (672, 250, 12, 2)
data_target_tensor: (672, 250, 12, 2)
current epoch: 14, predict 0 points
MAE: 1.71
RMSE: 2.86
MAPE: 53.74
PCC: 0.80
current epoch: 14, predict 1 points
MAE: 1.83
RMSE: 3.07
MAPE: 59.05
PCC: 0.76
current epoch: 14, predict 2 points
MAE: 1.94
RMSE: 3.28
MAPE: 63.94
PCC: 0.72
current epoch: 14, predict 3 points
MAE: 2.06
RMSE: 3.55
MAPE: 68.85
PCC: 0.67
current epoch: 14, predict 4 points
MAE: 2.21
RMSE: 3.85
MAPE: 73.63
PCC: 0.62
current epoch: 14, predict 5 points
MAE: 2.34
RMSE: 4.12
MAPE: 78.23
PCC: 0.58
current epoch: 14, predict 6 points
MAE: 2.45
RMSE: 4.33
MAPE: 82.08
PCC: 0.55
current epoch: 14, predict 7 points
MAE: 2.51
RMSE: 4.39
MAPE: 83.60
PCC: 0.53
current epoch: 14, predict 8 points
MAE: 2.52
RMSE: 4.38
MAPE: 83.10
PCC: 0.52
current epoch: 14, predict 9 points
MAE: 2.51
RMSE: 4.35
MAPE: 82.17
PCC: 0.53
current epoch: 14, predict 10 points
MAE: 2.46
RMSE: 4.24
MAPE: 78.84
PCC: 0.54
current epoch: 14, predict 11 points
MAE: 2.40
RMSE: 4.09
MAPE: 75.19
PCC: 0.55
all MAE: 2.24
all RMSE: 3.91
all MAPE: 73.54
all PCC: 0.55
1.7076399472892463 2.8632084553034587 53.743017658181046 0.802566573302257 
1.8293984797070069 3.0707571511350387 59.047647424229474 0.758962919205219 
1.937698018169474 3.2796478506132276 63.93873262502338 0.7202427423805052 
2.0647097458792407 3.5468101418080633 68.84544980756459 0.6736596286042714 
2.20723906336982 3.8469102812700786 73.6256552883246 0.6229258056660429 
2.3433739434569363 4.121800201381473 78.23453553816266 0.5772738753683698 
2.4520737045648553 4.325989866088186 82.08283976960654 0.545054086931633 
2.5059358914930905 4.392384531459033 83.59590658082554 0.5295443811519138 
2.5150919558670193 4.382405859274027 83.1010657198147 0.5248959831215726 
2.512659815184772 4.3547393632424525 82.17152100758408 0.5289000583716393 
2.458967379878674 4.237081738061432 78.8383421504246 0.5383999767010375 
2.4003934214597655 4.0888800539136865 75.19244227581108 0.5478268706298167 
2.244598447193325 3.911518118958205 73.53532791780447 0.5478268706298167 
fine tune the model ... 
epoch: 100, learning rate 0.000100
epoch: 100, train time every whole data:401.28s
epoch: 100, total time:24080.65s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.5456s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_0.55/epoch_100.params
epoch: 101, learning rate 0.000100
epoch: 101, train time every whole data:401.30s
epoch: 101, total time:24535.67s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.5421s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_0.55/epoch_101.params
epoch: 102, learning rate 0.000100
epoch: 102, train time every whole data:401.81s
epoch: 102, total time:24991.15s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.4646s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_0.55/epoch_102.params
epoch: 103, learning rate 0.000100
epoch: 103, train time every whole data:401.96s
epoch: 103, total time:25446.71s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.6575s
epoch: 104, learning rate 0.000100
epoch: 104, train time every whole data:402.17s
epoch: 104, total time:25902.55s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.5264s
epoch: 105, learning rate 0.000100
epoch: 105, train time every whole data:402.03s
epoch: 105, total time:26358.11s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.7236s
epoch: 106, learning rate 0.000100
epoch: 106, train time every whole data:401.71s
epoch: 106, total time:26813.55s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.7174s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_0.55/epoch_106.params
epoch: 107, learning rate 0.000100
epoch: 107, train time every whole data:402.05s
epoch: 107, total time:27269.48s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.7843s
epoch: 108, learning rate 0.000100
epoch: 108, train time every whole data:399.36s
epoch: 108, total time:27722.63s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.7582s
epoch: 109, learning rate 0.000100
epoch: 109, train time every whole data:402.07s
epoch: 109, total time:28178.46s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.5663s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_0.55/epoch_109.params
epoch: 110, learning rate 0.000100
epoch: 110, train time every whole data:402.17s
epoch: 110, total time:28634.35s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.6658s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_0.55/epoch_110.params
epoch: 111, learning rate 0.000100
epoch: 111, train time every whole data:402.54s
epoch: 111, total time:29090.71s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.5911s
epoch: 112, learning rate 0.000100
epoch: 112, train time every whole data:402.27s
epoch: 112, total time:29546.58s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.8284s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_0.55/epoch_112.params
epoch: 113, learning rate 0.000100
epoch: 113, train time every whole data:402.38s
epoch: 113, total time:30002.95s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.6284s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_0.55/epoch_113.params
epoch: 114, learning rate 0.000100
epoch: 114, train time every whole data:402.29s
epoch: 114, total time:30459.02s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.7396s
epoch: 115, learning rate 0.000100
epoch: 115, train time every whole data:402.07s
epoch: 115, total time:30914.83s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.6939s
epoch: 116, learning rate 0.000100
epoch: 116, train time every whole data:402.55s
epoch: 116, total time:31371.08s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.8546s
epoch: 117, learning rate 0.000100
epoch: 117, train time every whole data:402.24s
epoch: 117, total time:31827.18s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.8088s
epoch: 118, learning rate 0.000100
epoch: 118, train time every whole data:402.11s
epoch: 118, total time:32283.10s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.7797s
epoch: 119, learning rate 0.000100
epoch: 119, train time every whole data:402.32s
epoch: 119, total time:32739.21s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.6467s
epoch: 120, learning rate 0.000100
epoch: 120, train time every whole data:402.36s
epoch: 120, total time:33195.22s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.8418s
epoch: 121, learning rate 0.000100
epoch: 121, train time every whole data:402.00s
epoch: 121, total time:33651.06s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.7264s
epoch: 122, learning rate 0.000100
epoch: 122, train time every whole data:402.33s
epoch: 122, total time:34107.12s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.5251s
epoch: 123, learning rate 0.000100
epoch: 123, train time every whole data:401.83s
epoch: 123, total time:34562.48s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.6579s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_0.55/epoch_123.params
epoch: 124, learning rate 0.000100
epoch: 124, train time every whole data:401.63s
epoch: 124, total time:35017.90s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.6847s
epoch: 125, learning rate 0.000100
epoch: 125, train time every whole data:401.50s
epoch: 125, total time:35473.09s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.6048s
epoch: 126, learning rate 0.000100
epoch: 126, train time every whole data:401.60s
epoch: 126, total time:35928.30s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.4460s
epoch: 127, learning rate 0.000100
epoch: 127, train time every whole data:401.43s
epoch: 127, total time:36383.18s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.5983s
epoch: 128, learning rate 0.000100
epoch: 128, train time every whole data:401.47s
epoch: 128, total time:36838.26s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.7557s
epoch: 129, learning rate 0.000100
epoch: 129, train time every whole data:401.46s
epoch: 129, total time:37293.48s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.6665s
epoch: 130, learning rate 0.000100
epoch: 130, train time every whole data:401.40s
epoch: 130, total time:37748.55s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.5980s
epoch: 131, learning rate 0.000100
epoch: 131, train time every whole data:401.50s
epoch: 131, total time:38203.65s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.6563s
epoch: 132, learning rate 0.000100
epoch: 132, train time every whole data:401.44s
epoch: 132, total time:38658.75s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.3963s
epoch: 133, learning rate 0.000100
epoch: 133, train time every whole data:392.10s
epoch: 133, total time:39104.25s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 52.9395s
epoch: 134, learning rate 0.000100
epoch: 134, train time every whole data:391.31s
epoch: 134, total time:39548.51s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 52.8988s
epoch: 135, learning rate 0.000100
epoch: 135, train time every whole data:391.21s
epoch: 135, total time:39992.62s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.2044s
epoch: 136, learning rate 0.000100
epoch: 136, train time every whole data:391.56s
epoch: 136, total time:40437.39s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 52.9798s
epoch: 137, learning rate 0.000100
epoch: 137, train time every whole data:391.32s
epoch: 137, total time:40881.69s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.0349s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_0.55/epoch_137.params
epoch: 138, learning rate 0.000100
epoch: 138, train time every whole data:391.80s
epoch: 138, total time:41326.65s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 52.9471s
epoch: 139, learning rate 0.000100
epoch: 139, train time every whole data:391.49s
epoch: 139, total time:41771.09s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.2032s
epoch: 140, learning rate 0.000100
epoch: 140, train time every whole data:391.76s
epoch: 140, total time:42216.06s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 52.9172s
epoch: 141, learning rate 0.000100
epoch: 141, train time every whole data:391.51s
epoch: 141, total time:42660.49s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.0773s
epoch: 142, learning rate 0.000100
epoch: 142, train time every whole data:392.06s
epoch: 142, total time:43105.63s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.1721s
epoch: 143, learning rate 0.000100
epoch: 143, train time every whole data:392.25s
epoch: 143, total time:43551.06s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.1175s
epoch: 144, learning rate 0.000100
epoch: 144, train time every whole data:391.94s
epoch: 144, total time:43996.12s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.0455s
epoch: 145, learning rate 0.000100
epoch: 145, train time every whole data:392.92s
epoch: 145, total time:44442.09s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.2788s
epoch: 146, learning rate 0.000100
epoch: 146, train time every whole data:392.44s
epoch: 146, total time:44887.81s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.2300s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_0.55/epoch_146.params
epoch: 147, learning rate 0.000100
epoch: 147, train time every whole data:392.56s
epoch: 147, total time:45333.75s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.3111s
epoch: 148, learning rate 0.000100
epoch: 148, train time every whole data:392.24s
epoch: 148, total time:45779.31s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.3656s
epoch: 149, learning rate 0.000100
epoch: 149, train time every whole data:392.67s
epoch: 149, total time:46225.34s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.0733s
best epoch: 146
apply the best val model on the test data set ...
load weight from: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_0.55/epoch_146.params
predicting testing set batch 1 / 168, time: 0.31s
predicting testing set batch 101 / 168, time: 31.93s
test time on whole data:53.11s
input: (672, 250, 12, 2)
prediction: (672, 250, 12, 2)
data_target_tensor: (672, 250, 12, 2)
current epoch: 146, predict 0 points
MAE: 1.49
RMSE: 2.42
MAPE: 55.33
PCC: 0.85
current epoch: 146, predict 1 points
MAE: 1.55
RMSE: 2.53
MAPE: 56.88
PCC: 0.84
current epoch: 146, predict 2 points
MAE: 1.58
RMSE: 2.61
MAPE: 57.45
PCC: 0.83
current epoch: 146, predict 3 points
MAE: 1.61
RMSE: 2.67
MAPE: 57.65
PCC: 0.82
current epoch: 146, predict 4 points
MAE: 1.65
RMSE: 2.76
MAPE: 57.89
PCC: 0.82
current epoch: 146, predict 5 points
MAE: 1.69
RMSE: 2.85
MAPE: 58.35
PCC: 0.80
current epoch: 146, predict 6 points
MAE: 1.73
RMSE: 2.95
MAPE: 58.88
PCC: 0.79
current epoch: 146, predict 7 points
MAE: 1.76
RMSE: 3.01
MAPE: 59.31
PCC: 0.78
current epoch: 146, predict 8 points
MAE: 1.77
RMSE: 3.04
MAPE: 59.67
PCC: 0.77
current epoch: 146, predict 9 points
MAE: 1.78
RMSE: 3.03
MAPE: 60.15
PCC: 0.77
current epoch: 146, predict 10 points
MAE: 1.79
RMSE: 3.03
MAPE: 60.41
PCC: 0.77
current epoch: 146, predict 11 points
MAE: 1.81
RMSE: 3.07
MAPE: 60.79
PCC: 0.77
all MAE: 1.68
all RMSE: 2.84
all MAPE: 58.56
all PCC: 0.77
1.4945917380100915 2.4220780286471713 55.33423019249746 0.8537728328846085 
1.5484811944864867 2.5274226915661844 56.879294466800964 0.8405708985277693 
1.5803025732371248 2.606106261562376 57.45492476361365 0.8315076086644737 
1.6103034670402607 2.6727869989909205 57.64519193715469 0.8247199933568872 
1.6515603308442626 2.7565038477233257 57.89459781614207 0.8155482687661336 
1.6949339055287695 2.8507507222494173 58.34922110699182 0.8025812497218083 
1.7317292441943926 2.9468005165843545 58.88152057225171 0.7870846520141861 
1.7590048701077523 3.014795009428013 59.310048431561434 0.7758133714338535 
1.7711158872891573 3.0381331159872125 59.67347652916975 0.7713831933165728 
1.7789496487843848 3.0299817820055863 60.14782893293995 0.772603992783054 
1.7883032416449416 3.032872400512146 60.411073545783125 0.7731495590209675 
1.8085292367041998 3.0669870634755174 60.79412419389585 0.7686702054977318 
1.6848171114893187 2.838770128045769 58.564716332251244 0.7686702054977318 
