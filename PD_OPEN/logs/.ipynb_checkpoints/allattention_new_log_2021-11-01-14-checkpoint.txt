CUDA: True cuda:0
Read configuration file: configurations/bike.conf
total training epoch, fine tune epoch: 100 , 50
batch_size: 4
folder_dir: MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_new
load file: data/bike.npz
ori length: 3001 , percent: 1.0 , scale: 3001
train: torch.Size([3001, 250, 2, 12]) torch.Size([3001, 250, 2, 12]) torch.Size([3001, 250, 2, 12])
val: torch.Size([672, 250, 2, 12]) torch.Size([672, 250, 2, 12]) torch.Size([672, 250, 2, 12])
test: torch.Size([672, 250, 2, 12]) torch.Size([672, 250, 2, 12]) torch.Size([672, 250, 2, 12])
TemporalPositionalEncoding max_len: 12
h_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
en_lookup_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
EncoderDecoder(
  (encoder): Encoder(
    (layers): ModuleList(
      (0): EncoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn2): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (tcn2): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (1): EncoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn2): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (tcn2): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (2): EncoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn2): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (tcn2): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (3): EncoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn2): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (tcn2): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): Decoder(
    (layers): ModuleList(
      (0): DecoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (1): DecoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (2): DecoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (3): DecoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (decoder2): Decoder(
    (layers): ModuleList(
      (0): DecoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (1): DecoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (2): DecoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (3): DecoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (src_embed): Sequential(
    (0): Linear(in_features=1, out_features=64, bias=True)
    (1): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (2): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(250, 64)
    )
  )
  (src_embed2): Sequential(
    (0): Linear(in_features=1, out_features=64, bias=True)
    (1): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (2): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(250, 64)
    )
  )
  (trg_embed): Sequential(
    (0): Linear(in_features=1, out_features=64, bias=True)
    (1): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (2): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(250, 64)
    )
  )
  (trg_embed2): Sequential(
    (0): Linear(in_features=1, out_features=64, bias=True)
    (1): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (2): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(250, 64)
    )
  )
  (prediction_generator): Linear(in_features=64, out_features=1, bias=True)
  (prediction_generator2): Linear(in_features=64, out_features=1, bias=True)
)
delete the old one and create params directory experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_new
Net's state_dict:
encoder.layers.0.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.linears.2.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.linears.2.bias 	 torch.Size([64])
encoder.layers.0.self_attn.linears.3.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.linears.3.bias 	 torch.Size([64])
encoder.layers.0.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.0.feed_forward_gcn2.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.0.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.tcn.filter_convs.bias 	 torch.Size([64])
encoder.layers.0.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.tcn.gate_convs.bias 	 torch.Size([64])
encoder.layers.0.tcn2.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.tcn2.filter_convs.bias 	 torch.Size([64])
encoder.layers.0.tcn2.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.tcn2.gate_convs.bias 	 torch.Size([64])
encoder.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.2.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.2.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.3.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.3.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.4.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.4.norm.bias 	 torch.Size([64])
encoder.layers.1.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.linears.2.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.linears.2.bias 	 torch.Size([64])
encoder.layers.1.self_attn.linears.3.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.linears.3.bias 	 torch.Size([64])
encoder.layers.1.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.1.feed_forward_gcn2.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.1.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.tcn.filter_convs.bias 	 torch.Size([64])
encoder.layers.1.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.tcn.gate_convs.bias 	 torch.Size([64])
encoder.layers.1.tcn2.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.tcn2.filter_convs.bias 	 torch.Size([64])
encoder.layers.1.tcn2.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.tcn2.gate_convs.bias 	 torch.Size([64])
encoder.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.2.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.2.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.3.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.3.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.4.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.4.norm.bias 	 torch.Size([64])
encoder.layers.2.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.linears.2.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.linears.2.bias 	 torch.Size([64])
encoder.layers.2.self_attn.linears.3.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.linears.3.bias 	 torch.Size([64])
encoder.layers.2.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.2.feed_forward_gcn2.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.2.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.tcn.filter_convs.bias 	 torch.Size([64])
encoder.layers.2.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.tcn.gate_convs.bias 	 torch.Size([64])
encoder.layers.2.tcn2.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.tcn2.filter_convs.bias 	 torch.Size([64])
encoder.layers.2.tcn2.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.tcn2.gate_convs.bias 	 torch.Size([64])
encoder.layers.2.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.2.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.2.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.3.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.3.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.4.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.4.norm.bias 	 torch.Size([64])
encoder.layers.3.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.3.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.3.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.3.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.3.self_attn.linears.2.weight 	 torch.Size([64, 64])
encoder.layers.3.self_attn.linears.2.bias 	 torch.Size([64])
encoder.layers.3.self_attn.linears.3.weight 	 torch.Size([64, 64])
encoder.layers.3.self_attn.linears.3.bias 	 torch.Size([64])
encoder.layers.3.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.3.feed_forward_gcn2.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.3.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.3.tcn.filter_convs.bias 	 torch.Size([64])
encoder.layers.3.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.3.tcn.gate_convs.bias 	 torch.Size([64])
encoder.layers.3.tcn2.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.3.tcn2.filter_convs.bias 	 torch.Size([64])
encoder.layers.3.tcn2.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.3.tcn2.gate_convs.bias 	 torch.Size([64])
encoder.layers.3.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.3.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.3.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.3.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.3.sublayer.2.norm.weight 	 torch.Size([64])
encoder.layers.3.sublayer.2.norm.bias 	 torch.Size([64])
encoder.layers.3.sublayer.3.norm.weight 	 torch.Size([64])
encoder.layers.3.sublayer.3.norm.bias 	 torch.Size([64])
encoder.layers.3.sublayer.4.norm.weight 	 torch.Size([64])
encoder.layers.3.sublayer.4.norm.bias 	 torch.Size([64])
encoder.norm.weight 	 torch.Size([64])
encoder.norm.bias 	 torch.Size([64])
encoder.norm2.weight 	 torch.Size([64])
encoder.norm2.bias 	 torch.Size([64])
decoder.layers.0.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.0.self_attn.linears.2.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.linears.2.bias 	 torch.Size([64])
decoder.layers.0.self_attn.linears.3.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.linears.3.bias 	 torch.Size([64])
decoder.layers.0.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.0.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.linears.2.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.linears.2.bias 	 torch.Size([64])
decoder.layers.0.src_attn.linears.3.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.linears.3.bias 	 torch.Size([64])
decoder.layers.0.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.0.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.tcn.filter_convs.bias 	 torch.Size([64])
decoder.layers.0.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.tcn.gate_convs.bias 	 torch.Size([64])
decoder.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.3.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.3.norm.bias 	 torch.Size([64])
decoder.layers.1.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.1.self_attn.linears.2.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.linears.2.bias 	 torch.Size([64])
decoder.layers.1.self_attn.linears.3.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.linears.3.bias 	 torch.Size([64])
decoder.layers.1.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.1.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.linears.2.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.linears.2.bias 	 torch.Size([64])
decoder.layers.1.src_attn.linears.3.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.linears.3.bias 	 torch.Size([64])
decoder.layers.1.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.1.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.tcn.filter_convs.bias 	 torch.Size([64])
decoder.layers.1.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.tcn.gate_convs.bias 	 torch.Size([64])
decoder.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.3.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.3.norm.bias 	 torch.Size([64])
decoder.layers.2.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.2.self_attn.linears.2.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.linears.2.bias 	 torch.Size([64])
decoder.layers.2.self_attn.linears.3.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.linears.3.bias 	 torch.Size([64])
decoder.layers.2.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.2.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.linears.2.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.linears.2.bias 	 torch.Size([64])
decoder.layers.2.src_attn.linears.3.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.linears.3.bias 	 torch.Size([64])
decoder.layers.2.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.2.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.tcn.filter_convs.bias 	 torch.Size([64])
decoder.layers.2.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.tcn.gate_convs.bias 	 torch.Size([64])
decoder.layers.2.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.3.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.3.norm.bias 	 torch.Size([64])
decoder.layers.3.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.3.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.3.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.3.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.3.self_attn.linears.2.weight 	 torch.Size([64, 64])
decoder.layers.3.self_attn.linears.2.bias 	 torch.Size([64])
decoder.layers.3.self_attn.linears.3.weight 	 torch.Size([64, 64])
decoder.layers.3.self_attn.linears.3.bias 	 torch.Size([64])
decoder.layers.3.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.3.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.3.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.3.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.3.src_attn.linears.2.weight 	 torch.Size([64, 64])
decoder.layers.3.src_attn.linears.2.bias 	 torch.Size([64])
decoder.layers.3.src_attn.linears.3.weight 	 torch.Size([64, 64])
decoder.layers.3.src_attn.linears.3.bias 	 torch.Size([64])
decoder.layers.3.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.3.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.3.tcn.filter_convs.bias 	 torch.Size([64])
decoder.layers.3.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.3.tcn.gate_convs.bias 	 torch.Size([64])
decoder.layers.3.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.3.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.3.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.3.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.3.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.3.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.3.sublayer.3.norm.weight 	 torch.Size([64])
decoder.layers.3.sublayer.3.norm.bias 	 torch.Size([64])
decoder.norm.weight 	 torch.Size([64])
decoder.norm.bias 	 torch.Size([64])
decoder2.layers.0.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder2.layers.0.self_attn.linears.0.bias 	 torch.Size([64])
decoder2.layers.0.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder2.layers.0.self_attn.linears.1.bias 	 torch.Size([64])
decoder2.layers.0.self_attn.linears.2.weight 	 torch.Size([64, 64])
decoder2.layers.0.self_attn.linears.2.bias 	 torch.Size([64])
decoder2.layers.0.self_attn.linears.3.weight 	 torch.Size([64, 64])
decoder2.layers.0.self_attn.linears.3.bias 	 torch.Size([64])
decoder2.layers.0.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder2.layers.0.src_attn.linears.0.bias 	 torch.Size([64])
decoder2.layers.0.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder2.layers.0.src_attn.linears.1.bias 	 torch.Size([64])
decoder2.layers.0.src_attn.linears.2.weight 	 torch.Size([64, 64])
decoder2.layers.0.src_attn.linears.2.bias 	 torch.Size([64])
decoder2.layers.0.src_attn.linears.3.weight 	 torch.Size([64, 64])
decoder2.layers.0.src_attn.linears.3.bias 	 torch.Size([64])
decoder2.layers.0.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder2.layers.0.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder2.layers.0.tcn.filter_convs.bias 	 torch.Size([64])
decoder2.layers.0.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder2.layers.0.tcn.gate_convs.bias 	 torch.Size([64])
decoder2.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
decoder2.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
decoder2.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
decoder2.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
decoder2.layers.0.sublayer.2.norm.weight 	 torch.Size([64])
decoder2.layers.0.sublayer.2.norm.bias 	 torch.Size([64])
decoder2.layers.0.sublayer.3.norm.weight 	 torch.Size([64])
decoder2.layers.0.sublayer.3.norm.bias 	 torch.Size([64])
decoder2.layers.1.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder2.layers.1.self_attn.linears.0.bias 	 torch.Size([64])
decoder2.layers.1.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder2.layers.1.self_attn.linears.1.bias 	 torch.Size([64])
decoder2.layers.1.self_attn.linears.2.weight 	 torch.Size([64, 64])
decoder2.layers.1.self_attn.linears.2.bias 	 torch.Size([64])
decoder2.layers.1.self_attn.linears.3.weight 	 torch.Size([64, 64])
decoder2.layers.1.self_attn.linears.3.bias 	 torch.Size([64])
decoder2.layers.1.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder2.layers.1.src_attn.linears.0.bias 	 torch.Size([64])
decoder2.layers.1.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder2.layers.1.src_attn.linears.1.bias 	 torch.Size([64])
decoder2.layers.1.src_attn.linears.2.weight 	 torch.Size([64, 64])
decoder2.layers.1.src_attn.linears.2.bias 	 torch.Size([64])
decoder2.layers.1.src_attn.linears.3.weight 	 torch.Size([64, 64])
decoder2.layers.1.src_attn.linears.3.bias 	 torch.Size([64])
decoder2.layers.1.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder2.layers.1.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder2.layers.1.tcn.filter_convs.bias 	 torch.Size([64])
decoder2.layers.1.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder2.layers.1.tcn.gate_convs.bias 	 torch.Size([64])
decoder2.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
decoder2.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
decoder2.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
decoder2.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
decoder2.layers.1.sublayer.2.norm.weight 	 torch.Size([64])
decoder2.layers.1.sublayer.2.norm.bias 	 torch.Size([64])
decoder2.layers.1.sublayer.3.norm.weight 	 torch.Size([64])
decoder2.layers.1.sublayer.3.norm.bias 	 torch.Size([64])
decoder2.layers.2.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder2.layers.2.self_attn.linears.0.bias 	 torch.Size([64])
decoder2.layers.2.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder2.layers.2.self_attn.linears.1.bias 	 torch.Size([64])
decoder2.layers.2.self_attn.linears.2.weight 	 torch.Size([64, 64])
decoder2.layers.2.self_attn.linears.2.bias 	 torch.Size([64])
decoder2.layers.2.self_attn.linears.3.weight 	 torch.Size([64, 64])
decoder2.layers.2.self_attn.linears.3.bias 	 torch.Size([64])
decoder2.layers.2.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder2.layers.2.src_attn.linears.0.bias 	 torch.Size([64])
decoder2.layers.2.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder2.layers.2.src_attn.linears.1.bias 	 torch.Size([64])
decoder2.layers.2.src_attn.linears.2.weight 	 torch.Size([64, 64])
decoder2.layers.2.src_attn.linears.2.bias 	 torch.Size([64])
decoder2.layers.2.src_attn.linears.3.weight 	 torch.Size([64, 64])
decoder2.layers.2.src_attn.linears.3.bias 	 torch.Size([64])
decoder2.layers.2.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder2.layers.2.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder2.layers.2.tcn.filter_convs.bias 	 torch.Size([64])
decoder2.layers.2.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder2.layers.2.tcn.gate_convs.bias 	 torch.Size([64])
decoder2.layers.2.sublayer.0.norm.weight 	 torch.Size([64])
decoder2.layers.2.sublayer.0.norm.bias 	 torch.Size([64])
decoder2.layers.2.sublayer.1.norm.weight 	 torch.Size([64])
decoder2.layers.2.sublayer.1.norm.bias 	 torch.Size([64])
decoder2.layers.2.sublayer.2.norm.weight 	 torch.Size([64])
decoder2.layers.2.sublayer.2.norm.bias 	 torch.Size([64])
decoder2.layers.2.sublayer.3.norm.weight 	 torch.Size([64])
decoder2.layers.2.sublayer.3.norm.bias 	 torch.Size([64])
decoder2.layers.3.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder2.layers.3.self_attn.linears.0.bias 	 torch.Size([64])
decoder2.layers.3.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder2.layers.3.self_attn.linears.1.bias 	 torch.Size([64])
decoder2.layers.3.self_attn.linears.2.weight 	 torch.Size([64, 64])
decoder2.layers.3.self_attn.linears.2.bias 	 torch.Size([64])
decoder2.layers.3.self_attn.linears.3.weight 	 torch.Size([64, 64])
decoder2.layers.3.self_attn.linears.3.bias 	 torch.Size([64])
decoder2.layers.3.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder2.layers.3.src_attn.linears.0.bias 	 torch.Size([64])
decoder2.layers.3.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder2.layers.3.src_attn.linears.1.bias 	 torch.Size([64])
decoder2.layers.3.src_attn.linears.2.weight 	 torch.Size([64, 64])
decoder2.layers.3.src_attn.linears.2.bias 	 torch.Size([64])
decoder2.layers.3.src_attn.linears.3.weight 	 torch.Size([64, 64])
decoder2.layers.3.src_attn.linears.3.bias 	 torch.Size([64])
decoder2.layers.3.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder2.layers.3.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder2.layers.3.tcn.filter_convs.bias 	 torch.Size([64])
decoder2.layers.3.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder2.layers.3.tcn.gate_convs.bias 	 torch.Size([64])
decoder2.layers.3.sublayer.0.norm.weight 	 torch.Size([64])
decoder2.layers.3.sublayer.0.norm.bias 	 torch.Size([64])
decoder2.layers.3.sublayer.1.norm.weight 	 torch.Size([64])
decoder2.layers.3.sublayer.1.norm.bias 	 torch.Size([64])
decoder2.layers.3.sublayer.2.norm.weight 	 torch.Size([64])
decoder2.layers.3.sublayer.2.norm.bias 	 torch.Size([64])
decoder2.layers.3.sublayer.3.norm.weight 	 torch.Size([64])
decoder2.layers.3.sublayer.3.norm.bias 	 torch.Size([64])
decoder2.norm.weight 	 torch.Size([64])
decoder2.norm.bias 	 torch.Size([64])
src_embed.0.weight 	 torch.Size([64, 1])
src_embed.0.bias 	 torch.Size([64])
src_embed.1.pe 	 torch.Size([1, 1, 12, 64])
src_embed.2.embedding.weight 	 torch.Size([250, 64])
src_embed2.0.weight 	 torch.Size([64, 1])
src_embed2.0.bias 	 torch.Size([64])
src_embed2.1.pe 	 torch.Size([1, 1, 12, 64])
src_embed2.2.embedding.weight 	 torch.Size([250, 64])
trg_embed.0.weight 	 torch.Size([64, 1])
trg_embed.0.bias 	 torch.Size([64])
trg_embed.1.pe 	 torch.Size([1, 1, 12, 64])
trg_embed.2.embedding.weight 	 torch.Size([250, 64])
trg_embed2.0.weight 	 torch.Size([64, 1])
trg_embed2.0.bias 	 torch.Size([64])
trg_embed2.1.pe 	 torch.Size([1, 1, 12, 64])
trg_embed2.2.embedding.weight 	 torch.Size([250, 64])
prediction_generator.weight 	 torch.Size([1, 64])
prediction_generator.bias 	 torch.Size([1])
prediction_generator2.weight 	 torch.Size([1, 64])
prediction_generator2.bias 	 torch.Size([1])
Net's total params: 868482
Optimizer's state_dict:
state 	 {}
param_groups 	 [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367]}]
validation batch 1 / 168, loss: 2.35
validation batch 101 / 168, loss: 2.41
validation cost time: 51.9185s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_new/epoch_0.params
epoch: 0, learning rate 0.001000
epoch: 0, train time every whole data:180.39s
epoch: 0, total time:232.54s
validation batch 1 / 168, loss: 0.06
validation batch 101 / 168, loss: 0.02
validation cost time: 53.2278s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_new/epoch_1.params
epoch: 1, learning rate 0.001000
epoch: 1, train time every whole data:181.86s
epoch: 1, total time:467.79s
validation batch 1 / 168, loss: 0.05
validation batch 101 / 168, loss: 0.04
validation cost time: 53.2020s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_new/epoch_2.params
epoch: 2, learning rate 0.001000
epoch: 2, train time every whole data:181.57s
epoch: 2, total time:702.70s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.14
validation cost time: 53.3199s
epoch: 3, learning rate 0.001000
epoch: 3, train time every whole data:181.62s
epoch: 3, total time:937.64s
validation batch 1 / 168, loss: 0.08
validation batch 101 / 168, loss: 0.04
validation cost time: 53.3110s
epoch: 4, learning rate 0.001000
epoch: 4, train time every whole data:181.90s
epoch: 4, total time:1172.85s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.10
validation cost time: 53.3127s
epoch: 5, learning rate 0.001000
epoch: 5, train time every whole data:181.88s
epoch: 5, total time:1408.05s
validation batch 1 / 168, loss: 0.08
validation batch 101 / 168, loss: 0.04
validation cost time: 53.0780s
epoch: 6, learning rate 0.001000
epoch: 6, train time every whole data:181.63s
epoch: 6, total time:1642.77s
validation batch 1 / 168, loss: 0.06
validation batch 101 / 168, loss: 0.02
validation cost time: 53.3007s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_new/epoch_7.params
epoch: 7, learning rate 0.001000
epoch: 7, train time every whole data:181.57s
epoch: 7, total time:1877.84s
validation batch 1 / 168, loss: 0.08
validation batch 101 / 168, loss: 0.02
validation cost time: 53.3093s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_new/epoch_8.params
epoch: 8, learning rate 0.001000
epoch: 8, train time every whole data:181.64s
epoch: 8, total time:2112.94s
validation batch 1 / 168, loss: 0.09
validation batch 101 / 168, loss: 0.02
validation cost time: 53.1185s
epoch: 9, learning rate 0.001000
epoch: 9, train time every whole data:181.63s
epoch: 9, total time:2347.70s
validation batch 1 / 168, loss: 0.16
validation batch 101 / 168, loss: 0.14
validation cost time: 53.1828s
epoch: 10, learning rate 0.001000
epoch: 10, train time every whole data:181.95s
epoch: 10, total time:2582.84s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 53.1352s
epoch: 11, learning rate 0.001000
epoch: 11, train time every whole data:181.94s
epoch: 11, total time:2817.91s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 53.3379s
epoch: 12, learning rate 0.001000
epoch: 12, train time every whole data:181.97s
epoch: 12, total time:3053.22s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 53.1516s
epoch: 13, learning rate 0.001000
epoch: 13, train time every whole data:181.96s
epoch: 13, total time:3288.33s
validation batch 1 / 168, loss: 0.16
validation batch 101 / 168, loss: 0.02
validation cost time: 53.2761s
epoch: 14, learning rate 0.001000
epoch: 14, train time every whole data:181.92s
epoch: 14, total time:3523.53s
validation batch 1 / 168, loss: 0.16
validation batch 101 / 168, loss: 0.02
validation cost time: 53.1949s
epoch: 15, learning rate 0.001000
epoch: 15, train time every whole data:181.91s
epoch: 15, total time:3758.65s
validation batch 1 / 168, loss: 0.08
validation batch 101 / 168, loss: 0.02
validation cost time: 53.2788s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_new/epoch_16.params
epoch: 16, learning rate 0.001000
epoch: 16, train time every whole data:181.96s
epoch: 16, total time:3994.09s
validation batch 1 / 168, loss: 0.14
validation batch 101 / 168, loss: 0.02
validation cost time: 53.1144s
epoch: 17, learning rate 0.001000
epoch: 17, train time every whole data:181.99s
epoch: 17, total time:4229.20s
validation batch 1 / 168, loss: 0.14
validation batch 101 / 168, loss: 0.02
validation cost time: 53.1908s
epoch: 18, learning rate 0.001000
epoch: 18, train time every whole data:181.94s
epoch: 18, total time:4464.34s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 53.0496s
epoch: 19, learning rate 0.001000
epoch: 19, train time every whole data:181.94s
epoch: 19, total time:4699.33s
validation batch 1 / 168, loss: 0.15
validation batch 101 / 168, loss: 0.03
validation cost time: 53.2153s
epoch: 20, learning rate 0.001000
epoch: 20, train time every whole data:181.98s
epoch: 20, total time:4934.54s
validation batch 1 / 168, loss: 0.10
validation batch 101 / 168, loss: 0.02
validation cost time: 53.2631s
epoch: 21, learning rate 0.001000
epoch: 21, train time every whole data:181.99s
epoch: 21, total time:5169.80s
validation batch 1 / 168, loss: 0.14
validation batch 101 / 168, loss: 0.02
validation cost time: 53.0732s
epoch: 22, learning rate 0.001000
epoch: 22, train time every whole data:182.02s
epoch: 22, total time:5404.89s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 53.3505s
epoch: 23, learning rate 0.001000
epoch: 23, train time every whole data:181.95s
epoch: 23, total time:5640.20s
validation batch 1 / 168, loss: 0.10
validation batch 101 / 168, loss: 0.02
validation cost time: 53.0986s
epoch: 24, learning rate 0.001000
epoch: 24, train time every whole data:181.95s
epoch: 24, total time:5875.25s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 53.3437s
epoch: 25, learning rate 0.001000
epoch: 25, train time every whole data:182.02s
epoch: 25, total time:6110.62s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 53.1899s
epoch: 26, learning rate 0.001000
epoch: 26, train time every whole data:182.01s
epoch: 26, total time:6345.82s
validation batch 1 / 168, loss: 0.14
validation batch 101 / 168, loss: 0.02
validation cost time: 53.3383s
epoch: 27, learning rate 0.001000
epoch: 27, train time every whole data:182.05s
epoch: 27, total time:6581.22s
validation batch 1 / 168, loss: 0.14
validation batch 101 / 168, loss: 0.02
validation cost time: 53.2218s
epoch: 28, learning rate 0.001000
epoch: 28, train time every whole data:182.05s
epoch: 28, total time:6816.49s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 53.2557s
epoch: 29, learning rate 0.001000
epoch: 29, train time every whole data:182.10s
epoch: 29, total time:7051.85s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 53.1434s
epoch: 30, learning rate 0.001000
epoch: 30, train time every whole data:182.08s
epoch: 30, total time:7287.07s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 53.2911s
epoch: 31, learning rate 0.001000
epoch: 31, train time every whole data:182.17s
epoch: 31, total time:7522.54s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 53.1369s
epoch: 32, learning rate 0.001000
epoch: 32, train time every whole data:182.11s
epoch: 32, total time:7757.79s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 53.4197s
epoch: 33, learning rate 0.001000
epoch: 33, train time every whole data:182.21s
epoch: 33, total time:7993.43s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 53.4007s
epoch: 34, learning rate 0.001000
epoch: 34, train time every whole data:182.14s
epoch: 34, total time:8228.97s
validation batch 1 / 168, loss: 0.15
validation batch 101 / 168, loss: 0.02
validation cost time: 53.1108s
epoch: 35, learning rate 0.001000
epoch: 35, train time every whole data:182.08s
epoch: 35, total time:8464.17s
validation batch 1 / 168, loss: 0.15
validation batch 101 / 168, loss: 0.02
validation cost time: 53.2424s
epoch: 36, learning rate 0.001000
epoch: 36, train time every whole data:182.08s
epoch: 36, total time:8699.49s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 53.3106s
epoch: 37, learning rate 0.001000
epoch: 37, train time every whole data:182.04s
epoch: 37, total time:8934.85s
validation batch 1 / 168, loss: 0.16
validation batch 101 / 168, loss: 0.02
validation cost time: 53.3428s
epoch: 38, learning rate 0.001000
epoch: 38, train time every whole data:182.25s
epoch: 38, total time:9170.45s
validation batch 1 / 168, loss: 0.15
validation batch 101 / 168, loss: 0.02
validation cost time: 53.1430s
epoch: 39, learning rate 0.001000
epoch: 39, train time every whole data:182.45s
epoch: 39, total time:9406.05s
validation batch 1 / 168, loss: 0.14
validation batch 101 / 168, loss: 0.02
validation cost time: 53.4063s
epoch: 40, learning rate 0.001000
epoch: 40, train time every whole data:182.23s
epoch: 40, total time:9641.69s
validation batch 1 / 168, loss: 0.17
validation batch 101 / 168, loss: 0.02
validation cost time: 53.4281s
epoch: 41, learning rate 0.001000
epoch: 41, train time every whole data:182.19s
epoch: 41, total time:9877.32s
validation batch 1 / 168, loss: 0.16
validation batch 101 / 168, loss: 0.02
validation cost time: 53.2507s
epoch: 42, learning rate 0.001000
epoch: 42, train time every whole data:182.21s
epoch: 42, total time:10112.78s
validation batch 1 / 168, loss: 0.20
validation batch 101 / 168, loss: 0.02
validation cost time: 53.4282s
epoch: 43, learning rate 0.001000
epoch: 43, train time every whole data:182.47s
epoch: 43, total time:10348.68s
validation batch 1 / 168, loss: 0.15
validation batch 101 / 168, loss: 0.02
validation cost time: 53.3698s
epoch: 44, learning rate 0.001000
epoch: 44, train time every whole data:182.23s
epoch: 44, total time:10584.28s
validation batch 1 / 168, loss: 0.20
validation batch 101 / 168, loss: 0.02
validation cost time: 53.3803s
epoch: 45, learning rate 0.001000
epoch: 45, train time every whole data:182.08s
epoch: 45, total time:10819.75s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 53.3862s
epoch: 46, learning rate 0.001000
epoch: 46, train time every whole data:182.28s
epoch: 46, total time:11055.42s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 53.3020s
epoch: 47, learning rate 0.001000
epoch: 47, train time every whole data:182.32s
epoch: 47, total time:11291.04s
validation batch 1 / 168, loss: 0.19
validation batch 101 / 168, loss: 0.02
validation cost time: 53.3912s
epoch: 48, learning rate 0.001000
epoch: 48, train time every whole data:182.09s
epoch: 48, total time:11526.53s
validation batch 1 / 168, loss: 0.15
validation batch 101 / 168, loss: 0.02
validation cost time: 53.2919s
epoch: 49, learning rate 0.001000
epoch: 49, train time every whole data:182.21s
epoch: 49, total time:11762.04s
validation batch 1 / 168, loss: 0.15
validation batch 101 / 168, loss: 0.02
validation cost time: 53.3326s
epoch: 50, learning rate 0.001000
epoch: 50, train time every whole data:182.40s
epoch: 50, total time:11997.77s
validation batch 1 / 168, loss: 0.15
validation batch 101 / 168, loss: 0.02
validation cost time: 53.2808s
epoch: 51, learning rate 0.001000
epoch: 51, train time every whole data:182.20s
epoch: 51, total time:12233.26s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 53.2703s
epoch: 52, learning rate 0.001000
epoch: 52, train time every whole data:182.11s
epoch: 52, total time:12468.64s
validation batch 1 / 168, loss: 0.16
validation batch 101 / 168, loss: 0.02
validation cost time: 53.2784s
epoch: 53, learning rate 0.001000
epoch: 53, train time every whole data:182.36s
epoch: 53, total time:12704.29s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 53.3431s
epoch: 54, learning rate 0.001000
epoch: 54, train time every whole data:182.30s
epoch: 54, total time:12939.94s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 53.2716s
epoch: 55, learning rate 0.001000
epoch: 55, train time every whole data:182.09s
epoch: 55, total time:13175.31s
validation batch 1 / 168, loss: 0.14
validation batch 101 / 168, loss: 0.02
validation cost time: 53.2167s
epoch: 56, learning rate 0.001000
epoch: 56, train time every whole data:182.23s
epoch: 56, total time:13410.75s
validation batch 1 / 168, loss: 0.14
validation batch 101 / 168, loss: 0.02
validation cost time: 53.2917s
epoch: 57, learning rate 0.001000
epoch: 57, train time every whole data:182.34s
epoch: 57, total time:13646.39s
validation batch 1 / 168, loss: 0.19
validation batch 101 / 168, loss: 0.02
validation cost time: 53.3064s
epoch: 58, learning rate 0.001000
epoch: 58, train time every whole data:182.17s
epoch: 58, total time:13881.87s
validation batch 1 / 168, loss: 0.16
validation batch 101 / 168, loss: 0.02
validation cost time: 53.2343s
epoch: 59, learning rate 0.001000
epoch: 59, train time every whole data:182.02s
epoch: 59, total time:14117.14s
validation batch 1 / 168, loss: 0.17
validation batch 101 / 168, loss: 0.02
validation cost time: 53.3441s
epoch: 60, learning rate 0.001000
epoch: 60, train time every whole data:182.30s
epoch: 60, total time:14352.79s
validation batch 1 / 168, loss: 0.16
validation batch 101 / 168, loss: 0.02
validation cost time: 53.3018s
epoch: 61, learning rate 0.001000
epoch: 61, train time every whole data:182.34s
epoch: 61, total time:14588.43s
validation batch 1 / 168, loss: 0.15
validation batch 101 / 168, loss: 0.02
validation cost time: 53.2790s
epoch: 62, learning rate 0.001000
epoch: 62, train time every whole data:182.19s
epoch: 62, total time:14823.90s
validation batch 1 / 168, loss: 0.16
validation batch 101 / 168, loss: 0.02
validation cost time: 53.3062s
epoch: 63, learning rate 0.001000
epoch: 63, train time every whole data:182.15s
epoch: 63, total time:15059.36s
validation batch 1 / 168, loss: 0.17
validation batch 101 / 168, loss: 0.02
validation cost time: 53.4122s
epoch: 64, learning rate 0.001000
epoch: 64, train time every whole data:182.35s
epoch: 64, total time:15295.13s
validation batch 1 / 168, loss: 0.18
validation batch 101 / 168, loss: 0.02
validation cost time: 53.3362s
epoch: 65, learning rate 0.001000
epoch: 65, train time every whole data:182.23s
epoch: 65, total time:15530.70s
validation batch 1 / 168, loss: 0.14
validation batch 101 / 168, loss: 0.02
validation cost time: 53.2313s
epoch: 66, learning rate 0.001000
epoch: 66, train time every whole data:182.05s
epoch: 66, total time:15765.99s
validation batch 1 / 168, loss: 0.15
validation batch 101 / 168, loss: 0.02
validation cost time: 53.4116s
epoch: 67, learning rate 0.001000
epoch: 67, train time every whole data:182.29s
epoch: 67, total time:16001.69s
validation batch 1 / 168, loss: 0.17
validation batch 101 / 168, loss: 0.02
validation cost time: 53.1793s
epoch: 68, learning rate 0.001000
epoch: 68, train time every whole data:182.19s
epoch: 68, total time:16237.06s
validation batch 1 / 168, loss: 0.15
validation batch 101 / 168, loss: 0.02
validation cost time: 53.0694s
epoch: 69, learning rate 0.001000
epoch: 69, train time every whole data:182.00s
epoch: 69, total time:16472.14s
validation batch 1 / 168, loss: 0.17
validation batch 101 / 168, loss: 0.02
validation cost time: 53.2739s
epoch: 70, learning rate 0.001000
epoch: 70, train time every whole data:181.92s
epoch: 70, total time:16707.34s
validation batch 1 / 168, loss: 0.17
validation batch 101 / 168, loss: 0.02
validation cost time: 53.3661s
epoch: 71, learning rate 0.001000
epoch: 71, train time every whole data:182.14s
epoch: 71, total time:16942.85s
validation batch 1 / 168, loss: 0.19
validation batch 101 / 168, loss: 0.02
validation cost time: 53.2885s
epoch: 72, learning rate 0.001000
epoch: 72, train time every whole data:193.80s
epoch: 72, total time:17189.94s
validation batch 1 / 168, loss: 0.15
validation batch 101 / 168, loss: 0.02
validation cost time: 53.8585s
epoch: 73, learning rate 0.001000
epoch: 73, train time every whole data:184.47s
epoch: 73, total time:17428.27s
validation batch 1 / 168, loss: 0.16
validation batch 101 / 168, loss: 0.02
validation cost time: 53.5447s
epoch: 74, learning rate 0.001000
epoch: 74, train time every whole data:184.22s
epoch: 74, total time:17666.04s
validation batch 1 / 168, loss: 0.17
validation batch 101 / 168, loss: 0.02
validation cost time: 53.8161s
epoch: 75, learning rate 0.001000
epoch: 75, train time every whole data:184.11s
epoch: 75, total time:17903.97s
validation batch 1 / 168, loss: 0.17
validation batch 101 / 168, loss: 0.02
validation cost time: 53.6430s
epoch: 76, learning rate 0.001000
epoch: 76, train time every whole data:184.17s
epoch: 76, total time:18141.78s
validation batch 1 / 168, loss: 0.17
validation batch 101 / 168, loss: 0.02
validation cost time: 53.6643s
epoch: 77, learning rate 0.001000
epoch: 77, train time every whole data:184.11s
epoch: 77, total time:18379.56s
validation batch 1 / 168, loss: 0.16
validation batch 101 / 168, loss: 0.02
validation cost time: 53.9100s
epoch: 78, learning rate 0.001000
epoch: 78, train time every whole data:184.18s
epoch: 78, total time:18617.66s
validation batch 1 / 168, loss: 0.18
validation batch 101 / 168, loss: 0.02
validation cost time: 53.7425s
epoch: 79, learning rate 0.001000
epoch: 79, train time every whole data:184.16s
epoch: 79, total time:18855.56s
validation batch 1 / 168, loss: 0.09
validation batch 101 / 168, loss: 0.02
validation cost time: 53.7721s
epoch: 80, learning rate 0.001000
epoch: 80, train time every whole data:184.09s
epoch: 80, total time:19093.44s
validation batch 1 / 168, loss: 0.22
validation batch 101 / 168, loss: 0.02
validation cost time: 53.8200s
epoch: 81, learning rate 0.001000
epoch: 81, train time every whole data:184.00s
epoch: 81, total time:19331.26s
validation batch 1 / 168, loss: 0.20
validation batch 101 / 168, loss: 0.02
validation cost time: 53.6751s
epoch: 82, learning rate 0.001000
epoch: 82, train time every whole data:184.08s
epoch: 82, total time:19569.02s
validation batch 1 / 168, loss: 0.18
validation batch 101 / 168, loss: 0.02
validation cost time: 53.6952s
epoch: 83, learning rate 0.001000
epoch: 83, train time every whole data:184.14s
epoch: 83, total time:19806.86s
validation batch 1 / 168, loss: 0.17
validation batch 101 / 168, loss: 0.02
validation cost time: 53.8267s
epoch: 84, learning rate 0.001000
epoch: 84, train time every whole data:184.21s
epoch: 84, total time:20044.90s
validation batch 1 / 168, loss: 0.10
validation batch 101 / 168, loss: 0.02
validation cost time: 53.9603s
epoch: 85, learning rate 0.001000
epoch: 85, train time every whole data:184.04s
epoch: 85, total time:20282.91s
validation batch 1 / 168, loss: 0.20
validation batch 101 / 168, loss: 0.02
validation cost time: 53.9815s
epoch: 86, learning rate 0.001000
epoch: 86, train time every whole data:184.00s
epoch: 86, total time:20520.89s
validation batch 1 / 168, loss: 0.17
validation batch 101 / 168, loss: 0.02
validation cost time: 53.7186s
epoch: 87, learning rate 0.001000
epoch: 87, train time every whole data:184.07s
epoch: 87, total time:20758.69s
validation batch 1 / 168, loss: 0.16
validation batch 101 / 168, loss: 0.02
validation cost time: 53.8428s
epoch: 88, learning rate 0.001000
epoch: 88, train time every whole data:184.02s
epoch: 88, total time:20996.56s
validation batch 1 / 168, loss: 0.18
validation batch 101 / 168, loss: 0.02
validation cost time: 53.9636s
epoch: 89, learning rate 0.001000
epoch: 89, train time every whole data:184.08s
epoch: 89, total time:21234.61s
validation batch 1 / 168, loss: 0.21
validation batch 101 / 168, loss: 0.02
validation cost time: 53.8441s
epoch: 90, learning rate 0.001000
epoch: 90, train time every whole data:184.02s
epoch: 90, total time:21472.48s
validation batch 1 / 168, loss: 0.16
validation batch 101 / 168, loss: 0.02
validation cost time: 53.8949s
epoch: 91, learning rate 0.001000
epoch: 91, train time every whole data:184.13s
epoch: 91, total time:21710.50s
validation batch 1 / 168, loss: 0.18
validation batch 101 / 168, loss: 0.02
validation cost time: 53.9245s
epoch: 92, learning rate 0.001000
epoch: 92, train time every whole data:183.99s
epoch: 92, total time:21948.42s
validation batch 1 / 168, loss: 0.16
validation batch 101 / 168, loss: 0.02
validation cost time: 53.8610s
epoch: 93, learning rate 0.001000
epoch: 93, train time every whole data:184.01s
epoch: 93, total time:22186.29s
validation batch 1 / 168, loss: 0.17
validation batch 101 / 168, loss: 0.02
validation cost time: 53.9663s
epoch: 94, learning rate 0.001000
epoch: 94, train time every whole data:183.97s
epoch: 94, total time:22424.23s
validation batch 1 / 168, loss: 0.18
validation batch 101 / 168, loss: 0.02
validation cost time: 53.9016s
epoch: 95, learning rate 0.001000
epoch: 95, train time every whole data:183.94s
epoch: 95, total time:22662.07s
validation batch 1 / 168, loss: 0.17
validation batch 101 / 168, loss: 0.02
validation cost time: 53.7309s
epoch: 96, learning rate 0.001000
epoch: 96, train time every whole data:183.96s
epoch: 96, total time:22899.78s
validation batch 1 / 168, loss: 0.17
validation batch 101 / 168, loss: 0.02
validation cost time: 53.7172s
epoch: 97, learning rate 0.001000
epoch: 97, train time every whole data:183.98s
epoch: 97, total time:23137.49s
validation batch 1 / 168, loss: 0.14
validation batch 101 / 168, loss: 0.02
validation cost time: 53.7109s
epoch: 98, learning rate 0.001000
epoch: 98, train time every whole data:183.96s
epoch: 98, total time:23375.16s
validation batch 1 / 168, loss: 0.17
validation batch 101 / 168, loss: 0.02
validation cost time: 53.7485s
epoch: 99, learning rate 0.001000
epoch: 99, train time every whole data:183.93s
epoch: 99, total time:23612.85s
best epoch: 16
apply the best val model on the test data set ...
load weight from: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_new/epoch_16.params
predicting testing set batch 1 / 168, time: 0.32s
predicting testing set batch 101 / 168, time: 32.35s
test time on whole data:53.83s
input: (672, 250, 12, 2)
prediction: (672, 250, 12, 2)
data_target_tensor: (672, 250, 12, 2)
current epoch: 16, predict 0 points
MAE: 1.61
RMSE: 2.65
MAPE: 56.60
PCC: 0.83
current epoch: 16, predict 1 points
MAE: 1.77
RMSE: 2.93
MAPE: 64.43
PCC: 0.78
current epoch: 16, predict 2 points
MAE: 1.96
RMSE: 3.31
MAPE: 73.19
PCC: 0.72
current epoch: 16, predict 3 points
MAE: 2.22
RMSE: 3.79
MAPE: 83.77
PCC: 0.64
current epoch: 16, predict 4 points
MAE: 2.45
RMSE: 4.21
MAPE: 93.11
PCC: 0.58
current epoch: 16, predict 5 points
MAE: 2.65
RMSE: 4.56
MAPE: 100.90
PCC: 0.52
current epoch: 16, predict 6 points
MAE: 2.82
RMSE: 4.83
MAPE: 107.42
PCC: 0.47
current epoch: 16, predict 7 points
MAE: 2.87
RMSE: 4.89
MAPE: 108.14
PCC: 0.44
current epoch: 16, predict 8 points
MAE: 2.81
RMSE: 4.78
MAPE: 103.03
PCC: 0.43
current epoch: 16, predict 9 points
MAE: 2.73
RMSE: 4.67
MAPE: 95.72
PCC: 0.42
current epoch: 16, predict 10 points
MAE: 2.64
RMSE: 4.58
MAPE: 87.83
PCC: 0.42
current epoch: 16, predict 11 points
MAE: 2.58
RMSE: 4.48
MAPE: 82.68
PCC: 0.44
all MAE: 2.43
all RMSE: 4.21
all MAPE: 88.07
all PCC: 0.44
1.6051941476890905 2.6470026094152876 56.59778400133496 0.827387014348933 
1.7674125406146937 2.9253929795670475 64.428944209855 0.7751785782054802 
1.9647762098709742 3.307538326544062 73.19358888382014 0.7159149374122675 
2.2181477823703593 3.789093143666943 83.77407053119754 0.6442963515292414 
2.452125117588788 4.21209931029588 93.1109417162124 0.5786519557668682 
2.6549129474863764 4.563835323373612 100.89797166078533 0.5170766216191772 
2.820219976879213 4.82682138457808 107.41511737810683 0.4671583988637206 
2.8663937832440824 4.886654749670477 108.13787572720146 0.43855732328810076 
2.808884411015326 4.780982616885668 103.02924861115656 0.42714664906412814 
2.727956588164504 4.6699110173704526 95.71737433015068 0.42244437638324195 
2.638090089931818 4.580592647776534 87.82564847567686 0.4244526498003069 
2.5813817594486865 4.477046815676767 82.67531109426115 0.43697247811725703 
2.4254579461919925 4.206158156001795 88.06780690493717 0.43697247811725703 
fine tune the model ... 
epoch: 100, learning rate 0.000100
epoch: 100, train time every whole data:403.96s
epoch: 100, total time:24081.28s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.9724s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_new/epoch_100.params
epoch: 101, learning rate 0.000100
epoch: 101, train time every whole data:403.49s
epoch: 101, total time:24538.88s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 54.1677s
epoch: 102, learning rate 0.000100
epoch: 102, train time every whole data:395.70s
epoch: 102, total time:24988.75s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.4888s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_new/epoch_102.params
epoch: 103, learning rate 0.000100
epoch: 103, train time every whole data:394.67s
epoch: 103, total time:25437.02s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.4338s
epoch: 104, learning rate 0.000100
epoch: 104, train time every whole data:397.28s
epoch: 104, total time:25887.74s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.1714s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_new/epoch_104.params
epoch: 105, learning rate 0.000100
epoch: 105, train time every whole data:396.17s
epoch: 105, total time:26337.32s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.3848s
epoch: 106, learning rate 0.000100
epoch: 106, train time every whole data:393.25s
epoch: 106, total time:26783.97s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.4421s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_new/epoch_106.params
epoch: 107, learning rate 0.000100
epoch: 107, train time every whole data:392.81s
epoch: 107, total time:27230.43s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.4964s
epoch: 108, learning rate 0.000100
epoch: 108, train time every whole data:392.56s
epoch: 108, total time:27676.48s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.3892s
epoch: 109, learning rate 0.000100
epoch: 109, train time every whole data:392.63s
epoch: 109, total time:28122.51s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.5087s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_new/epoch_109.params
epoch: 110, learning rate 0.000100
epoch: 110, train time every whole data:392.92s
epoch: 110, total time:28569.09s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.5558s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_new/epoch_110.params
epoch: 111, learning rate 0.000100
epoch: 111, train time every whole data:392.87s
epoch: 111, total time:29015.66s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.4241s
epoch: 112, learning rate 0.000100
epoch: 112, train time every whole data:392.97s
epoch: 112, total time:29462.06s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 53.5002s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_new/epoch_112.params
epoch: 113, learning rate 0.000100
epoch: 113, train time every whole data:392.91s
epoch: 113, total time:29908.58s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.5191s
epoch: 114, learning rate 0.000100
epoch: 114, train time every whole data:392.98s
epoch: 114, total time:30355.09s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 53.4651s
epoch: 115, learning rate 0.000100
epoch: 115, train time every whole data:393.00s
epoch: 115, total time:30801.55s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.4191s
epoch: 116, learning rate 0.000100
epoch: 116, train time every whole data:393.16s
epoch: 116, total time:31248.13s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.2997s
epoch: 117, learning rate 0.000100
epoch: 117, train time every whole data:392.94s
epoch: 117, total time:31694.37s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.3202s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_new/epoch_117.params
epoch: 118, learning rate 0.000100
epoch: 118, train time every whole data:393.03s
epoch: 118, total time:32140.89s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 53.5178s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_new/epoch_118.params
epoch: 119, learning rate 0.000100
epoch: 119, train time every whole data:392.96s
epoch: 119, total time:32587.52s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 53.4671s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_new/epoch_119.params
epoch: 120, learning rate 0.000100
epoch: 120, train time every whole data:392.90s
epoch: 120, total time:33034.02s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 53.2475s
epoch: 121, learning rate 0.000100
epoch: 121, train time every whole data:393.05s
epoch: 121, total time:33480.32s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.5092s
epoch: 122, learning rate 0.000100
epoch: 122, train time every whole data:393.11s
epoch: 122, total time:33926.94s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.4107s
epoch: 123, learning rate 0.000100
epoch: 123, train time every whole data:392.94s
epoch: 123, total time:34373.29s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 53.2949s
epoch: 124, learning rate 0.000100
epoch: 124, train time every whole data:392.97s
epoch: 124, total time:34819.56s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 53.2649s
epoch: 125, learning rate 0.000100
epoch: 125, train time every whole data:393.02s
epoch: 125, total time:35265.85s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.4338s
epoch: 126, learning rate 0.000100
epoch: 126, train time every whole data:392.90s
epoch: 126, total time:35712.19s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.4178s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_new/epoch_126.params
epoch: 127, learning rate 0.000100
epoch: 127, train time every whole data:393.01s
epoch: 127, total time:36158.75s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 53.2701s
epoch: 128, learning rate 0.000100
epoch: 128, train time every whole data:393.00s
epoch: 128, total time:36605.02s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 53.4262s
epoch: 129, learning rate 0.000100
epoch: 129, train time every whole data:393.15s
epoch: 129, total time:37051.60s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 53.3243s
epoch: 130, learning rate 0.000100
epoch: 130, train time every whole data:393.03s
epoch: 130, total time:37497.95s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.4313s
epoch: 131, learning rate 0.000100
epoch: 131, train time every whole data:393.20s
epoch: 131, total time:37944.59s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 53.4181s
epoch: 132, learning rate 0.000100
epoch: 132, train time every whole data:393.15s
epoch: 132, total time:38391.16s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.4974s
epoch: 133, learning rate 0.000100
epoch: 133, train time every whole data:393.08s
epoch: 133, total time:38837.75s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 53.3818s
epoch: 134, learning rate 0.000100
epoch: 134, train time every whole data:392.49s
epoch: 134, total time:39283.62s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.4107s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_new/epoch_134.params
epoch: 135, learning rate 0.000100
epoch: 135, train time every whole data:392.40s
epoch: 135, total time:39729.53s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.3976s
epoch: 136, learning rate 0.000100
epoch: 136, train time every whole data:393.12s
epoch: 136, total time:40176.06s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.4955s
epoch: 137, learning rate 0.000100
epoch: 137, train time every whole data:391.97s
epoch: 137, total time:40621.53s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.1482s
epoch: 138, learning rate 0.000100
epoch: 138, train time every whole data:392.24s
epoch: 138, total time:41066.93s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.5163s
epoch: 139, learning rate 0.000100
epoch: 139, train time every whole data:392.10s
epoch: 139, total time:41512.55s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 53.1748s
epoch: 140, learning rate 0.000100
epoch: 140, train time every whole data:392.31s
epoch: 140, total time:41958.04s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 53.4921s
epoch: 141, learning rate 0.000100
epoch: 141, train time every whole data:392.48s
epoch: 141, total time:42404.02s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.3564s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_new/epoch_141.params
epoch: 142, learning rate 0.000100
epoch: 142, train time every whole data:392.76s
epoch: 142, total time:42850.30s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 53.2511s
epoch: 143, learning rate 0.000100
epoch: 143, train time every whole data:391.72s
epoch: 143, total time:43295.27s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.4354s
epoch: 144, learning rate 0.000100
epoch: 144, train time every whole data:392.74s
epoch: 144, total time:43741.45s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 53.3868s
epoch: 145, learning rate 0.000100
epoch: 145, train time every whole data:392.13s
epoch: 145, total time:44186.98s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.3725s
epoch: 146, learning rate 0.000100
epoch: 146, train time every whole data:392.95s
epoch: 146, total time:44633.31s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.3147s
epoch: 147, learning rate 0.000100
epoch: 147, train time every whole data:392.04s
epoch: 147, total time:45078.67s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 53.4316s
epoch: 148, learning rate 0.000100
epoch: 148, train time every whole data:392.92s
epoch: 148, total time:45525.02s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.2809s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_new/epoch_148.params
epoch: 149, learning rate 0.000100
epoch: 149, train time every whole data:392.54s
epoch: 149, total time:45971.00s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 53.4357s
best epoch: 148
apply the best val model on the test data set ...
load weight from: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_new/epoch_148.params
predicting testing set batch 1 / 168, time: 0.32s
predicting testing set batch 101 / 168, time: 32.15s
test time on whole data:53.47s
input: (672, 250, 12, 2)
prediction: (672, 250, 12, 2)
data_target_tensor: (672, 250, 12, 2)
current epoch: 148, predict 0 points
MAE: 1.48
RMSE: 2.38
MAPE: 55.22
PCC: 0.86
current epoch: 148, predict 1 points
MAE: 1.53
RMSE: 2.49
MAPE: 56.70
PCC: 0.84
current epoch: 148, predict 2 points
MAE: 1.56
RMSE: 2.55
MAPE: 56.87
PCC: 0.84
current epoch: 148, predict 3 points
MAE: 1.59
RMSE: 2.62
MAPE: 57.22
PCC: 0.83
current epoch: 148, predict 4 points
MAE: 1.63
RMSE: 2.69
MAPE: 57.48
PCC: 0.82
current epoch: 148, predict 5 points
MAE: 1.66
RMSE: 2.78
MAPE: 57.94
PCC: 0.81
current epoch: 148, predict 6 points
MAE: 1.69
RMSE: 2.86
MAPE: 58.57
PCC: 0.80
current epoch: 148, predict 7 points
MAE: 1.71
RMSE: 2.91
MAPE: 59.18
PCC: 0.79
current epoch: 148, predict 8 points
MAE: 1.74
RMSE: 2.94
MAPE: 60.12
PCC: 0.78
current epoch: 148, predict 9 points
MAE: 1.75
RMSE: 2.97
MAPE: 61.02
PCC: 0.78
current epoch: 148, predict 10 points
MAE: 1.76
RMSE: 2.99
MAPE: 61.60
PCC: 0.77
current epoch: 148, predict 11 points
MAE: 1.79
RMSE: 3.03
MAPE: 62.16
PCC: 0.77
all MAE: 1.66
all RMSE: 2.77
all MAPE: 58.67
all PCC: 0.77
1.4758854079482455 2.3809517638687008 55.21715176144749 0.8573353073456317 
1.5334366773869843 2.489255130787278 56.69554236673894 0.8436957519923806 
1.5614015684938503 2.5543709632364924 56.87483134786086 0.8362422677601659 
1.5895424323587546 2.616033008101085 57.22004789921037 0.829278520277394 
1.6253630052674561 2.691168976746818 57.484517240099954 0.8206718777237346 
1.663037955170586 2.7774935500721334 57.94350690384211 0.8091564638038821 
1.6943797851875424 2.8637749984960195 58.57277836885794 0.7955062199127543 
1.7146525082566022 2.9072819688649814 59.1823281469685 0.7882122951309514 
1.7352936413214497 2.9437183224927703 60.116076834867805 0.781214558826776 
1.751337661456849 2.9662878431271014 61.01716742010193 0.7767081988475425 
1.7629332172437793 2.985635658868024 61.60238157359183 0.7738729255470167 
1.786290113809829 3.025116644967777 62.1600518135649 0.7689693428309534 
1.6577961644918273 2.774494110487295 58.67397802793518 0.7689693428309534 
