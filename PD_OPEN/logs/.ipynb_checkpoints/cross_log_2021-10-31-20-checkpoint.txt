CUDA: True cuda:0
Read configuration file: configurations/bike.conf
total training epoch, fine tune epoch: 100 , 50
batch_size: 4
folder_dir: MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEcross
load file: data/bike.npz
ori length: 3001 , percent: 1.0 , scale: 3001
train: torch.Size([3001, 250, 2, 12]) torch.Size([3001, 250, 2, 12]) torch.Size([3001, 250, 2, 12])
val: torch.Size([672, 250, 2, 12]) torch.Size([672, 250, 2, 12]) torch.Size([672, 250, 2, 12])
test: torch.Size([672, 250, 2, 12]) torch.Size([672, 250, 2, 12]) torch.Size([672, 250, 2, 12])
TemporalPositionalEncoding max_len: 13
en_lookup_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
EncoderDecoder_ms(
  (encoder): Encoder_ms(
    (layers): ModuleList(
      (0): EncoderLayer_ms(
        (layer): EncoderLayer(
          (self_attn): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
              (2): Linear(in_features=64, out_features=64, bias=True)
              (3): Linear(in_features=64, out_features=64, bias=True)
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (feed_forward_gcn): PositionWiseGCNFeedForward(
            (gcn): spatialAttentionScaledGCN(
              (Theta): Linear(in_features=64, out_features=64, bias=False)
              (SAt): Spatial_Attention_layer(
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (tcn): TCN(
            (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
          )
          (sublayer): ModuleList(
            (0): SublayerConnection(
              (dropout): Dropout(p=0.0, inplace=False)
              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            )
            (1): SublayerConnection(
              (dropout): Dropout(p=0.0, inplace=False)
              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            )
            (2): SublayerConnection(
              (dropout): Dropout(p=0.0, inplace=False)
              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (layer2): EncoderLayer(
          (self_attn): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
              (2): Linear(in_features=64, out_features=64, bias=True)
              (3): Linear(in_features=64, out_features=64, bias=True)
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (feed_forward_gcn): PositionWiseGCNFeedForward(
            (gcn): spatialAttentionScaledGCN(
              (Theta): Linear(in_features=64, out_features=64, bias=False)
              (SAt): Spatial_Attention_layer(
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (tcn): TCN(
            (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
          )
          (sublayer): ModuleList(
            (0): SublayerConnection(
              (dropout): Dropout(p=0.0, inplace=False)
              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            )
            (1): SublayerConnection(
              (dropout): Dropout(p=0.0, inplace=False)
              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            )
            (2): SublayerConnection(
              (dropout): Dropout(p=0.0, inplace=False)
              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (layerc): EncoderLayer_cross(
          (self_attn): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
              (2): Linear(in_features=64, out_features=64, bias=True)
              (3): Linear(in_features=64, out_features=64, bias=True)
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (feed_forward_gcn): PositionWiseGCNFeedForward(
            (gcn): spatialAttentionScaledGCN(
              (Theta): Linear(in_features=64, out_features=64, bias=False)
              (SAt): Spatial_Attention_layer(
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (sublayer): SublayerConnection2(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (sublayer_): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layerc2): EncoderLayer_cross(
          (self_attn): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
              (2): Linear(in_features=64, out_features=64, bias=True)
              (3): Linear(in_features=64, out_features=64, bias=True)
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (feed_forward_gcn): PositionWiseGCNFeedForward(
            (gcn): spatialAttentionScaledGCN(
              (Theta): Linear(in_features=64, out_features=64, bias=False)
              (SAt): Spatial_Attention_layer(
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (sublayer): SublayerConnection2(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (sublayer_): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (1): EncoderLayer_ms(
        (layer): EncoderLayer(
          (self_attn): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
              (2): Linear(in_features=64, out_features=64, bias=True)
              (3): Linear(in_features=64, out_features=64, bias=True)
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (feed_forward_gcn): PositionWiseGCNFeedForward(
            (gcn): spatialAttentionScaledGCN(
              (Theta): Linear(in_features=64, out_features=64, bias=False)
              (SAt): Spatial_Attention_layer(
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (tcn): TCN(
            (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
          )
          (sublayer): ModuleList(
            (0): SublayerConnection(
              (dropout): Dropout(p=0.0, inplace=False)
              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            )
            (1): SublayerConnection(
              (dropout): Dropout(p=0.0, inplace=False)
              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            )
            (2): SublayerConnection(
              (dropout): Dropout(p=0.0, inplace=False)
              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (layer2): EncoderLayer(
          (self_attn): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
              (2): Linear(in_features=64, out_features=64, bias=True)
              (3): Linear(in_features=64, out_features=64, bias=True)
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (feed_forward_gcn): PositionWiseGCNFeedForward(
            (gcn): spatialAttentionScaledGCN(
              (Theta): Linear(in_features=64, out_features=64, bias=False)
              (SAt): Spatial_Attention_layer(
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (tcn): TCN(
            (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
          )
          (sublayer): ModuleList(
            (0): SublayerConnection(
              (dropout): Dropout(p=0.0, inplace=False)
              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            )
            (1): SublayerConnection(
              (dropout): Dropout(p=0.0, inplace=False)
              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            )
            (2): SublayerConnection(
              (dropout): Dropout(p=0.0, inplace=False)
              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (layerc): EncoderLayer_cross(
          (self_attn): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
              (2): Linear(in_features=64, out_features=64, bias=True)
              (3): Linear(in_features=64, out_features=64, bias=True)
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (feed_forward_gcn): PositionWiseGCNFeedForward(
            (gcn): spatialAttentionScaledGCN(
              (Theta): Linear(in_features=64, out_features=64, bias=False)
              (SAt): Spatial_Attention_layer(
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (sublayer): SublayerConnection2(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (sublayer_): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layerc2): EncoderLayer_cross(
          (self_attn): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
              (2): Linear(in_features=64, out_features=64, bias=True)
              (3): Linear(in_features=64, out_features=64, bias=True)
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (feed_forward_gcn): PositionWiseGCNFeedForward(
            (gcn): spatialAttentionScaledGCN(
              (Theta): Linear(in_features=64, out_features=64, bias=False)
              (SAt): Spatial_Attention_layer(
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (sublayer): SublayerConnection2(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (sublayer_): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (2): EncoderLayer_ms(
        (layer): EncoderLayer(
          (self_attn): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
              (2): Linear(in_features=64, out_features=64, bias=True)
              (3): Linear(in_features=64, out_features=64, bias=True)
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (feed_forward_gcn): PositionWiseGCNFeedForward(
            (gcn): spatialAttentionScaledGCN(
              (Theta): Linear(in_features=64, out_features=64, bias=False)
              (SAt): Spatial_Attention_layer(
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (tcn): TCN(
            (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
          )
          (sublayer): ModuleList(
            (0): SublayerConnection(
              (dropout): Dropout(p=0.0, inplace=False)
              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            )
            (1): SublayerConnection(
              (dropout): Dropout(p=0.0, inplace=False)
              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            )
            (2): SublayerConnection(
              (dropout): Dropout(p=0.0, inplace=False)
              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (layer2): EncoderLayer(
          (self_attn): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
              (2): Linear(in_features=64, out_features=64, bias=True)
              (3): Linear(in_features=64, out_features=64, bias=True)
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (feed_forward_gcn): PositionWiseGCNFeedForward(
            (gcn): spatialAttentionScaledGCN(
              (Theta): Linear(in_features=64, out_features=64, bias=False)
              (SAt): Spatial_Attention_layer(
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (tcn): TCN(
            (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
          )
          (sublayer): ModuleList(
            (0): SublayerConnection(
              (dropout): Dropout(p=0.0, inplace=False)
              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            )
            (1): SublayerConnection(
              (dropout): Dropout(p=0.0, inplace=False)
              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            )
            (2): SublayerConnection(
              (dropout): Dropout(p=0.0, inplace=False)
              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (layerc): EncoderLayer_cross(
          (self_attn): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
              (2): Linear(in_features=64, out_features=64, bias=True)
              (3): Linear(in_features=64, out_features=64, bias=True)
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (feed_forward_gcn): PositionWiseGCNFeedForward(
            (gcn): spatialAttentionScaledGCN(
              (Theta): Linear(in_features=64, out_features=64, bias=False)
              (SAt): Spatial_Attention_layer(
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (sublayer): SublayerConnection2(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (sublayer_): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layerc2): EncoderLayer_cross(
          (self_attn): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
              (2): Linear(in_features=64, out_features=64, bias=True)
              (3): Linear(in_features=64, out_features=64, bias=True)
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (feed_forward_gcn): PositionWiseGCNFeedForward(
            (gcn): spatialAttentionScaledGCN(
              (Theta): Linear(in_features=64, out_features=64, bias=False)
              (SAt): Spatial_Attention_layer(
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (sublayer): SublayerConnection2(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (sublayer_): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (3): EncoderLayer_ms(
        (layer): EncoderLayer(
          (self_attn): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
              (2): Linear(in_features=64, out_features=64, bias=True)
              (3): Linear(in_features=64, out_features=64, bias=True)
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (feed_forward_gcn): PositionWiseGCNFeedForward(
            (gcn): spatialAttentionScaledGCN(
              (Theta): Linear(in_features=64, out_features=64, bias=False)
              (SAt): Spatial_Attention_layer(
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (tcn): TCN(
            (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
          )
          (sublayer): ModuleList(
            (0): SublayerConnection(
              (dropout): Dropout(p=0.0, inplace=False)
              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            )
            (1): SublayerConnection(
              (dropout): Dropout(p=0.0, inplace=False)
              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            )
            (2): SublayerConnection(
              (dropout): Dropout(p=0.0, inplace=False)
              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (layer2): EncoderLayer(
          (self_attn): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
              (2): Linear(in_features=64, out_features=64, bias=True)
              (3): Linear(in_features=64, out_features=64, bias=True)
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (feed_forward_gcn): PositionWiseGCNFeedForward(
            (gcn): spatialAttentionScaledGCN(
              (Theta): Linear(in_features=64, out_features=64, bias=False)
              (SAt): Spatial_Attention_layer(
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (tcn): TCN(
            (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
          )
          (sublayer): ModuleList(
            (0): SublayerConnection(
              (dropout): Dropout(p=0.0, inplace=False)
              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            )
            (1): SublayerConnection(
              (dropout): Dropout(p=0.0, inplace=False)
              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            )
            (2): SublayerConnection(
              (dropout): Dropout(p=0.0, inplace=False)
              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (layerc): EncoderLayer_cross(
          (self_attn): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
              (2): Linear(in_features=64, out_features=64, bias=True)
              (3): Linear(in_features=64, out_features=64, bias=True)
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (feed_forward_gcn): PositionWiseGCNFeedForward(
            (gcn): spatialAttentionScaledGCN(
              (Theta): Linear(in_features=64, out_features=64, bias=False)
              (SAt): Spatial_Attention_layer(
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (sublayer): SublayerConnection2(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (sublayer_): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layerc2): EncoderLayer_cross(
          (self_attn): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
              (2): Linear(in_features=64, out_features=64, bias=True)
              (3): Linear(in_features=64, out_features=64, bias=True)
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (feed_forward_gcn): PositionWiseGCNFeedForward(
            (gcn): spatialAttentionScaledGCN(
              (Theta): Linear(in_features=64, out_features=64, bias=False)
              (SAt): Spatial_Attention_layer(
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (sublayer): SublayerConnection2(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (sublayer_): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): Decoder(
    (layers): ModuleList(
      (0): DecoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (1): DecoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (2): DecoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (3): DecoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (decoder2): Decoder(
    (layers): ModuleList(
      (0): DecoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (1): DecoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (2): DecoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (3): DecoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (src_embed): Sequential(
    (0): Linear(in_features=1, out_features=64, bias=True)
    (1): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (2): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(250, 64)
    )
  )
  (src_embed2): Sequential(
    (0): Linear(in_features=1, out_features=64, bias=True)
    (1): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (2): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(250, 64)
    )
  )
  (trg_embed): Sequential(
    (0): Linear(in_features=1, out_features=64, bias=True)
    (1): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (2): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(250, 64)
    )
  )
  (trg_embed2): Sequential(
    (0): Linear(in_features=1, out_features=64, bias=True)
    (1): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (2): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(250, 64)
    )
  )
  (prediction_generator): Linear(in_features=64, out_features=1, bias=True)
  (prediction_generator2): Linear(in_features=64, out_features=1, bias=True)
)
delete the old one and create params directory experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEcross
Net's state_dict:
encoder.layers.0.layer.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.0.layer.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.0.layer.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.0.layer.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.0.layer.self_attn.linears.2.weight 	 torch.Size([64, 64])
encoder.layers.0.layer.self_attn.linears.2.bias 	 torch.Size([64])
encoder.layers.0.layer.self_attn.linears.3.weight 	 torch.Size([64, 64])
encoder.layers.0.layer.self_attn.linears.3.bias 	 torch.Size([64])
encoder.layers.0.layer.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.0.layer.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.layer.tcn.filter_convs.bias 	 torch.Size([64])
encoder.layers.0.layer.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.layer.tcn.gate_convs.bias 	 torch.Size([64])
encoder.layers.0.layer.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.0.layer.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.0.layer.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.0.layer.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.0.layer.sublayer.2.norm.weight 	 torch.Size([64])
encoder.layers.0.layer.sublayer.2.norm.bias 	 torch.Size([64])
encoder.layers.0.layer2.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.0.layer2.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.0.layer2.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.0.layer2.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.0.layer2.self_attn.linears.2.weight 	 torch.Size([64, 64])
encoder.layers.0.layer2.self_attn.linears.2.bias 	 torch.Size([64])
encoder.layers.0.layer2.self_attn.linears.3.weight 	 torch.Size([64, 64])
encoder.layers.0.layer2.self_attn.linears.3.bias 	 torch.Size([64])
encoder.layers.0.layer2.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.0.layer2.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.layer2.tcn.filter_convs.bias 	 torch.Size([64])
encoder.layers.0.layer2.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.layer2.tcn.gate_convs.bias 	 torch.Size([64])
encoder.layers.0.layer2.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.0.layer2.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.0.layer2.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.0.layer2.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.0.layer2.sublayer.2.norm.weight 	 torch.Size([64])
encoder.layers.0.layer2.sublayer.2.norm.bias 	 torch.Size([64])
encoder.layers.0.layerc.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.0.layerc.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.0.layerc.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.0.layerc.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.0.layerc.self_attn.linears.2.weight 	 torch.Size([64, 64])
encoder.layers.0.layerc.self_attn.linears.2.bias 	 torch.Size([64])
encoder.layers.0.layerc.self_attn.linears.3.weight 	 torch.Size([64, 64])
encoder.layers.0.layerc.self_attn.linears.3.bias 	 torch.Size([64])
encoder.layers.0.layerc.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.0.layerc.sublayer.norm.weight 	 torch.Size([64])
encoder.layers.0.layerc.sublayer.norm.bias 	 torch.Size([64])
encoder.layers.0.layerc.sublayer_.norm.weight 	 torch.Size([64])
encoder.layers.0.layerc.sublayer_.norm.bias 	 torch.Size([64])
encoder.layers.0.layerc2.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.0.layerc2.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.0.layerc2.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.0.layerc2.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.0.layerc2.self_attn.linears.2.weight 	 torch.Size([64, 64])
encoder.layers.0.layerc2.self_attn.linears.2.bias 	 torch.Size([64])
encoder.layers.0.layerc2.self_attn.linears.3.weight 	 torch.Size([64, 64])
encoder.layers.0.layerc2.self_attn.linears.3.bias 	 torch.Size([64])
encoder.layers.0.layerc2.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.0.layerc2.sublayer.norm.weight 	 torch.Size([64])
encoder.layers.0.layerc2.sublayer.norm.bias 	 torch.Size([64])
encoder.layers.0.layerc2.sublayer_.norm.weight 	 torch.Size([64])
encoder.layers.0.layerc2.sublayer_.norm.bias 	 torch.Size([64])
encoder.layers.1.layer.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.1.layer.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.1.layer.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.1.layer.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.1.layer.self_attn.linears.2.weight 	 torch.Size([64, 64])
encoder.layers.1.layer.self_attn.linears.2.bias 	 torch.Size([64])
encoder.layers.1.layer.self_attn.linears.3.weight 	 torch.Size([64, 64])
encoder.layers.1.layer.self_attn.linears.3.bias 	 torch.Size([64])
encoder.layers.1.layer.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.1.layer.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.layer.tcn.filter_convs.bias 	 torch.Size([64])
encoder.layers.1.layer.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.layer.tcn.gate_convs.bias 	 torch.Size([64])
encoder.layers.1.layer.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.1.layer.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.1.layer.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.1.layer.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.1.layer.sublayer.2.norm.weight 	 torch.Size([64])
encoder.layers.1.layer.sublayer.2.norm.bias 	 torch.Size([64])
encoder.layers.1.layer2.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.1.layer2.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.1.layer2.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.1.layer2.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.1.layer2.self_attn.linears.2.weight 	 torch.Size([64, 64])
encoder.layers.1.layer2.self_attn.linears.2.bias 	 torch.Size([64])
encoder.layers.1.layer2.self_attn.linears.3.weight 	 torch.Size([64, 64])
encoder.layers.1.layer2.self_attn.linears.3.bias 	 torch.Size([64])
encoder.layers.1.layer2.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.1.layer2.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.layer2.tcn.filter_convs.bias 	 torch.Size([64])
encoder.layers.1.layer2.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.layer2.tcn.gate_convs.bias 	 torch.Size([64])
encoder.layers.1.layer2.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.1.layer2.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.1.layer2.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.1.layer2.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.1.layer2.sublayer.2.norm.weight 	 torch.Size([64])
encoder.layers.1.layer2.sublayer.2.norm.bias 	 torch.Size([64])
encoder.layers.1.layerc.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.1.layerc.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.1.layerc.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.1.layerc.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.1.layerc.self_attn.linears.2.weight 	 torch.Size([64, 64])
encoder.layers.1.layerc.self_attn.linears.2.bias 	 torch.Size([64])
encoder.layers.1.layerc.self_attn.linears.3.weight 	 torch.Size([64, 64])
encoder.layers.1.layerc.self_attn.linears.3.bias 	 torch.Size([64])
encoder.layers.1.layerc.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.1.layerc.sublayer.norm.weight 	 torch.Size([64])
encoder.layers.1.layerc.sublayer.norm.bias 	 torch.Size([64])
encoder.layers.1.layerc.sublayer_.norm.weight 	 torch.Size([64])
encoder.layers.1.layerc.sublayer_.norm.bias 	 torch.Size([64])
encoder.layers.1.layerc2.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.1.layerc2.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.1.layerc2.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.1.layerc2.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.1.layerc2.self_attn.linears.2.weight 	 torch.Size([64, 64])
encoder.layers.1.layerc2.self_attn.linears.2.bias 	 torch.Size([64])
encoder.layers.1.layerc2.self_attn.linears.3.weight 	 torch.Size([64, 64])
encoder.layers.1.layerc2.self_attn.linears.3.bias 	 torch.Size([64])
encoder.layers.1.layerc2.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.1.layerc2.sublayer.norm.weight 	 torch.Size([64])
encoder.layers.1.layerc2.sublayer.norm.bias 	 torch.Size([64])
encoder.layers.1.layerc2.sublayer_.norm.weight 	 torch.Size([64])
encoder.layers.1.layerc2.sublayer_.norm.bias 	 torch.Size([64])
encoder.layers.2.layer.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.2.layer.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.2.layer.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.2.layer.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.2.layer.self_attn.linears.2.weight 	 torch.Size([64, 64])
encoder.layers.2.layer.self_attn.linears.2.bias 	 torch.Size([64])
encoder.layers.2.layer.self_attn.linears.3.weight 	 torch.Size([64, 64])
encoder.layers.2.layer.self_attn.linears.3.bias 	 torch.Size([64])
encoder.layers.2.layer.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.2.layer.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.layer.tcn.filter_convs.bias 	 torch.Size([64])
encoder.layers.2.layer.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.layer.tcn.gate_convs.bias 	 torch.Size([64])
encoder.layers.2.layer.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.2.layer.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.2.layer.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.2.layer.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.2.layer.sublayer.2.norm.weight 	 torch.Size([64])
encoder.layers.2.layer.sublayer.2.norm.bias 	 torch.Size([64])
encoder.layers.2.layer2.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.2.layer2.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.2.layer2.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.2.layer2.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.2.layer2.self_attn.linears.2.weight 	 torch.Size([64, 64])
encoder.layers.2.layer2.self_attn.linears.2.bias 	 torch.Size([64])
encoder.layers.2.layer2.self_attn.linears.3.weight 	 torch.Size([64, 64])
encoder.layers.2.layer2.self_attn.linears.3.bias 	 torch.Size([64])
encoder.layers.2.layer2.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.2.layer2.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.layer2.tcn.filter_convs.bias 	 torch.Size([64])
encoder.layers.2.layer2.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.layer2.tcn.gate_convs.bias 	 torch.Size([64])
encoder.layers.2.layer2.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.2.layer2.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.2.layer2.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.2.layer2.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.2.layer2.sublayer.2.norm.weight 	 torch.Size([64])
encoder.layers.2.layer2.sublayer.2.norm.bias 	 torch.Size([64])
encoder.layers.2.layerc.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.2.layerc.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.2.layerc.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.2.layerc.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.2.layerc.self_attn.linears.2.weight 	 torch.Size([64, 64])
encoder.layers.2.layerc.self_attn.linears.2.bias 	 torch.Size([64])
encoder.layers.2.layerc.self_attn.linears.3.weight 	 torch.Size([64, 64])
encoder.layers.2.layerc.self_attn.linears.3.bias 	 torch.Size([64])
encoder.layers.2.layerc.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.2.layerc.sublayer.norm.weight 	 torch.Size([64])
encoder.layers.2.layerc.sublayer.norm.bias 	 torch.Size([64])
encoder.layers.2.layerc.sublayer_.norm.weight 	 torch.Size([64])
encoder.layers.2.layerc.sublayer_.norm.bias 	 torch.Size([64])
encoder.layers.2.layerc2.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.2.layerc2.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.2.layerc2.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.2.layerc2.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.2.layerc2.self_attn.linears.2.weight 	 torch.Size([64, 64])
encoder.layers.2.layerc2.self_attn.linears.2.bias 	 torch.Size([64])
encoder.layers.2.layerc2.self_attn.linears.3.weight 	 torch.Size([64, 64])
encoder.layers.2.layerc2.self_attn.linears.3.bias 	 torch.Size([64])
encoder.layers.2.layerc2.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.2.layerc2.sublayer.norm.weight 	 torch.Size([64])
encoder.layers.2.layerc2.sublayer.norm.bias 	 torch.Size([64])
encoder.layers.2.layerc2.sublayer_.norm.weight 	 torch.Size([64])
encoder.layers.2.layerc2.sublayer_.norm.bias 	 torch.Size([64])
encoder.layers.3.layer.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.3.layer.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.3.layer.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.3.layer.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.3.layer.self_attn.linears.2.weight 	 torch.Size([64, 64])
encoder.layers.3.layer.self_attn.linears.2.bias 	 torch.Size([64])
encoder.layers.3.layer.self_attn.linears.3.weight 	 torch.Size([64, 64])
encoder.layers.3.layer.self_attn.linears.3.bias 	 torch.Size([64])
encoder.layers.3.layer.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.3.layer.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.3.layer.tcn.filter_convs.bias 	 torch.Size([64])
encoder.layers.3.layer.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.3.layer.tcn.gate_convs.bias 	 torch.Size([64])
encoder.layers.3.layer.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.3.layer.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.3.layer.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.3.layer.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.3.layer.sublayer.2.norm.weight 	 torch.Size([64])
encoder.layers.3.layer.sublayer.2.norm.bias 	 torch.Size([64])
encoder.layers.3.layer2.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.3.layer2.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.3.layer2.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.3.layer2.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.3.layer2.self_attn.linears.2.weight 	 torch.Size([64, 64])
encoder.layers.3.layer2.self_attn.linears.2.bias 	 torch.Size([64])
encoder.layers.3.layer2.self_attn.linears.3.weight 	 torch.Size([64, 64])
encoder.layers.3.layer2.self_attn.linears.3.bias 	 torch.Size([64])
encoder.layers.3.layer2.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.3.layer2.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.3.layer2.tcn.filter_convs.bias 	 torch.Size([64])
encoder.layers.3.layer2.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.3.layer2.tcn.gate_convs.bias 	 torch.Size([64])
encoder.layers.3.layer2.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.3.layer2.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.3.layer2.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.3.layer2.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.3.layer2.sublayer.2.norm.weight 	 torch.Size([64])
encoder.layers.3.layer2.sublayer.2.norm.bias 	 torch.Size([64])
encoder.layers.3.layerc.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.3.layerc.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.3.layerc.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.3.layerc.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.3.layerc.self_attn.linears.2.weight 	 torch.Size([64, 64])
encoder.layers.3.layerc.self_attn.linears.2.bias 	 torch.Size([64])
encoder.layers.3.layerc.self_attn.linears.3.weight 	 torch.Size([64, 64])
encoder.layers.3.layerc.self_attn.linears.3.bias 	 torch.Size([64])
encoder.layers.3.layerc.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.3.layerc.sublayer.norm.weight 	 torch.Size([64])
encoder.layers.3.layerc.sublayer.norm.bias 	 torch.Size([64])
encoder.layers.3.layerc.sublayer_.norm.weight 	 torch.Size([64])
encoder.layers.3.layerc.sublayer_.norm.bias 	 torch.Size([64])
encoder.layers.3.layerc2.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.3.layerc2.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.3.layerc2.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.3.layerc2.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.3.layerc2.self_attn.linears.2.weight 	 torch.Size([64, 64])
encoder.layers.3.layerc2.self_attn.linears.2.bias 	 torch.Size([64])
encoder.layers.3.layerc2.self_attn.linears.3.weight 	 torch.Size([64, 64])
encoder.layers.3.layerc2.self_attn.linears.3.bias 	 torch.Size([64])
encoder.layers.3.layerc2.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.3.layerc2.sublayer.norm.weight 	 torch.Size([64])
encoder.layers.3.layerc2.sublayer.norm.bias 	 torch.Size([64])
encoder.layers.3.layerc2.sublayer_.norm.weight 	 torch.Size([64])
encoder.layers.3.layerc2.sublayer_.norm.bias 	 torch.Size([64])
encoder.norm.weight 	 torch.Size([64])
encoder.norm.bias 	 torch.Size([64])
encoder.norm2.weight 	 torch.Size([64])
encoder.norm2.bias 	 torch.Size([64])
decoder.layers.0.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.0.self_attn.linears.2.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.linears.2.bias 	 torch.Size([64])
decoder.layers.0.self_attn.linears.3.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.linears.3.bias 	 torch.Size([64])
decoder.layers.0.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.0.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.linears.2.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.linears.2.bias 	 torch.Size([64])
decoder.layers.0.src_attn.linears.3.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.linears.3.bias 	 torch.Size([64])
decoder.layers.0.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.0.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.tcn.filter_convs.bias 	 torch.Size([64])
decoder.layers.0.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.tcn.gate_convs.bias 	 torch.Size([64])
decoder.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.3.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.3.norm.bias 	 torch.Size([64])
decoder.layers.1.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.1.self_attn.linears.2.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.linears.2.bias 	 torch.Size([64])
decoder.layers.1.self_attn.linears.3.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.linears.3.bias 	 torch.Size([64])
decoder.layers.1.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.1.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.linears.2.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.linears.2.bias 	 torch.Size([64])
decoder.layers.1.src_attn.linears.3.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.linears.3.bias 	 torch.Size([64])
decoder.layers.1.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.1.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.tcn.filter_convs.bias 	 torch.Size([64])
decoder.layers.1.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.tcn.gate_convs.bias 	 torch.Size([64])
decoder.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.3.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.3.norm.bias 	 torch.Size([64])
decoder.layers.2.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.2.self_attn.linears.2.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.linears.2.bias 	 torch.Size([64])
decoder.layers.2.self_attn.linears.3.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.linears.3.bias 	 torch.Size([64])
decoder.layers.2.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.2.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.linears.2.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.linears.2.bias 	 torch.Size([64])
decoder.layers.2.src_attn.linears.3.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.linears.3.bias 	 torch.Size([64])
decoder.layers.2.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.2.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.tcn.filter_convs.bias 	 torch.Size([64])
decoder.layers.2.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.tcn.gate_convs.bias 	 torch.Size([64])
decoder.layers.2.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.3.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.3.norm.bias 	 torch.Size([64])
decoder.layers.3.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.3.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.3.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.3.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.3.self_attn.linears.2.weight 	 torch.Size([64, 64])
decoder.layers.3.self_attn.linears.2.bias 	 torch.Size([64])
decoder.layers.3.self_attn.linears.3.weight 	 torch.Size([64, 64])
decoder.layers.3.self_attn.linears.3.bias 	 torch.Size([64])
decoder.layers.3.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.3.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.3.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.3.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.3.src_attn.linears.2.weight 	 torch.Size([64, 64])
decoder.layers.3.src_attn.linears.2.bias 	 torch.Size([64])
decoder.layers.3.src_attn.linears.3.weight 	 torch.Size([64, 64])
decoder.layers.3.src_attn.linears.3.bias 	 torch.Size([64])
decoder.layers.3.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.3.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.3.tcn.filter_convs.bias 	 torch.Size([64])
decoder.layers.3.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.3.tcn.gate_convs.bias 	 torch.Size([64])
decoder.layers.3.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.3.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.3.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.3.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.3.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.3.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.3.sublayer.3.norm.weight 	 torch.Size([64])
decoder.layers.3.sublayer.3.norm.bias 	 torch.Size([64])
decoder.norm.weight 	 torch.Size([64])
decoder.norm.bias 	 torch.Size([64])
decoder2.layers.0.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder2.layers.0.self_attn.linears.0.bias 	 torch.Size([64])
decoder2.layers.0.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder2.layers.0.self_attn.linears.1.bias 	 torch.Size([64])
decoder2.layers.0.self_attn.linears.2.weight 	 torch.Size([64, 64])
decoder2.layers.0.self_attn.linears.2.bias 	 torch.Size([64])
decoder2.layers.0.self_attn.linears.3.weight 	 torch.Size([64, 64])
decoder2.layers.0.self_attn.linears.3.bias 	 torch.Size([64])
decoder2.layers.0.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder2.layers.0.src_attn.linears.0.bias 	 torch.Size([64])
decoder2.layers.0.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder2.layers.0.src_attn.linears.1.bias 	 torch.Size([64])
decoder2.layers.0.src_attn.linears.2.weight 	 torch.Size([64, 64])
decoder2.layers.0.src_attn.linears.2.bias 	 torch.Size([64])
decoder2.layers.0.src_attn.linears.3.weight 	 torch.Size([64, 64])
decoder2.layers.0.src_attn.linears.3.bias 	 torch.Size([64])
decoder2.layers.0.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder2.layers.0.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder2.layers.0.tcn.filter_convs.bias 	 torch.Size([64])
decoder2.layers.0.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder2.layers.0.tcn.gate_convs.bias 	 torch.Size([64])
decoder2.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
decoder2.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
decoder2.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
decoder2.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
decoder2.layers.0.sublayer.2.norm.weight 	 torch.Size([64])
decoder2.layers.0.sublayer.2.norm.bias 	 torch.Size([64])
decoder2.layers.0.sublayer.3.norm.weight 	 torch.Size([64])
decoder2.layers.0.sublayer.3.norm.bias 	 torch.Size([64])
decoder2.layers.1.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder2.layers.1.self_attn.linears.0.bias 	 torch.Size([64])
decoder2.layers.1.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder2.layers.1.self_attn.linears.1.bias 	 torch.Size([64])
decoder2.layers.1.self_attn.linears.2.weight 	 torch.Size([64, 64])
decoder2.layers.1.self_attn.linears.2.bias 	 torch.Size([64])
decoder2.layers.1.self_attn.linears.3.weight 	 torch.Size([64, 64])
decoder2.layers.1.self_attn.linears.3.bias 	 torch.Size([64])
decoder2.layers.1.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder2.layers.1.src_attn.linears.0.bias 	 torch.Size([64])
decoder2.layers.1.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder2.layers.1.src_attn.linears.1.bias 	 torch.Size([64])
decoder2.layers.1.src_attn.linears.2.weight 	 torch.Size([64, 64])
decoder2.layers.1.src_attn.linears.2.bias 	 torch.Size([64])
decoder2.layers.1.src_attn.linears.3.weight 	 torch.Size([64, 64])
decoder2.layers.1.src_attn.linears.3.bias 	 torch.Size([64])
decoder2.layers.1.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder2.layers.1.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder2.layers.1.tcn.filter_convs.bias 	 torch.Size([64])
decoder2.layers.1.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder2.layers.1.tcn.gate_convs.bias 	 torch.Size([64])
decoder2.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
decoder2.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
decoder2.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
decoder2.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
decoder2.layers.1.sublayer.2.norm.weight 	 torch.Size([64])
decoder2.layers.1.sublayer.2.norm.bias 	 torch.Size([64])
decoder2.layers.1.sublayer.3.norm.weight 	 torch.Size([64])
decoder2.layers.1.sublayer.3.norm.bias 	 torch.Size([64])
decoder2.layers.2.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder2.layers.2.self_attn.linears.0.bias 	 torch.Size([64])
decoder2.layers.2.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder2.layers.2.self_attn.linears.1.bias 	 torch.Size([64])
decoder2.layers.2.self_attn.linears.2.weight 	 torch.Size([64, 64])
decoder2.layers.2.self_attn.linears.2.bias 	 torch.Size([64])
decoder2.layers.2.self_attn.linears.3.weight 	 torch.Size([64, 64])
decoder2.layers.2.self_attn.linears.3.bias 	 torch.Size([64])
decoder2.layers.2.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder2.layers.2.src_attn.linears.0.bias 	 torch.Size([64])
decoder2.layers.2.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder2.layers.2.src_attn.linears.1.bias 	 torch.Size([64])
decoder2.layers.2.src_attn.linears.2.weight 	 torch.Size([64, 64])
decoder2.layers.2.src_attn.linears.2.bias 	 torch.Size([64])
decoder2.layers.2.src_attn.linears.3.weight 	 torch.Size([64, 64])
decoder2.layers.2.src_attn.linears.3.bias 	 torch.Size([64])
decoder2.layers.2.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder2.layers.2.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder2.layers.2.tcn.filter_convs.bias 	 torch.Size([64])
decoder2.layers.2.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder2.layers.2.tcn.gate_convs.bias 	 torch.Size([64])
decoder2.layers.2.sublayer.0.norm.weight 	 torch.Size([64])
decoder2.layers.2.sublayer.0.norm.bias 	 torch.Size([64])
decoder2.layers.2.sublayer.1.norm.weight 	 torch.Size([64])
decoder2.layers.2.sublayer.1.norm.bias 	 torch.Size([64])
decoder2.layers.2.sublayer.2.norm.weight 	 torch.Size([64])
decoder2.layers.2.sublayer.2.norm.bias 	 torch.Size([64])
decoder2.layers.2.sublayer.3.norm.weight 	 torch.Size([64])
decoder2.layers.2.sublayer.3.norm.bias 	 torch.Size([64])
decoder2.layers.3.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder2.layers.3.self_attn.linears.0.bias 	 torch.Size([64])
decoder2.layers.3.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder2.layers.3.self_attn.linears.1.bias 	 torch.Size([64])
decoder2.layers.3.self_attn.linears.2.weight 	 torch.Size([64, 64])
decoder2.layers.3.self_attn.linears.2.bias 	 torch.Size([64])
decoder2.layers.3.self_attn.linears.3.weight 	 torch.Size([64, 64])
decoder2.layers.3.self_attn.linears.3.bias 	 torch.Size([64])
decoder2.layers.3.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder2.layers.3.src_attn.linears.0.bias 	 torch.Size([64])
decoder2.layers.3.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder2.layers.3.src_attn.linears.1.bias 	 torch.Size([64])
decoder2.layers.3.src_attn.linears.2.weight 	 torch.Size([64, 64])
decoder2.layers.3.src_attn.linears.2.bias 	 torch.Size([64])
decoder2.layers.3.src_attn.linears.3.weight 	 torch.Size([64, 64])
decoder2.layers.3.src_attn.linears.3.bias 	 torch.Size([64])
decoder2.layers.3.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder2.layers.3.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder2.layers.3.tcn.filter_convs.bias 	 torch.Size([64])
decoder2.layers.3.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder2.layers.3.tcn.gate_convs.bias 	 torch.Size([64])
decoder2.layers.3.sublayer.0.norm.weight 	 torch.Size([64])
decoder2.layers.3.sublayer.0.norm.bias 	 torch.Size([64])
decoder2.layers.3.sublayer.1.norm.weight 	 torch.Size([64])
decoder2.layers.3.sublayer.1.norm.bias 	 torch.Size([64])
decoder2.layers.3.sublayer.2.norm.weight 	 torch.Size([64])
decoder2.layers.3.sublayer.2.norm.bias 	 torch.Size([64])
decoder2.layers.3.sublayer.3.norm.weight 	 torch.Size([64])
decoder2.layers.3.sublayer.3.norm.bias 	 torch.Size([64])
decoder2.norm.weight 	 torch.Size([64])
decoder2.norm.bias 	 torch.Size([64])
src_embed.0.weight 	 torch.Size([64, 1])
src_embed.0.bias 	 torch.Size([64])
src_embed.1.pe 	 torch.Size([1, 1, 13, 64])
src_embed.2.embedding.weight 	 torch.Size([250, 64])
src_embed2.0.weight 	 torch.Size([64, 1])
src_embed2.0.bias 	 torch.Size([64])
src_embed2.1.pe 	 torch.Size([1, 1, 13, 64])
src_embed2.2.embedding.weight 	 torch.Size([250, 64])
trg_embed.0.weight 	 torch.Size([64, 1])
trg_embed.0.bias 	 torch.Size([64])
trg_embed.1.pe 	 torch.Size([1, 1, 12, 64])
trg_embed.2.embedding.weight 	 torch.Size([250, 64])
trg_embed2.0.weight 	 torch.Size([64, 1])
trg_embed2.0.bias 	 torch.Size([64])
trg_embed2.1.pe 	 torch.Size([1, 1, 12, 64])
trg_embed2.2.embedding.weight 	 torch.Size([250, 64])
prediction_generator.weight 	 torch.Size([1, 64])
prediction_generator.bias 	 torch.Size([1])
prediction_generator2.weight 	 torch.Size([1, 64])
prediction_generator2.bias 	 torch.Size([1])
Net's total params: 1103618
Optimizer's state_dict:
state 	 {}
param_groups 	 [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511]}]
validation batch 1 / 168, loss: 0.19
validation batch 101 / 168, loss: 0.23
validation cost time: 51.2904s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEcross/epoch_0.params
epoch: 0, learning rate 0.001000
epoch: 0, train time every whole data:232.49s
epoch: 0, total time:283.94s
validation batch 1 / 168, loss: 0.06
validation batch 101 / 168, loss: 0.03
validation cost time: 52.1250s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEcross/epoch_1.params
epoch: 1, learning rate 0.001000
epoch: 1, train time every whole data:234.59s
epoch: 1, total time:570.74s
validation batch 1 / 168, loss: 0.05
validation batch 101 / 168, loss: 0.03
validation cost time: 52.3512s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEcross/epoch_2.params
epoch: 2, learning rate 0.001000
epoch: 2, train time every whole data:234.38s
epoch: 2, total time:857.59s
validation batch 1 / 168, loss: 0.14
validation batch 101 / 168, loss: 0.11
validation cost time: 52.3820s
epoch: 3, learning rate 0.001000
epoch: 3, train time every whole data:234.34s
epoch: 3, total time:1144.31s
validation batch 1 / 168, loss: 0.08
validation batch 101 / 168, loss: 0.05
validation cost time: 52.1969s
epoch: 4, learning rate 0.001000
epoch: 4, train time every whole data:234.31s
epoch: 4, total time:1430.83s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.09
validation cost time: 52.0974s
epoch: 5, learning rate 0.001000
epoch: 5, train time every whole data:234.69s
epoch: 5, total time:1717.62s
validation batch 1 / 168, loss: 0.10
validation batch 101 / 168, loss: 0.03
validation cost time: 52.0769s
epoch: 6, learning rate 0.001000
epoch: 6, train time every whole data:234.35s
epoch: 6, total time:2004.05s
validation batch 1 / 168, loss: 0.10
validation batch 101 / 168, loss: 0.04
validation cost time: 52.2381s
epoch: 7, learning rate 0.001000
epoch: 7, train time every whole data:233.09s
epoch: 7, total time:2289.38s
validation batch 1 / 168, loss: 0.07
validation batch 101 / 168, loss: 0.03
validation cost time: 51.8084s
epoch: 8, learning rate 0.001000
epoch: 8, train time every whole data:233.40s
epoch: 8, total time:2574.59s
validation batch 1 / 168, loss: 0.10
validation batch 101 / 168, loss: 0.06
validation cost time: 51.7316s
epoch: 9, learning rate 0.001000
epoch: 9, train time every whole data:233.57s
epoch: 9, total time:2859.90s
validation batch 1 / 168, loss: 0.07
validation batch 101 / 168, loss: 0.04
validation cost time: 51.8392s
epoch: 10, learning rate 0.001000
epoch: 10, train time every whole data:233.66s
epoch: 10, total time:3145.40s
validation batch 1 / 168, loss: 0.09
validation batch 101 / 168, loss: 0.06
validation cost time: 51.7578s
epoch: 11, learning rate 0.001000
epoch: 11, train time every whole data:233.43s
epoch: 11, total time:3430.59s
validation batch 1 / 168, loss: 0.09
validation batch 101 / 168, loss: 0.03
validation cost time: 51.7985s
epoch: 12, learning rate 0.001000
epoch: 12, train time every whole data:233.33s
epoch: 12, total time:3715.72s
validation batch 1 / 168, loss: 0.08
validation batch 101 / 168, loss: 0.04
validation cost time: 51.8997s
epoch: 13, learning rate 0.001000
epoch: 13, train time every whole data:233.73s
epoch: 13, total time:4001.36s
validation batch 1 / 168, loss: 0.08
validation batch 101 / 168, loss: 0.04
validation cost time: 51.6994s
epoch: 14, learning rate 0.001000
epoch: 14, train time every whole data:233.25s
epoch: 14, total time:4286.32s
validation batch 1 / 168, loss: 0.10
validation batch 101 / 168, loss: 0.06
validation cost time: 51.9349s
epoch: 15, learning rate 0.001000
epoch: 15, train time every whole data:233.32s
epoch: 15, total time:4571.58s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.08
validation cost time: 51.7284s
epoch: 16, learning rate 0.001000
epoch: 16, train time every whole data:233.71s
epoch: 16, total time:4857.02s
validation batch 1 / 168, loss: 0.08
validation batch 101 / 168, loss: 0.03
validation cost time: 51.8393s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEcross/epoch_17.params
epoch: 17, learning rate 0.001000
epoch: 17, train time every whole data:234.03s
epoch: 17, total time:5143.11s
validation batch 1 / 168, loss: 0.09
validation batch 101 / 168, loss: 0.06
validation cost time: 51.8003s
epoch: 18, learning rate 0.001000
epoch: 18, train time every whole data:233.84s
epoch: 18, total time:5428.75s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 51.6804s
epoch: 19, learning rate 0.001000
epoch: 19, train time every whole data:233.55s
epoch: 19, total time:5713.99s
validation batch 1 / 168, loss: 0.08
validation batch 101 / 168, loss: 0.02
validation cost time: 51.7965s
epoch: 20, learning rate 0.001000
epoch: 20, train time every whole data:233.87s
epoch: 20, total time:5999.66s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 52.3170s
epoch: 21, learning rate 0.001000
epoch: 21, train time every whole data:232.45s
epoch: 21, total time:6284.43s
validation batch 1 / 168, loss: 0.15
validation batch 101 / 168, loss: 0.02
validation cost time: 51.4162s
epoch: 22, learning rate 0.001000
epoch: 22, train time every whole data:232.30s
epoch: 22, total time:6568.15s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 51.4509s
epoch: 23, learning rate 0.001000
epoch: 23, train time every whole data:232.01s
epoch: 23, total time:6851.61s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 51.5080s
epoch: 24, learning rate 0.001000
epoch: 24, train time every whole data:232.79s
epoch: 24, total time:7135.92s
validation batch 1 / 168, loss: 0.05
validation batch 101 / 168, loss: 0.02
validation cost time: 51.5223s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEcross/epoch_25.params
epoch: 25, learning rate 0.001000
epoch: 25, train time every whole data:233.03s
epoch: 25, total time:7420.61s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 51.6288s
epoch: 26, learning rate 0.001000
epoch: 26, train time every whole data:233.14s
epoch: 26, total time:7705.39s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 51.5431s
epoch: 27, learning rate 0.001000
epoch: 27, train time every whole data:233.26s
epoch: 27, total time:7990.20s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 51.5726s
epoch: 28, learning rate 0.001000
epoch: 28, train time every whole data:233.25s
epoch: 28, total time:8275.03s
validation batch 1 / 168, loss: 0.08
validation batch 101 / 168, loss: 0.02
validation cost time: 51.5217s
epoch: 29, learning rate 0.001000
epoch: 29, train time every whole data:233.04s
epoch: 29, total time:8559.59s
validation batch 1 / 168, loss: 0.08
validation batch 101 / 168, loss: 0.02
validation cost time: 51.6085s
epoch: 30, learning rate 0.001000
epoch: 30, train time every whole data:232.30s
epoch: 30, total time:8843.51s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 51.3584s
epoch: 31, learning rate 0.001000
epoch: 31, train time every whole data:232.30s
epoch: 31, total time:9127.17s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 51.4730s
epoch: 32, learning rate 0.001000
epoch: 32, train time every whole data:232.45s
epoch: 32, total time:9411.10s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 51.5548s
epoch: 33, learning rate 0.001000
epoch: 33, train time every whole data:232.69s
epoch: 33, total time:9695.35s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 51.4308s
epoch: 34, learning rate 0.001000
epoch: 34, train time every whole data:232.29s
epoch: 34, total time:9979.08s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 51.3537s
epoch: 35, learning rate 0.001000
epoch: 35, train time every whole data:232.26s
epoch: 35, total time:10262.69s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 51.4443s
epoch: 36, learning rate 0.001000
epoch: 36, train time every whole data:232.36s
epoch: 36, total time:10546.50s
validation batch 1 / 168, loss: 0.15
validation batch 101 / 168, loss: 0.02
validation cost time: 51.4140s
epoch: 37, learning rate 0.001000
epoch: 37, train time every whole data:232.39s
epoch: 37, total time:10830.31s
validation batch 1 / 168, loss: 0.15
validation batch 101 / 168, loss: 0.02
validation cost time: 51.4047s
epoch: 38, learning rate 0.001000
epoch: 38, train time every whole data:229.87s
epoch: 38, total time:11111.59s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 51.5600s
epoch: 39, learning rate 0.001000
epoch: 39, train time every whole data:232.08s
epoch: 39, total time:11395.23s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 51.3133s
epoch: 40, learning rate 0.001000
epoch: 40, train time every whole data:229.77s
epoch: 40, total time:11676.32s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 51.5362s
epoch: 41, learning rate 0.001000
epoch: 41, train time every whole data:228.43s
epoch: 41, total time:11956.29s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 51.5251s
epoch: 42, learning rate 0.001000
epoch: 42, train time every whole data:232.11s
epoch: 42, total time:12239.93s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 51.4944s
epoch: 43, learning rate 0.001000
epoch: 43, train time every whole data:232.16s
epoch: 43, total time:12523.59s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 51.5022s
epoch: 44, learning rate 0.001000
epoch: 44, train time every whole data:232.29s
epoch: 44, total time:12807.39s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 51.4611s
epoch: 45, learning rate 0.001000
epoch: 45, train time every whole data:232.33s
epoch: 45, total time:13091.19s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 51.3618s
epoch: 46, learning rate 0.001000
epoch: 46, train time every whole data:232.20s
epoch: 46, total time:13374.76s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 51.5624s
epoch: 47, learning rate 0.001000
epoch: 47, train time every whole data:232.08s
epoch: 47, total time:13658.41s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 51.3110s
epoch: 48, learning rate 0.001000
epoch: 48, train time every whole data:232.07s
epoch: 48, total time:13941.79s
validation batch 1 / 168, loss: 0.14
validation batch 101 / 168, loss: 0.02
validation cost time: 51.4799s
epoch: 49, learning rate 0.001000
epoch: 49, train time every whole data:227.70s
epoch: 49, total time:14220.97s
validation batch 1 / 168, loss: 0.10
validation batch 101 / 168, loss: 0.02
validation cost time: 51.3262s
epoch: 50, learning rate 0.001000
epoch: 50, train time every whole data:232.08s
epoch: 50, total time:14504.38s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 51.2968s
epoch: 51, learning rate 0.001000
epoch: 51, train time every whole data:232.20s
epoch: 51, total time:14787.88s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 51.6212s
epoch: 52, learning rate 0.001000
epoch: 52, train time every whole data:232.46s
epoch: 52, total time:15071.97s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 51.2554s
epoch: 53, learning rate 0.001000
epoch: 53, train time every whole data:232.17s
epoch: 53, total time:15355.40s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 51.4350s
epoch: 54, learning rate 0.001000
epoch: 54, train time every whole data:232.14s
epoch: 54, total time:15638.97s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 51.3965s
epoch: 55, learning rate 0.001000
epoch: 55, train time every whole data:232.13s
epoch: 55, total time:15922.51s
validation batch 1 / 168, loss: 0.14
validation batch 101 / 168, loss: 0.02
validation cost time: 51.5242s
epoch: 56, learning rate 0.001000
epoch: 56, train time every whole data:232.13s
epoch: 56, total time:16206.17s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 51.3691s
epoch: 57, learning rate 0.001000
epoch: 57, train time every whole data:232.12s
epoch: 57, total time:16489.67s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 51.4302s
epoch: 58, learning rate 0.001000
epoch: 58, train time every whole data:232.13s
epoch: 58, total time:16773.23s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 51.3291s
epoch: 59, learning rate 0.001000
epoch: 59, train time every whole data:232.22s
epoch: 59, total time:17056.79s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 51.4463s
epoch: 60, learning rate 0.001000
epoch: 60, train time every whole data:232.01s
epoch: 60, total time:17340.25s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 51.3137s
epoch: 61, learning rate 0.001000
epoch: 61, train time every whole data:232.21s
epoch: 61, total time:17623.78s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 51.3248s
epoch: 62, learning rate 0.001000
epoch: 62, train time every whole data:232.17s
epoch: 62, total time:17907.27s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 51.5264s
epoch: 63, learning rate 0.001000
epoch: 63, train time every whole data:232.30s
epoch: 63, total time:18191.10s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 51.5477s
epoch: 64, learning rate 0.001000
epoch: 64, train time every whole data:232.25s
epoch: 64, total time:18474.91s
validation batch 1 / 168, loss: 0.10
validation batch 101 / 168, loss: 0.02
validation cost time: 51.4087s
epoch: 65, learning rate 0.001000
epoch: 65, train time every whole data:232.27s
epoch: 65, total time:18758.60s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 51.3677s
epoch: 66, learning rate 0.001000
epoch: 66, train time every whole data:232.24s
epoch: 66, total time:19042.21s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 51.3384s
epoch: 67, learning rate 0.001000
epoch: 67, train time every whole data:232.10s
epoch: 67, total time:19325.66s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 51.4140s
epoch: 68, learning rate 0.001000
epoch: 68, train time every whole data:228.74s
epoch: 68, total time:19605.81s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 51.5196s
epoch: 69, learning rate 0.001000
epoch: 69, train time every whole data:233.13s
epoch: 69, total time:19890.47s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 51.7065s
epoch: 70, learning rate 0.001000
epoch: 70, train time every whole data:233.28s
epoch: 70, total time:20175.46s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 51.5608s
epoch: 71, learning rate 0.001000
epoch: 71, train time every whole data:233.36s
epoch: 71, total time:20460.39s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 51.6361s
epoch: 72, learning rate 0.001000
epoch: 72, train time every whole data:233.16s
epoch: 72, total time:20745.19s
validation batch 1 / 168, loss: 0.15
validation batch 101 / 168, loss: 0.02
validation cost time: 51.5434s
epoch: 73, learning rate 0.001000
epoch: 73, train time every whole data:233.26s
epoch: 73, total time:21030.00s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 51.5191s
epoch: 74, learning rate 0.001000
epoch: 74, train time every whole data:233.09s
epoch: 74, total time:21314.61s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 51.4180s
epoch: 75, learning rate 0.001000
epoch: 75, train time every whole data:232.32s
epoch: 75, total time:21598.36s
validation batch 1 / 168, loss: 0.14
validation batch 101 / 168, loss: 0.02
validation cost time: 51.3713s
epoch: 76, learning rate 0.001000
epoch: 76, train time every whole data:232.00s
epoch: 76, total time:21881.73s
validation batch 1 / 168, loss: 0.14
validation batch 101 / 168, loss: 0.02
validation cost time: 51.3027s
epoch: 77, learning rate 0.001000
epoch: 77, train time every whole data:232.20s
epoch: 77, total time:22165.24s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 51.3622s
epoch: 78, learning rate 0.001000
epoch: 78, train time every whole data:232.23s
epoch: 78, total time:22448.83s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 51.4797s
epoch: 79, learning rate 0.001000
epoch: 79, train time every whole data:232.06s
epoch: 79, total time:22732.38s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 51.4075s
epoch: 80, learning rate 0.001000
epoch: 80, train time every whole data:232.15s
epoch: 80, total time:23015.94s
validation batch 1 / 168, loss: 0.14
validation batch 101 / 168, loss: 0.02
validation cost time: 51.2892s
epoch: 81, learning rate 0.001000
epoch: 81, train time every whole data:232.16s
epoch: 81, total time:23299.40s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 51.3994s
epoch: 82, learning rate 0.001000
epoch: 82, train time every whole data:232.40s
epoch: 82, total time:23583.20s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 51.3809s
epoch: 83, learning rate 0.001000
epoch: 83, train time every whole data:232.23s
epoch: 83, total time:23866.82s
validation batch 1 / 168, loss: 0.15
validation batch 101 / 168, loss: 0.02
validation cost time: 51.4311s
epoch: 84, learning rate 0.001000
epoch: 84, train time every whole data:232.43s
epoch: 84, total time:24150.68s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 51.5553s
epoch: 85, learning rate 0.001000
epoch: 85, train time every whole data:233.16s
epoch: 85, total time:24435.41s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 53.0631s
epoch: 86, learning rate 0.001000
epoch: 86, train time every whole data:235.44s
epoch: 86, total time:24723.92s
validation batch 1 / 168, loss: 0.15
validation batch 101 / 168, loss: 0.02
validation cost time: 52.1337s
epoch: 87, learning rate 0.001000
epoch: 87, train time every whole data:235.11s
epoch: 87, total time:25011.17s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 52.1653s
epoch: 88, learning rate 0.001000
epoch: 88, train time every whole data:234.87s
epoch: 88, total time:25298.21s
validation batch 1 / 168, loss: 0.14
validation batch 101 / 168, loss: 0.02
validation cost time: 52.3525s
epoch: 89, learning rate 0.001000
epoch: 89, train time every whole data:234.83s
epoch: 89, total time:25585.41s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 52.5414s
epoch: 90, learning rate 0.001000
epoch: 90, train time every whole data:235.55s
epoch: 90, total time:25873.51s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 51.9238s
epoch: 91, learning rate 0.001000
epoch: 91, train time every whole data:234.90s
epoch: 91, total time:26160.34s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 51.7759s
epoch: 92, learning rate 0.001000
epoch: 92, train time every whole data:234.39s
epoch: 92, total time:26446.50s
validation batch 1 / 168, loss: 0.16
validation batch 101 / 168, loss: 0.02
validation cost time: 52.1931s
epoch: 93, learning rate 0.001000
epoch: 93, train time every whole data:234.83s
epoch: 93, total time:26733.53s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 51.9315s
epoch: 94, learning rate 0.001000
epoch: 94, train time every whole data:234.81s
epoch: 94, total time:27020.27s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 52.2629s
epoch: 95, learning rate 0.001000
epoch: 95, train time every whole data:234.87s
epoch: 95, total time:27307.41s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 51.6895s
epoch: 96, learning rate 0.001000
epoch: 96, train time every whole data:234.53s
epoch: 96, total time:27593.64s
validation batch 1 / 168, loss: 0.16
validation batch 101 / 168, loss: 0.02
validation cost time: 52.0093s
epoch: 97, learning rate 0.001000
epoch: 97, train time every whole data:234.56s
epoch: 97, total time:27880.21s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 51.8855s
epoch: 98, learning rate 0.001000
epoch: 98, train time every whole data:234.07s
epoch: 98, total time:28166.17s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 51.9668s
epoch: 99, learning rate 0.001000
epoch: 99, train time every whole data:234.86s
epoch: 99, total time:28453.00s
best epoch: 25
apply the best val model on the test data set ...
load weight from: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEcross/epoch_25.params
predicting testing set batch 1 / 168, time: 0.30s
predicting testing set batch 101 / 168, time: 31.34s
test time on whole data:52.20s
input: (672, 250, 12, 2)
prediction: (672, 250, 12, 2)
data_target_tensor: (672, 250, 12, 2)
current epoch: 25, predict 0 points
MAE: 1.61
RMSE: 2.61
MAPE: 54.18
PCC: 0.84
current epoch: 25, predict 1 points
MAE: 1.73
RMSE: 2.84
MAPE: 59.59
PCC: 0.80
current epoch: 25, predict 2 points
MAE: 1.86
RMSE: 3.08
MAPE: 64.81
PCC: 0.76
current epoch: 25, predict 3 points
MAE: 1.98
RMSE: 3.33
MAPE: 69.74
PCC: 0.73
current epoch: 25, predict 4 points
MAE: 2.09
RMSE: 3.55
MAPE: 73.97
PCC: 0.69
current epoch: 25, predict 5 points
MAE: 2.19
RMSE: 3.74
MAPE: 77.58
PCC: 0.65
current epoch: 25, predict 6 points
MAE: 2.30
RMSE: 3.96
MAPE: 81.05
PCC: 0.60
current epoch: 25, predict 7 points
MAE: 2.39
RMSE: 4.14
MAPE: 83.59
PCC: 0.56
current epoch: 25, predict 8 points
MAE: 2.45
RMSE: 4.23
MAPE: 85.09
PCC: 0.53
current epoch: 25, predict 9 points
MAE: 2.49
RMSE: 4.27
MAPE: 85.99
PCC: 0.51
current epoch: 25, predict 10 points
MAE: 2.50
RMSE: 4.27
MAPE: 84.91
PCC: 0.50
current epoch: 25, predict 11 points
MAE: 2.46
RMSE: 4.18
MAPE: 80.91
PCC: 0.51
all MAE: 2.17
all RMSE: 3.73
all MAPE: 75.12
all PCC: 0.51
1.6102270189706414 2.605991601443742 54.17787783786368 0.8383828223582596 
1.7328659368101507 2.843924516950809 59.58821083218554 0.7988929157867575 
1.8556242433738495 3.0845903372054013 64.80603870569017 0.7631531907931273 
1.9781482822207646 3.3338547408298957 69.74351723544424 0.725974056302685 
2.088168092694577 3.5507818718900466 73.97294782830667 0.6908371421451548 
2.1891707474320596 3.7445553801094555 77.57759630377643 0.6527853558453623 
2.295856999730514 3.961342631790082 81.04528897816512 0.604666254728084 
2.3871749498449444 4.139214543323732 83.58534602425462 0.5600244090031304 
2.448951866571126 4.2337918077237795 85.08513466076093 0.5298435587333307 
2.489876158618501 4.272140657552197 85.98879712342617 0.5129199197946891 
2.50273000833605 4.27057832948045 84.90670204030909 0.4990633039672292 
2.4584619212115983 4.183829291085085 80.91226265332021 0.5108414506929002 
2.169771352151231 3.7291856675756865 75.11643418804795 0.5108414506929002 
fine tune the model ... 
epoch: 100, learning rate 0.000100
epoch: 100, train time every whole data:429.56s
epoch: 100, total time:28945.68s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 51.6394s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEcross/epoch_100.params
epoch: 101, learning rate 0.000100
epoch: 101, train time every whole data:430.64s
epoch: 101, total time:29428.12s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 52.1285s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEcross/epoch_101.params
epoch: 102, learning rate 0.000100
epoch: 102, train time every whole data:429.33s
epoch: 102, total time:29909.76s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 52.0627s
epoch: 103, learning rate 0.000100
epoch: 103, train time every whole data:428.90s
epoch: 103, total time:30390.74s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 52.0062s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEcross/epoch_103.params
epoch: 104, learning rate 0.000100
epoch: 104, train time every whole data:429.77s
epoch: 104, total time:30872.64s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 51.9999s
epoch: 105, learning rate 0.000100
epoch: 105, train time every whole data:429.05s
epoch: 105, total time:31353.70s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 51.7459s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEcross/epoch_105.params
epoch: 106, learning rate 0.000100
epoch: 106, train time every whole data:430.70s
epoch: 106, total time:31836.23s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 52.0543s
epoch: 107, learning rate 0.000100
epoch: 107, train time every whole data:429.58s
epoch: 107, total time:32317.88s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 52.1134s
epoch: 108, learning rate 0.000100
epoch: 108, train time every whole data:429.23s
epoch: 108, total time:32799.22s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 51.7871s
epoch: 109, learning rate 0.000100
epoch: 109, train time every whole data:429.67s
epoch: 109, total time:33280.68s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 51.7506s
epoch: 110, learning rate 0.000100
epoch: 110, train time every whole data:429.54s
epoch: 110, total time:33761.98s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 52.0086s
epoch: 111, learning rate 0.000100
epoch: 111, train time every whole data:429.42s
epoch: 111, total time:34243.41s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 52.1748s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEcross/epoch_111.params
epoch: 112, learning rate 0.000100
epoch: 112, train time every whole data:430.21s
epoch: 112, total time:34725.92s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 51.6345s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEcross/epoch_112.params
epoch: 113, learning rate 0.000100
epoch: 113, train time every whole data:430.15s
epoch: 113, total time:35207.85s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 51.9382s
epoch: 114, learning rate 0.000100
epoch: 114, train time every whole data:429.78s
epoch: 114, total time:35689.57s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 52.2550s
epoch: 115, learning rate 0.000100
epoch: 115, train time every whole data:430.74s
epoch: 115, total time:36172.57s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 52.1199s
epoch: 116, learning rate 0.000100
epoch: 116, train time every whole data:430.96s
epoch: 116, total time:36655.65s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 51.7219s
epoch: 117, learning rate 0.000100
epoch: 117, train time every whole data:429.64s
epoch: 117, total time:37137.02s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 51.8895s
epoch: 118, learning rate 0.000100
epoch: 118, train time every whole data:430.72s
epoch: 118, total time:37619.63s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 52.1114s
epoch: 119, learning rate 0.000100
epoch: 119, train time every whole data:429.71s
epoch: 119, total time:38101.46s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 52.0108s
epoch: 120, learning rate 0.000100
epoch: 120, train time every whole data:430.26s
epoch: 120, total time:38583.74s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 51.7313s
epoch: 121, learning rate 0.000100
epoch: 121, train time every whole data:429.98s
epoch: 121, total time:39065.46s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 51.8788s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEcross/epoch_121.params
epoch: 122, learning rate 0.000100
epoch: 122, train time every whole data:429.75s
epoch: 122, total time:39547.21s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 52.0185s
epoch: 123, learning rate 0.000100
epoch: 123, train time every whole data:430.14s
epoch: 123, total time:40029.38s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 51.8090s
epoch: 124, learning rate 0.000100
epoch: 124, train time every whole data:431.12s
epoch: 124, total time:40512.31s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 51.7982s
epoch: 125, learning rate 0.000100
epoch: 125, train time every whole data:430.43s
epoch: 125, total time:40994.54s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 52.3194s
epoch: 126, learning rate 0.000100
epoch: 126, train time every whole data:429.80s
epoch: 126, total time:41476.67s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 52.0864s
epoch: 127, learning rate 0.000100
epoch: 127, train time every whole data:429.75s
epoch: 127, total time:41958.51s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 52.0280s
epoch: 128, learning rate 0.000100
epoch: 128, train time every whole data:430.42s
epoch: 128, total time:42440.96s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 51.8591s
epoch: 129, learning rate 0.000100
epoch: 129, train time every whole data:430.01s
epoch: 129, total time:42922.84s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 52.0553s
epoch: 130, learning rate 0.000100
epoch: 130, train time every whole data:429.91s
epoch: 130, total time:43404.81s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 52.0637s
epoch: 131, learning rate 0.000100
epoch: 131, train time every whole data:431.06s
epoch: 131, total time:43887.94s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 51.6915s
epoch: 132, learning rate 0.000100
epoch: 132, train time every whole data:430.54s
epoch: 132, total time:44370.17s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 51.7065s
epoch: 133, learning rate 0.000100
epoch: 133, train time every whole data:430.28s
epoch: 133, total time:44852.17s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 52.1471s
epoch: 134, learning rate 0.000100
epoch: 134, train time every whole data:430.60s
epoch: 134, total time:45334.92s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 52.2006s
epoch: 135, learning rate 0.000100
epoch: 135, train time every whole data:428.89s
epoch: 135, total time:45816.02s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 51.8947s
epoch: 136, learning rate 0.000100
epoch: 136, train time every whole data:430.12s
epoch: 136, total time:46298.04s
