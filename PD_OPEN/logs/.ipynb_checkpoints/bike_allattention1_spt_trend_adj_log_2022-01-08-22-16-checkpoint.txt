total training epoch, fine tune epoch: 40 , 40
batch_size: 4
folder_dir: MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention1_spt_trend_adj
load file: data/bike.npz
ori length: 3001 , percent: 1.0 , scale: 3001
train: torch.Size([3001, 250, 2, 12]) torch.Size([3001, 250, 2, 12]) torch.Size([3001, 250, 2, 12])
val: torch.Size([672, 250, 2, 12]) torch.Size([672, 250, 2, 12]) torch.Size([672, 250, 2, 12])
test: torch.Size([672, 250, 2, 12]) torch.Size([672, 250, 2, 12]) torch.Size([672, 250, 2, 12])
TemporalPositionalEncoding max_len: 12
h_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
en_lookup_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
EncoderDecoder(
  (encoder): Encoder(
    (layers): ModuleList(
      (0): EncoderLayer(
        (self_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (2): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (3): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (feed_forward_gcn): ModuleList(
          (0): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn_cross): spatialAttentionScaledGCN_cross(
          (Theta1): Linear(in_features=64, out_features=64, bias=False)
          (Theta2): Linear(in_features=64, out_features=64, bias=False)
          (SAt_cross): Spatial_Attention_layer_cross(
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (6): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (7): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (sublayer2): SublayerConnection2(
          (dropout): Dropout(p=0.0, inplace=False)
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): EncoderLayer(
        (self_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (2): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (3): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (feed_forward_gcn): ModuleList(
          (0): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn_cross): spatialAttentionScaledGCN_cross(
          (Theta1): Linear(in_features=64, out_features=64, bias=False)
          (Theta2): Linear(in_features=64, out_features=64, bias=False)
          (SAt_cross): Spatial_Attention_layer_cross(
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (6): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (7): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (sublayer2): SublayerConnection2(
          (dropout): Dropout(p=0.0, inplace=False)
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): EncoderLayer(
        (self_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (2): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (3): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (feed_forward_gcn): ModuleList(
          (0): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn_cross): spatialAttentionScaledGCN_cross(
          (Theta1): Linear(in_features=64, out_features=64, bias=False)
          (Theta2): Linear(in_features=64, out_features=64, bias=False)
          (SAt_cross): Spatial_Attention_layer_cross(
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (6): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (7): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (sublayer2): SublayerConnection2(
          (dropout): Dropout(p=0.0, inplace=False)
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): Decoder(
    (layers): ModuleList(
      (0): DecoderLayer(
        (self_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_qc_kc(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_qc_kc(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (src_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (2): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (3): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (feed_forward_gcn): ModuleList(
          (0): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn_cross): spatialAttentionScaledGCN_cross(
          (Theta1): Linear(in_features=64, out_features=64, bias=False)
          (Theta2): Linear(in_features=64, out_features=64, bias=False)
          (SAt_cross): Spatial_Attention_layer_cross(
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (6): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (7): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (8): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (9): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (sublayer2): SublayerConnection2(
          (dropout): Dropout(p=0.0, inplace=False)
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): DecoderLayer(
        (self_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_qc_kc(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_qc_kc(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (src_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (2): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (3): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (feed_forward_gcn): ModuleList(
          (0): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn_cross): spatialAttentionScaledGCN_cross(
          (Theta1): Linear(in_features=64, out_features=64, bias=False)
          (Theta2): Linear(in_features=64, out_features=64, bias=False)
          (SAt_cross): Spatial_Attention_layer_cross(
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (6): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (7): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (8): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (9): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (sublayer2): SublayerConnection2(
          (dropout): Dropout(p=0.0, inplace=False)
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): DecoderLayer(
        (self_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_qc_kc(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_qc_kc(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (src_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (2): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (3): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (feed_forward_gcn): ModuleList(
          (0): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn_cross): spatialAttentionScaledGCN_cross(
          (Theta1): Linear(in_features=64, out_features=64, bias=False)
          (Theta2): Linear(in_features=64, out_features=64, bias=False)
          (SAt_cross): Spatial_Attention_layer_cross(
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (6): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (7): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (8): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (9): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (sublayer2): SublayerConnection2(
          (dropout): Dropout(p=0.0, inplace=False)
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (src_embed): Sequential(
    (0): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (1): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(250, 64)
    )
  )
  (src_embed2): Sequential(
    (0): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (1): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(250, 64)
    )
  )
  (trg_embed): Sequential(
    (0): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (1): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(250, 64)
    )
  )
  (trg_embed2): Sequential(
    (0): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (1): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(250, 64)
    )
  )
  (prediction_generator): Linear(in_features=64, out_features=1, bias=True)
  (prediction_generator2): Linear(in_features=64, out_features=1, bias=True)
)
delete the old one and create params directory experiments/bike/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention1_spt_trend_adj
Net's state_dict:
encoder.layers.0.self_attn.0.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.0.linears.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.0.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.0.linears.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.1.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.1.linears.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.1.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.1.linears.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.2.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.2.linears.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.2.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.2.linears.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.2.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.2.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.2.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.2.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.3.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.3.linears.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.3.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.3.linears.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.3.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.3.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.3.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.3.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.0.feed_forward_gcn.0.Theta.weight 	 torch.Size([64, 64])
encoder.layers.0.feed_forward_gcn.1.Theta.weight 	 torch.Size([64, 64])
encoder.layers.0.feed_forward_gcn_cross.Theta1.weight 	 torch.Size([64, 64])
encoder.layers.0.feed_forward_gcn_cross.Theta2.weight 	 torch.Size([64, 64])
encoder.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.2.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.2.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.3.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.3.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.4.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.4.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.5.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.5.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.6.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.6.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.7.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.7.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer2.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer2.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer2.norm2.weight 	 torch.Size([64])
encoder.layers.0.sublayer2.norm2.bias 	 torch.Size([64])
encoder.layers.1.self_attn.0.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.0.linears.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.0.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.0.linears.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.1.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.1.linears.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.1.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.1.linears.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.2.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.2.linears.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.2.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.2.linears.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.2.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.2.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.2.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.2.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.3.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.3.linears.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.3.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.3.linears.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.3.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.3.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.3.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.3.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.1.feed_forward_gcn.0.Theta.weight 	 torch.Size([64, 64])
encoder.layers.1.feed_forward_gcn.1.Theta.weight 	 torch.Size([64, 64])
encoder.layers.1.feed_forward_gcn_cross.Theta1.weight 	 torch.Size([64, 64])
encoder.layers.1.feed_forward_gcn_cross.Theta2.weight 	 torch.Size([64, 64])
encoder.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.2.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.2.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.3.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.3.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.4.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.4.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.5.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.5.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.6.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.6.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.7.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.7.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer2.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer2.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer2.norm2.weight 	 torch.Size([64])
encoder.layers.1.sublayer2.norm2.bias 	 torch.Size([64])
encoder.layers.2.self_attn.0.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.0.linears.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.0.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.0.linears.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.0.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.0.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.0.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.0.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.1.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.1.linears.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.1.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.1.linears.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.1.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.1.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.1.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.1.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.2.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.2.linears.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.2.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.2.linears.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.2.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.2.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.2.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.2.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.3.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.3.linears.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.3.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.3.linears.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.3.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.3.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.3.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.3.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.2.feed_forward_gcn.0.Theta.weight 	 torch.Size([64, 64])
encoder.layers.2.feed_forward_gcn.1.Theta.weight 	 torch.Size([64, 64])
encoder.layers.2.feed_forward_gcn_cross.Theta1.weight 	 torch.Size([64, 64])
encoder.layers.2.feed_forward_gcn_cross.Theta2.weight 	 torch.Size([64, 64])
encoder.layers.2.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.2.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.2.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.3.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.3.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.4.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.4.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.5.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.5.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.6.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.6.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.7.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.7.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer2.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer2.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer2.norm2.weight 	 torch.Size([64])
encoder.layers.2.sublayer2.norm2.bias 	 torch.Size([64])
encoder.norm.weight 	 torch.Size([64])
encoder.norm.bias 	 torch.Size([64])
encoder.norm2.weight 	 torch.Size([64])
encoder.norm2.bias 	 torch.Size([64])
decoder.layers.0.self_attn.0.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.0.linears.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.0.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.0.linears.1.bias 	 torch.Size([64])
decoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.0.self_attn.1.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.1.linears.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.1.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.1.linears.1.bias 	 torch.Size([64])
decoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.0.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.0.linears.0.bias 	 torch.Size([64])
decoder.layers.0.src_attn.0.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.0.linears.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.0.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.0.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.0.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.0.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.1.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.1.linears.0.bias 	 torch.Size([64])
decoder.layers.0.src_attn.1.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.1.linears.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.1.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.1.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.1.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.1.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.2.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.2.linears.0.bias 	 torch.Size([64])
decoder.layers.0.src_attn.2.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.2.linears.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.2.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.2.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.2.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.2.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.3.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.3.linears.0.bias 	 torch.Size([64])
decoder.layers.0.src_attn.3.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.3.linears.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.3.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.3.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.3.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.3.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.feed_forward_gcn.0.Theta.weight 	 torch.Size([64, 64])
decoder.layers.0.feed_forward_gcn.1.Theta.weight 	 torch.Size([64, 64])
decoder.layers.0.feed_forward_gcn_cross.Theta1.weight 	 torch.Size([64, 64])
decoder.layers.0.feed_forward_gcn_cross.Theta2.weight 	 torch.Size([64, 64])
decoder.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.3.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.3.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.4.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.4.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.5.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.5.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.6.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.6.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.7.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.7.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.8.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.8.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.9.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.9.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer2.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer2.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer2.norm2.weight 	 torch.Size([64])
decoder.layers.0.sublayer2.norm2.bias 	 torch.Size([64])
decoder.layers.1.self_attn.0.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.0.linears.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.0.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.0.linears.1.bias 	 torch.Size([64])
decoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.1.self_attn.1.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.1.linears.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.1.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.1.linears.1.bias 	 torch.Size([64])
decoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.0.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.0.linears.0.bias 	 torch.Size([64])
decoder.layers.1.src_attn.0.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.0.linears.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.0.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.0.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.0.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.0.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.1.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.1.linears.0.bias 	 torch.Size([64])
decoder.layers.1.src_attn.1.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.1.linears.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.1.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.1.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.1.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.1.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.2.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.2.linears.0.bias 	 torch.Size([64])
decoder.layers.1.src_attn.2.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.2.linears.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.2.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.2.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.2.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.2.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.3.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.3.linears.0.bias 	 torch.Size([64])
decoder.layers.1.src_attn.3.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.3.linears.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.3.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.3.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.3.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.3.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.feed_forward_gcn.0.Theta.weight 	 torch.Size([64, 64])
decoder.layers.1.feed_forward_gcn.1.Theta.weight 	 torch.Size([64, 64])
decoder.layers.1.feed_forward_gcn_cross.Theta1.weight 	 torch.Size([64, 64])
decoder.layers.1.feed_forward_gcn_cross.Theta2.weight 	 torch.Size([64, 64])
decoder.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.3.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.3.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.4.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.4.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.5.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.5.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.6.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.6.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.7.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.7.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.8.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.8.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.9.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.9.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer2.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer2.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer2.norm2.weight 	 torch.Size([64])
decoder.layers.1.sublayer2.norm2.bias 	 torch.Size([64])
decoder.layers.2.self_attn.0.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.0.linears.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.0.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.0.linears.1.bias 	 torch.Size([64])
decoder.layers.2.self_attn.0.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.self_attn.0.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.0.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.self_attn.0.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.2.self_attn.1.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.1.linears.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.1.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.1.linears.1.bias 	 torch.Size([64])
decoder.layers.2.self_attn.1.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.self_attn.1.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.1.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.self_attn.1.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.0.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.0.linears.0.bias 	 torch.Size([64])
decoder.layers.2.src_attn.0.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.0.linears.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.0.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.0.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.0.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.0.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.1.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.1.linears.0.bias 	 torch.Size([64])
decoder.layers.2.src_attn.1.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.1.linears.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.1.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.1.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.1.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.1.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.2.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.2.linears.0.bias 	 torch.Size([64])
decoder.layers.2.src_attn.2.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.2.linears.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.2.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.2.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.2.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.2.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.3.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.3.linears.0.bias 	 torch.Size([64])
decoder.layers.2.src_attn.3.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.3.linears.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.3.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.3.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.3.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.3.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.feed_forward_gcn.0.Theta.weight 	 torch.Size([64, 64])
decoder.layers.2.feed_forward_gcn.1.Theta.weight 	 torch.Size([64, 64])
decoder.layers.2.feed_forward_gcn_cross.Theta1.weight 	 torch.Size([64, 64])
decoder.layers.2.feed_forward_gcn_cross.Theta2.weight 	 torch.Size([64, 64])
decoder.layers.2.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.3.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.3.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.4.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.4.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.5.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.5.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.6.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.6.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.7.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.7.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.8.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.8.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.9.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.9.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer2.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer2.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer2.norm2.weight 	 torch.Size([64])
decoder.layers.2.sublayer2.norm2.bias 	 torch.Size([64])
decoder.norm.weight 	 torch.Size([64])
decoder.norm.bias 	 torch.Size([64])
decoder.norm2.weight 	 torch.Size([64])
decoder.norm2.bias 	 torch.Size([64])
src_embed.0.pe 	 torch.Size([1, 1, 12, 64])
src_embed.1.embedding.weight 	 torch.Size([250, 64])
src_embed2.0.pe 	 torch.Size([1, 1, 12, 64])
src_embed2.1.embedding.weight 	 torch.Size([250, 64])
trg_embed.0.pe 	 torch.Size([1, 1, 12, 64])
trg_embed.1.embedding.weight 	 torch.Size([250, 64])
trg_embed2.0.pe 	 torch.Size([1, 1, 12, 64])
trg_embed2.1.embedding.weight 	 torch.Size([250, 64])
prediction_generator.weight 	 torch.Size([1, 64])
prediction_generator.bias 	 torch.Size([1])
prediction_generator2.weight 	 torch.Size([1, 64])
prediction_generator2.bias 	 torch.Size([1])
Net's total params: 1165186
Optimizer's state_dict:
state 	 {}
param_groups 	 [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411]}]
predicting testing set batch 1 / 168, time: 0.70s
predicting testing set batch 101 / 168, time: 35.01s
test time on whole data:58.35s
22.540769324931983 29.24307158133782 914.1349694306989 0.06481493099341853 
27.12801120184699 32.86577058711611 1123.8076742834153 0.05738836105199683 
31.53551188456205 37.04801103327808 1309.7992546504286 0.04658033641274871 
33.50064108799469 39.56868715366398 1389.695241875786 0.03766268427876668 
32.86773295063091 40.26945541531591 1358.4088513381603 0.030394024030665222 
31.998170594973846 40.78909686056021 1314.0217178969299 0.02536180487091463 
31.933522434815675 41.71103379271998 1302.9706645333692 0.021276467590297044 
31.72924991828425 41.95808569711958 1287.6492631678507 0.017435570848052438 
31.065729514798594 41.182360999831076 1252.43572017046 0.01349454716456836 
30.755617916030985 40.05862388800743 1232.8711974641728 0.009680655144176775 
30.235656323799333 38.87850115796837 1209.831606120547 0.006428318084115925 
28.885631335729467 37.86080490030686 1157.5992721956948 0.004001555230579451 
30.34802037403323 38.62736680910702 1237.771083930791 0.004001555230579451 
epoch: 0, train time every whole data:210.63s
epoch: 0, total time:278.64s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.76s
test time on whole data:59.50s
2.430780837359262 3.945681756798562 60.45604310955455 0.627371947073298 
2.4403250511018117 3.9970844646406256 61.225929129120885 0.5934123895768519 
2.455436790288825 4.09261676372531 61.070120036145035 0.5451782516859023 
2.495188813518999 4.171540426421324 62.60455755459824 0.49443189611339083 
2.535378380987084 4.264641121230839 63.497459670476495 0.44212711183225256 
2.587558051548366 4.334804768991579 65.23961999614507 0.39213803620623866 
2.6463870865850754 4.397222295047551 67.36104291510588 0.3422715945536977 
2.7011465934618775 4.452847018639621 68.98911786716336 0.29851753377250956 
2.7527210197963177 4.493963819896154 70.21334110037733 0.2635801413307819 
2.803352267079499 4.530807667308971 71.17127543806797 0.2333899172334219 
2.8488981238573436 4.571003429383185 71.43854819340365 0.20718553782315258 
2.9033736168262325 4.5800214166996405 72.6657773216751 0.18732626787415646 
2.633378886034224 4.324658507429374 66.32798820169245 0.18732626787415646 
epoch: 1, train time every whole data:211.47s
epoch: 1, total time:561.74s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 35.87s
test time on whole data:59.41s
2.7319678130037195 3.946864769390072 88.92409010227705 0.5266035599109001 
2.7505480075979696 3.991877406992036 89.77178146940771 0.5074265332514786 
2.8297683081273877 4.113947129869938 90.4422048513156 0.4528713076408221 
2.8988995246410014 4.183806476436328 93.68700993466523 0.42201901642671 
2.974584292304924 4.258869295971731 96.9050133392664 0.3881132003277298 
3.053373020289377 4.328323856341156 100.19777297829953 0.35757140021610534 
3.1303464589450685 4.403610559553241 103.09817064866311 0.3222289456968253 
3.198347594850741 4.475720662037251 105.24484532874945 0.2876762214900562 
3.253996210451548 4.530209908027898 106.76291938489813 0.26030691749503326 
3.31617811697482 4.589571828910123 108.47812719992905 0.23258629449387655 
3.363756596379514 4.6440465297041476 108.96712211283324 0.20553058944687544 
3.411638049197694 4.681745158683383 109.78927845666368 0.1863381599266721 
3.0761169993969806 4.352305118504372 100.18948866634594 0.1863381599266721 
epoch: 2, train time every whole data:210.31s
epoch: 2, total time:841.33s
predicting testing set batch 1 / 168, time: 0.34s
predicting testing set batch 101 / 168, time: 35.43s
test time on whole data:59.20s
2.3143289126563107 3.731009853920742 70.53282178546696 0.6507899397932592 
2.3794424849671443 3.885012868234072 72.15302016653023 0.6078743313264362 
2.5948078813426907 4.332158451696322 71.9717849072335 0.49650226358045746 
2.6150369649800873 4.373871461938869 72.3206053276632 0.4814317236160665 
2.6646671501653536 4.441523589542451 73.42477024423243 0.4615909439415473 
2.708740193553535 4.501872370601553 74.30138742090953 0.4410734269303166 
2.7422011482847766 4.544970211791462 74.65634507319027 0.4238844636399973 
2.7780575984640135 4.592676036906604 74.79083449158168 0.4113428985623401 
2.7963310754911177 4.628725751292322 74.618204963761 0.39849736746350833 
2.819316843872003 4.659583479291297 75.04300343706409 0.382245587878546 
2.8696483564001642 4.708310165893 76.69672407908708 0.36295166480794316 
2.894084494583575 4.733204150647356 77.06505133994376 0.34604017694871686 
2.6813885920633975 4.438127874898176 73.9646503630042 0.34604017694871686 
epoch: 3, train time every whole data:211.71s
epoch: 3, total time:1124.62s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.77s
test time on whole data:59.39s
2.7207308285428833 4.172193339801696 84.32968711722927 0.657762377009522 
2.8095037477445746 4.333918815678448 86.49930717697845 0.6227467480669967 
2.991071309829663 4.673195146404489 89.86793549806002 0.5355179776996373 
3.013303962203186 4.708114149632503 90.16800521256957 0.5287507231438124 
3.095386636489736 4.811089644065945 92.63257405449734 0.5091715599169522 
3.127863134408458 4.831804226372006 93.26003783935053 0.510862111833693 
3.1497858833143755 4.828798368209436 94.8417377029109 0.5198199304569797 
3.151487984503309 4.809857530841571 95.66123379089203 0.5282361507241337 
3.1479941100870215 4.802184930307428 95.78860572716313 0.534527844762479 
3.1622968041512762 4.82607882811758 95.94020196321415 0.5258479265827407 
3.1997766819055236 4.890701464750627 97.02438294949498 0.50626593876978 
3.2443026224550393 4.969204255728598 98.11116796984842 0.46999599415565396 
3.067791975469587 4.726732916732829 92.84398521789444 0.46999599415565396 
epoch: 4, train time every whole data:211.74s
epoch: 4, total time:1407.86s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.73s
test time on whole data:59.51s
1.8898150276109753 3.305612516547847 59.93247490886885 0.7406099596046087 
1.9689186005328916 3.4544298972257543 61.91810207838062 0.7132700810245849 
2.1213727918118237 3.747639591419916 64.57740519278613 0.6683376461456874 
2.1482610676763136 3.7911841386378007 65.09607387503735 0.6594978230929636 
2.2308895377803237 3.919315362606966 66.57195890825533 0.6444051607249195 
2.3418850606107817 4.062767387495584 68.57964701337241 0.6346683828882711 
2.363091849163086 4.082834261610984 68.9091207951566 0.635423405306062 
2.421978193813225 4.129367190372871 71.07010680217607 0.633259016123501 
2.472986607716197 4.163526098783289 73.38208870381962 0.6273219348110998 
2.5220440627624767 4.208332127320918 75.22892234220319 0.6302747776701566 
2.537854856358664 4.245423464616999 75.14545107909018 0.620059198828653 
2.5643217300280394 4.321144514845326 75.26824050866222 0.5864419159263738 
2.2986182821553998 3.964501646308654 68.80693304008403 0.5864419159263738 
epoch: 5, train time every whole data:212.01s
epoch: 5, total time:1690.72s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 36.14s
test time on whole data:59.97s
2.046674376205497 3.0892804430171776 73.04573823940817 0.7498195692370635 
2.089812637378506 3.1988534261150234 74.41853410780452 0.7270557571249194 
2.1156967108921103 3.3204718074939508 74.15500746344044 0.6962786471379891 
2.10626086570562 3.321781224908626 73.0205140812161 0.6943630269694103 
2.141580980977753 3.3899616129912746 73.97537244429692 0.6776539147599354 
2.1598660693037366 3.4468655617839925 72.59833344454096 0.6624771483449042 
2.199542844364331 3.5106581660830005 73.80365104444463 0.6511903661335641 
2.215931028776137 3.5518465850859458 73.933125733594 0.6440748400965829 
2.254794298337684 3.616419794155602 74.75018833236355 0.6353300373616616 
2.272853077580088 3.641468675055744 74.5166790608321 0.6334185646761491 
2.259010081953236 3.633504570330743 72.81504241906585 0.6287758034229444 
2.305749159714828 3.702158172935898 74.11170702025991 0.6105693019827166 
2.180647677599127 3.4568320532022265 73.76200248284268 0.6105693019827166 
epoch: 6, train time every whole data:212.02s
epoch: 6, total time:1973.03s
predicting testing set batch 1 / 168, time: 0.34s
predicting testing set batch 101 / 168, time: 35.91s
test time on whole data:59.73s
2.1830587782100555 3.3746588151540515 71.33209937146235 0.768510942233373 
2.248381600808441 3.4848118904619945 73.46928437281535 0.7460330664193614 
2.3098911842861702 3.6382440062712007 74.08015939774789 0.7259952272477335 
2.354382768803409 3.7258494092894345 74.80008985065567 0.715200856221482 
2.409887120025853 3.8569062449380915 75.58254209018233 0.6907537235596739 
2.4574198021288254 3.957590592704243 76.03821169148188 0.6746079052167245 
2.4686121335660243 3.984494380973291 76.37712855912505 0.6689128118364764 
2.48655428234337 4.0081665446661585 77.09142107531957 0.6656808947062736 
2.4948132041753937 4.025972529067027 77.57832268991397 0.6607954325794343 
2.5054847455884195 4.041620677653806 78.02704072239811 0.6595020807230646 
2.5406871498694557 4.097365637763835 78.22465783610545 0.6566597830975234 
2.5805569472518703 4.17433603811743 78.71778522457191 0.6380125330709184 
2.419977476421441 3.8717727629973777 75.94335299466246 0.6380125330709184 
epoch: 7, train time every whole data:212.69s
epoch: 7, total time:2255.81s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 36.01s
test time on whole data:59.73s
1.7668657886686603 3.1398842339704394 52.067095598352 0.7823238623639512 
1.8237762215461226 3.258659226903433 52.85782816537918 0.7615218572850815 
1.884657503242294 3.405451740357191 52.95683461678935 0.740743039748191 
1.9090289978489634 3.42771083256419 53.48625700811004 0.7327037164605688 
1.9564483180916203 3.512011539075454 53.68340971053666 0.7220855022317116 
1.995234718008765 3.5849542122455524 53.99463705107167 0.7116935214840431 
2.0179562164719793 3.622668170943646 53.993738565701776 0.7054605535146038 
2.021215380853663 3.6232359324087695 54.45683869322339 0.7024292780245206 
2.029089521961198 3.636089838720494 54.954574059857656 0.7008705621941148 
2.0264582671156774 3.628022984271 55.263259851970005 0.7012515028141958 
2.0508367624734305 3.6691775968065263 56.285429854583654 0.6939189943678156 
2.0976129245756283 3.7572246282547677 57.35019277987755 0.6690070458422134 
1.9649317184048336 3.5263888795087692 54.27924744800554 0.6690070458422134 
epoch: 8, train time every whole data:211.54s
epoch: 8, total time:2539.40s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.46s
test time on whole data:59.01s
2.039435362613627 3.1725680063137154 67.50439403569875 0.7456730418557559 
2.079535188362978 3.2304486384895155 69.12456601440077 0.7337760062545671 
2.145223938142792 3.3787877158167396 69.94424009033719 0.7094837735560979 
2.1568095987770883 3.3800386407309793 70.22339309044919 0.7109231729357701 
2.1940128087403163 3.4506765287828123 70.33042887654481 0.700744376792366 
2.252204677759448 3.5595273640055654 71.19086166158681 0.682784888272996 
2.3121229573669178 3.6770411541889834 71.09517773883917 0.6691332209266022 
2.33638652457288 3.734007007474874 71.19328851304549 0.660588867300424 
2.3681413884560265 3.7929370065000136 72.13119949499782 0.6493142050030205 
2.3710880487921338 3.813796475784449 72.09054543147502 0.6450323026345313 
2.4097394439898254 3.887309524130712 72.90752339121298 0.6350441052302712 
2.4588538010011294 3.986938883128548 72.99934890760404 0.6130107583293716 
2.2602961448812637 3.5976956633499397 70.89466656063401 0.6130107583293716 
epoch: 9, train time every whole data:210.94s
epoch: 9, total time:2821.66s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.54s
test time on whole data:59.03s
1.9006117071025073 2.9891354586928576 63.512150641543975 0.7713540802265852 
1.9380717705995554 3.059475431123352 63.71281692238081 0.7602309700490683 
2.00737372260656 3.2128267129551302 63.56223692845933 0.7375397518870239 
2.0474448737807216 3.2757091052912184 63.50868479842232 0.729916826989466 
2.0965191423517786 3.3764938453080617 63.71412871023423 0.7135023526750622 
2.1308610671673502 3.4454330182553607 63.78234430686419 0.7044304117199862 
2.1584843392758852 3.490012202764319 63.99665832887875 0.7001316481707556 
2.1655628826243003 3.4888497066115907 63.97892701727722 0.7037291589055042 
2.1717332104602387 3.4983967593487475 64.31489439802478 0.7032955835964285 
2.170522512447089 3.5062103751749953 64.31885877830167 0.7014897073560488 
2.202351013858847 3.570930151845744 64.5786650781554 0.6933682153581567 
2.254141046254319 3.696907944264237 65.48382107410457 0.6677065251198754 
2.103639774044096 3.390216127992616 64.0387071572394 0.6677065251198754 
epoch: 10, train time every whole data:211.21s
epoch: 10, total time:3103.82s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 37.08s
test time on whole data:61.80s
1.7156365116470094 2.8231956763806383 62.81638539450459 0.7887208756589175 
1.7561834142815675 2.898039005192706 64.27500977283839 0.7755771756726166 
1.7774367330518683 2.994852088532664 62.641003676118764 0.7629508974331304 
1.8102054270934314 3.033852478966176 63.18171004606358 0.7563764337878941 
1.864359576458555 3.1439299847817264 63.20807541350821 0.7397399605096282 
1.9301486085421804 3.267025009487554 63.971765814192985 0.7168916837987549 
1.982660314278411 3.4094719102384325 62.54742298662514 0.6924537588501272 
2.014838159117493 3.490788341352348 61.917146592414554 0.6787289939812572 
2.0246091971861286 3.5070238509354223 61.534967322227594 0.6774181765341171 
2.009646698721374 3.4617718468493663 60.593418115400056 0.6864625328238977 
1.9970116089561156 3.4405523445919064 59.918150831805214 0.6892734608453716 
2.032771369624528 3.524212082240837 59.77998335604384 0.672009629262876 
1.909625634913222 3.25897307136877 62.19869482365718 0.672009629262876 
epoch: 11, train time every whole data:211.27s
epoch: 11, total time:3387.79s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.47s
test time on whole data:59.06s
1.6829504908311756 2.8142679457782758 57.04152269865368 0.7994769151209257 
1.7143399149920968 2.8643631714883413 59.083205571086005 0.7881209783796145 
1.7497531119013825 2.9528635233357243 59.717742257010165 0.7758671033522034 
1.797219332917549 3.0164732869312907 61.32915582077836 0.7641706650094314 
1.8483704738054603 3.106953676600649 62.27171436452963 0.7487957903855963 
1.9095756744015961 3.2163898692522 63.74055976633297 0.7272809601654765 
1.9551629886173953 3.332891651480866 63.67582672370238 0.7035300297955358 
1.9951213426296377 3.4189400670301597 64.31156274155106 0.683837500022136 
2.0328929362702404 3.4874624443131523 65.6757685759425 0.6695020821176065 
2.0550885591460837 3.506970708710555 66.68692628492661 0.6653668291063547 
2.052736595976832 3.4819257350189563 66.70779552569194 0.6708822808112419 
2.0702221899570987 3.5302264893391717 66.61233170522314 0.6598181540636386 
1.9052861342872123 3.2376223419808636 63.07136017910444 0.6598181540636386 
epoch: 12, train time every whole data:211.43s
epoch: 12, total time:3669.25s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.58s
test time on whole data:59.13s
1.8058971988450558 2.7264184968151763 59.559748435858964 0.8096201294923129 
1.8477580994252294 2.8022831953443506 60.25038929803356 0.7958438179463095 
1.8950521172913943 2.899091479694033 61.59945797941702 0.777521106583333 
1.9052772867263605 2.912184055181203 61.696194483839676 0.7736274795167355 
1.9374542166251867 2.9585338361540985 63.539700474023995 0.7657471366296633 
1.961048241884492 2.998748291058321 64.31578927904341 0.7589091617408457 
1.9935755043460854 3.0648536327976985 65.44648770431051 0.7482914930939704 
2.01685078966795 3.119015199358296 66.68109251949173 0.7399757927608843 
2.0224875498740444 3.1650986062446527 66.99129825351378 0.7289364548810154 
2.009379365397351 3.190588531153133 65.69139343828141 0.7188481112847446 
1.9938059967747401 3.201887617896045 64.07531305425337 0.7159170033662683 
1.9916062965665366 3.2369384559777457 62.930129490022615 0.7124896101852493 
1.9483493886187022 3.0271858897121495 63.56488433199205 0.7124896101852493 
epoch: 13, train time every whole data:215.43s
epoch: 13, total time:3954.55s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.57s
test time on whole data:59.19s
1.6950778813106673 2.8008527328207418 56.36819506214552 0.8091680369864971 
1.7722724727511938 2.965991532028271 57.466087311171435 0.7926188690203254 
1.8756083126618925 3.18868072694542 58.2665078837569 0.7682861339598558 
1.9334723406356893 3.2869637708453165 59.025015383153686 0.7539789388637992 
1.9785168009500596 3.369898106764892 59.44099401876507 0.7375961799812787 
1.9943469912871896 3.3919507328022536 59.48447273139362 0.729841276217058 
1.9896122294792995 3.391685236749416 59.18851311072017 0.7244947298410256 
1.9866241645904346 3.365164571208701 59.60195872603138 0.7238651511638632 
1.9758508099776115 3.3334672689530684 60.27041758678524 0.7250826930392721 
1.9734477538017645 3.316669046148327 61.123351043542904 0.724292738255341 
1.9909508957838018 3.330738617068171 62.182711084328204 0.7226191828034594 
2.0353607599780497 3.4220459881110545 63.2857807585624 0.7086594526781144 
1.9334284511006379 3.268786954454322 59.642092503023946 0.7086594526781144 
epoch: 14, train time every whole data:211.00s
epoch: 14, total time:4234.63s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.60s
test time on whole data:59.66s
1.6492957904761922 2.604793474701021 59.960409640725054 0.8223970268654233 
1.6757634156984942 2.6812069592330086 59.36694324901143 0.8124186983524838 
1.705815371254459 2.7774516060842793 58.517695115234716 0.8020006322215181 
1.7207172005751303 2.7928159222217293 58.29430884477963 0.8005752246150286 
1.7565841049096946 2.8778596661750284 58.08667689211393 0.787975585444484 
1.7898634552183073 2.9672390721250164 58.1147419009208 0.775156159683951 
1.8182344898475067 3.032171934261706 57.89332481572288 0.7654841474919722 
1.8294507878389918 3.032760431091795 57.89226801149579 0.7637435542895954 
1.8443523522543588 3.058013664662464 58.6259442133241 0.752723150037453 
1.8635272700376808 3.0888978043388247 59.16700607104624 0.7425291870443849 
1.8798605162764765 3.1326778842750636 59.40047326585001 0.7341917670232679 
1.9207721771001816 3.2306627010629545 60.03980975773234 0.7149812586428353 
1.7878530776239563 2.9454732765986273 58.77996039692215 0.7149812586428353 
epoch: 15, train time every whole data:211.96s
epoch: 15, total time:4516.77s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.48s
test time on whole data:59.32s
1.6166671505190786 2.6438221584912855 57.49180770082445 0.823314208199869 
1.6524810572124662 2.699131825671946 59.750580646356596 0.8127571589181263 
1.6907719298096462 2.760577415442776 61.23790323544544 0.8028259036767487 
1.7354084823672615 2.8316992897047597 62.92612067817763 0.7910627275009199 
1.782531445923217 2.921128634360784 63.457757567244755 0.7758054369999599 
1.8204701151459344 3.013330900446614 63.430668981743366 0.7602634243919227 
1.8508493117298044 3.12851866905603 62.15828569842417 0.7423444029798557 
1.8732823005943071 3.1952976091477128 61.548040758644674 0.7319892778577479 
1.898090532460117 3.259354165317182 61.47498104804712 0.7203759120403661 
1.9233532553143977 3.3055962424076593 61.387657283650434 0.7093171218733043 
1.9430665176383974 3.350682311437278 61.194131625771156 0.7016853591512403 
1.9789020503955406 3.4375322278632208 61.002871526350674 0.6862430575496383 
1.8138228457591807 3.056675537550899 61.42177412351172 0.6862430575496383 
epoch: 16, train time every whole data:211.16s
epoch: 16, total time:4797.17s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.49s
test time on whole data:58.94s
2.222560101285754 3.372288628667261 70.97190255528075 0.7906816647295641 
2.2527009646107574 3.45132342243565 71.5827287548633 0.7783623945911387 
2.29164516430153 3.539743317629649 71.49961969023379 0.7686200703119385 
2.304993349123569 3.551869062996254 72.18467190991025 0.7654994234127016 
2.3220488882683927 3.5903895110521287 72.6928398966995 0.7570304547580237 
2.327144001972817 3.602002080823922 73.059090116246 0.7537118985300174 
2.3077665957268327 3.578599120768793 72.86927353118371 0.7529574539832652 
2.2856920084252597 3.558636022463564 72.77577479451409 0.7484304921548904 
2.2679964864712563 3.5435401399715087 72.99209442075374 0.7424508745599291 
2.2437747844898452 3.526132299088857 72.95354272258237 0.7370831689945582 
2.219894587920003 3.5016200417139713 72.81930680135919 0.7372987109935994 
2.2271380414239 3.5555648707600773 72.77387714415806 0.7260642649036082 
2.2727795811683267 3.53151016536037 72.43126644327977 0.7260642649036082 
epoch: 17, train time every whole data:211.18s
epoch: 17, total time:5077.69s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 36.16s
test time on whole data:60.76s
1.6580340025871991 2.6790747945789186 57.808168330660045 0.832745301787003 
1.6889835449974275 2.750168180974537 58.49223643334681 0.8253308168702437 
1.7344227714354084 2.841127566250196 58.82153359646528 0.8180997434227054 
1.7399898523438189 2.830656512193107 59.23028017171078 0.8172850196684094 
1.7565335384107061 2.883829684079942 59.296741144845285 0.8083174845071245 
1.7806036217404264 2.9439710720556276 59.367415220332774 0.8001250854441312 
1.7940904278550298 2.9697038217169025 58.91830156992739 0.7945717285025883 
1.8008606537682492 2.986130972743142 58.76179492802478 0.7866173945106334 
1.8097847984889965 3.016245885627008 59.36295333459489 0.7759749644398032 
1.809547887269319 3.0266789260798217 59.58164876415959 0.7730306234156247 
1.8101721801890858 3.031765462546293 59.70324240175313 0.7735069866953997 
1.8364472786905688 3.1050470959743564 59.71944296777163 0.7661479003509961 
1.7682892131480197 2.924558243899732 59.0886715615296 0.7661479003509961 
epoch: 18, train time every whole data:211.76s
epoch: 18, total time:5359.18s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.42s
test time on whole data:58.93s
1.803058737975767 2.692627471543384 65.15352867018441 0.8101418483111625 
1.822525090394985 2.759869660901931 65.12054613997117 0.7991333635788398 
1.828569395591638 2.7948622445681326 63.6682896052544 0.7938917309340162 
1.838089111721232 2.8205564801197625 62.859150810224016 0.789461526679813 
1.8590372886273656 2.870399128278318 62.666033558519764 0.7819175594996791 
1.8797318386029274 2.9104392603250595 62.915771749672246 0.7753637984248494 
1.8955864036832715 2.950834241880133 63.17034998454494 0.7669669901953204 
1.8980033516168948 2.949131858697235 63.7469104320388 0.7662809707240906 
1.898830066707961 2.94529552051339 64.34420017762793 0.766443438191666 
1.89961310170174 2.941952275997844 64.18058341394118 0.767265022743465 
1.9027197654361703 2.973846220720191 63.65691001878838 0.7629708769934429 
1.9360475074359704 3.087057055495368 63.472839593928676 0.7448187731158376 
1.871817638291327 2.8932694577503706 63.74624728169621 0.7448187731158376 
epoch: 19, train time every whole data:211.26s
epoch: 19, total time:5640.87s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.43s
test time on whole data:58.95s
1.687133251581962 2.5675062974888743 62.69696090191125 0.829607218782749 
1.703707124919054 2.641603617385912 62.055532287330394 0.819209875960624 
1.7165541496056886 2.7240129104654485 59.400094765643416 0.8113605997188664 
1.7314526509471415 2.758826690342154 58.32332288459651 0.8093118203105 
1.760149790058888 2.8470004069430823 57.14514537646532 0.8019071952128056 
1.7825268714932636 2.9184873672398455 56.668783649461616 0.7949039999723534 
1.8065638264330726 2.984260332546707 56.6379307336852 0.7865121211710674 
1.8236608928637135 3.0103587279705923 57.664663101661795 0.7783178368270017 
1.834095745366865 3.0309051825130524 58.248182606935586 0.7713535702255855 
1.8317760913810206 3.0289125630061675 58.11651494131082 0.7706826818267658 
1.839845026965652 3.045314187738982 58.111094981871894 0.7677157275976209 
1.8733935068652388 3.130681866176087 58.31355415691315 0.7542476471269517 
1.7825715773734634 2.8958070769804456 58.61506797194133 0.7542476471269517 
epoch: 20, train time every whole data:212.32s
epoch: 20, total time:5922.53s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.43s
test time on whole data:58.94s
1.6318320728817157 2.64556830038227 55.57832343207203 0.8303739547194353 
1.6618138647988616 2.7123409536724057 56.85599814709652 0.8213121771351319 
1.6864354685404825 2.7372092993593307 57.845981191563176 0.8156737997121982 
1.7045537640032846 2.765247209551603 58.739272537032726 0.8099945595786406 
1.7273836284530837 2.826450294823435 58.891579861070184 0.8015853212431456 
1.7543624801909816 2.8819788891839666 58.5285634822313 0.7963288877843668 
1.7817290751416945 2.950808332982251 57.576920371798515 0.7906740815768843 
1.8041554015523622 3.005079516048171 57.24016447696742 0.7841070098333692 
1.8177293216995007 3.028546309678375 57.4885856041493 0.7762823313845256 
1.8188355151523081 3.0286148003138242 57.788219555425755 0.7731578279996795 
1.8278043840067195 3.050368515944205 58.315050596159324 0.7677719453804226 
1.8638450429341091 3.1327850504558667 59.244327830643904 0.7557520149915188 
1.756706668279592 2.9010173341424172 57.841106596474944 0.7557520149915188 
epoch: 21, train time every whole data:211.39s
epoch: 21, total time:6203.10s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.50s
test time on whole data:59.42s
1.648009369321611 2.6141825548031856 62.1522190775334 0.8254309544792231 
1.6706172457385275 2.6699654160682957 63.12199930848501 0.8144312575847059 
1.684119475690648 2.6992118997950714 63.20952917378969 0.8090634653355334 
1.7015321582970875 2.7223240579697894 63.93131817144532 0.8067352838592481 
1.7200720301671397 2.756631390646208 64.0798107258893 0.8019314225166673 
1.731453023427033 2.7851907404919083 63.683084263867826 0.7985856025453814 
1.757342518242076 2.8535301891802174 63.420841430630595 0.7889180416563665 
1.7968629076480866 2.947862333611748 63.510461473437864 0.7747645176191934 
1.833035533253547 3.0217463893442913 64.19425627607744 0.7629265876290827 
1.8512206594989236 3.061547087089081 64.71305202733816 0.7571661588721288 
1.8525321588254577 3.072556538342592 64.79904729296342 0.7545915463815551 
1.8632165021663976 3.095848117455165 64.58291471082099 0.7487327322224064 
1.7591677985230445 2.863232307032031 63.783245954354264 0.7487327322224064 
epoch: 22, train time every whole data:211.22s
epoch: 22, total time:6484.34s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.49s
test time on whole data:59.01s
1.6769390886541278 2.6153002637475313 52.9342943740757 0.8327221053937562 
1.711063872022909 2.709225902635051 52.69582114205317 0.8224652467358036 
1.7438634710095469 2.7898042284716253 52.453426480725106 0.8135557125626764 
1.7538365429276157 2.8111853217778497 52.05822063922131 0.8110282835806761 
1.7770725989106688 2.8527676846643657 51.94492120764813 0.8078103221385267 
1.7999061841236517 2.8937725155713325 52.49196871196654 0.8018855543332339 
1.812350309827232 2.916465723439673 53.34135396333385 0.7937974416136327 
1.8055039265172645 2.889849716332864 54.65641617581332 0.7891441829444521 
1.8083628908200633 2.8872924312181802 56.243997090334105 0.782103566936598 
1.811081812466894 2.8881770947148815 56.88527018593697 0.7795265023710266 
1.8241096678045357 2.9254107383437478 57.19914319640074 0.7730815554097735 
1.8618610982687345 3.016478632763464 57.85231253013142 0.7590588413068551 
1.7821626219461035 2.851459763362646 54.2298612969643 0.7590588413068551 
epoch: 23, train time every whole data:211.59s
epoch: 23, total time:6765.21s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.49s
test time on whole data:59.03s
1.5834470367286178 2.618486249898814 54.27328644270536 0.8357378480154167 
1.5990902720140736 2.6403796005862876 55.218830289597065 0.8286778776147368 
1.6213026250697495 2.6679806047943995 55.654236989438 0.8233085849860481 
1.6350311149222156 2.6981821050422576 55.64867749332708 0.8207597625328963 
1.6564011089376929 2.753826919847457 55.7593971746203 0.8143317377277601 
1.678348190183973 2.795514072003886 56.15385886757947 0.8089240665020611 
1.6987196030986629 2.8401460294345915 56.76767069499349 0.8009530485065689 
1.7148059624648164 2.8814732525430915 57.430627683391556 0.7918417330339106 
1.7280993397179103 2.9038107533852737 58.12008320627488 0.7866525109994151 
1.7332132942518663 2.902852050156403 58.27384629264164 0.7873280729840424 
1.7434055650227127 2.921607461293887 58.477594134895924 0.7855361921150062 
1.7747487986858579 2.9993996300993033 58.94967111730702 0.7747174182288983 
1.6805510759248456 2.8045352597179463 56.72739681756087 0.7747174182288983 
epoch: 24, train time every whole data:211.39s
epoch: 24, total time:7045.11s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 37.04s
test time on whole data:61.61s
1.6244796043851724 2.6775357633177332 56.99105020971218 0.8205472011192433 
1.6528929529962617 2.7735631793290048 57.738084770237954 0.8089798053332525 
1.6753221981707251 2.827093807892435 58.5135481193859 0.8022723955731388 
1.6911280819258343 2.842833749231909 59.413436890051585 0.8008013332217556 
1.7201676985723455 2.882667622689322 60.754655946903505 0.7930964172038815 
1.7583807131444946 2.948754393595761 62.403252283643354 0.7785746968983241 
1.8039383899087884 3.0470232912343254 64.03509123171848 0.7589307957089914 
1.8461362283848048 3.1333656242247585 65.59095578633612 0.7442838542259791 
1.8786859411498797 3.1921983293236447 67.01403103081117 0.7344046506220255 
1.9023351716329122 3.2217947104874143 68.20913134026381 0.7294900826893732 
1.9220768786982767 3.247870874762909 68.74532035813647 0.7233307122427844 
1.9540399032830305 3.314224362435348 69.16248460180003 0.7088005509173699 
1.7857986468543772 3.015876177843056 63.214507644374166 0.7088005509173699 
epoch: 25, train time every whole data:211.26s
epoch: 25, total time:7329.88s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.51s
test time on whole data:59.07s
1.5714356193942505 2.5669733184183565 55.2338768144601 0.8376023798287109 
1.593190445731261 2.6511113831183195 55.51128857677759 0.8258540576644992 
1.621970555749234 2.679397094485953 56.083490736344956 0.8231797209321141 
1.6391979573120674 2.7090519009216343 56.35796654011995 0.8198537614921861 
1.662269074238748 2.751049451816868 56.52817320240746 0.8156049460316902 
1.685389955372594 2.8011633397388724 56.72668910691196 0.8113434356414506 
1.7101850026793601 2.855450435767786 57.09882399188054 0.8066546057880738 
1.7357346960421474 2.902762168954657 57.715965583791494 0.8019170054771672 
1.760191747742306 2.9501002577254756 58.59629484681717 0.7946244980493896 
1.7802056312622236 2.9927822757564506 59.32998164368103 0.7867314575935433 
1.7918805540269684 3.0141331894444385 59.994080897170754 0.781068149487153 
1.81106988597883 3.0552144496122597 60.55826715576698 0.774427018373321 
1.6968934271274991 2.8315110897337403 57.47799711956619 0.774427018373321 
epoch: 26, train time every whole data:212.11s
epoch: 26, total time:7611.23s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.58s
test time on whole data:59.11s
1.851265190090452 2.9294760410363474 59.89364990606194 0.8095047453132441 
1.8839006302931478 2.9946934328865877 61.07800976559663 0.7957440787872179 
1.924683790923939 3.0369593372872257 61.57604221903041 0.7950245235221532 
1.9663665579149412 3.1257594431924924 61.987314892005905 0.7876016825549979 
2.0070215427657323 3.210494153343012 62.16429011157727 0.7859889373545096 
2.042673909362228 3.2590651576582803 62.925507218607926 0.7836760015268348 
2.0788721827700556 3.302323237002131 64.42038883975137 0.7741697427566168 
2.101777760722098 3.324989307424061 65.93696818282797 0.7663036762028999 
2.115191623820169 3.3536953962016103 67.24446625286107 0.7556438429862733 
2.12965465645838 3.372021931273098 68.51052584967087 0.750672373206433 
2.1521456507463896 3.42033329692906 69.4520754598737 0.7453000472857764 
2.1915201897795002 3.5055741856898806 70.25262775721566 0.7353308307584897 
2.0370894738039196 3.2408681805010606 64.620340157852 0.7353308307584897 
epoch: 27, train time every whole data:212.96s
epoch: 27, total time:7892.98s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 36.52s
test time on whole data:61.12s
1.6825460927806617 2.618533762902348 59.093091458142574 0.8383495714338205 
1.7074961158266913 2.672454565698447 59.93319571110566 0.8319869804444668 
1.748719790291928 2.7820236116730146 60.17780214599503 0.8215712798725803 
1.7878219559444557 2.860015375299435 61.01191876349014 0.8147203487581296 
1.8260112478893604 2.9328222912862727 61.43026606827402 0.8072815889397998 
1.85889119681645 2.9795770204662317 62.30415374031332 0.8009095519831101 
1.888121029373347 3.018143054899038 63.47922455928495 0.7916513023606833 
1.9188563172816344 3.0626997942865524 64.86027457738702 0.782421409207817 
1.9602577089874873 3.1543645987019504 66.44835346495275 0.7660734260354188 
2.0019629894125144 3.232480132310634 67.85467640128728 0.7545662640543956 
2.03604265477872 3.3091185753946264 68.56246122657829 0.7461258001703954 
2.0846185239613764 3.42252132831488 69.38353026254228 0.7311274279497533 
1.8751121352787188 3.0131597611570307 63.71176952203622 0.7311274279497533 
epoch: 28, train time every whole data:210.99s
epoch: 28, total time:8179.22s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.85s
test time on whole data:59.90s
1.6038822452745267 2.5126456260739363 57.48631153536209 0.836382141167872 
1.6338632186435695 2.568255524182988 58.74142003978354 0.8288193615718134 
1.656072365335588 2.609527121476249 59.11523176341134 0.8230979775744187 
1.6678576368368452 2.6344921292731125 59.239374421099896 0.819677409563255 
1.6800236068433594 2.666061098033257 58.937935545132056 0.8147751840746394 
1.692011764798668 2.700297732086661 58.98551201432861 0.8103843944259547 
1.7102981385404155 2.7534572311561383 59.00263050797435 0.8038948141899375 
1.7335677811967298 2.8188737568314566 59.21906436879033 0.7950002045260804 
1.7601513087998721 2.886430194690245 59.45544422231273 0.7856145163578682 
1.7823574520675023 2.9450365226540125 59.455515674844904 0.7791459951498858 
1.8024819599795376 3.0121298177985 59.285759514519874 0.7729777962650574 
1.84647647751238 3.130997865413055 59.49825698409401 0.7586806685068912 
1.7140869963190828 2.7758987091096934 59.03522792210069 0.7586806685068912 
epoch: 29, train time every whole data:211.81s
epoch: 29, total time:8459.53s
predicting testing set batch 1 / 168, time: 0.34s
predicting testing set batch 101 / 168, time: 35.44s
test time on whole data:58.94s
1.5929893137522575 2.4954975373387116 56.54769227237843 0.8391719487546359 
1.6153618021894778 2.565733009951955 56.55480315963464 0.8295876412819787 
1.6352979282474234 2.599103363142237 57.02781134817755 0.8248162426903785 
1.6432623669401343 2.6042040574492407 57.57266744367075 0.8235648244857952 
1.6574960258442555 2.638169367896676 57.78154883973827 0.8188535215294552 
1.6705443168269205 2.678109126195282 57.96980320097224 0.8136806396412225 
1.6839540512768463 2.7228759162889866 57.8263106280648 0.8080018820942741 
1.7009465222525455 2.7703011715632955 57.59138004766389 0.80235210031209 
1.7192473166821791 2.824104753485823 57.537605963793936 0.7961952855633533 
1.7420784894968604 2.8833433013214367 57.63710045416297 0.7884942857349623 
1.7550123930901644 2.9244645406165253 57.714567477772626 0.784245544653337 
1.7867681072584043 3.0063687591180313 57.93651729204022 0.7739024292573696 
1.683579886154789 2.730209409880558 57.4748414247013 0.7739024292573696 
epoch: 30, train time every whole data:212.95s
epoch: 30, total time:8741.47s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.45s
test time on whole data:58.97s
1.5757727571194549 2.535849482990892 53.339496747296636 0.8400514404172799 
1.6086181566226518 2.6171537529708147 53.9528823034254 0.8319220370061052 
1.641413287775591 2.685657175858623 54.18391315617542 0.8241139043546275 
1.6607551283631474 2.7218402738370098 54.8999897838012 0.8172266392016354 
1.680889343390596 2.7590240144857043 55.63526025592318 0.8092366387422041 
1.6997017570292312 2.789510218702247 57.023792124210026 0.8012970319210156 
1.7132654133262557 2.814239882413745 58.298743082057726 0.7951732465476706 
1.7309519704363 2.8377575887526745 59.46469002294265 0.7902891880355921 
1.7512814050331889 2.880838189415292 60.255862602165756 0.7831395073516929 
1.7783170326393807 2.9402494084626873 60.38311195630115 0.7739738740029798 
1.8092564627996512 3.0326512996219375 60.113563967344064 0.7599833810571258 
1.8601704416385896 3.1665539997066117 60.31340453694774 0.738034111812137 
1.70919942968117 2.820105254039827 57.32222230728337 0.738034111812137 
epoch: 31, train time every whole data:211.67s
epoch: 31, total time:9022.09s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 37.14s
test time on whole data:61.78s
1.5518661209336881 2.5172833785746986 55.70627349081162 0.8399025582667006 
1.5744570502276045 2.5761876203173095 55.309570171720466 0.8331824446392376 
1.5988232829660354 2.6247548001390175 55.164297577009016 0.8271669184858559 
1.62058112799394 2.673355590944407 55.59105918505577 0.8196582432621882 
1.6434699096026875 2.7050646807007768 55.98475515170933 0.8146182893726207 
1.664930602172035 2.7358908963881508 56.778016067743465 0.8101396337418223 
1.6874335950926123 2.787410548513858 57.57637741983034 0.8026377173290836 
1.7084042946706037 2.841962382290026 58.13435546331228 0.7948558650231639 
1.7286062774338005 2.8897439909134754 58.49259081491548 0.7881114611739187 
1.7446038509952349 2.924341232657676 58.660817484262665 0.7837945395109236 
1.7583132753942516 2.952268816632252 59.074595864214366 0.7814936179044741 
1.7776213855931446 2.9943130226002395 59.2858191702563 0.7774028598745922 
1.6715925644229699 2.772524442823699 57.14663057838576 0.7774028598745922 
epoch: 32, train time every whole data:212.08s
epoch: 32, total time:9306.00s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.48s
test time on whole data:59.40s
1.5484611894971736 2.5213933686510943 54.50495480618927 0.8416565975180987 
1.567101097142856 2.5701223487814566 54.57324611144002 0.837144741886457 
1.5875629599607948 2.6155544269224493 54.542874432865794 0.8331739307338434 
1.6016765308218697 2.6476935699751136 54.60509086274775 0.8294612721113752 
1.6246494687059452 2.6989274847708655 54.59576012018271 0.8239576791999972 
1.6487706467876477 2.7473248168929967 54.773687937809534 0.8193194943714961 
1.6739921965152913 2.807772607897717 55.00634864775562 0.8112151418587361 
1.7005831871503698 2.874618738190387 55.459049628546744 0.8015229979852095 
1.7243711997011588 2.9256697870006176 56.26996333485679 0.7937939332471802 
1.7395296258748998 2.9485458654469343 57.10873634719884 0.7888468228288121 
1.7541811604181394 2.974740284993907 58.050146143215606 0.784274095523556 
1.7836597675642087 3.029302548480946 59.269292436158636 0.7750897467192963 
1.6628782525116963 2.78496862414492 55.72999378524054 0.7750897467192963 
epoch: 33, train time every whole data:211.19s
epoch: 33, total time:9587.30s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.50s
test time on whole data:59.02s
1.604827350108574 2.486200235578484 56.85247367930381 0.840164406497883 
1.6187487835743952 2.5237244842628344 56.9903936350889 0.8347928386799114 
1.6321763208116449 2.5845058196137716 56.330267625026686 0.8275675315978321 
1.6466243252668176 2.642024149171172 55.67484708465705 0.8220430879880251 
1.6742722260509395 2.7122005584030364 55.30152115525393 0.8149976072626052 
1.7095252519358126 2.784928853344449 55.10264994915285 0.8076654382351596 
1.7471381490357398 2.8743736754243705 55.015886268060534 0.797395062077298 
1.7804492527587072 2.9523569059228754 55.099761490009925 0.7876426198810051 
1.805938078108288 3.0074298894984377 55.20567362475178 0.7800872838075813 
1.8210370640472642 3.029871442849332 55.181030720124205 0.7759940096172597 
1.8263968156766857 3.0357882763188844 55.41366968305411 0.7735542627503124 
1.8437920623819033 3.071197101330641 55.70866395137042 0.7664099320954336 
1.7259104733130644 2.8162275643091244 55.656369730293505 0.7664099320954336 
epoch: 34, train time every whole data:212.86s
epoch: 34, total time:9868.17s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.50s
test time on whole data:59.06s
1.5802691681535825 2.5490913250094414 52.81112724497192 0.8415250693568653 
1.6035199249027563 2.6065187609626337 53.413668140948204 0.8334128291443492 
1.620407628706346 2.6236066223073844 54.35268298869214 0.8277072086032417 
1.621313929199995 2.6099942205221187 54.87822115780501 0.8274012030821442 
1.6336170762517446 2.6258467988305765 55.448071778234976 0.8247305156007808 
1.6456728326895584 2.6515367192738175 55.9345658839239 0.8211217155199612 
1.6669313944087674 2.70254308820668 56.58487744545888 0.8132051528755506 
1.6824940323657578 2.744990547433161 56.887261149258464 0.806509255042081 
1.7001771607241105 2.780984438994076 57.0822790928764 0.8008775021553923 
1.7120809296813926 2.798945405119896 56.825965058945826 0.7985537621172222 
1.721941419459968 2.831470305037612 56.67677219737016 0.7942425069739021 
1.7456008485554761 2.893602579403549 56.60774773193123 0.7867022314861855 
1.6611688620916214 2.703543178475385 55.62535559266526 0.7867022314861855 
epoch: 35, train time every whole data:212.13s
epoch: 35, total time:10148.65s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.52s
test time on whole data:59.09s
1.6396905314659789 2.500331101612772 59.35041779404333 0.8384152100674764 
1.6631284880866075 2.5801313807824777 58.43863399666588 0.8274029793974143 
1.6710682334216933 2.626900719339119 57.42890722854492 0.8217861771317033 
1.6729396121177291 2.6317210867458076 56.89667914355834 0.8220867155387844 
1.6896911271035318 2.6694367408179938 57.00396711688046 0.8173254412215215 
1.7186811738887005 2.7388221205125194 57.69020703977302 0.80697745827771 
1.7569661541727504 2.8349574226770735 58.351060543039026 0.7916498239531051 
1.7935968424620194 2.9210227212313784 58.90103105469521 0.7772785016677457 
1.8211796750903484 2.9870753522732447 59.192661357544004 0.7652164415145374 
1.8378237873023109 3.035468921509886 59.30425190979655 0.7558860424205872 
1.848895036193498 3.0714584014935147 59.60056365814032 0.7500802426819395 
1.879296343882169 3.1452447640984147 60.17021307983688 0.737302771048972 
1.7494130837656114 2.8194976701926495 58.527414426669864 0.737302771048972 
epoch: 36, train time every whole data:211.48s
epoch: 36, total time:10429.90s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.46s
test time on whole data:59.08s
1.5807440643002766 2.5544093073016207 56.94003554768743 0.8398803438648785 
1.6093859797439405 2.6240717150426947 57.777806402077715 0.8323822975471546 
1.6382105435387542 2.688595224134277 58.32701291633858 0.8242365178744808 
1.6631925031790245 2.7201182823999197 59.32199183504716 0.8193701039873942 
1.6876702992539143 2.7581169424454455 59.87448557116382 0.8140937563788865 
1.7103112584992888 2.795837269822758 60.20982506644533 0.8089152382021296 
1.7241877363230147 2.8376822836945426 59.89953422085912 0.8030629203574957 
1.7375431403287998 2.866442061297086 59.675626548888786 0.7989112322437827 
1.7522889880259478 2.8934733789616494 59.76540390049062 0.7949734942308313 
1.7696076015583462 2.9296737073665833 60.10583521828766 0.7901261580941762 
1.784038073357106 2.9589966755442987 60.614416746012154 0.7872966426540737 
1.8205013239600119 3.038600413470849 61.3408164110346 0.7772878670886655 
1.7064734593390354 2.8088420358889876 59.48779528853062 0.7772878670886655 
epoch: 37, train time every whole data:211.49s
epoch: 37, total time:10710.07s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.59s
test time on whole data:59.16s
1.5999116314511215 2.626695935278151 53.90691460968481 0.8402197589774578 
1.6251245674294021 2.6743176552739962 54.57373780362954 0.8332837734303922 
1.6557141880530508 2.7326798090742175 55.28015737205347 0.8269747548107307 
1.682828247902028 2.7923301761941164 55.882259247571895 0.8207808990305124 
1.7146525469982907 2.8759756936116183 56.21436233928948 0.8135812332193169 
1.7449700347861896 2.9400113588824373 56.59884797419562 0.8092536933905878 
1.7743091096087757 2.995762015024028 56.78690522311519 0.8043031697520842 
1.7923018503980268 3.033040540013469 56.929743993441484 0.7991229898186283 
1.812633140946694 3.07707988395894 57.31556926135156 0.7920640640066998 
1.832440012459865 3.1215513464326787 57.746845438887426 0.7848035850593162 
1.8488250843957954 3.1576748838273208 58.374424414338435 0.7765822111746703 
1.8778122238727908 3.2300912844532443 59.15744470272628 0.7613101521343082 
1.746793553191836 2.9442300204055454 56.56401550478493 0.7613101521343082 
epoch: 38, train time every whole data:212.69s
epoch: 38, total time:10991.61s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.54s
test time on whole data:59.08s
1.590621601878355 2.6085006604427354 54.68953152164791 0.8406383146076274 
1.6124973370702493 2.6527104687119727 55.576991053879674 0.8356588476172887 
1.6286265640273867 2.6766882649131962 56.309368615429825 0.8300729885449957 
1.6383373376617119 2.691208651188809 56.99852443822921 0.8249281699196115 
1.65402375554728 2.715588976825943 57.64609034613662 0.8186881650029963 
1.674651568858485 2.75688948797293 58.463113644872266 0.8112158437587537 
1.6964112901317754 2.800768622186785 58.98057159956222 0.8042486033580908 
1.7166086362447768 2.8344580383347107 59.39586622751527 0.799596669428961 
1.7380488517218757 2.875898214226348 59.99296817875589 0.7934158826784851 
1.7492173788307146 2.898528057078214 60.53112260806931 0.7897543813496889 
1.7560232924999049 2.911907658974518 61.10478516445207 0.7876754475412839 
1.7764986188378895 2.9621494315555337 61.790555485317235 0.7797981334831618 
1.6859638527758671 2.7842941039828113 58.45675032784655 0.7797981334831618 
epoch: 39, train time every whole data:211.65s
epoch: 39, total time:11271.48s
fine tune the model ... 
epoch: 40, train time every whole data:437.16s
epoch: 40, total time:11708.65s
predicting testing set batch 1 / 168, time: 0.34s
predicting testing set batch 101 / 168, time: 35.64s
test time on whole data:59.81s
1.5132833796145306 2.4711463113551395 54.90969165269684 0.847288849764182 
1.5357818886958772 2.513769159608217 55.155938784898936 0.8429979830678473 
1.5590570279601075 2.5671702235696916 55.21675093729479 0.8373949229580581 
1.5765605857148766 2.6041785189839297 55.450415555277324 0.8339588898930981 
1.5993996786893834 2.6521941156363176 55.63873516633383 0.8291252884336574 
1.6240827079498696 2.6988799166594535 56.07374229939642 0.823927496437039 
1.6495646827407182 2.7576574272190206 56.50945904783444 0.815875956269381 
1.6691991938582311 2.8037334192727594 56.973676839290476 0.8085957365034139 
1.6880029135884806 2.8424471907599465 57.698243890312696 0.8010638464387165 
1.6990233243891881 2.8612082239337386 58.43313828588289 0.7972041010967893 
1.7031715898982116 2.868309192982483 58.92653921965315 0.7959028739337471 
1.7217058513935302 2.906711327289111 59.3678267934716 0.7911940503021364 
1.6282360687077504 2.716056840024897 56.69625947881154 0.7911940503021364 
epoch: 41, train time every whole data:429.23s
epoch: 41, total time:12206.55s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.45s
test time on whole data:58.95s
1.5106628507287907 2.464905542960387 55.1316929234273 0.8490048839344226 
1.5327842914065613 2.505496894883051 55.65388633888414 0.8439365041876011 
1.5520045243294112 2.5453460623744917 55.90622313035233 0.8389392454612404 
1.5663927483739597 2.5764982835974646 55.95927039173281 0.8362568706304678 
1.5890664074682586 2.629195745348711 56.01064878364688 0.8310065749809924 
1.6128178043580126 2.675436627976737 56.32749497537135 0.826107213067091 
1.6374691973482924 2.73218413706127 56.74252487288284 0.8181654741563795 
1.655932417861585 2.774558772549673 57.152101537473996 0.8110318303823005 
1.6731578420950544 2.8092530076137257 57.813618368865164 0.8042308294385915 
1.686204125734401 2.8322408365455374 58.49891043286749 0.7996465629807823 
1.6913460243454292 2.844241502311858 58.900826980726684 0.7975453372052449 
1.7082599720706542 2.879621361142122 59.38386226774992 0.7928026288520413 
1.6180081838433675 2.692574070343508 56.9568246373913 0.7928026288520413 
epoch: 42, train time every whole data:437.87s
epoch: 42, total time:12713.60s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.69s
test time on whole data:59.28s
1.5106971144097014 2.470055122484651 54.9090108368795 0.8489308444453348 
1.5352218620842766 2.521604434437634 55.19255553545509 0.8435683034627445 
1.5570930656384498 2.5665047855056584 55.3433745319293 0.8388827631331833 
1.5736212570969725 2.5971320175589296 55.62585897233821 0.8357799307952263 
1.5948030085919336 2.6413724339342344 55.93413577692187 0.8305409974264663 
1.6157021506232698 2.6785437076111167 56.44713557944632 0.8258290576347446 
1.6370545717708411 2.7277934545981144 57.01089876781814 0.8179392710656064 
1.6546849638493288 2.7677141912276513 57.59207284201678 0.8106941735857716 
1.6731057908801097 2.8086127922462047 58.332347363080785 0.8031905801690634 
1.6866777682369132 2.8317221971685784 59.06489474544875 0.7990050659953687 
1.6936760845377687 2.846779154519283 59.409428190520345 0.797091126768991 
1.7137753494247085 2.8906173301528706 59.81079936414845 0.7915335401445152 
1.620509415595356 2.6989353300396575 57.056135786158634 0.7915335401445152 
epoch: 43, train time every whole data:436.53s
epoch: 43, total time:13220.75s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 36.24s
test time on whole data:59.86s
1.5098809870501892 2.4672275116386073 54.91959352439573 0.8495877687351141 
1.5335630710546282 2.5163080749869 55.38163961207928 0.8443082295308653 
1.5549803487759615 2.563197605543291 55.693065011653445 0.83919188030108 
1.5718428382737828 2.59603532788691 56.05197530182863 0.8357378788479575 
1.5964987773127144 2.6488834626221798 56.366780087979485 0.8299031806918876 
1.6238627320040195 2.70144771049074 56.9320079223727 0.8239052971478362 
1.6502336844819643 2.761735335471455 57.446463949596364 0.8153748560516357 
1.6706448593390661 2.806712589151644 57.91299887144482 0.8076479538687739 
1.6891907538578268 2.8488367156875074 58.592857372264305 0.7992259797989016 
1.7036436427773995 2.8719769019467365 59.36525554747565 0.7943472936003657 
1.7091923859790854 2.8831206851161078 59.75031857452093 0.7923671654569644 
1.726459136082303 2.9155729524239797 60.204612590767034 0.7879913477329488 
1.6283327680824118 2.7191403780623498 57.38489351179342 0.7879913477329488 
epoch: 44, train time every whole data:436.24s
epoch: 44, total time:13726.77s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.56s
test time on whole data:59.12s
1.5042060045378194 2.4375388038721164 55.84847461319211 0.8496559322346102 
1.5264129381195775 2.481372793345782 56.20786121794038 0.8445876637258706 
1.546554077187287 2.523328321846952 56.44979815929864 0.8397170757685021 
1.5632896864675871 2.557371227832423 56.600971182137805 0.8363905522594678 
1.586156256527507 2.607791600718988 56.699301202938365 0.8311016142725769 
1.610243499424752 2.6554248536194733 57.098630602592905 0.825832923080307 
1.634211851902927 2.7091596014048993 57.52478405358852 0.818310621238658 
1.652785039383918 2.7520962982392647 57.946627900239754 0.8111627708511733 
1.672205379417521 2.797857534170394 58.589607925082824 0.8029666164390264 
1.6835985991143223 2.8165689871328 59.20362873591607 0.7993890106297711 
1.6879534598420418 2.827004433756613 59.47324189138704 0.7977972437681187 
1.7049611361317691 2.863187296847953 59.877087180725866 0.7927255417332443 
1.6143814940047525 2.6727395581670117 57.62673959984623 0.7927255417332443 
epoch: 45, train time every whole data:435.46s
epoch: 45, total time:14230.17s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.67s
test time on whole data:59.26s
1.5055950032008723 2.445791407153721 55.65581118434489 0.8505064328055403 
1.5281215774681243 2.493320060358987 55.88789339120266 0.8453075416166229 
1.5493932878052195 2.5371977022095544 55.99866927882168 0.8408845558757572 
1.5658994823654315 2.570219814419438 56.181448037565154 0.8376587963539268 
1.5879313988355654 2.618021265014184 56.428469228722534 0.8323296927038266 
1.6095876424829698 2.6600334510417074 56.8505717605171 0.8275083199313132 
1.6340406507435477 2.7111344206436203 57.309744325954114 0.8202832002167192 
1.6530827061240339 2.7535628436415163 57.70999361658708 0.8136649960525457 
1.6738743191121945 2.802777276697118 58.31592924299199 0.8055554092147947 
1.6869787094707467 2.831177812296313 58.95578881541855 0.8007543626806619 
1.6963799968129467 2.853544656983578 59.307145903400446 0.7975834066927454 
1.714387878876268 2.8905912061815373 59.7195668656024 0.7930185105790066 
1.6171060544414935 2.6844222995661875 57.36016060810508 0.7930185105790066 
epoch: 46, train time every whole data:436.76s
epoch: 46, total time:14735.33s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.64s
test time on whole data:59.28s
1.50163625810455 2.4425825138534756 55.24019737383055 0.8507769584257825 
1.5238819792377096 2.488311219762616 55.67110261189087 0.8451786243076332 
1.5434507880876993 2.5263517229007935 56.05733336987814 0.840538579840193 
1.560389489452665 2.5617853928155596 56.298474694572555 0.8365483792997104 
1.5831013488317174 2.6141109414052894 56.531019774228085 0.8305670430566944 
1.6061818322487884 2.658439269761559 56.948177523165135 0.8258284130742022 
1.6320117110899162 2.7154529621913546 57.37043064541558 0.8184208902984715 
1.6531567659715989 2.7653891101167405 57.726366357609 0.8110021589415584 
1.6732912212243924 2.811922280000398 58.236811463435025 0.8032608563220385 
1.6865295392614568 2.8373717304011445 58.870293251924764 0.7986446164717717 
1.6921849934713293 2.8527897689486403 59.19312079850354 0.7959953624099446 
1.7085867461031747 2.8856540482954136 59.689547595068206 0.7913033549768113 
1.6137002227570831 2.684027300108637 57.31948373785155 0.7913033549768113 
epoch: 47, train time every whole data:436.17s
epoch: 47, total time:15239.79s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.71s
test time on whole data:59.38s
1.502477835315679 2.4428405868310326 55.363387493993656 0.8510663234696534 
1.5257919793437633 2.49257203481874 55.703936148538034 0.8454615685253513 
1.5471200429107106 2.536039812211194 55.98070009385951 0.8404479623114632 
1.5642350456744787 2.570710048974215 56.305885647587495 0.836298123891741 
1.5830491552856707 2.6056956542800447 56.59989532432014 0.8321659419579046 
1.602271602759404 2.641270779277205 57.131568486685026 0.8274652597164911 
1.6240257194496337 2.690836131956002 57.64645361481098 0.8200104899048335 
1.6415520080200263 2.732773832485896 58.09903697098 0.8135083397633144 
1.6601770453798983 2.7755352410517418 58.655389072996655 0.8067041900489652 
1.6718470191129793 2.7958982822016414 59.13952065340899 0.803749462384769 
1.6777454086640584 2.8132698509854395 59.26660312198746 0.801795963999717 
1.6965536953065368 2.8547690984691974 59.58424944873146 0.7967692691004464 
1.6080705464352365 2.66583138354592 57.45646863954538 0.7967692691004464 
epoch: 48, train time every whole data:437.70s
epoch: 48, total time:15747.32s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 35.72s
test time on whole data:59.37s
1.5004391457645134 2.4317665899590777 55.849239391520335 0.8509187954718918 
1.5238727434316561 2.484388061622293 55.955983019617285 0.8454327887212993 
1.5450229329324905 2.5307818683353793 56.08982849520622 0.8405833074735589 
1.5611622312349223 2.5660523956232666 56.19288703323484 0.8369885380239577 
1.585707079200074 2.61998639062203 56.41156786720081 0.8311667541084566 
1.608307802936417 2.6640466244561174 56.84070586117317 0.8262835850915472 
1.6312174025774888 2.71423619049017 57.3345140038546 0.8189183930808921 
1.649566009035955 2.755741782921583 57.828061534170736 0.8116587373947176 
1.667984108646888 2.7953358156237664 58.47996495516118 0.8045203459907097 
1.6802807057553104 2.817918083684434 59.13209928270442 0.8002719103133368 
1.6847386655948524 2.8294241123484385 59.39081253766905 0.7984684819476007 
1.7025596105465222 2.8660713104024764 59.80546480307337 0.7934553315011273 
1.611738203138091 2.676633282370074 57.44266930377422 0.7934553315011273 
epoch: 49, train time every whole data:438.32s
epoch: 49, total time:16255.14s
predicting testing set batch 1 / 168, time: 0.34s
predicting testing set batch 101 / 168, time: 35.86s
test time on whole data:59.75s
1.50452039769283 2.451069494540885 55.05714529042868 0.8504054094119018 
1.5261195898049822 2.491748764719625 55.52094278356735 0.8453827027657699 
1.5448606368981834 2.5271222848402064 55.90238871223529 0.8410742162487153 
1.5615033651423595 2.561908754087773 56.208886123892064 0.8367639212050559 
1.5831596738819387 2.6055092010552756 56.45429027714787 0.83189338474282 
1.6041748531346343 2.6470566164150484 56.85535857096639 0.8270382568512485 
1.6278969529087521 2.701391989873497 57.33851916137416 0.8193760402327207 
1.6482212941068268 2.748980618399755 57.842965491346185 0.8118371007764774 
1.6700634401115102 2.7991438642687902 58.60797719862039 0.8033328345460019 
1.6852865479364105 2.8297873625640553 59.38842483192601 0.7981593839408765 
1.6917744040945988 2.843047435963975 59.69524435067191 0.7962333052440606 
1.7108356584637825 2.8808470066804404 60.1596431436039 0.7910002182357923 
1.6132014011814009 2.6777070137865575 57.41940643539319 0.7910002182357923 
epoch: 50, train time every whole data:438.99s
epoch: 50, total time:16762.66s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 36.49s
test time on whole data:60.08s
1.4984637332472595 2.4289808331178997 55.865775748211476 0.8512453778340385 
1.5206021439010897 2.4782614113115646 56.08623160003295 0.8457345449456045 
1.54107870679056 2.5205336021427467 56.18555769217384 0.8412910732201762 
1.5588298341727682 2.560868553237596 56.288946496579875 0.837083895266183 
1.5816200544603525 2.6102324511518904 56.432061495931706 0.8318410254915104 
1.6030379878748209 2.651785004024439 56.79709449623353 0.8271402718094553 
1.627244789283368 2.7045824415348325 57.26799275515451 0.8194949861901162 
1.6467782231041541 2.750166035079081 57.75331944164801 0.8120056550147119 
1.667246681060642 2.7943382218148876 58.38455746768351 0.804532858965284 
1.6807470977046484 2.8197965577067667 59.0626452674358 0.8001872233658368 
1.687054077185247 2.837699556945479 59.32249383055507 0.7976327708850618 
1.704171652663854 2.8719400972547837 59.725907551270616 0.7933260464369815 
1.609739581787397 2.672958393484288 57.43111947001336 0.7933260464369815 
epoch: 51, train time every whole data:438.36s
epoch: 51, total time:17270.68s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.48s
test time on whole data:59.04s
1.5063127274348267 2.4509063567307354 55.11293221128236 0.8513063753003488 
1.528863300494406 2.496800522497932 55.5614717991195 0.8456307813895638 
1.5507742864114364 2.543196181681055 55.85057094455439 0.8405798536489167 
1.5697407157247265 2.5832257879553584 56.122037656488246 0.8363200218728398 
1.593654771310233 2.632622791043475 56.449625926279445 0.8312084744128287 
1.616432757925863 2.6712939847621326 56.895204119974785 0.8271379700355844 
1.6416229020181512 2.7274419435649366 57.38619775019994 0.8191829249710819 
1.6616263622628258 2.7752148504825205 57.8342685079393 0.8114333335182538 
1.6812982743231668 2.818292448705343 58.418839908446884 0.8040061709856753 
1.6929859636001112 2.842789172043425 59.05166284773008 0.799499606088241 
1.6987424928624006 2.8570012122245307 59.36242473384101 0.7970804540794254 
1.7157122696843 2.8901068379019415 59.86242116971495 0.7925058041855476 
1.6214805686710372 2.6945705364019283 57.325723688340425 0.7925058041855476 
epoch: 52, train time every whole data:436.51s
epoch: 52, total time:17775.93s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.74s
test time on whole data:59.36s
1.4990084198755877 2.4199079334480342 56.05274098237304 0.8517037812880754 
1.521863010966086 2.468753640878993 56.35272385068939 0.8459741776287476 
1.5431559563266735 2.5149211942817424 56.43947131187799 0.8411327925997691 
1.559357517259018 2.552654954993515 56.43905444426321 0.8374487925828067 
1.5823090486678162 2.603326157196484 56.561334409348795 0.8321014444887712 
1.602665219351117 2.642158222758385 56.88923938692669 0.8276576290970112 
1.6246295923251837 2.690441299451584 57.384345592704065 0.8202754588928385 
1.6417810458705007 2.7294596677627077 57.927747480947176 0.813382174311351 
1.6604346581403875 2.76940662673476 58.61436273927405 0.8064281798816629 
1.6734849757227515 2.7961573020185226 59.34003130252188 0.8018788639862795 
1.6810929212091223 2.8183535997904747 59.66647359117313 0.7985750269357713 
1.7015580298914796 2.860190808092912 60.1245515757144 0.7928822547751778 
1.6076116996338103 2.6591073641821765 57.64941168038784 0.7928822547751778 
epoch: 53, train time every whole data:438.11s
epoch: 53, total time:18282.82s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.55s
test time on whole data:59.12s
1.5020816619653432 2.448405311512266 54.832540564440336 0.851612296212609 
1.5274052947361376 2.503688850838328 55.13270841612997 0.8453998468983492 
1.549827827855235 2.5487828435571145 55.467012579696316 0.8404005108785046 
1.5677205821896594 2.5858195362397547 55.728765002588 0.8362402381277813 
1.593254597268023 2.639668463853352 56.083788584643834 0.8301605500270263 
1.6164193570896805 2.6835988834271842 56.56197433270863 0.8250478491258908 
1.639340814453328 2.7333139392572807 57.09389375916448 0.8176317069967294 
1.6568884122077199 2.772258145034664 57.67212640779895 0.8105202475599588 
1.6754148395670845 2.8126170286623795 58.38791484363072 0.8028698342421605 
1.687274799256009 2.8342036432619726 59.13961630526412 0.7986183126685364 
1.6931085819511542 2.8494852686821908 59.478387863194705 0.7959512762075528 
1.7105319111005715 2.8845468614561693 59.93237444933429 0.7909982447359977 
1.6182723899699956 2.694988832723942 57.12602029954071 0.7909982447359977 
epoch: 54, train time every whole data:438.26s
epoch: 54, total time:18789.17s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 36.56s
test time on whole data:61.17s
1.5001278306717674 2.4253059874086187 55.399972141075246 0.8515868011939144 
1.5236393122637555 2.4778310121191995 55.5272255028627 0.8457617916214907 
1.5445745910273068 2.522367063229641 55.710961064283836 0.84089326663508 
1.5609659975093921 2.5586153882039793 55.87891165142289 0.8368575774315156 
1.5843904901581507 2.6054395275593385 56.12665707941602 0.8316796880287051 
1.604969536140916 2.644828281105062 56.50314218401542 0.8271338835241965 
1.6277122702938283 2.6946120231318136 56.98303419529774 0.8199520791780013 
1.6458654981684826 2.7346238661637097 57.43904923676326 0.8134496321918029 
1.6652473721294885 2.7753443743773194 57.97774294975441 0.8068612866509659 
1.6767939392664426 2.799623797238558 58.50458008291252 0.8029514971337235 
1.682925803022193 2.822293117842493 58.72012351937765 0.7996857253888388 
1.6993311200395582 2.8553520091416087 59.08943215037355 0.7956910996561579 
1.6097119800576067 2.663205160423597 56.98847383779566 0.7956910996561579 
epoch: 55, train time every whole data:435.62s
epoch: 55, total time:19294.83s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.72s
test time on whole data:59.33s
1.4978458091248537 2.4288815917765474 55.362594681903985 0.8518564336329072 
1.521037329556864 2.4784760714075773 55.61646857211886 0.8460671082048183 
1.540968773234813 2.5163569743667535 55.91238589686319 0.8414889777268613 
1.5577139293636595 2.550832705641964 56.108758237098634 0.837564258862483 
1.57993084098514 2.5966817143326746 56.36388795116283 0.8323125545700087 
1.6015182567403785 2.638605282074817 56.7304566749344 0.8273147588641876 
1.6256875913240725 2.6927988600975628 57.21015580111661 0.8197398702226736 
1.6451207424950387 2.736485203522996 57.69463806480325 0.8130569820490134 
1.6662858029192402 2.785064412649893 58.28434181701617 0.8052097412740366 
1.6804549530319692 2.814800296646416 58.90487356142506 0.8004562076991262 
1.687665685828775 2.836806121204832 59.13940380496451 0.7971366924701513 
1.7049484239139905 2.870803969915042 59.55055545180904 0.7925405784840389 
1.6090981782098996 2.666056528592502 57.23995453353478 0.7925405784840389 
epoch: 56, train time every whole data:436.04s
epoch: 56, total time:19799.05s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.64s
test time on whole data:59.30s
1.4983456542561984 2.4390845873335536 55.2273776264257 0.8517247551487755 
1.52295003026919 2.4932381952540177 55.48961100440953 0.845656043490596 
1.5460932475241522 2.539626895320483 55.773360926972174 0.8406740623126291 
1.5655644523096048 2.582503860699024 55.99376305257005 0.8361544208453171 
1.5918943217719594 2.639561139678012 56.32318576517028 0.829824413289463 
1.6157092976823804 2.6832853211538423 56.79099898623389 0.8246864861623795 
1.6394475674437625 2.734796172833244 57.3317089261361 0.8169374427143479 
1.6586140832985263 2.7807649976661275 57.90641998981367 0.8089401588114202 
1.6797008396534339 2.825976180247992 58.55877481485267 0.8011139825866155 
1.6917700995229008 2.850573870712683 59.191903770446565 0.7969617750859528 
1.698163150578826 2.8661209307372792 59.437587136093626 0.7947819325303349 
1.7137883669828908 2.8971506536304505 59.851060794888674 0.7909103275534338 
1.6185034259411522 2.6985105822096442 57.323067840328626 0.7909103275534338 
epoch: 57, train time every whole data:432.13s
epoch: 57, total time:20299.84s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.54s
test time on whole data:59.13s
1.498076223226264 2.42707626610521 55.78528483308601 0.8511877401923404 
1.5213627332870272 2.478922967655687 56.010343872645265 0.8452023051786678 
1.5420036378272233 2.517925803984568 56.30751975414518 0.840937543524313 
1.5581322367089312 2.554371636624487 56.4480028224539 0.8369987834847651 
1.5822579214764494 2.6038412789947625 56.75568386584715 0.8315836915549026 
1.6052334696702837 2.6506809345671405 57.12701685081323 0.8263085657397734 
1.6313257824897411 2.70918474612416 57.584171935284026 0.8182720291091033 
1.6515003001158615 2.752354041926481 58.04609115596699 0.8114190447208269 
1.6730219115056097 2.8037993752362107 58.59957765128681 0.8028269962559921 
1.6871383028566127 2.836554602469967 59.16715037034327 0.7973062678045877 
1.694674876205357 2.8587957756204556 59.38398659246488 0.7937618115390018 
1.710271300893809 2.8884469904862797 59.84414553611438 0.7895887722405786 
1.612916558021931 2.6777622643133063 57.58832341506582 0.7895887722405786 
epoch: 58, train time every whole data:435.58s
epoch: 58, total time:20803.61s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.45s
test time on whole data:58.97s
1.4981859174661694 2.441435196081927 55.09505181281374 0.8515691046607096 
1.5218010397353874 2.491239804494909 55.3835596960002 0.8458632629406238 
1.5432884669266642 2.535241640837411 55.701345521366285 0.8409033655149677 
1.5609594608362587 2.5720834427993124 56.039243623381154 0.8364814186946459 
1.5843677573892332 2.619040603497049 56.48082201473633 0.8309545058913251 
1.6070148325403708 2.6639922775506966 56.96654295842806 0.8255179229263938 
1.6302591811632294 2.7125900434645254 57.50557337238654 0.8185931925135195 
1.6489205381147387 2.756169252089442 58.0329822167536 0.811502739968882 
1.6707752507566695 2.8058112913183626 58.67676113413456 0.8033184985323217 
1.684524279316621 2.8345263553528888 59.33283888714267 0.7985426009200579 
1.6933928244221246 2.8556225331667653 59.64425082179589 0.7953833905400047 
1.7096962602849872 2.8864868947921596 60.08080264212753 0.7912186249938775 
1.6127654840793713 2.685055718376316 57.41174277199859 0.7912186249938775 
epoch: 59, train time every whole data:434.77s
epoch: 59, total time:21306.39s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.56s
test time on whole data:59.18s
1.4974160731646808 2.4307598484678112 55.72875393615189 0.851172551275852 
1.5209526467915802 2.480433764138725 55.92686248081258 0.8456626702531761 
1.5419831315930932 2.5234704811667794 56.18062519371496 0.8407813717496111 
1.5588587818737363 2.558649879121321 56.394768072538746 0.8368520416265797 
1.581066611302928 2.6051903561837184 56.66504981052165 0.8315631634436945 
1.601645724436623 2.6449177239973176 57.00883047775298 0.8270311574034473 
1.6245925302281088 2.6975120202754947 57.46512243953842 0.8195412949378161 
1.6432027848990014 2.7383712012087913 57.960921811215705 0.8128955816557992 
1.6654563111038434 2.7914260262850124 58.543836590698064 0.8041872538088378 
1.6800631416256406 2.8249713087071666 59.116564614726094 0.7989970110610126 
1.689234634560666 2.8470855085554914 59.24927464850248 0.7962499258608857 
1.7076481651161752 2.8822183640761216 59.52914830330719 0.7922762988966721 
1.6093433780580064 2.6726889208676288 57.4808875954767 0.7922762988966721 
epoch: 60, train time every whole data:436.79s
epoch: 60, total time:21810.81s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.56s
test time on whole data:59.13s
1.4971311657903272 2.4220235120094307 56.1550951515814 0.8513892126464128 
1.5195999577041006 2.4708828327323795 56.295875367384006 0.8459129268462685 
1.540502189614056 2.514230604684203 56.508955665876634 0.841012070342441 
1.5572852740203518 2.551712894050473 56.75190096392338 0.8367282870387237 
1.5802100506090515 2.6000747665283668 57.13442438722968 0.8310149892885116 
1.6019206181816048 2.638945851074058 57.53103898267702 0.8265847779961911 
1.62650686694318 2.693251045938334 58.00344731697966 0.8190288877815033 
1.6449721247729445 2.7327676353108625 58.44356835973541 0.8131618835785853 
1.6664827951191081 2.785014329397678 58.99215860029019 0.8049308977630907 
1.6805505642534366 2.815007482336957 59.626891093206034 0.8001667371853719 
1.6902528703709443 2.8408624040238832 59.940563692134376 0.7962569126291237 
1.705732958057363 2.8682416978842475 60.41689580502359 0.7927031992260954 
1.6092622862863724 2.6650200094799614 57.9834812360078 0.7927031992260954 
epoch: 61, train time every whole data:436.75s
epoch: 61, total time:22317.19s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 37.04s
test time on whole data:61.51s
1.4974295436956344 2.4276436701682718 55.3310611632592 0.8517711410412317 
1.521867972217589 2.4772377531517207 55.71609440379309 0.8459623053687134 
1.5430089386176495 2.523667446006825 55.99691186576078 0.8407212696002262 
1.560985577695249 2.563999703726689 56.25137947751466 0.8362229164088655 
1.5846514856433052 2.6101287044153065 56.58854337557896 0.8310973490155817 
1.6084433121164108 2.6577161537349827 57.018313542110235 0.825421613651235 
1.6343007211917568 2.718053487548266 57.534767393409204 0.8169092017579724 
1.6540381089688412 2.763030483886066 58.02087158769249 0.8097655871805747 
1.6752498577310748 2.8149010930357967 58.62020385079604 0.8010171002085203 
1.6890643397902272 2.843614117572804 59.22596998386266 0.796169501888238 
1.697164299025777 2.8645797818615644 59.49529186914793 0.7929021197925881 
1.712054695292509 2.89026014893771 59.96207232533221 0.7895459333512791 
1.6148549043321687 2.6839144643848094 57.480208845068745 0.7895459333512791 
epoch: 62, train time every whole data:435.41s
epoch: 62, total time:22824.82s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.57s
test time on whole data:59.13s
1.5031709073922108 2.4484845955216334 54.61058545884989 0.8510889600323067 
1.5280795468966522 2.4992553304423892 54.868832499770726 0.845660305580597 
1.5525300572660885 2.55146418112303 55.06693166264828 0.8402196085594723 
1.570413226658833 2.5917305040479777 55.35230734414394 0.8358211206490096 
1.5937652553834376 2.638580740566069 55.79055964241917 0.8304665164425374 
1.6162989496548794 2.681066467387898 56.30596827092479 0.8255122582559191 
1.6400843177553976 2.7334860244254973 56.83521128290291 0.8181277797229066 
1.6605750349884232 2.775198097259619 57.33223662991498 0.8111870792638562 
1.682989874231496 2.8320023827679455 57.89087608599354 0.8013976197475517 
1.6978326397707597 2.8602457519286104 58.50176288006307 0.7966001042592584 
1.708546343816178 2.8885773146633653 58.80721173265972 0.79206740576904 
1.7258882125885713 2.9191546034019162 59.300390912937694 0.7877411119891743 
1.6233478638669105 2.705840477944553 56.721995396854076 0.7877411119891743 
epoch: 63, train time every whole data:437.94s
epoch: 63, total time:23330.46s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.54s
test time on whole data:59.77s
1.4980733580970693 2.427456405335497 55.89016158511825 0.8521391764256518 
1.5231729774699503 2.485032705392394 56.1211469078166 0.8457129943742451 
1.5475399917113106 2.537365790305498 56.264484292269444 0.8403041113357721 
1.5669065826050936 2.580237729298095 56.50676483509317 0.8356142604509839 
1.5907551430057556 2.6310748887913316 56.829747552232654 0.829887835650585 
1.6149200549879599 2.6798592304296367 57.267646570017405 0.8238723966807335 
1.6388015389676605 2.730882074449993 57.75701508675747 0.8164549580029052 
1.6572899704450474 2.7721027248283416 58.30117988604698 0.8094688329699217 
1.6779966588274886 2.8194503177179544 58.952169231453844 0.8013628448295236 
1.690434660083836 2.8447532723312086 59.600127840515206 0.797179443087018 
1.6981681814878469 2.8635473461418077 59.81596052531325 0.7946320301362322 
1.7122275045333164 2.889531775264989 60.16288843938613 0.7916294228132241 
1.6180238851851947 2.692605206633241 57.78919067767245 0.7916294228132241 
epoch: 64, train time every whole data:437.63s
epoch: 64, total time:23836.70s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.63s
test time on whole data:60.55s
1.4969853783439668 2.4308937233507635 55.344460197159485 0.8513334208675848 
1.5204427852234137 2.480694717595625 55.553668317096204 0.8457467915665414 
1.5419774240517012 2.5245914166075467 55.76484007794746 0.8411203089743117 
1.56005983177333 2.567685851760676 55.96756309688553 0.8364628845159738 
1.5836298144341756 2.6164864070116765 56.300673201126784 0.8312517247115465 
1.6064515409785367 2.6618924152059003 56.75810506151875 0.8261751597905269 
1.6315163700365949 2.7193622235950996 57.29121908600505 0.8183844844366638 
1.6519742415040022 2.76099000365831 57.85993112434209 0.811892053815162 
1.6730108090808526 2.809742913021783 58.467024977221016 0.8038914182857083 
1.685595422007587 2.8376584691313766 59.08985028623781 0.7993086209062564 
1.6957674354091288 2.864691490595748 59.4576559430836 0.795101572724358 
1.7131750789886961 2.896662578398453 59.9703452798395 0.7906732443214682 
1.6133821776526656 2.6851971426072407 57.31886434410013 0.7906732443214682 
epoch: 65, train time every whole data:435.58s
epoch: 65, total time:24343.02s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.53s
test time on whole data:59.14s
1.4976073356735564 2.4385854317344444 55.29477486621849 0.8515602306455113 
1.522129655040091 2.489179819996072 55.690991671020576 0.8455998816141317 
1.5442998052026544 2.531856704572037 55.89836589393965 0.841276730472117 
1.5624148977821073 2.571249417149367 56.09790355374098 0.8371453464821272 
1.585399733696665 2.6198964887992546 56.39251007260998 0.8316066039142439 
1.606872070194976 2.6601303245454333 56.74528623674796 0.8269693989253707 
1.6283400371383343 2.7068421030523315 57.20467721554054 0.8199293866602421 
1.6453531756760287 2.744754339149989 57.70142097588585 0.8133291459366466 
1.6658844002392144 2.7939921508953187 58.349348190541924 0.8047883089000776 
1.6766369359575743 2.8149663049032365 59.0116390539133 0.8009561700333325 
1.686254883273549 2.838449235432591 59.392767095052335 0.7971947717928597 
1.7005121343830334 2.864329585852323 59.85926505253608 0.7937893387221414 
1.6101420886881488 2.676390043915978 57.30332701978567 0.7937893387221414 
epoch: 66, train time every whole data:436.74s
epoch: 66, total time:24849.45s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.64s
test time on whole data:59.24s
1.5096890838841597 2.427879880193655 55.99036256271543 0.8515913700611524 
1.534872564929848 2.485518154995317 56.07833977259838 0.8452379904901157 
1.557963978290824 2.5333046731872435 56.23540040715811 0.840259176452251 
1.579309121876955 2.5777953307782044 56.57855781767561 0.8353412815611696 
1.6057920603155202 2.6351320932678615 56.96727683123286 0.8286873860644921 
1.6322398900555535 2.685431940422025 57.42827895000397 0.8230641220282175 
1.657411924892327 2.740087171302134 57.836264592760244 0.8158180451775292 
1.677390707136531 2.7866327458974833 58.248504963045676 0.8084879684489366 
1.696820871864756 2.832194628857535 58.74623980758461 0.8006505641020553 
1.708957609859783 2.8568438038543236 59.33860641028807 0.7962177937532973 
1.7157571022420057 2.8759117781996175 59.59477382346425 0.7930414085263016 
1.7291702296717004 2.9001530244318086 60.096213016381014 0.7896220168413313 
1.633781262084997 2.6992061676374566 57.76164668837772 0.7896220168413313 
epoch: 67, train time every whole data:437.79s
epoch: 67, total time:25356.20s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.53s
test time on whole data:59.07s
1.5054045699687586 2.4153787553664405 55.647816449483386 0.8513665647123672 
1.528445075565683 2.4621107189892566 55.819419155312424 0.8459473581452953 
1.5496053040303468 2.5107175656622256 55.97333306993724 0.8404466382989072 
1.565945730329979 2.5480712258727323 56.04714705374138 0.836442865234706 
1.5892241030266243 2.597283639193424 56.30288862305275 0.8309324150026063 
1.6117591873457033 2.6393129254272854 56.71112400013343 0.8261987519913394 
1.6347558844980916 2.69070584610617 57.19708784182743 0.8188639557878018 
1.652933675551787 2.7309864251314075 57.686969202095206 0.8122394391298992 
1.6728193648050407 2.7764143807800243 58.30351843328814 0.8045460851199293 
1.6854149870609065 2.801175808308616 58.96785286701333 0.8001272864199378 
1.6946803553262282 2.8290647408322025 59.28608040405244 0.7957032299733147 
1.70787966615618 2.8536828077031973 59.653550364885575 0.7923103761894384 
1.616572325305444 2.6583928229604328 57.29980762315099 0.7923103761894384 
epoch: 68, train time every whole data:437.07s
epoch: 68, total time:25862.18s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.55s
test time on whole data:59.10s
1.4995125829461253 2.4302899348635147 55.17525965506774 0.8514050956105522 
1.52425498610664 2.481827537908148 55.44602839667526 0.8454921579273539 
1.5465794582850345 2.5315208992657774 55.705564461340806 0.8398564132075045 
1.5638140930895295 2.566210210121879 55.944729872144705 0.8362740692673956 
1.588027424584542 2.6177048059207744 56.34139582059362 0.8302723589695172 
1.6094019444798606 2.6594799463816816 56.774913821760094 0.8253359186446275 
1.6312823516080777 2.7067296778315515 57.30114993895823 0.8181768512985539 
1.6491986310775613 2.746250929270001 57.81636514523388 0.8112816535280316 
1.6691847819431374 2.7889692546557616 58.413388595738404 0.8040004275237905 
1.6816094534993171 2.815671351914106 59.03792962137931 0.7994075557298335 
1.6905128952584096 2.8404644764557077 59.29699274209314 0.795555184188648 
1.7047731891139632 2.8680637503312174 59.72851640073307 0.7916724583626976 
1.61317931599935 2.674784797204323 57.2486060776608 0.7916724583626976 
epoch: 69, train time every whole data:435.49s
epoch: 69, total time:26366.61s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.53s
test time on whole data:59.04s
1.5010538859873832 2.423795827202907 55.520137507182724 0.8519017355129849 
1.5259197997706277 2.4776217518828196 55.735915884198185 0.8456481788125068 
1.5480929372852579 2.522002306341025 55.90836081932877 0.8410145371296325 
1.5677148687239026 2.5661380679127173 56.108204111368224 0.8364420352207615 
1.5946732545538496 2.623859960680568 56.44783662927884 0.8303089202187386 
1.6205628526170872 2.675483124799501 56.85254731071249 0.8249020911012118 
1.646374675585844 2.73170620473756 57.297565215843136 0.8172944998044872 
1.6673983323453438 2.7773796252179235 57.76358372643522 0.8097780150371771 
1.689614715973891 2.8277909048398464 58.34677194992962 0.8010359395391657 
1.70428136678519 2.8594318555887464 59.06461663866488 0.7953605423544547 
1.7146778901048183 2.8833882715849053 59.49555839772136 0.7913639706708012 
1.72986482034189 2.9120554093465074 60.059531238814145 0.7871599358695877 
1.625852450006257 2.6948192573922354 57.383466794726004 0.7871599358695877 
epoch: 70, train time every whole data:437.64s
epoch: 70, total time:26873.75s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.97s
test time on whole data:59.54s
1.4973901849550506 2.424430661192566 55.50665509687324 0.8521584163660796 
1.5219386015696716 2.477754906460653 55.66526946021375 0.8461849866977679 
1.5440959173396585 2.5249701227459456 55.86790597271016 0.8409141521485444 
1.5622637212532795 2.564335329948273 56.120347903272126 0.8363561636720154 
1.5857336799129844 2.6125274787724586 56.50476717806164 0.8304015106860188 
1.6084177525214673 2.6561825741910807 56.94250694848109 0.825187720231059 
1.6315977431968565 2.7056589286275825 57.381458799440125 0.8184380214068643 
1.6507397739390532 2.746097240738119 57.86068318334871 0.8120427676746895 
1.6719289430014435 2.793910568535305 58.45332985533979 0.8042173611830068 
1.6852342860527514 2.82319179493629 59.11760642122543 0.799204378843628 
1.6957091682579013 2.849185803643583 59.46838064390669 0.7950149997237755 
1.7107478097059896 2.875901152613008 59.97717844565743 0.7911758619445377 
1.6138164651421756 2.6751274823249713 57.40559058935833 0.7911758619445377 
epoch: 71, train time every whole data:437.14s
epoch: 71, total time:27381.76s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.66s
test time on whole data:59.21s
1.4957475775443017 2.4283571356776856 55.74512395098623 0.851666901623386 
1.5199156163180514 2.4807552689297716 55.984887517405504 0.8456303388066374 
1.5418605397235425 2.5253161624683034 56.192891040179994 0.8406935666276862 
1.5613605897251872 2.5683698265842874 56.3930078064204 0.8361851742486954 
1.5866257212371344 2.625079595803293 56.673863669810196 0.829879758432453 
1.6107117529841406 2.67311339865252 57.0237007442672 0.8246269667282897 
1.6352809336053296 2.7255548733498602 57.44528274778459 0.8176284801778093 
1.6555438604960662 2.770874996919861 57.93980971214572 0.8103876055123563 
1.6773309991085636 2.82010298669875 58.518366211455294 0.8021487985242802 
1.6905019814752575 2.846561209816352 59.183494764422626 0.7976439913869177 
1.7003993983345904 2.870955043542429 59.52503016211645 0.7937862918637076 
1.7130067670093405 2.8939777833754072 59.99719135824638 0.7905841227812841 
1.6156904781301256 2.6901234166443238 57.55196429187859 0.7905841227812841 
epoch: 72, train time every whole data:437.24s
epoch: 72, total time:27887.26s
predicting testing set batch 1 / 168, time: 0.34s
predicting testing set batch 101 / 168, time: 35.38s
test time on whole data:58.85s
1.5012784108618895 2.4432931052672138 55.5218993153815 0.8508294073250625 
1.5254968605485877 2.487850700371393 56.0014587070106 0.8452971857682242 
1.5476749610341198 2.533520191008381 56.23643526381993 0.8401008928836408 
1.5671255639829629 2.5766873653779743 56.46401388556804 0.8355083561640775 
1.5926161999768977 2.631347076972225 56.7749561195583 0.8293280731609726 
1.6168263512297223 2.680401773436243 57.16231153317754 0.8237274589932451 
1.6414549381226478 2.734422430940724 57.63934950063662 0.8162610903908453 
1.660521695236986 2.7737457062745428 58.17763302966756 0.8097642727694977 
1.681656305906762 2.821695523555096 58.76759212892962 0.8013887262864163 
1.6926791868349982 2.8430807637680564 59.36990615741177 0.7975374332277644 
1.7011150665819823 2.866485364516295 59.62831129969227 0.793718244510134 
1.7117177345902614 2.8833857799783975 60.04044106829332 0.7914812859551266 
1.620013606242318 2.693698244379765 57.6487750068824 0.7914812859551266 
epoch: 73, train time every whole data:435.99s
epoch: 73, total time:28392.56s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.90s
test time on whole data:59.59s
1.4967448838036508 2.4290541712750406 55.75813196765084 0.8512303450856101 
1.5211479755106072 2.476535527611981 55.985001168796636 0.845985660773596 
1.5432397443747947 2.5247871114266096 56.12496834073873 0.8406566181380353 
1.5627812460088837 2.566433978529375 56.28895371116419 0.8364285582102824 
1.5873831036466928 2.6186159096749817 56.54833571710803 0.8305778164615272 
1.6107156691701994 2.6626223047897546 56.9624940428791 0.8256123004020915 
1.635360531536064 2.7180770714064773 57.415101740727835 0.817772000008227 
1.6547493209159445 2.7616157837629087 57.92377273593762 0.8106339584276967 
1.675533900989929 2.808864792069284 58.52396176650983 0.8025283051334939 
1.6880066418583903 2.8344281301393646 59.18682573240618 0.7979081977714804 
1.6991123751749595 2.865080254562962 59.54373095405941 0.7928427517850029 
1.712257424561218 2.8875304302966582 60.01049735255871 0.7896790738391948 
1.6155860681292777 2.6836861827580476 57.52272566132144 0.7896790738391948 
epoch: 74, train time every whole data:438.53s
epoch: 74, total time:28901.34s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.61s
test time on whole data:59.25s
1.4954757057653651 2.4292134435189943 55.53374598684907 0.8513337009392317 
1.5206659479464093 2.4800653245218576 55.754340130990975 0.8456506091429066 
1.5423102431492437 2.5262846570534245 55.95524334824973 0.8404654441584679 
1.5619908997842245 2.5702936322812593 56.07598745214346 0.8361460678498425 
1.587900220588293 2.6268673533543363 56.33483892667683 0.8302228659190157 
1.6109607693560954 2.670457706747516 56.71890106051798 0.8257274725996472 
1.6355646152734047 2.723237466154073 57.17293661708124 0.8185337184735997 
1.6561884473018527 2.769231202831931 57.73447930691275 0.8111988468711707 
1.6780431684353168 2.8167917262797917 58.382154453141844 0.80330657996611 
1.6926809342882285 2.8447192573730407 59.161019598064115 0.7986439232781546 
1.70578028616797 2.8778765895444325 59.6361933151073 0.7935441293263117 
1.721929384758962 2.902189869083766 60.24146487683697 0.7904806440905271 
1.6174575519012804 2.6908547075154243 57.39185761507599 0.7904806440905271 
epoch: 75, train time every whole data:436.12s
epoch: 75, total time:29405.63s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.53s
test time on whole data:59.06s
1.4959102491884537 2.4330401278331832 55.41673418547951 0.851274044449216 
1.5202389308443027 2.4820237105832743 55.72135810957883 0.8456486713725724 
1.5418451073523611 2.5282130642008385 55.92515814490899 0.8406367845958395 
1.5602252249262696 2.5700466514357845 56.15031193297519 0.836014243713048 
1.5838019285041485 2.6193947766668435 56.56244694999906 0.8300804033287791 
1.6048916533122815 2.6563093327192067 57.06955487322845 0.8255508564429934 
1.628015273746724 2.707217565040223 57.642867370946725 0.8182328075036222 
1.6486216516776808 2.751624901016626 58.210097389204996 0.8114240582843832 
1.6703292529308016 2.8001337585307406 58.80326371119753 0.8037258723965478 
1.6835024455293481 2.831036018193354 59.43570905920473 0.7985912108169304 
1.6940303315570844 2.8608817260560393 59.73930137817275 0.793948530095361 
1.7061998451937521 2.8801581137475067 60.212971086042735 0.791325356791637 
1.611467657896934 2.6806446810455307 57.57423904586495 0.791325356791637 
epoch: 76, train time every whole data:436.96s
epoch: 76, total time:29910.68s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.51s
test time on whole data:59.08s
1.500934396159436 2.421242837475091 55.93752998211035 0.8511978600176597 
1.5233648258231225 2.4648809176931157 56.24410586594075 0.8459699976353475 
1.5442333508558748 2.5109877776058034 56.40888896893297 0.8406684836925709 
1.5627637691344356 2.555375583467153 56.49345244172718 0.8358631658297059 
1.587283463636147 2.609444222230396 56.71551647099935 0.8297267456103026 
1.6115029198140616 2.657338444612142 57.089205871051206 0.824309951016413 
1.6363625174126633 2.7157900978352245 57.511799299153786 0.8163252330456868 
1.6571880991273515 2.7655922594011866 58.01974623364424 0.8085975931763264 
1.67809890951163 2.8131421369983136 58.546286469336394 0.8007734161206785 
1.691044433644751 2.842519537391224 59.180198334545096 0.7959859770057282 
1.7011546327900142 2.870280697455306 59.410454731436225 0.7920007153124273 
1.7150224344230125 2.893906319004784 59.821030724578904 0.7890989709713286 
1.617412812694375 2.6813338259774326 57.61492226162186 0.7890989709713286 
epoch: 77, train time every whole data:437.02s
epoch: 77, total time:30416.26s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 37.24s
test time on whole data:61.90s
1.4948637702613181 2.429721771458728 55.73424849078856 0.851200738868874 
1.5194355231906687 2.4786494543099282 56.03941557612737 0.8454546123336687 
1.5412641649732277 2.5228270448912573 56.18569330082942 0.8405208493990746 
1.559823284231215 2.565332285450939 56.317589678125614 0.8361327045206368 
1.5847789797385534 2.6202994557499455 56.572649980784384 0.8301500280114394 
1.609052032167092 2.6670964011333176 57.000595917677764 0.8250057222632736 
1.6318929975944616 2.7180519613658496 57.44491087342378 0.8181142289965795 
1.6506005224535862 2.7581334810761464 57.94347326840098 0.8116227728867378 
1.6706515558683093 2.8046632305748433 58.488023032577594 0.8038019794539119 
1.6841722925297384 2.8338466089387753 59.1684619374059 0.7987834048716733 
1.696245407876869 2.8661238354007446 59.5331134825419 0.7937484927116982 
1.7102935921778637 2.885956962543329 60.05109095297436 0.7911867474070867 
1.6127561769219085 2.6833988416676546 57.54001583933424 0.7911867474070867 
epoch: 78, train time every whole data:436.08s
epoch: 78, total time:30922.20s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.54s
test time on whole data:59.11s
1.4967549625565075 2.4301303467015973 55.40724292887999 0.8515529124771035 
1.5202397720799559 2.4753844696344665 55.813975566216776 0.8461480232183259 
1.5425269405775304 2.52191927531188 56.196627242142995 0.8404039197251764 
1.5608864206297413 2.5638389928078245 56.328829008320255 0.8357909585998844 
1.5853229658255974 2.615705158499118 56.59995953023478 0.8298366708793925 
1.6094191296611513 2.6609737109919314 56.99420153470106 0.8247850482034854 
1.6337661643369745 2.715220241917635 57.47216759669136 0.8172667236840596 
1.6536778908267262 2.7594471709172064 58.00642492282155 0.8099991744138116 
1.6745342256998021 2.803251043226149 58.61930147033 0.8024346426048765 
1.6867587693311452 2.8278533394955288 59.30153445054511 0.7978905243400395 
1.6966562028121026 2.855174071079361 59.65097916537718 0.7933311176064443 
1.707830126355624 2.8739897049813994 60.13480502716163 0.790547336803309 
1.6140311308910715 2.6792859733866545 57.54392133349718 0.790547336803309 
epoch: 79, train time every whole data:434.76s
epoch: 79, total time:31426.09s
predicting testing set batch 1 / 168, time: 0.35s
predicting testing set batch 101 / 168, time: 35.57s
test time on whole data:59.11s
1.5002584966033519 2.449891861506269 54.8790443821842 0.8516061308366663 
1.526291496415312 2.5046032808709233 55.27524494510077 0.8452219049496185 
1.5481889859439717 2.549726596650312 55.62378973754063 0.8398249880978872 
1.565058126541919 2.5849529892117498 55.94244486678558 0.835472383526892 
1.588946319911008 2.6354481476090297 56.360029093956555 0.8290327938088302 
1.6111063394558038 2.67477417835634 56.843747445781624 0.8243669247008865 
1.6346732304513987 2.727855578557355 57.39672889673041 0.8166163893422497 
1.655015887152581 2.769525939848826 57.97863385286103 0.8098044938183501 
1.675015177887288 2.8138372209954317 58.51832050734992 0.8024698065921743 
1.6865622683139074 2.8387295980456657 59.11585131227982 0.7981457557919605 
1.6963343736316476 2.8657466831928877 59.399351088572814 0.7937896740391455 
1.708035274780932 2.8852006590505543 59.86256619921434 0.7910315645952795 
1.6162904980907602 2.6954053771637816 57.26640655227897 0.7910315645952795 
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention1_spt_trend_adj/epoch_79.params
