total training epoch, fine tune epoch: 30 , 50
batch_size: 4
folder_dir: MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention1_spt_trend_sample
load file: data/bike.npz
ori length: 3001 , percent: 1.0 , scale: 3001
train: torch.Size([3001, 250, 2, 12]) torch.Size([3001, 250, 2, 12]) torch.Size([3001, 250, 2, 12])
val: torch.Size([672, 250, 2, 12]) torch.Size([672, 250, 2, 12]) torch.Size([672, 250, 2, 12])
test: torch.Size([672, 250, 2, 12]) torch.Size([672, 250, 2, 12]) torch.Size([672, 250, 2, 12])
TemporalPositionalEncoding max_len: 12
h_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
en_lookup_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
EncoderDecoder(
  (encoder): Encoder(
    (layers): ModuleList(
      (0): EncoderLayer(
        (self_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (2): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (3): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (feed_forward_gcn): ModuleList(
          (0): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn_cross): spatialAttentionScaledGCN_cross(
          (Theta): Linear(in_features=64, out_features=64, bias=False)
          (SAt_cross): Spatial_Attention_layer_cross(
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (Gate): Linear(in_features=64, out_features=1, bias=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (6): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (7): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (sublayer2): SublayerConnection2(
          (dropout): Dropout(p=0.0, inplace=False)
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): EncoderLayer(
        (self_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (2): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (3): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (feed_forward_gcn): ModuleList(
          (0): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn_cross): spatialAttentionScaledGCN_cross(
          (Theta): Linear(in_features=64, out_features=64, bias=False)
          (SAt_cross): Spatial_Attention_layer_cross(
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (Gate): Linear(in_features=64, out_features=1, bias=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (6): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (7): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (sublayer2): SublayerConnection2(
          (dropout): Dropout(p=0.0, inplace=False)
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): EncoderLayer(
        (self_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (2): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (3): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (feed_forward_gcn): ModuleList(
          (0): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn_cross): spatialAttentionScaledGCN_cross(
          (Theta): Linear(in_features=64, out_features=64, bias=False)
          (SAt_cross): Spatial_Attention_layer_cross(
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (Gate): Linear(in_features=64, out_features=1, bias=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (6): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (7): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (sublayer2): SublayerConnection2(
          (dropout): Dropout(p=0.0, inplace=False)
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): Decoder(
    (layers): ModuleList(
      (0): DecoderLayer(
        (self_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_qc_kc(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_qc_kc(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (src_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (2): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (3): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (feed_forward_gcn): ModuleList(
          (0): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn_cross): spatialAttentionScaledGCN_cross(
          (Theta): Linear(in_features=64, out_features=64, bias=False)
          (SAt_cross): Spatial_Attention_layer_cross(
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (Gate): Linear(in_features=64, out_features=1, bias=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (6): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (7): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (8): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (9): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (sublayer2): SublayerConnection2(
          (dropout): Dropout(p=0.0, inplace=False)
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): DecoderLayer(
        (self_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_qc_kc(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_qc_kc(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (src_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (2): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (3): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (feed_forward_gcn): ModuleList(
          (0): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn_cross): spatialAttentionScaledGCN_cross(
          (Theta): Linear(in_features=64, out_features=64, bias=False)
          (SAt_cross): Spatial_Attention_layer_cross(
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (Gate): Linear(in_features=64, out_features=1, bias=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (6): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (7): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (8): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (9): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (sublayer2): SublayerConnection2(
          (dropout): Dropout(p=0.0, inplace=False)
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): DecoderLayer(
        (self_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_qc_kc(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_qc_kc(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (src_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (2): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (3): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (feed_forward_gcn): ModuleList(
          (0): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn_cross): spatialAttentionScaledGCN_cross(
          (Theta): Linear(in_features=64, out_features=64, bias=False)
          (SAt_cross): Spatial_Attention_layer_cross(
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (Gate): Linear(in_features=64, out_features=1, bias=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (6): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (7): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (8): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (9): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (sublayer2): SublayerConnection2(
          (dropout): Dropout(p=0.0, inplace=False)
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (src_embed): Sequential(
    (0): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (1): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(250, 64)
    )
  )
  (src_embed2): Sequential(
    (0): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (1): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(250, 64)
    )
  )
  (trg_embed): Sequential(
    (0): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (1): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(250, 64)
    )
  )
  (trg_embed2): Sequential(
    (0): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (1): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(250, 64)
    )
  )
  (prediction_generator): Linear(in_features=64, out_features=1, bias=True)
  (prediction_generator2): Linear(in_features=64, out_features=1, bias=True)
)
create params directory experiments/bike/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention1_spt_trend_sample
Net's state_dict:
encoder.layers.0.self_attn.0.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.0.linears.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.0.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.0.linears.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.1.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.1.linears.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.1.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.1.linears.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.2.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.2.linears.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.2.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.2.linears.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.2.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.2.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.2.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.2.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.3.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.3.linears.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.3.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.3.linears.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.3.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.3.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.3.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.3.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.0.feed_forward_gcn.0.Theta.weight 	 torch.Size([64, 64])
encoder.layers.0.feed_forward_gcn.1.Theta.weight 	 torch.Size([64, 64])
encoder.layers.0.feed_forward_gcn_cross.Theta.weight 	 torch.Size([64, 64])
encoder.layers.0.feed_forward_gcn_cross.Gate.weight 	 torch.Size([1, 64])
encoder.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.2.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.2.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.3.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.3.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.4.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.4.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.5.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.5.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.6.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.6.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.7.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.7.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer2.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer2.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer2.norm2.weight 	 torch.Size([64])
encoder.layers.0.sublayer2.norm2.bias 	 torch.Size([64])
encoder.layers.1.self_attn.0.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.0.linears.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.0.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.0.linears.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.1.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.1.linears.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.1.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.1.linears.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.2.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.2.linears.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.2.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.2.linears.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.2.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.2.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.2.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.2.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.3.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.3.linears.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.3.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.3.linears.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.3.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.3.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.3.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.3.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.1.feed_forward_gcn.0.Theta.weight 	 torch.Size([64, 64])
encoder.layers.1.feed_forward_gcn.1.Theta.weight 	 torch.Size([64, 64])
encoder.layers.1.feed_forward_gcn_cross.Theta.weight 	 torch.Size([64, 64])
encoder.layers.1.feed_forward_gcn_cross.Gate.weight 	 torch.Size([1, 64])
encoder.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.2.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.2.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.3.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.3.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.4.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.4.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.5.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.5.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.6.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.6.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.7.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.7.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer2.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer2.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer2.norm2.weight 	 torch.Size([64])
encoder.layers.1.sublayer2.norm2.bias 	 torch.Size([64])
encoder.layers.2.self_attn.0.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.0.linears.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.0.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.0.linears.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.0.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.0.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.0.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.0.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.1.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.1.linears.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.1.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.1.linears.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.1.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.1.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.1.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.1.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.2.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.2.linears.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.2.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.2.linears.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.2.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.2.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.2.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.2.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.3.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.3.linears.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.3.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.3.linears.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.3.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.3.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.3.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.3.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.2.feed_forward_gcn.0.Theta.weight 	 torch.Size([64, 64])
encoder.layers.2.feed_forward_gcn.1.Theta.weight 	 torch.Size([64, 64])
encoder.layers.2.feed_forward_gcn_cross.Theta.weight 	 torch.Size([64, 64])
encoder.layers.2.feed_forward_gcn_cross.Gate.weight 	 torch.Size([1, 64])
encoder.layers.2.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.2.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.2.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.3.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.3.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.4.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.4.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.5.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.5.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.6.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.6.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.7.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.7.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer2.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer2.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer2.norm2.weight 	 torch.Size([64])
encoder.layers.2.sublayer2.norm2.bias 	 torch.Size([64])
encoder.norm.weight 	 torch.Size([64])
encoder.norm.bias 	 torch.Size([64])
encoder.norm2.weight 	 torch.Size([64])
encoder.norm2.bias 	 torch.Size([64])
decoder.layers.0.self_attn.0.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.0.linears.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.0.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.0.linears.1.bias 	 torch.Size([64])
decoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.0.self_attn.1.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.1.linears.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.1.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.1.linears.1.bias 	 torch.Size([64])
decoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.0.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.0.linears.0.bias 	 torch.Size([64])
decoder.layers.0.src_attn.0.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.0.linears.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.0.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.0.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.0.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.0.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.1.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.1.linears.0.bias 	 torch.Size([64])
decoder.layers.0.src_attn.1.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.1.linears.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.1.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.1.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.1.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.1.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.2.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.2.linears.0.bias 	 torch.Size([64])
decoder.layers.0.src_attn.2.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.2.linears.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.2.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.2.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.2.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.2.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.3.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.3.linears.0.bias 	 torch.Size([64])
decoder.layers.0.src_attn.3.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.3.linears.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.3.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.3.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.3.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.3.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.feed_forward_gcn.0.Theta.weight 	 torch.Size([64, 64])
decoder.layers.0.feed_forward_gcn.1.Theta.weight 	 torch.Size([64, 64])
decoder.layers.0.feed_forward_gcn_cross.Theta.weight 	 torch.Size([64, 64])
decoder.layers.0.feed_forward_gcn_cross.Gate.weight 	 torch.Size([1, 64])
decoder.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.3.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.3.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.4.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.4.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.5.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.5.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.6.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.6.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.7.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.7.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.8.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.8.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.9.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.9.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer2.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer2.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer2.norm2.weight 	 torch.Size([64])
decoder.layers.0.sublayer2.norm2.bias 	 torch.Size([64])
decoder.layers.1.self_attn.0.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.0.linears.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.0.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.0.linears.1.bias 	 torch.Size([64])
decoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.1.self_attn.1.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.1.linears.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.1.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.1.linears.1.bias 	 torch.Size([64])
decoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.0.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.0.linears.0.bias 	 torch.Size([64])
decoder.layers.1.src_attn.0.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.0.linears.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.0.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.0.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.0.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.0.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.1.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.1.linears.0.bias 	 torch.Size([64])
decoder.layers.1.src_attn.1.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.1.linears.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.1.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.1.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.1.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.1.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.2.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.2.linears.0.bias 	 torch.Size([64])
decoder.layers.1.src_attn.2.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.2.linears.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.2.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.2.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.2.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.2.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.3.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.3.linears.0.bias 	 torch.Size([64])
decoder.layers.1.src_attn.3.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.3.linears.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.3.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.3.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.3.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.3.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.feed_forward_gcn.0.Theta.weight 	 torch.Size([64, 64])
decoder.layers.1.feed_forward_gcn.1.Theta.weight 	 torch.Size([64, 64])
decoder.layers.1.feed_forward_gcn_cross.Theta.weight 	 torch.Size([64, 64])
decoder.layers.1.feed_forward_gcn_cross.Gate.weight 	 torch.Size([1, 64])
decoder.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.3.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.3.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.4.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.4.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.5.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.5.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.6.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.6.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.7.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.7.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.8.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.8.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.9.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.9.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer2.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer2.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer2.norm2.weight 	 torch.Size([64])
decoder.layers.1.sublayer2.norm2.bias 	 torch.Size([64])
decoder.layers.2.self_attn.0.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.0.linears.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.0.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.0.linears.1.bias 	 torch.Size([64])
decoder.layers.2.self_attn.0.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.self_attn.0.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.0.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.self_attn.0.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.2.self_attn.1.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.1.linears.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.1.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.1.linears.1.bias 	 torch.Size([64])
decoder.layers.2.self_attn.1.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.self_attn.1.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.1.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.self_attn.1.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.0.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.0.linears.0.bias 	 torch.Size([64])
decoder.layers.2.src_attn.0.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.0.linears.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.0.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.0.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.0.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.0.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.1.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.1.linears.0.bias 	 torch.Size([64])
decoder.layers.2.src_attn.1.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.1.linears.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.1.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.1.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.1.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.1.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.2.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.2.linears.0.bias 	 torch.Size([64])
decoder.layers.2.src_attn.2.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.2.linears.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.2.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.2.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.2.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.2.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.3.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.3.linears.0.bias 	 torch.Size([64])
decoder.layers.2.src_attn.3.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.3.linears.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.3.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.3.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.3.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.3.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.feed_forward_gcn.0.Theta.weight 	 torch.Size([64, 64])
decoder.layers.2.feed_forward_gcn.1.Theta.weight 	 torch.Size([64, 64])
decoder.layers.2.feed_forward_gcn_cross.Theta.weight 	 torch.Size([64, 64])
decoder.layers.2.feed_forward_gcn_cross.Gate.weight 	 torch.Size([1, 64])
decoder.layers.2.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.3.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.3.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.4.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.4.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.5.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.5.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.6.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.6.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.7.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.7.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.8.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.8.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.9.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.9.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer2.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer2.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer2.norm2.weight 	 torch.Size([64])
decoder.layers.2.sublayer2.norm2.bias 	 torch.Size([64])
decoder.norm.weight 	 torch.Size([64])
decoder.norm.bias 	 torch.Size([64])
decoder.norm2.weight 	 torch.Size([64])
decoder.norm2.bias 	 torch.Size([64])
src_embed.0.pe 	 torch.Size([1, 1, 12, 64])
src_embed.1.embedding.weight 	 torch.Size([250, 64])
src_embed2.0.pe 	 torch.Size([1, 1, 12, 64])
src_embed2.1.embedding.weight 	 torch.Size([250, 64])
trg_embed.0.pe 	 torch.Size([1, 1, 12, 64])
trg_embed.1.embedding.weight 	 torch.Size([250, 64])
trg_embed2.0.pe 	 torch.Size([1, 1, 12, 64])
trg_embed2.1.embedding.weight 	 torch.Size([250, 64])
prediction_generator.weight 	 torch.Size([1, 64])
prediction_generator.bias 	 torch.Size([1])
prediction_generator2.weight 	 torch.Size([1, 64])
prediction_generator2.bias 	 torch.Size([1])
Net's total params: 1140994
Optimizer's state_dict:
state 	 {}
param_groups 	 [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411]}]
train the model ... 
epoch: 0, train time every whole data:448.85s
epoch: 0, total time:448.85s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.54s
test time on whole data:60.78s
2.426476206320294 3.965070001276412 59.62987032953764 0.6144679662958 
2.448633144878472 4.032810038287823 60.365887361539116 0.5774745145740152 
2.501901557515597 4.106924973985882 62.96769777685483 0.5219013121782214 
2.560142430358256 4.171998464076135 65.67225829026103 0.4738129596375272 
2.6067144818539245 4.2552834721731765 66.742393433832 0.42389917492530876 
2.655553769977231 4.33331148995533 67.83893234881397 0.37476658523086326 
2.695717366296 4.407033902550205 68.08218025292072 0.3323459753594328 
2.73021309412324 4.478447625845508 67.6270243666191 0.29563463082407443 
2.7790150725209997 4.534223883696707 68.29865766435398 0.25935579507274126 
2.8265479132361 4.58454756725872 68.72871879378816 0.22988830948836467 
2.871636468521807 4.599766683007162 69.22808915925673 0.2089876967259151 
2.9438421099806824 4.574387151727524 72.87963125081099 0.18716592531720888 
2.6705328012985503 4.342439230771044 66.50531284573172 0.18716592531720888 
epoch: 1, train time every whole data:450.58s
epoch: 1, total time:971.14s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.64s
test time on whole data:60.94s
2.2474666555119414 3.9283698927412702 61.950598995786585 0.6474547167137893 
2.302555897375214 4.032865004565665 63.83520613700176 0.6097653619062621 
2.3615977150873237 4.148358041288779 64.83970879812307 0.5674643020225987 
2.4217517307282734 4.240958832789376 66.64551125802276 0.5171151158402381 
2.5054976095397556 4.360160005417909 69.11984608508544 0.46492874064823825 
2.5704239796771713 4.445844345323791 70.87149109169594 0.4146467524791832 
2.6448403103916593 4.532378872350406 72.92195683155511 0.3649356370790252 
2.721455203106006 4.613438673472255 74.82912075739334 0.3191904034182492 
2.792785705910552 4.67571936715283 76.52768510843929 0.2777447254278125 
2.8746617944751467 4.741791433110016 78.37186032405708 0.2412186675894326 
2.9591906694375156 4.797196665810064 80.22329613752918 0.20657872642084973 
3.0491997375900723 4.823520943197627 82.56628663289676 0.17109211865769028 
2.620952250735886 4.454584586008985 71.8922536875369 0.17109211865769028 
epoch: 2, train time every whole data:450.48s
epoch: 2, total time:1493.46s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.65s
test time on whole data:60.91s
2.6449047283759963 4.205929171510476 82.02999071284816 0.682187351987286 
2.7208922435030165 4.323062688893329 84.01788251988155 0.6407675628490885 
2.8400370039809495 4.652506482066849 82.34263235981777 0.5838050083213003 
2.8405017845008875 4.689726753640598 81.33560224082413 0.553140829547232 
2.9037320817261048 4.786539988174547 82.04750448218985 0.5221546438474086 
2.9042510050640753 4.82614481427664 80.5086805628232 0.49516600456438603 
2.9137952161818035 4.8713859830109785 79.3002791677139 0.4670896168084949 
2.9308959064716915 4.9102169324373115 78.99936863468268 0.43614896901890693 
2.961121507241967 4.957902531926998 79.17819791400234 0.40368823210201693 
3.0135488730330198 5.013670259262973 80.7235953763761 0.36856144989314193 
3.0626628360706603 5.056620159912483 82.31520575644355 0.333351170147434 
3.0658971239852586 5.042057270257701 81.73221311436488 0.2943745389771507 
2.900186692511286 4.7851399429734744 81.21087025792293 0.2943745389771507 
epoch: 3, train time every whole data:450.44s
epoch: 3, total time:2015.40s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.67s
test time on whole data:61.00s
1.9235690316391134 3.1977603431446044 64.97799270575013 0.7175218991263297 
2.0301342952809343 3.462804348131992 63.725343165832804 0.6651318649300025 
2.1736517365530488 3.8536972509382896 58.572143541816416 0.6078963812638446 
2.2389232397970877 3.9705844727542434 60.4891482701921 0.5659951291014939 
2.32355692515948 4.15039940597024 59.07786587807483 0.5416508605939341 
2.40649567588605 4.284781030320839 58.34055335822984 0.5226707397945182 
2.4728841447019505 4.3771547190891305 57.964725843361066 0.5075990447869932 
2.544315789696805 4.493276470320797 57.30147341057983 0.49834542822536565 
2.6007345116786835 4.579899510614082 57.46553319083334 0.47550357461867127 
2.6313850327857016 4.624131682037197 58.379761737595125 0.4402184951377395 
2.668092357578377 4.666891693321948 59.48126597907023 0.4023890829637079 
2.6970623632394486 4.665740052674593 59.916635734341526 0.3648353201208997 
2.3925670919997235 4.219740029114424 59.640927256243984 0.3648353201208997 
epoch: 4, train time every whole data:450.56s
epoch: 4, total time:2537.55s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.69s
test time on whole data:61.03s
1.9331133851038202 3.4506371891211387 58.23921230748611 0.7357747149842784 
2.0650305851132917 3.706182204408192 61.17046635016887 0.6870696375294748 
2.2137191849305693 4.0177970775028164 62.59189934443508 0.6264636243220675 
2.267970512705988 4.109560248944137 63.653011856745856 0.5929575359487349 
2.3572538324096017 4.251307385248143 64.21150868656407 0.5660125895015139 
2.4031777617310484 4.311555118406216 63.94165265816496 0.5506327048431533 
2.432327867134962 4.329803107291433 64.05094702732352 0.5509473035895368 
2.4331686415856795 4.318351313007535 63.5162704384595 0.5494447131119217 
2.4636867928484545 4.349579656706263 64.83863534590216 0.5442291523260042 
2.5041776369587474 4.410607260826805 65.88160870005447 0.5246096323225723 
2.5495420816878656 4.478524598385757 67.27754671725464 0.49661924620056386 
2.587208432384811 4.5331608806630985 68.10954007298932 0.46237097238796604 
2.3508647262162365 4.20031117021809 63.95698140889341 0.46237097238796604 
epoch: 5, train time every whole data:450.47s
epoch: 5, total time:3059.64s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.70s
test time on whole data:61.03s
1.9217234590138708 3.2658528172808223 61.38263039622217 0.7361468229046255 
2.0041183832438576 3.4410627612955578 63.09531109647251 0.7051468684895092 
2.1118776049074675 3.695976307315524 63.95460306116257 0.6705578947473626 
2.156665508664612 3.7917912987908475 64.65579624320888 0.6526759013206641 
2.2326739559558533 3.93703325580973 65.73391943527872 0.6345060041735773 
2.257842535456465 3.9766828967737324 65.89004508440972 0.6263950835692621 
2.258803512458645 3.9768332121154644 65.68418547817133 0.6193793487708324 
2.281679210433204 4.00770834924905 65.89499910093664 0.6183861124547917 
2.3078563793798286 4.029793690168913 66.83372031923572 0.6026525548772059 
2.3725320931323584 4.122574515705453 67.86968547799815 0.5896757216797098 
2.450010912398054 4.234433073506796 69.93725324245456 0.5516039520193913 
2.538066389268885 4.3640141360278575 72.90647642301224 0.49930004794013394 
2.241154162026092 3.9152021728762394 66.15335800630527 0.49930004794013394 
epoch: 6, train time every whole data:450.58s
epoch: 6, total time:3582.04s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.71s
test time on whole data:61.05s
1.9741730396596804 3.1884668335075537 58.084509894551914 0.7602138590491251 
2.0084180678182415 3.2967332770601736 58.51441569033076 0.7347142565353264 
2.080889287611558 3.498548176837336 58.56808249198144 0.6960404438007076 
2.0799013652481317 3.514924667766072 58.231118769803594 0.6947427945026914 
2.099820334892897 3.5698302121271395 57.462911977725724 0.6873411049448264 
2.1072149758902157 3.5854008012590786 56.550543935219636 0.6868526875920319 
2.114658954423276 3.605362611674286 55.699177613402426 0.6843459695864654 
2.126350312834428 3.6482828619330387 54.688534153862435 0.6764250351282387 
2.14316925628368 3.6793001454768097 54.689440074107885 0.6646711980544561 
2.182390267062223 3.7710754315432062 54.074933738924 0.6438038280833621 
2.2290167209362344 3.856910197984266 55.09462016173515 0.6108473209551997 
2.2922866631032277 3.9620783463056055 57.16312657288023 0.5620523075547311 
2.1198574371469827 3.6040345498027992 56.56836413002998 0.5620523075547311 
epoch: 7, train time every whole data:450.58s
epoch: 7, total time:4104.55s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.65s
test time on whole data:60.92s
1.9610531093818802 2.975458022321776 69.86652270162922 0.774153551825796 
1.9962318255291098 3.061788429698806 71.22700107106785 0.7559707354170861 
2.0694615438160975 3.2081103833745197 73.18063309426836 0.7256500975743646 
2.06871790994961 3.211103037493837 72.56716109697896 0.7248315349669117 
2.095845438754541 3.239072391903985 72.25449929972976 0.7196854062578285 
2.1208576850533665 3.260022376189973 71.99527477736872 0.713899308310289 
2.1439951780889004 3.2897634007566317 71.31646043989134 0.7053094366515488 
2.1619315240283807 3.3126628131090987 70.97440731471283 0.6977539807270788 
2.197550257820104 3.3508661066010728 71.51785150833948 0.6875996656565015 
2.1924445118453533 3.3660824699153853 69.51618808375719 0.6824305443909844 
2.2428629655274785 3.4613276804259283 70.66427087933624 0.6579923903423959 
2.355624039817158 3.653825967192442 74.4595781190156 0.6062013374910178 
2.133881332467665 3.2868008274026077 71.62831823895111 0.6062013374910178 
epoch: 8, train time every whole data:450.55s
epoch: 8, total time:4626.75s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.75s
test time on whole data:61.09s
1.7777852545911004 2.9100205087619746 58.45570837588482 0.777515549086648 
1.8302801128466215 3.0246272400061476 59.79768456540769 0.7574217779428575 
1.8953099612430448 3.1830264214907884 59.929562616199775 0.7322591193035289 
1.9373420365719745 3.2513821938823746 60.52339343300245 0.7195004136859275 
1.9651741056349128 3.316490395131124 59.58495631313298 0.7096324177530189 
1.9802614653036885 3.357930947125945 59.66428137573296 0.7004409009496514 
1.986120413694442 3.379102464330206 59.168034729402066 0.6977486653862596 
1.9959923983875307 3.3994490088866867 59.19173810371444 0.6948734835977093 
2.001705927138882 3.4230116078471955 58.909444998071656 0.6893170001908092 
2.0201553683128384 3.4785651435713967 58.554303971752255 0.6837864000525804 
2.061900380772317 3.570755611402578 58.607202239379895 0.6656796617955825 
2.145728693073172 3.7113098140825667 61.14774915030211 0.6225149549967461 
1.9664796764642103 3.3405422287672564 59.461163153386046 0.6225149549967461 
epoch: 9, train time every whole data:450.86s
epoch: 9, total time:5149.46s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.71s
test time on whole data:61.05s
1.958622217106766 3.511387610126807 49.82976659871644 0.7769350104893677 
1.998968021639667 3.598972327856393 50.414061741344106 0.7596817379033004 
2.0362763624052915 3.6836566654873026 50.824488269142435 0.744280004221253 
2.0438768492994743 3.676149541901574 51.30941743318969 0.7385503993759509 
2.0399904597271235 3.6493458449781153 51.55675879055634 0.7322051946176973 
2.023134876148509 3.5946621802531893 51.96205383232545 0.7263061275547922 
2.0141914001168417 3.5712125938497854 52.709721082148675 0.7159470243528434 
2.0147420815604606 3.564571736786985 53.3571443714152 0.7062799360392784 
2.0125236520496683 3.564231141432483 53.86374038070328 0.704865008627573 
2.0277219617196494 3.59991084902854 54.125439548287055 0.7020428900684518 
2.0888893900355767 3.7096264488650705 54.602450304658014 0.6847588477098071 
2.171576370940854 3.842201492126983 56.89655712663415 0.6373266668053195 
2.0358761368958236 3.631480889838497 52.62107024703063 0.6373266668053195 
epoch: 10, train time every whole data:450.60s
epoch: 10, total time:5671.77s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.69s
test time on whole data:61.04s
2.097071367336792 3.343944920852006 66.22496383897449 0.7860773165025962 
2.177193488895627 3.477100959307131 68.21010106991989 0.772672482431431 
2.24793490768224 3.621757564630112 69.46628048444971 0.7593457478080948 
2.2703064377479967 3.668033606572331 70.21875400058515 0.75373644507214 
2.2828438070054564 3.7199946381799767 70.04879036361412 0.743354556166463 
2.2877868726090305 3.7433317221969333 69.7283012605522 0.7381660421880962 
2.2888703650012614 3.7486810315724632 69.79648285729859 0.7312372345689148 
2.2891429308221807 3.751448610499984 69.78148901866467 0.7293177613197269 
2.27052217414239 3.7301183481711857 69.52352102388063 0.7224400214360208 
2.290662730049874 3.759738698874185 70.79167946434039 0.7130661546851399 
2.3666811983752996 3.8976191438624763 72.49859829624779 0.687346494136901 
2.4490242703302454 4.060661406895672 74.46735629237394 0.6397632138406035 
2.276503379166533 3.714279761746364 70.06310190633579 0.6397632138406035 
epoch: 11, train time every whole data:450.57s
epoch: 11, total time:6194.14s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.61s
test time on whole data:60.90s
1.7179835086691948 2.8598226723950293 61.30354786196806 0.7918360532009586 
1.771179355623112 2.943415085759993 62.48441062968701 0.7803288747809566 
1.8315507540246028 3.0471375329850017 62.91930990199345 0.7692085198080393 
1.875122980194521 3.1074781083062373 63.49188536147879 0.7650292000029595 
1.9481422859148256 3.2290131632688754 64.35262307807065 0.7536154815210059 
2.0126276758742474 3.334414231514794 65.20208323918972 0.7426674288448638 
2.0787068297402667 3.444026388254199 66.94887214909136 0.7269340444973534 
2.1197709429548786 3.508016484175686 67.80364260584855 0.7192264909944724 
2.158747739836751 3.568035549573718 68.5960384500736 0.7131506995837543 
2.1988470009781773 3.628840408725935 70.00950593381154 0.7062041675363925 
2.269772776947401 3.7539037055341944 71.25768404235356 0.6912606205986216 
2.3445477820754586 3.906729700723981 72.82316698138418 0.655573719850231 
2.0272499694027863 3.3757687704093247 66.43292700197635 0.655573719850231 
epoch: 12, train time every whole data:450.49s
epoch: 12, total time:6716.26s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.65s
test time on whole data:60.98s
1.9064604007629233 3.1747201626689807 60.20005653085434 0.7976909432530187 
1.9377771277494196 3.226987839734677 62.15934513149604 0.7794400567517917 
1.9852947471607476 3.327167124367397 63.50474078604951 0.7640515583344273 
1.9929969563419443 3.328078942984238 64.49300397919284 0.7595538126602315 
2.029298824658085 3.3778237469604155 65.04190516034015 0.756309310787043 
2.080795553771158 3.4564998732440113 65.14134833772796 0.7546740138298575 
2.1705223780135134 3.6114607459339174 66.59903445491344 0.7398566483848215 
2.2280934592623796 3.7143817397768455 67.37594470904287 0.7288595054409064 
2.256415731979445 3.761595286310024 67.81358184548584 0.7197677215563049 
2.2861409536854675 3.7922860117226707 69.12084543567309 0.7145424787151586 
2.320716415060418 3.878646742843433 69.38440822576109 0.7029520104967248 
2.3850791708868706 4.004607663949546 70.7432705508555 0.6728213994304678 
2.1316326432776975 3.5642510855644023 65.9649599700085 0.6728213994304678 
epoch: 13, train time every whole data:450.56s
epoch: 13, total time:7238.46s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.60s
test time on whole data:60.92s
1.7163047160299583 2.9020922727273337 55.61321695365078 0.7952086188957771 
1.758440093853378 2.9751009036574527 56.7483981551837 0.7839699723617437 
1.8087521638745176 3.0949756979330143 56.873530229124704 0.770803480908178 
1.8365406063975145 3.1312315667194537 57.33400279868002 0.7673454616278887 
1.8708082915940987 3.2055670666346443 57.908424100820156 0.7548686125199296 
1.8960095947936533 3.23311951143105 58.00309462491479 0.7554323480698996 
1.9129551222973635 3.266385335534377 58.310280462755635 0.7511408151994803 
1.9239628014749892 3.2888033960259038 58.167434262759365 0.7493753275837081 
1.9437956112195693 3.329391542695053 58.67337696034378 0.7389147632861958 
1.9722872710507362 3.390734176616572 59.700661453086724 0.7238470518200837 
2.014534376543636 3.4962085034498243 60.311001724556746 0.7018907426250128 
2.099939539656043 3.678165951685914 62.04806488857999 0.6555995398101359 
1.8961941823987882 3.255832952079481 58.30770510248253 0.6555995398101359 
epoch: 14, train time every whole data:450.50s
epoch: 14, total time:7760.47s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.65s
test time on whole data:60.98s
1.705415756358987 2.8738345196766875 54.48378442691559 0.8098679757901326 
1.7566755139613082 2.9655338293561067 55.39562583956681 0.7990582767470185 
1.804137211899495 3.0505968629562226 56.25902521794656 0.7842951196062513 
1.8349021361845412 3.1008363908207097 56.67971952151244 0.7756152125652417 
1.8741795325117807 3.181422925794884 56.633927005667914 0.7619097567704453 
1.8862513259714027 3.2028806213391876 56.31198916871302 0.7620096903847863 
1.907275380122431 3.248615315981725 56.49253185154076 0.7594291811841116 
1.925137409034318 3.292162101845614 56.30096147201621 0.7621007681378635 
1.9486436118697303 3.3378151335101633 56.51012283300878 0.7584054277458276 
1.9805262249886457 3.422268726967198 57.252621239662446 0.7450493087562898 
2.03649662111806 3.556649472527998 57.59072334655846 0.7264350690942573 
2.120586184836037 3.7187905279702793 59.2300452609679 0.6861770864356257 
1.898352242404728 3.2542083488443905 56.59513459618696 0.6861770864356257 
epoch: 15, train time every whole data:450.39s
epoch: 15, total time:8282.57s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.72s
test time on whole data:61.07s
1.6785848720542023 2.8471097585377314 52.28318642970223 0.8247145969777875 
1.720237337823425 2.9390414029628116 52.822287671530454 0.8127158215638105 
1.7494221289008856 2.9953582589850045 53.04149294273819 0.8045712849415168 
1.7637963163291237 3.0185993655701764 53.6913154311212 0.7954744241930792 
1.7849004856286836 3.0670592476382534 54.449934511932476 0.7813379700612478 
1.8102140500692738 3.1100593402037786 55.20916716421254 0.7714284888438743 
1.8247863194493665 3.1192433423857415 56.11266263239031 0.770612631551381 
1.8386099088716188 3.1424235246736725 56.459214361632405 0.7655045853049788 
1.8630542535003096 3.1961222427203526 57.16415346026329 0.756024798759575 
1.8865835034048983 3.251562038066382 57.4608809925448 0.7479395100310512 
1.9309713174329095 3.360109323159688 57.6601534283811 0.7342161569628537 
2.016748740332467 3.536749094027567 59.01693447638897 0.6978931746148563 
1.822325769483097 3.1371260685010838 55.4477381730018 0.6978931746148563 
epoch: 16, train time every whole data:450.68s
epoch: 16, total time:8804.94s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.59s
test time on whole data:60.89s
1.6880704750520665 2.9217604639500894 52.92958315414037 0.8187324614415501 
1.7089865345318935 2.960304445525304 54.350931691634486 0.8045961426704742 
1.7365104591838483 3.001871104907303 55.80327934126025 0.7947369739269988 
1.7530506142415994 3.024039161572088 56.669460175276285 0.7891743238260641 
1.785231678717282 3.0835102961532965 57.13072039650865 0.7804035121580211 
1.8143057286199182 3.13301777128995 57.35570289903728 0.7708267478218814 
1.8398545446136878 3.186443654072151 57.87191687897641 0.7606921732872388 
1.8526875917317258 3.207359278601528 57.893378187223455 0.7589132395296265 
1.8682869631860937 3.231386073638153 58.58903456762262 0.7512189431537183 
1.8786494046439017 3.2397334227176224 59.4206771138275 0.7465386659101051 
1.9169420408537345 3.3291628962801965 60.21327957876677 0.7286535658972368 
2.001775956034217 3.528905944866337 61.4976887116214 0.6873229582676696 
1.8203626659508307 3.1582533908431323 57.477262229974 0.6873229582676696 
epoch: 17, train time every whole data:450.76s
epoch: 17, total time:9327.35s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.67s
test time on whole data:61.00s
1.6859756718419847 2.613012743190191 56.59343716261833 0.8220329971448127 
1.715326428738467 2.681116668645372 57.21067952438492 0.8127725726194854 
1.744517051859271 2.7397398921225986 57.45279078131011 0.8057508693911837 
1.7531715344745844 2.769315095409515 57.23178119999244 0.8017509570630684 
1.7768923120831273 2.8204531604789658 57.34043054161829 0.7938657551946419 
1.79855775538761 2.874746818668659 57.12952761721103 0.7856470888096344 
1.8338458309210837 2.9751007985725724 57.40516311640111 0.7694962873639462 
1.870496875637078 3.0593916789959046 57.720227432509205 0.757236865839353 
1.9024052392573407 3.1363578267709777 58.134467250061064 0.7459029983960644 
1.911205941641792 3.1575091372996287 58.36826719451328 0.743547979411082 
1.9315891945189132 3.2031626750028073 58.60001148332916 0.7365042530333793 
1.98767995480652 3.3401158835363014 58.70340259117661 0.7141865156560859 
1.8259719825973142 2.9558552072941033 57.657546696108476 0.7141865156560859 
epoch: 18, train time every whole data:450.57s
epoch: 18, total time:9849.66s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.67s
test time on whole data:61.01s
1.6624716023176553 2.769323464755891 55.28837585310647 0.8193070638965789 
1.6968732989828679 2.8303544425146314 56.2898609740039 0.8114934002407627 
1.7394018228352957 2.917596244349855 56.96582889199554 0.8019559251882968 
1.7724170460883706 2.9833803160206824 57.371626045307714 0.7959521905346868 
1.830789631193681 3.1180380140136266 58.13950169082991 0.7805244197042146 
1.8874156594072424 3.233460034140266 59.025278577448844 0.7674176346290507 
1.952365851830425 3.3748033056347984 60.43752620884604 0.746482106589466 
2.016825110897333 3.4867297976057188 61.80995079593327 0.7305746635477388 
2.0867075882750963 3.6023615255177877 63.5932659528337 0.7125961021610162 
2.146956151839523 3.704916934071388 65.21691317819138 0.691514182151777 
2.1948214034311295 3.7979621373465813 66.74280832306448 0.6702735550196631 
2.2653068951762148 3.9404066093104975 67.98645788096222 0.6369477207074427 
1.9376960051895695 3.33506284614125 60.739170035817935 0.6369477207074427 
epoch: 19, train time every whole data:450.65s
epoch: 19, total time:10372.02s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.63s
test time on whole data:60.91s
1.704413605707387 2.6175360072644662 58.79483056655373 0.8221176857307093 
1.7322090167883073 2.6842692928874743 59.70112108039676 0.8129182448434675 
1.7509721071214548 2.7762658531941566 58.808228975741464 0.8028298889862195 
1.7774645742365114 2.8664245814047087 57.60881981472803 0.7934427035817478 
1.8165037387946532 2.9815524790218175 56.42253191426797 0.7810688651141224 
1.849058150757991 3.071848831581351 54.93365251905998 0.7724752649101627 
1.8717534750343434 3.1524256650962887 54.43331174165195 0.761180284533583 
1.884707899718235 3.178540708203568 54.23240058260005 0.7577449967342089 
1.8927570137056033 3.204040657978858 54.414987961285 0.7501500696618696 
1.8907339873783113 3.204812166242936 54.743456118424284 0.7452084729962652 
1.8982618841703627 3.2139971085924532 55.1908444972948 0.738616039379425 
1.9568720071792958 3.3492419584899116 55.945542982975226 0.7108867371753104 
1.835475621716038 3.033583607727855 56.269034544359855 0.7108867371753104 
epoch: 20, train time every whole data:450.60s
epoch: 20, total time:10894.28s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.66s
test time on whole data:60.98s
1.6677041954821241 2.835044309697405 52.52771228068167 0.8302868426705536 
1.725030033640652 2.9699925646579577 53.71141051474871 0.8161059583657317 
1.800356295178866 3.1249927219338485 54.82043456809327 0.8008172420261495 
1.8443030072865743 3.1905838302311764 56.1046160425449 0.7947643862286335 
1.878924327639508 3.2563376815667726 56.894901327636326 0.7849847714644808 
1.9020488335791799 3.294969193028374 57.6336843195356 0.7729834271538324 
1.905773762976928 3.31511323620007 58.57960896555523 0.7583721190201903 
1.898708114156322 3.2906486600331406 59.34397595987113 0.7536538502314655 
1.8865246600671006 3.251991111984919 60.42112965838017 0.7508619007196425 
1.8889062113076271 3.2523086756028956 61.66391312576827 0.7433666090763323 
1.9123736373458413 3.2905750943454803 63.364391629907125 0.7314252109908387 
1.9792548480372698 3.44589338094645 64.50609535438244 0.7017747792111101 
1.8574923272248327 3.2137421304474643 58.29785516430128 0.7017747792111101 
epoch: 21, train time every whole data:450.67s
epoch: 21, total time:11416.73s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.65s
test time on whole data:60.98s
1.600474735239166 2.5947219228826555 56.12827181019486 0.8319464005771082 
1.638596533736835 2.6865690427394036 56.73739988453027 0.8223121705902359 
1.6800479414389424 2.78330834270077 56.903956565893324 0.816163697537179 
1.7185039122281152 2.8634077738347132 57.387578492868265 0.810230505750092 
1.7747053952444167 2.9901452180896655 57.973670611337134 0.798142171032425 
1.8351245612309626 3.1123486903637434 58.55505683905447 0.7851266669280504 
1.898295782639246 3.2444760060851134 59.576197099134035 0.7669806480036052 
1.9503335227580474 3.3327555871878296 60.43791637166272 0.7556509925763786 
1.9994997952318794 3.4271987377590913 61.27527768574193 0.7394096502748881 
2.035032751468232 3.497765633037521 61.944005920417446 0.7275627099406539 
2.065453294126583 3.555291914060127 62.78705205003353 0.7179923867061535 
2.1234569202902773 3.678289038303934 63.767206857572326 0.6984744276707728 
1.8599604288027252 3.1663290797758417 59.456268904539854 0.6984744276707728 
epoch: 22, train time every whole data:450.59s
epoch: 22, total time:11938.97s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.70s
test time on whole data:61.06s
1.6459529671935986 2.6051843922288875 61.0353988137683 0.8223425002539105 
1.6697898736416938 2.6972065032987627 59.862628550022656 0.8099898362135787 
1.6994528610036663 2.7758301702032506 58.988131641978626 0.802641032343352 
1.7060971794654394 2.7878172723503147 58.81876540359256 0.8024361177219339 
1.7184154213297935 2.794126856196369 59.055973393920794 0.8012983033516179 
1.7256224219877097 2.7880282531229237 59.06712372449512 0.8016943683143853 
1.7498574041624864 2.844454672063187 59.347514092826145 0.7926253023368555 
1.7798439981191463 2.9189869348803645 59.09587549977573 0.7816112912187978 
1.8127306189754357 3.006927656739818 58.84850809053359 0.7661237369759366 
1.8221099615609717 3.0454003250913924 57.79901075925663 0.7618679015651738 
1.8326676115370577 3.0754142306922305 57.24630804079809 0.7559597294064725 
1.8826865201468268 3.1940976504537346 57.28279818869076 0.7379187944056472 
1.7537689032603188 2.8825224777504816 58.870628961326155 0.7379187944056472 
epoch: 23, train time every whole data:450.58s
epoch: 23, total time:12461.56s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.69s
test time on whole data:61.04s
1.622028203543187 2.6228504613103847 53.88041175660347 0.829673531808507 
1.6654747706509772 2.739713852214745 53.929632152591736 0.8147463406553425 
1.7014382884786243 2.8229380402075606 53.78289907224578 0.805477663070394 
1.7208795642274477 2.8299265751785243 53.60173030725591 0.806510788613604 
1.7407498815627325 2.847455148478479 53.67676791985425 0.804466449267063 
1.7581486261906545 2.8733153080829528 53.61268576650635 0.8011122337930796 
1.7705436118054425 2.909565754799195 53.995990546443295 0.7935724296577645 
1.7787287317329041 2.9295812786331332 54.401724236664286 0.7885398724905742 
1.7907253088953772 2.9662521842257226 55.16744614769264 0.7794523305369911 
1.8087005496590087 3.0086700685865444 56.114186732860574 0.7707656145665671 
1.8306177901004752 3.053452001166857 57.11018734810398 0.7614615797624925 
1.8913208445732792 3.1974068717029382 57.83320339212704 0.7364245205513305 
1.7566130142850092 2.9036260175098283 54.75896002608511 0.7364245205513305 
epoch: 24, train time every whole data:451.16s
epoch: 24, total time:12984.46s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.83s
test time on whole data:61.24s
1.6090179435621415 2.5601603095648766 57.70754378003582 0.8294977442435629 
1.6425990141577842 2.6589168620971555 57.47266740829957 0.8155846583736527 
1.6714216677825011 2.7522691982450453 56.162445425709194 0.8057577583658403 
1.7047342432627366 2.850310974585839 55.20370683101567 0.798618926714548 
1.7422597052960525 2.9321991196505808 54.907296650687734 0.7913262767090492 
1.7603217739551549 2.9431431242058057 54.526543094056414 0.79202650324762 
1.7696831218125741 2.9459813973765194 54.71813139404807 0.7895301831007948 
1.7707315279293274 2.928451470592974 55.059830245464006 0.7897902535048387 
1.779939249690356 2.9460515260923157 55.99407475235627 0.7809101988422052 
1.8016449178834224 2.9883301090074834 57.01314478578017 0.7706249748749769 
1.8325698533272814 3.06310873091252 58.20720477096384 0.7551588472814045 
1.8873513087980627 3.1896815296046954 58.75742365172708 0.7337569215414956 
1.7476895272881163 2.9012077285488713 56.310830694643634 0.7337569215414956 
epoch: 25, train time every whole data:451.32s
epoch: 25, total time:13507.78s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.65s
test time on whole data:60.97s
1.5390222172710513 2.5031526783658635 56.34140008478873 0.842540775085557 
1.564746367518923 2.5671288257202054 56.589384049179124 0.8349162242260401 
1.5885556544044188 2.6207215011737053 56.507211953600766 0.8291944351468189 
1.6113891228315909 2.6708906372408916 56.76152804354724 0.8247370936247458 
1.6375914357506802 2.723165766011653 57.02697487589923 0.8197501067916153 
1.6591907949942564 2.763125536686662 57.355712615100884 0.8152727568763091 
1.6856900908215238 2.8188665473069223 57.98603186710819 0.8069629330132239 
1.704488809729261 2.85309945338617 58.45021385525163 0.8019537202191991 
1.7290716665386268 2.9108893405809213 59.43871103611702 0.7909846488840625 
1.7539349376841316 2.9619959447624056 60.024072738995116 0.7825466130719332 
1.776344811513665 3.0102938740989607 60.88404101143984 0.7737960073682246 
1.8309092683451516 3.132920470390108 61.44813860476466 0.756046524363341 
1.6734112647836068 2.800568364295288 58.23454054670522 0.756046524363341 
epoch: 26, train time every whole data:450.78s
epoch: 26, total time:14030.37s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.69s
test time on whole data:61.03s
1.5340352910021764 2.493831421357197 55.854366492531696 0.8443301851246522 
1.561003020845531 2.5627699293261696 55.94179672240461 0.8364375275445526 
1.584578691538512 2.614383772093521 55.84565608940568 0.8309007047349118 
1.6043045891521588 2.6535056857308623 55.977019463990054 0.828050512770021 
1.6302746112833597 2.707411900805252 56.229860070446335 0.8227507603232157 
1.6536522498654114 2.7532026944359935 56.624539218008294 0.8172221104986832 
1.6809199888826836 2.807671324432083 57.35056760750729 0.8093816398634562 
1.7010009069888896 2.844027863966164 57.81609439787899 0.8042612631235769 
1.725633468254691 2.897639849755607 58.67027831554741 0.7951001952130278 
1.7490707962822525 2.9467824111553225 59.0575530793292 0.7875927990399743 
1.7689006692432754 2.996873614351422 59.83865176948593 0.778515055954823 
1.8165531251191915 3.0925665425073148 60.51356804034012 0.7659198850810555 
1.6674939507048443 2.7864233255935535 57.47674583579059 0.7659198850810555 
epoch: 27, train time every whole data:450.61s
epoch: 27, total time:14552.67s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.65s
test time on whole data:61.02s
1.5297141888113248 2.4855826316080245 55.9227754588427 0.8447904580524542 
1.5568755925403288 2.554348349011024 56.04489460344958 0.8373381048148442 
1.5825712947801998 2.6172900196088307 56.1042126000186 0.8300463515288559 
1.6033772826659538 2.6587076036325814 56.374681042189366 0.8264923727092469 
1.630227612214695 2.709436230689845 56.67372887995846 0.8213898625802172 
1.6558946058842399 2.7580876870667117 57.02058563997586 0.8149360849933265 
1.6830627565119594 2.8164985348766733 57.617084976931324 0.8057367219392262 
1.7017792076393963 2.855530201317477 57.98855068933011 0.7996498215858633 
1.7273944522522036 2.913406945198375 58.82708808676074 0.7887640760708728 
1.7529936150994507 2.9686893350837527 59.30968613408143 0.77944097024716 
1.7694365856863914 3.003750742189124 60.15218819757886 0.7726381126275365 
1.8151822223087684 3.093033288135244 60.952348570145865 0.7593652341009666 
1.667375784699576 2.792057016783079 57.74907056980357 0.7593652341009666 
epoch: 28, train time every whole data:450.79s
epoch: 28, total time:15075.15s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.62s
test time on whole data:60.91s
1.5282334954255217 2.474091039084641 56.641783210298826 0.8447467102947518 
1.5544651385292056 2.540448355424421 56.62761502962809 0.8370232810298481 
1.579628500551074 2.6008218850429676 56.496185422154646 0.8303277307984503 
1.5986923561640793 2.6381023938781456 56.60234373376104 0.8278599634524669 
1.6238649600164166 2.6896408694939113 56.8399079654551 0.8227519886552611 
1.6473239776233122 2.734704363814281 57.23169627762337 0.8174023642909958 
1.6766214838525546 2.796593290532675 57.924132735560676 0.808497771089682 
1.6957502086760388 2.833962749503879 58.28569353856117 0.8035067890099377 
1.7243118898100442 2.9000079890174684 59.06043788393707 0.7928459482986442 
1.75039836195608 2.9596454432313424 59.426132617661374 0.7840733457149033 
1.77168755965059 3.012378578871852 60.28219535113109 0.7744356945680401 
1.8155895184133024 3.098187419072193 61.181562429709025 0.761305072372942 
1.6638806208890182 2.7794881928341724 58.05005088245684 0.761305072372942 
epoch: 29, train time every whole data:450.67s
epoch: 29, total time:15597.44s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.66s
test time on whole data:60.97s
1.5281232676576113 2.4765970766139125 55.76588709084407 0.845462140336612 
1.5557173942956364 2.5436447455735944 55.919000987129486 0.8372306919334398 
1.5775609484700752 2.590384546046295 56.15369902021972 0.8311318232051853 
1.5941461772046805 2.619173263065972 56.40907935496645 0.8283414078298031 
1.6170611948428586 2.664171752728963 56.67211985196364 0.823547217180097 
1.640071394641928 2.7082412921238124 57.102370637840174 0.8185764127565169 
1.669004213919952 2.769583840890407 57.81364085108298 0.8100875766571368 
1.6863127087241128 2.8032826873049497 58.20240276807353 0.8054826703284296 
1.7114616014958315 2.859629562270628 58.93565166223597 0.7962221503634669 
1.7329666685781309 2.910988743158465 59.21312263593993 0.7888503726114586 
1.7535945590338005 2.966611838949153 59.90170456172245 0.7793722391892797 
1.7942367313284249 3.055026709915713 60.45946316771298 0.766943785957142 
1.655021405016087 2.7525821748027073 57.71243090011484 0.766943785957142 
epoch: 30, train time every whole data:450.19s
epoch: 30, total time:16119.25s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.73s
test time on whole data:61.11s
1.5256953459063634 2.4601436099736285 56.37037055775293 0.8463766642170236 
1.5530447650259094 2.536298063679676 55.97553215580698 0.8383887891715793 
1.5803704765674083 2.6098026221092296 55.574183451463156 0.8316409076235839 
1.606442406736137 2.6611248801954046 55.59077342647032 0.828453499211902 
1.6359965865232404 2.7210347284374086 55.623678898513596 0.8237603878887244 
1.6603341616118061 2.7649554379344186 55.99930724610375 0.8187161357719882 
1.6858253760204784 2.8188275703232075 56.68595055975576 0.810100921567558 
1.7024287522650723 2.850362386017014 57.25673155361588 0.8049889138991311 
1.7267458479343247 2.900721052028455 58.202403991811735 0.7956828640728663 
1.7524231010398694 2.957639500735204 58.70398674020143 0.7869993214991279 
1.7744848607312889 3.0116907885520634 59.43276789781715 0.7780781538108159 
1.816364446565154 3.1004591048485803 60.107845232118414 0.7658720311451362 
1.6683463439105877 2.7889973568548627 57.127030802767024 0.7658720311451362 
epoch: 31, train time every whole data:451.84s
epoch: 31, total time:16642.90s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.68s
test time on whole data:61.03s
1.523439288848479 2.465366539551935 55.6897007621125 0.8469298067681744 
1.5515730256378828 2.5382132839353044 55.63675914329921 0.8388136055438592 
1.576566840208978 2.5968492185636367 55.52103378961487 0.8324224145915774 
1.597879909554585 2.63567294346473 55.71357660674945 0.8293206504668013 
1.6240849146672658 2.6855714624314917 55.85471104987916 0.8248792489700959 
1.649586142658744 2.7334064757722114 56.19698560749998 0.8192599135651029 
1.6775353388859047 2.7928564611881694 56.78769408467852 0.8108785992854535 
1.6966431789039855 2.8328168514355454 57.14915239948021 0.8050794233367348 
1.7204019394124903 2.8856216680587017 57.85068337259506 0.7955254568535925 
1.7435472621269346 2.938046494684583 58.177715830640906 0.7874069647513967 
1.7614037182705389 2.9835215054061024 58.85087547964076 0.778762575754555 
1.7960476202346563 3.0564673250420133 59.537553889709805 0.767998933237314 
1.659892431617537 2.7677003517439123 56.9139379319463 0.767998933237314 
epoch: 32, train time every whole data:450.99s
epoch: 32, total time:17165.65s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.64s
test time on whole data:60.99s
1.5279598754966366 2.493697950667174 55.236465723849825 0.8461741141045716 
1.5565267592477834 2.5616701379327784 55.416606121028465 0.8383929424539603 
1.5818497535918972 2.6146836585017073 55.672877603970115 0.8324751588926272 
1.6028228585851334 2.656667034549025 56.08352990647738 0.8287809808422345 
1.628139942145596 2.7053338926057005 56.46896845105326 0.8241211444427112 
1.6521162159858893 2.750843616360963 56.97875843177799 0.8183163851091161 
1.678142930112779 2.8061489841665006 57.72996560521611 0.8094395169222205 
1.6924075543930133 2.8317629452441766 58.2639840059745 0.8045165220381028 
1.71253243237042 2.8722247235162035 59.203365036456255 0.7959690970531683 
1.732179539005494 2.9151772031046974 59.721129270370575 0.7887064518907146 
1.7518444341106252 2.9609880733652636 60.66021152470835 0.7802369958179076 
1.789292117608977 3.033278064725845 61.4438552827177 0.7692807154897383 
1.6588178677211871 2.7714409380805054 57.74008645320067 0.7692807154897383 
epoch: 33, train time every whole data:450.90s
epoch: 33, total time:17688.37s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.72s
test time on whole data:61.08s
1.5334674514063766 2.485077919417363 55.13041564111835 0.8464566724457928 
1.5632680245787793 2.5577677919836623 55.12661984500266 0.8389682438863524 
1.5911583036631345 2.625094212146957 55.17796569763371 0.8322623875813179 
1.6148491868947057 2.6712428194196023 55.48006514521527 0.828334637436602 
1.6404281312072915 2.715902941137567 55.738989198689694 0.8243912415012401 
1.6617042718348758 2.7532362317475045 56.30973093760815 0.8191168032650626 
1.6861684103790848 2.8019111933044742 57.065531619609914 0.8110238341570193 
1.7031428501535917 2.839766447557253 57.717775900547096 0.8041746034953613 
1.7234063399415462 2.883449244459473 58.621579078173426 0.7949508100049656 
1.7439292017612607 2.9278908457036503 59.13395009569351 0.7875637962066852 
1.763579057173626 2.971372023380904 59.91343593400549 0.7795255869735161 
1.7979259251687854 3.046219961040839 60.575411066922804 0.7682431405101416 
1.668585596180255 2.7780568240777606 57.16605745083536 0.7682431405101416 
epoch: 34, train time every whole data:450.85s
epoch: 34, total time:18211.03s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.71s
test time on whole data:61.10s
1.5266971048119344 2.506818464666415 54.9941349561123 0.8457958025309351 
1.5551495714554828 2.572663659996151 55.29882738986313 0.838091824071359 
1.5849834662142785 2.6420684663247145 55.644995456044214 0.8300970148401112 
1.610626192438638 2.691021283667109 56.115585826196266 0.8260514333629333 
1.642154681084855 2.747500182103366 56.50629476690669 0.8215114742351093 
1.6743212153232168 2.8098676265994063 57.061520828156176 0.8146260881292534 
1.709603123904605 2.8825464518428294 57.84534244431917 0.8048421328267508 
1.7341993505638094 2.9337132527596275 58.32482517265301 0.7977047193250386 
1.7565282950074013 2.979985656460083 59.03285136606058 0.7886824619481011 
1.7764684223230218 3.0221116521798708 59.401476228063274 0.7816745395872086 
1.7896253257714034 3.0512214729652785 60.08843106360953 0.7747958266224728 
1.821738202198719 3.1120610207203154 60.98531966668877 0.764475385320986 
1.6818412459247805 2.835681412861716 57.60840700847181 0.764475385320986 
epoch: 35, train time every whole data:450.96s
epoch: 35, total time:18733.65s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.70s
test time on whole data:61.01s
1.535840338857401 2.4774985189468794 55.8235247055197 0.8471387133046508 
1.5650069037442584 2.546844364529441 55.88653175338474 0.8395998335135183 
1.591886952641287 2.6116620143362796 56.045382529804066 0.8321478591197671 
1.6145044015724035 2.6544677636323772 56.3845164459321 0.8279784554337293 
1.6421907657103703 2.7057838290792517 56.665197173386716 0.823241494726532 
1.667673819703449 2.7548879554691066 57.1999378925825 0.8176580131214688 
1.6972344515600375 2.8166915461819215 57.89952914546185 0.8090362842919626 
1.7185367149616635 2.862157958149341 58.319693330779465 0.8023166206519862 
1.74032871107899 2.9127240246361703 58.93585424342604 0.7929813196140975 
1.760660235215067 2.959272851989446 59.206294760147436 0.7859904074665304 
1.7762721689723964 2.9950086627051125 59.81739361358731 0.7790057414921159 
1.8062297386617532 3.0590645917811385 60.55651092826216 0.7688485689117449 
1.6763637668899232 2.785333254403291 57.72845100427936 0.7688485689117449 
epoch: 36, train time every whole data:450.81s
epoch: 36, total time:19256.17s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.69s
test time on whole data:61.02s
1.5187959244791418 2.474884055487806 55.60312329871575 0.8471941974395059 
1.5481656321315538 2.5482727320264775 55.51493452918248 0.8399348365287742 
1.580110477775424 2.6245693422703265 55.63276689947324 0.8322458739778822 
1.6071470404721442 2.6799811590741025 55.98910875160562 0.8281336690930502 
1.6366017291483779 2.7381814232167776 56.32471449820662 0.8232528934854244 
1.6648943616170435 2.786937967361535 56.872159425452686 0.8180557900897124 
1.6939166993678858 2.84695236312065 57.61550218327653 0.8092437051884455 
1.715345227376425 2.890482046496228 58.17028536515526 0.802109349683093 
1.7381287647506134 2.940736303706574 58.96937283823724 0.7919988662053001 
1.7589522485114812 2.9838850309417033 59.456537546353196 0.7850100351632879 
1.7778481883575163 3.0226159950521305 60.311074035063726 0.7772908627005273 
1.811912801186155 3.085917461589093 61.21059625281614 0.7674406738230916 
1.6709849245978134 2.808093765183394 57.63928237674555 0.7674406738230916 
epoch: 37, train time every whole data:450.78s
epoch: 37, total time:19778.75s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.71s
test time on whole data:61.04s
1.5265230798909353 2.4746483475568977 56.09011916040534 0.8478141675155639 
1.5547728618791417 2.5435366735144784 56.11464112791009 0.8401979536184941 
1.5840495096394527 2.6115830420805195 56.164270858706104 0.8334315190850659 
1.6091521856468172 2.656353473888694 56.512500364769814 0.8301258088979329 
1.6380603010782173 2.714783590506713 56.77743882865515 0.8246949948291724 
1.6656417845440585 2.7687995446702134 57.230232137804805 0.8188540093829763 
1.6947828719510387 2.8316029807277188 57.826721903281694 0.8107649508128622 
1.7145455002836174 2.873689322723901 58.194580912157214 0.8045945993226498 
1.7341739872764086 2.913764367709152 58.82162665879225 0.7967114831605961 
1.75402004216434 2.954516106559701 59.21613837583814 0.7905971475095463 
1.771757514172899 2.990804842187236 60.03640171417302 0.7833685316003357 
1.8013818722956236 3.0498751217680833 60.94075411897183 0.7742160875089391 
1.6707384592352124 2.787595285669456 57.82720158747922 0.7742160875089391 
epoch: 38, train time every whole data:450.57s
epoch: 38, total time:20301.34s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.70s
test time on whole data:61.04s
1.5241834427791514 2.480518843559634 55.95246253859979 0.8474940856409792 
1.5528346147708418 2.54771642484612 55.921973112474596 0.8405867885722985 
1.5834288557911558 2.6220845747620767 56.00731421748362 0.8332975000318746 
1.6097789953907153 2.673202019586152 56.41236326745356 0.8291648068572426 
1.639567056817579 2.7301534866250665 56.76173175217929 0.8241764894674489 
1.6690632433987977 2.78422543488672 57.29528906807045 0.8190342446287124 
1.7012572610908676 2.854591657627901 58.07040138987225 0.8092949361370356 
1.721271110567486 2.89583864314944 58.57173446499221 0.8023895545740317 
1.7405583661538326 2.9338275232758626 59.36275538265085 0.793697870178226 
1.7580206906146236 2.9666981500644423 59.85310832954649 0.7873864953796241 
1.7700114780926102 2.9895639510614074 60.75469072056159 0.7807458502048403 
1.7934512552359985 3.0291183862458655 61.75009805213971 0.7732516361003096 
1.6719521975586382 2.7977235723362788 58.05959577424268 0.7732516361003096 
epoch: 39, train time every whole data:450.98s
epoch: 39, total time:20824.17s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.72s
test time on whole data:61.03s
1.5174158467779912 2.476456714602085 55.259715247032084 0.8479461973994201 
1.5448377901503727 2.543028125503419 55.181613727742594 0.8407956806260557 
1.5721430539666188 2.6062599874307852 55.30762380611867 0.8338406483097719 
1.5930428115174706 2.6470113109495856 55.592729294496145 0.8303883704102711 
1.618834984825037 2.6956817350882134 55.825262426625066 0.8260401295036575 
1.6429174291612136 2.744034966233108 56.18165071592851 0.8206885624579976 
1.6699724289848514 2.8001531309175807 56.73884961185559 0.8134294767355064 
1.6865718855243177 2.8325096270662327 57.15721441686813 0.8083621560261461 
1.7057996499029298 2.8758440440628865 57.85921886025409 0.7996122514252695 
1.724226607317726 2.9138633809707035 58.33180508076868 0.7935522797543733 
1.7434651583885508 2.9550276610706705 59.21706240156803 0.7853813909537788 
1.7753719246951598 3.014694086906932 60.019469389873784 0.7768472784949867 
1.6495499642676865 2.763469043455526 56.88943223989658 0.7768472784949867 
epoch: 40, train time every whole data:451.07s
epoch: 40, total time:21347.06s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.75s
test time on whole data:61.12s
1.5153811383929459 2.466081199097121 56.04132683884316 0.8473589935617181 
1.543707378267089 2.5378233623785738 55.87272847611252 0.8392672498909635 
1.5722052569765421 2.608749683425478 55.74698159409528 0.8320631314071127 
1.595108941204225 2.6545337696470144 55.95000798559822 0.8288866948304395 
1.6229141434114427 2.7106363820100947 56.1575078592645 0.8242469566671754 
1.6511755382666098 2.7641278433006367 56.68079251661561 0.8187228044602108 
1.6826289320822272 2.82921480741015 57.389331278822844 0.8106313145023882 
1.7048010601803127 2.8707217776124314 57.825408134268365 0.8052932561791414 
1.728828930493799 2.924545453579041 58.46926982746346 0.7954345906928662 
1.7531315425629062 2.9766075894600177 58.84757112817483 0.7878873897202648 
1.7716159272787295 3.0147142968184752 59.59898191814309 0.7805699113525043 
1.8008026434226583 3.0701504934127484 60.52784186340858 0.771262800139285 
1.661858452711624 2.7918805761825136 57.42572571282748 0.771262800139285 
epoch: 41, train time every whole data:450.62s
epoch: 41, total time:21869.49s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.66s
test time on whole data:60.99s
1.5139521848259583 2.4547428393881137 56.4542142359229 0.8481181295770354 
1.5406018452805776 2.514836955968123 56.432238205607845 0.8414481337032803 
1.5674045018982141 2.579938763307103 56.365729393531275 0.8342571078959229 
1.5897024385704703 2.6260162340395214 56.58754490958854 0.8297964566659701 
1.6156291484940974 2.6761340731230665 56.74672186533436 0.825214127275704 
1.6402752673474275 2.7248860874286236 57.19111387698549 0.819901167933529 
1.6691386529868912 2.7895498013523765 57.89757339738959 0.8109628568098024 
1.6876300607423875 2.8302059337848102 58.44900354743139 0.8042832881058727 
1.7078965983937184 2.870966040490909 59.26944536040397 0.7961841658574752 
1.729459666652605 2.9164632172550893 59.75471335596602 0.7892809108795984 
1.7492921974006153 2.960030713928028 60.423415075051864 0.7821092715703583 
1.7786313412948733 3.0201646025813687 60.98548508716141 0.7737063989607729 
1.649134491990653 2.7524526010522075 58.046517658812924 0.7737063989607729 
epoch: 42, train time every whole data:450.79s
epoch: 42, total time:22391.95s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.65s
test time on whole data:60.97s
1.5344949206512066 2.4952277876259488 55.83864705460403 0.8483408559698845 
1.563673117873658 2.5615782336573982 55.87857191151716 0.8414088803573454 
1.5909057401605837 2.6210593513714024 56.23519460067613 0.834389974843423 
1.6129054316527964 2.660919042834153 56.758747894483804 0.8302724018817886 
1.6374698242454657 2.7051909125997655 57.19381095822349 0.8257755651398713 
1.6622768165032777 2.751191056125361 57.787042620743826 0.8206386722306943 
1.6905446080984103 2.8080810328242927 58.55785169765129 0.8131506674038865 
1.710834757536295 2.845862203327712 59.08096028918901 0.8073346209370185 
1.7324709253698765 2.8910314874566296 59.83723850257478 0.798884042852807 
1.7536024202191758 2.934522825281563 60.35594193490043 0.7923942427014071 
1.7734118292981846 2.976492915997785 61.236366759746964 0.7845942617328489 
1.8025971953652444 3.033211215678488 62.09345567668033 0.7759019490124738 
1.6720989655811813 2.7784740346521932 58.40459897294321 0.7759019490124738 
epoch: 43, train time every whole data:450.78s
epoch: 43, total time:22914.55s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.72s
test time on whole data:61.04s
1.5124969143494076 2.4535597775430977 55.78590699853836 0.8484012892770084 
1.5400330516121217 2.5153126470055245 55.94847915224349 0.841090704197325 
1.567997723155522 2.5873766165715124 56.05661548808665 0.8326199740908817 
1.590240212727693 2.625957992722633 56.40776556621153 0.828944171483435 
1.6141009413557392 2.6722912276138913 56.67947025320233 0.8240225395741868 
1.638670267156547 2.715193843993298 57.240607909616706 0.8188101559878874 
1.665935544997365 2.773832955875499 58.09023613587604 0.8103609330699244 
1.6831467151094583 2.8077679089858614 58.72594786477128 0.8047938173736955 
1.7051220319643616 2.852348991519875 59.6393295713509 0.7962329735099484 
1.724393690804463 2.8922130604064527 60.085355695906706 0.7901796965135607 
1.7446224093501057 2.9365372466101216 60.850138085141126 0.7825562004372904 
1.7727380734710467 2.996687620092375 61.50852257872012 0.7732440706527847 
1.646624798004486 2.7406239130368784 58.084970881717666 0.7732440706527847 
epoch: 44, train time every whole data:450.58s
epoch: 44, total time:23436.85s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.70s
test time on whole data:61.05s
1.5120799700503371 2.450391659544245 56.17935378747476 0.84839603459322 
1.5399068266727207 2.524614170982476 55.97239785644673 0.8401429946611184 
1.5680716868162687 2.590641966812475 55.977793516058185 0.8334606792261972 
1.5896466807286653 2.632574298532653 56.347282652686836 0.8297169702152208 
1.615730369818796 2.686296570875344 56.66020727239554 0.8244833318096371 
1.6409443496125085 2.7356293566601213 57.17912214040928 0.8190177354335226 
1.6708082566685265 2.795133180471688 57.87306383338028 0.8116134212160566 
1.6923689326663458 2.8381478238222844 58.292028861456835 0.8056666885755485 
1.7149912077233727 2.888087484571302 58.87371248252896 0.7966158138373648 
1.7353995604820194 2.9317765593021914 59.219197948292724 0.790057878253781 
1.753936072198674 2.968534316320952 59.957783673815555 0.7827537693466564 
1.7809643993116029 3.0221684260186015 60.82287182889493 0.7735815893011702 
1.6512373593958198 2.7608836167032123 57.77965325968535 0.7735815893011702 
epoch: 45, train time every whole data:450.29s
epoch: 45, total time:23959.05s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.65s
test time on whole data:60.96s
1.5129332652145198 2.4606115192844458 56.124594652477 0.8480305949715371 
1.543737645351461 2.541721883426 55.91281093977517 0.8393959756125512 
1.574498345840811 2.6169061434095466 55.751805832009694 0.8321986435138937 
1.5982720476176944 2.6621461737622485 56.04921984260286 0.8283596869106038 
1.6239778645161893 2.7128253987645237 56.30083046573636 0.823499195699325 
1.649589310032626 2.760834216387488 56.8323152511033 0.8176397435013683 
1.6767294133426178 2.817523462926381 57.59479454726587 0.8094870442425206 
1.6957494507781452 2.858322730698977 58.168331272370764 0.8026447727175271 
1.7153215031592797 2.8998741107728017 59.0064564902009 0.7936392189751574 
1.7367902466945706 2.944883040396001 59.694881635584295 0.7859831765183988 
1.7530774740345243 2.9755045014787442 60.641239124517284 0.7796414473645366 
1.7812013528929758 3.026970408548787 61.615926829211844 0.7710659613412456 
1.655156493289618 2.7784593539621185 57.80786427279442 0.7710659613412456 
epoch: 46, train time every whole data:450.53s
epoch: 46, total time:24481.20s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.67s
test time on whole data:60.98s
1.514621777876768 2.4542968688217215 55.468838868319814 0.8487048962631611 
1.5425471254703367 2.518326269706378 55.64871312780117 0.8410024997837247 
1.5670300674706343 2.5771883197320484 55.81211662147755 0.8342046169665288 
1.5895551706529445 2.6162552942313324 56.12877462645205 0.8306358878635145 
1.615892229191604 2.6736804761538395 56.37051528822183 0.8251227646154854 
1.644459467602539 2.7323188469798336 56.86794182181385 0.8187401884071196 
1.675106608073715 2.8006400807381593 57.53459397176316 0.8102116204980123 
1.6963286268567401 2.8463548017812 57.928881026751924 0.8038564694208841 
1.71706517234214 2.8945178112132406 58.48869740934274 0.794880308141651 
1.735957491815445 2.9344651274497155 58.825080363229 0.7885965919081582 
1.7520486658507337 2.971336361441033 59.66260020247898 0.7808364239313405 
1.776021273440637 3.0167635172784686 60.52205798250148 0.7729240000441034 
1.6522194730536865 2.758784554929317 57.438320380146166 0.7729240000441034 
epoch: 47, train time every whole data:450.69s
epoch: 47, total time:25003.46s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.77s
test time on whole data:61.11s
1.510161662652379 2.4552579579031906 56.30093895829829 0.848580220604529 
1.5389407193967628 2.5214716535606887 56.362855916127806 0.8413254295725333 
1.5656817612023581 2.5822983271628166 56.53418494656898 0.8346094696682222 
1.587265636614657 2.6236510204446843 57.152874157819966 0.8297437845250095 
1.612332504125844 2.6711172526230063 57.55309017876721 0.8246184367221173 
1.6390049469455898 2.722830809210434 58.170028691541134 0.818278516038594 
1.6699041684428673 2.7866854888876964 58.97640054658726 0.8098496102006721 
1.6948288757478198 2.8404262629641743 59.50915675634595 0.8020032053519648 
1.7186224710811817 2.8980710833161756 60.14845586874319 0.7916325206000583 
1.74073676894889 2.94520759494678 60.470416742650045 0.7844971146504344 
1.7575815808399624 2.9791251084803503 61.11442679066176 0.7783697381032644 
1.7830989465434104 3.029958873831783 61.83994286806617 0.7701087304733635 
1.651513336878477 2.760572609677816 58.6778369573171 0.7701087304733635 
epoch: 48, train time every whole data:450.88s
epoch: 48, total time:25526.06s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.67s
test time on whole data:61.01s
1.5117599432765552 2.463400728843274 55.62578684476481 0.8484295561602141 
1.541133260011407 2.529896319150371 55.72288766037465 0.8410019821764729 
1.5691391018950158 2.5930479026618816 55.971262848589895 0.8341682447751804 
1.5911524400752748 2.6378998558482385 56.49133093214155 0.8292245312780779 
1.6166373722563896 2.6858004059436382 56.86681050239733 0.8243981965212204 
1.6419379373454444 2.739093414465053 57.41340089075953 0.817890055350832 
1.6688938857688613 2.790249072009023 58.212738788813844 0.8110300863815646 
1.6881383487403925 2.8242717857345916 58.74018210073585 0.8057540365409809 
1.7091881754275944 2.873344340127025 59.407813546387835 0.7966786595854759 
1.7318955002247045 2.9228714489688192 59.799899953314615 0.7893784083701858 
1.7539930163793975 2.971075269963633 60.49702074616483 0.781180646811309 
1.78334961631016 3.0304649646054167 61.21942415430499 0.7720984876883571 
1.6506015498092663 2.7604284168464917 57.99748414596707 0.7720984876883571 
epoch: 49, train time every whole data:450.75s
epoch: 49, total time:26048.44s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.68s
test time on whole data:61.00s
1.513443793646193 2.467837849034658 55.782517782342886 0.8485862691891912 
1.5424663774717067 2.5318369201700284 55.888933155920014 0.8419183201917044 
1.56966437164632 2.5960646047290505 55.97641076700929 0.8349690176257588 
1.5932300853724812 2.6422728008493266 56.316740317261974 0.8305305348156986 
1.619891434518709 2.6951397859991095 56.58462896614167 0.8256067498575033 
1.6462931367384182 2.749145954128376 57.08586851786915 0.819116299071158 
1.6737642270633508 2.8059932249245723 57.845666985792334 0.8111072333358093 
1.6948783765578908 2.8484592793830243 58.43304259317718 0.8043601320206527 
1.7173616645776977 2.9013674869907558 59.12825312528878 0.7943254253677696 
1.7422765460344298 2.956539643027178 59.57276162529139 0.7861574598256781 
1.7640239583585589 3.002017579716166 60.149384020831235 0.7786146106868925 
1.7944981413716006 3.0612088718451336 60.77013299699111 0.7698989719712112 
1.6559826761131131 2.7774785968969438 57.7946222822181 0.7698989719712112 
epoch: 50, train time every whole data:450.90s
epoch: 50, total time:26571.08s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.71s
test time on whole data:61.08s
1.5088405888845169 2.457607512502557 55.6303769100585 0.8490741554650028 
1.5382309995246608 2.524153706051652 55.6246594418075 0.8420519031192006 
1.5653155946072546 2.5886611273851674 55.714811821670764 0.8352182640125034 
1.588467341089089 2.6357913245959645 56.05432089754488 0.8306970428706124 
1.6140107177103027 2.685974197086796 56.36413852577963 0.8260621520546085 
1.6396310956985467 2.736755694481247 56.89845391023234 0.8200152866265266 
1.66675301122488 2.791764642523657 57.670564245549414 0.8123338494656754 
1.6866987397409976 2.8314952718907516 58.22220761148057 0.8060467136673372 
1.7070431766659908 2.8792696881392312 58.866562595897484 0.7970149636760374 
1.728096612773747 2.924909821862845 59.26247215766107 0.7902406250836512 
1.7481505160338822 2.966706918349548 59.945272401043084 0.7827961210436415 
1.7766139365361915 3.019921250327944 60.67044956096309 0.7747365728794595 
1.6473210275408383 2.758953893988364 57.57711833516264 0.7747365728794595 
epoch: 51, train time every whole data:452.40s
epoch: 51, total time:27095.08s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.82s
test time on whole data:61.25s
1.508852700564212 2.457628391129773 55.711604456720096 0.8489146870455674 
1.5381811780634203 2.5240819633808713 55.73403960438233 0.841745834675341 
1.5651797761754798 2.5871897250122786 55.90758446443714 0.8347985575038817 
1.5879352507077689 2.6325263748075853 56.2937767815718 0.8302822668059006 
1.6128203914758883 2.680731676341093 56.630447378571056 0.825736560444494 
1.6384650975958932 2.732667206409232 57.18731339586943 0.8194295567386931 
1.6650630634234598 2.785290071345181 57.97886973398886 0.8120123443219968 
1.6844065191879691 2.8241115947255717 58.55394586343431 0.8056248061090784 
1.7046407486176385 2.8713788130016247 59.24681399006906 0.7965181127298936 
1.7252010782183635 2.915223139356026 59.686352511579734 0.7897208058584854 
1.7446553679207961 2.954625782051734 60.425305435990275 0.7825717476133793 
1.7725303632172622 3.0074460032329267 61.19351364988317 0.774255194809603 
1.6456609612640127 2.752874248412266 57.87923197953352 0.774255194809603 
epoch: 52, train time every whole data:451.70s
epoch: 52, total time:27618.77s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.64s
test time on whole data:60.96s
1.5084152783121736 2.456476371981972 55.69377215000772 0.8491791622533597 
1.5384123838202406 2.5262694489388355 55.63688097084207 0.8418759196534263 
1.5662359571402804 2.593291069872021 55.72709347275514 0.8347931440535347 
1.589932742680822 2.64059719417342 56.08665805740556 0.8302495478393551 
1.6160293439242635 2.690320073144504 56.396360785071245 0.825758010903033 
1.6425809765451012 2.7441731907249722 56.94271814149453 0.8192553707864556 
1.6697407570775775 2.798433051177831 57.70865924482671 0.8117052965762246 
1.68969266134057 2.8384463008481218 58.27566880977899 0.8051599187579938 
1.709888144241912 2.885670949826677 58.946372306317905 0.7959365882661149 
1.731145687960443 2.9313800047082914 59.39378147921387 0.788904512344027 
1.7507034660185732 2.9703477546327752 60.13167290361602 0.781881908842742 
1.7788584660006954 3.0224945004891945 60.89839836860133 0.7738276905988682 
1.649302988755221 2.7635886015393605 57.65326627924375 0.7738276905988682 
epoch: 53, train time every whole data:451.13s
epoch: 53, total time:28141.40s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.77s
test time on whole data:61.15s
1.508556718396023 2.45660631860656 55.589208172041836 0.8492098053586389 
1.5383465087705601 2.5250870299068042 55.57885118125865 0.8419238106926447 
1.5662372685502328 2.5925935025756344 55.703793278138825 0.834647751342871 
1.589931864275996 2.639042996269329 56.08569166056411 0.8301381078859255 
1.6159672761772361 2.6894823311117713 56.39962107515567 0.8254671770852922 
1.642732259644905 2.7433771397115776 56.95511083424344 0.8189952635830292 
1.6695705890970394 2.7982996088914516 57.71379371491432 0.8112826894115199 
1.6888562504812366 2.8365355572854725 58.28388590298719 0.8048152583361868 
1.7086338989634422 2.882614858417927 58.97445953976178 0.7955684862241906 
1.7292403383318866 2.925941725894072 59.42617677065023 0.7888009809833657 
1.7484139333456046 2.9643921847431054 60.17992516885996 0.7817715090455089 
1.7759073500874496 3.0165784526563177 60.94384550302343 0.7735679659801195 
1.648532854676801 2.7612027288724854 57.652962359596714 0.7735679659801195 
epoch: 54, train time every whole data:452.12s
epoch: 54, total time:28665.31s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.85s
test time on whole data:61.31s
1.5076917893027089 2.453544830681932 55.75635863302634 0.8491182424096261 
1.537194600840587 2.522093889808257 55.684033278311205 0.8417662375012415 
1.565203409969984 2.5890715765927363 55.778105016468196 0.8345964342188595 
1.5883876836881752 2.635396841815275 56.12699731622828 0.830230085028867 
1.6141416556964672 2.68606892203162 56.437949704855015 0.8256459656207725 
1.640573088114815 2.7396062686256384 56.98132040533539 0.819411925014634 
1.6673111575209492 2.7932610301741025 57.74236379347462 0.8120736555337963 
1.686435855107382 2.831269147254443 58.3236776711214 0.8057415325896917 
1.7059873899000564 2.8756951234973718 58.99912432823675 0.7968772686128188 
1.7266125641304644 2.9203518812484512 59.438047224940945 0.7899152780012868 
1.7459534154738343 2.959986974438457 60.159867640292994 0.7826512185334632 
1.773427485970869 3.0124810431441915 60.90299491603144 0.7744061619215155 
1.6465766746430244 2.7568534505451447 57.694332851811026 0.7744061619215155 
epoch: 55, train time every whole data:451.95s
epoch: 55, total time:29189.32s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.79s
test time on whole data:61.23s
1.5082518568329868 2.455841136509102 55.78549861043041 0.8491667673748611 
1.5381323221482868 2.525802988433151 55.73519988619603 0.8417352893817038 
1.5667519255349678 2.5952075718711485 55.831221613686424 0.8342998117808276 
1.5903749140119623 2.641392071021525 56.210399272427736 0.8298544193676498 
1.6164214456945303 2.691103765577599 56.533838093219245 0.8253553990234741 
1.6428211339003451 2.7452089185359623 57.08583590014899 0.8189041539684715 
1.6693933333089308 2.7986233536964376 57.852757111394794 0.8114929655670751 
1.6882648430848937 2.8351884150207036 58.429243941395406 0.8052955781746368 
1.7071836300659038 2.87879434460712 59.10401620675173 0.7965180236099142 
1.7269074467172225 2.9205577395125397 59.54555263590326 0.7900068717516032 
1.7457381301249955 2.9580585051155737 60.302048775630404 0.7830656468126833 
1.772320199056218 3.007525754423344 61.06114324903703 0.7752898912948987 
1.6477134317067703 2.7595912139559386 57.78982765402836 0.7752898912948987 
epoch: 56, train time every whole data:451.83s
epoch: 56, total time:29713.09s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.82s
test time on whole data:61.25s
1.5075279108085449 2.450058076791998 55.90404629940004 0.8491271998624037 
1.5362698632961227 2.5167011448152476 55.852294071924256 0.8418848993245078 
1.5635594132770563 2.5833380506525336 55.947040041923046 0.8345838066528455 
1.5862798247295653 2.627520070298602 56.29650046828467 0.8302215561222309 
1.6114909612941777 2.6760283343305247 56.585003018532 0.8256877603187925 
1.6381878349427135 2.7311572756729077 57.11679102950112 0.8189904042767083 
1.664835434965878 2.7844653502112804 57.85348573304636 0.8117470012250432 
1.6843725978299267 2.824229527522491 58.39717066568658 0.8054144243381249 
1.7047825231352556 2.871514589084268 59.04988762968877 0.7964715941203562 
1.7256674569869148 2.917101376614228 59.460394838008746 0.7895477595836006 
1.745375344977581 2.957817342518917 60.19485771827955 0.7823012545548147 
1.7725787449156245 3.0094291517955023 60.92647836124705 0.774272949507898 
1.6450773259299467 2.7511263993915294 57.79875558948044 0.774272949507898 
epoch: 57, train time every whole data:451.72s
epoch: 57, total time:30236.90s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.77s
test time on whole data:61.15s
1.506705932663044 2.4475832976937975 56.06836819809142 0.8491673591966652 
1.5351695673008938 2.513667810523455 55.98842468514608 0.8418989556548965 
1.562320010550409 2.579880387792265 56.04969043038997 0.8346452814701931 
1.585150961520239 2.6253510977410057 56.37711770922942 0.8301956747702867 
1.6107391988686508 2.676267620543426 56.64036109150564 0.8255714360456521 
1.638114906494284 2.73292354789372 57.158896731163644 0.8190386232295256 
1.6661515365389308 2.7901957967139848 57.89176909881053 0.8115553238558401 
1.6868120221311138 2.8318999219524823 58.44887792819833 0.8050548776390022 
1.70735377914902 2.8799369201483938 59.096661349763245 0.7958888383613052 
1.7282762764098034 2.9250510681680213 59.53166055863222 0.788921973357031 
1.7476533792534221 2.964153655170801 60.28075480238899 0.7817354862622411 
1.7750927653157462 3.0155050919634574 61.05984455841201 0.773547197153391 
1.6457950280162965 2.7541333872387317 57.88279382367916 0.773547197153391 
epoch: 58, train time every whole data:451.69s
epoch: 58, total time:30760.65s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.79s
test time on whole data:61.18s
1.507737665416939 2.4540457069819652 55.732418404944696 0.8491425063719545 
1.5371432566174439 2.5217846923405185 55.68992565946013 0.8417543138427339 
1.5648061070966401 2.587793664260466 55.78896380061611 0.8345810017394526 
1.5874939171341027 2.6323697794125973 56.14231246029716 0.8302992404243241 
1.612836610538885 2.6815173993494663 56.45178854408685 0.8257809478139254 
1.6392693388488675 2.7362488200289796 57.00716835274914 0.8192422432960657 
1.6661737147335496 2.7905393919127777 57.77932968655465 0.8119159432199362 
1.6862872390572337 2.8304506578683153 58.36970354269977 0.805459963171434 
1.7067742623961752 2.87782897824749 59.055930978607066 0.7963386183703665 
1.7279600447224719 2.92361235219307 59.52351147601552 0.7892133635950651 
1.7475309737296332 2.9639472960337683 60.29810454916687 0.7818873250667612 
1.7752228420159468 3.0158764017794795 61.106243254485804 0.7736059128332073 
1.646602997692324 2.7567166781307684 57.74554876577186 0.7736059128332073 
epoch: 59, train time every whole data:451.37s
epoch: 59, total time:31283.94s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.76s
test time on whole data:61.22s
1.5066181955302045 2.447339849684505 56.098739036105 0.8491192827166524 
1.5357993046816971 2.516295155850248 55.9390781634147 0.8417157885138289 
1.5639172502946819 2.5857624337123406 55.94361716789504 0.834316248003115 
1.5871686412231731 2.6321534600850907 56.25774577315109 0.8299127809997137 
1.6129065843004555 2.682387498099021 56.54576647829137 0.8253503662250847 
1.639821263581337 2.738087764479057 57.09609339886388 0.8186775134670058 
1.6666906113496849 2.792137066810774 57.85801213100626 0.8113552635394059 
1.6862607491823534 2.8309325439979376 58.438075868967864 0.8051082596634983 
1.7064662848974446 2.8776647019297155 59.104571219473335 0.7961141652368783 
1.7274002362859568 2.922643700763814 59.52682661775616 0.7892573732682063 
1.746811886592635 2.9619684349432407 60.240960032440526 0.7822984753742795 
1.774079583704915 3.0130726574880167 60.96654282429614 0.7744073879984226 
1.6461617159687116 2.755491680323236 57.83476138888628 0.7744073879984226 
epoch: 60, train time every whole data:451.86s
epoch: 60, total time:31807.74s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.72s
test time on whole data:61.06s
1.5071997819258167 2.4502032318782754 55.91959876602215 0.8491962889476028 
1.535870696532407 2.516049637327998 55.88095582145266 0.8419647189815815 
1.5631452721685526 2.5819412191547215 55.94622969224554 0.8347614037158807 
1.585750860702956 2.626894265354557 56.27077430495262 0.8303355014688791 
1.6108559701709697 2.6765008395190844 56.53901622866907 0.82571415270236 
1.6372414063679144 2.731584126082682 57.052365925399265 0.8190688275677231 
1.6635448038504415 2.785219152540692 57.77564954375883 0.8118457071234417 
1.682551285523123 2.8231576474192903 58.31875652226175 0.8057759827880653 
1.7023203527588575 2.8688312095674746 58.95562417062692 0.7970490829540551 
1.7227140046450353 2.9128507146528544 59.35755642488467 0.7903911340063402 
1.7417800964000856 2.952078232886951 60.06366128174161 0.7834254883557182 
1.768689064300752 3.002173207259376 60.779744280810476 0.7757260241652826 
1.6434719662789092 2.7491903453792177 57.73841777434584 0.7757260241652826 
epoch: 61, train time every whole data:451.47s
epoch: 61, total time:32331.05s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.69s
test time on whole data:61.06s
1.507676671816657 2.452117032700473 55.762994096633655 0.8491619842736347 
1.5371522880103439 2.52073069444867 55.71004186680793 0.8417812347271361 
1.56493524357916 2.5881777786088818 55.784990430390025 0.8345356843369761 
1.588129861314382 2.633188549542378 56.15144535750893 0.8300944137266186 
1.613411392943224 2.682276071623536 56.45481711744045 0.8254426040177066 
1.6399122475523147 2.7358806622474434 56.99583346315828 0.8188612184706137 
1.6660446252140793 2.788399920905059 57.73338299724027 0.8116446527652305 
1.6851007821729318 2.827094709311265 58.29009503690864 0.8053617872992666 
1.7050870428496883 2.8734413435336195 58.94441206389267 0.7963697464262555 
1.7258670150670445 2.9180306561190585 59.35210479786021 0.7895428007589419 
1.744757518202776 2.956720022211566 60.05208828692798 0.7826467050208332 
1.7716984699427016 3.008588041951608 60.76305179653006 0.7745866282474904 
1.6458144298887754 2.7539661887388873 57.666365219897195 0.7745866282474904 
epoch: 62, train time every whole data:452.48s
epoch: 62, total time:32855.36s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.78s
test time on whole data:61.15s
1.5073046492206907 2.4517625993753787 55.992223575825385 0.8491267960466223 
1.53644397744971 2.519507702276477 55.93426494872995 0.8417625740880398 
1.56424186996477 2.5858073185594965 56.03384589146388 0.8345790740129776 
1.5872309460413776 2.6311897048888726 56.3982960977317 0.8301179025473339 
1.6129072342233821 2.6815398252144336 56.71225692838123 0.8253743823142391 
1.6394021956016798 2.7358081297540817 57.26385153140478 0.818838241282237 
1.6661649706363677 2.790059777210095 58.020879546330576 0.8114483338343792 
1.685973628847017 2.829148525361373 58.609098791212254 0.8051289625853364 
1.7063980765041142 2.876275628916878 59.291636003983136 0.796074506615947 
1.7274458074545753 2.9216199551001987 59.73538509141686 0.7890934710422519 
1.7468349519452702 2.9608552187774864 60.46792565678151 0.7820742739751906 
1.7741156700442413 3.0123180760226855 61.224181683376734 0.7739448787014823 
1.646205331494433 2.7550254540050805 57.97375127154049 0.7739448787014823 
epoch: 63, train time every whole data:452.86s
epoch: 63, total time:33380.03s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.80s
test time on whole data:61.20s
1.5078439084266624 2.455360602702723 55.73143784646998 0.8491304586475451 
1.5369335448726835 2.5218798512792993 55.72059212016449 0.841897491422938 
1.5648590525564339 2.589195357391827 55.828997496456246 0.8345504336363162 
1.588267792287327 2.6359551932385688 56.19556328520979 0.829896054653806 
1.614371572775855 2.6866206163243804 56.500516389837074 0.8252693407957146 
1.64142797279216 2.7419406067067573 57.04310166248542 0.8187218155874655 
1.668945124037564 2.7976185539961964 57.798621548196735 0.8113373364623873 
1.689390027566946 2.838205247639034 58.37255283399845 0.804964552876979 
1.7099454943396684 2.8860151238765597 59.01403593993313 0.7959151710781145 
1.7313019430373042 2.9317442043517277 59.43680340215002 0.7890637813397031 
1.7507482806735095 2.9713428416970356 60.1477230137955 0.7820215799771569 
1.778636550776217 3.0239171260588575 60.89712320499082 0.7738303945648656 
1.6485559386785276 2.762189254384109 57.72401822896788 0.7738303945648656 
epoch: 64, train time every whole data:452.98s
epoch: 64, total time:33904.87s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.90s
test time on whole data:61.37s
1.5066174980665423 2.4475823401557553 56.09980943660741 0.8490698528832493 
1.5351223455416483 2.514231767955014 56.02177324980171 0.8417033504082334 
1.5624160229341082 2.5804900352563216 56.061986763584656 0.8345615843471469 
1.5853636008831007 2.626669573271282 56.374259790034756 0.8300722374275021 
1.6106374671278256 2.6768006187312796 56.65262047690105 0.8254548793362602 
1.6369879384625348 2.73114484268746 57.186675726961745 0.8189270162657462 
1.6631873762038136 2.7835453064183957 57.9368397049013 0.8118698040229569 
1.682594647278477 2.8225679463254134 58.51210396332854 0.8055649182522464 
1.70293844486365 2.869793754529269 59.1847653535434 0.7965755601844979 
1.7239259618079024 2.9152955369610583 59.60984524517448 0.7896620173875265 
1.7437256100183973 2.9553297412701887 60.327119454923064 0.7826633027926072 
1.771175149303728 3.0073266491652233 61.03826268909567 0.7746743286966163 
1.6437243385409774 2.7495821238342204 57.917264316187264 0.7746743286966163 
epoch: 65, train time every whole data:452.94s
epoch: 65, total time:34430.01s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.81s
test time on whole data:61.19s
1.507132796596913 2.448883277274546 55.967067515660894 0.8490352474100491 
1.5360703052686793 2.5167909781591953 55.870745946016974 0.8416548356187201 
1.56418475476271 2.584932402524978 55.925520992008316 0.8343784152485438 
1.5878888947528211 2.6323128837658167 56.25870628136869 0.8298106058790398 
1.613962288411955 2.6838977194586078 56.57444961923391 0.8249896382623819 
1.6408683787870797 2.739005934562088 57.130335342630936 0.8182659028258984 
1.6670008733151924 2.792009094769914 57.888190244090865 0.8109244282532925 
1.685993945761362 2.830445563269345 58.47752810670185 0.8044740673053529 
1.705470077901103 2.8754398782025077 59.16517362972718 0.7955368476843975 
1.7257652576329807 2.9188294440197478 59.61407616372786 0.7886848863508553 
1.744196024512606 2.9561024985583995 60.34692575313944 0.781899196926677 
1.7703318156238113 3.0055718695951374 61.096445224362114 0.7740224067417784 
1.6457387844439344 2.7539991253452785 57.859693184872675 0.7740224067417784 
epoch: 66, train time every whole data:452.76s
epoch: 66, total time:34954.63s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.81s
test time on whole data:61.20s
1.5073373196012385 2.4531358673322643 55.758093084030804 0.8490673872962363 
1.536470815594707 2.5205813724999797 55.72542229510981 0.8416845571907706 
1.5642107460752483 2.58700024652033 55.83103088145079 0.8344266338108186 
1.5873022092390097 2.6324293827796748 56.190624280295 0.8299493816058007 
1.6132504659749212 2.6833774289079364 56.50950381691313 0.8252037685674637 
1.6401091313983003 2.738661753047047 57.06829158909542 0.8185343686325695 
1.66705832770591 2.7936380806718195 57.82786533511707 0.8111029457335022 
1.6872438759916417 2.8337541121791707 58.40953914616202 0.8047255169185052 
1.7076544460417438 2.881747915685482 59.07304003196471 0.7955807933725523 
1.7284706276413053 2.9264225384111238 59.50417601658254 0.7887692647794529 
1.7476737568347405 2.964954997855877 60.23690196051409 0.7818483418145624 
1.774715784353958 3.015546409504372 60.97047938864686 0.7739267783687973 
1.6467914588710604 2.758044562389489 57.75884457721615 0.7739267783687973 
epoch: 67, train time every whole data:452.77s
epoch: 67, total time:35479.24s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.91s
test time on whole data:61.39s
1.507441174722942 2.449432039054388 55.884033945658906 0.8490796461250044 
1.535903854373399 2.5148562847841243 55.85213141046393 0.841821276736395 
1.5631931117594775 2.5805214926560587 55.93209422474391 0.8345916904199665 
1.5862286252523108 2.6264466120868906 56.273770832151115 0.8300031752191064 
1.6116336638721682 2.6764007849974187 56.5647970880992 0.8253437244306034 
1.638272678965614 2.731419474724727 57.09766309479938 0.8187123726493695 
1.6649921517959307 2.786532370952307 57.84295256226405 0.8112820366934639 
1.6845466842901493 2.8260429979804167 58.410295709737625 0.8050064569039396 
1.7050978849994107 2.8741043671027606 59.07788416972338 0.7959007006687577 
1.7258488758686221 2.9193259770504345 59.490766304398235 0.7890229157630408 
1.7450943677891047 2.9585998524541464 60.20283340560169 0.7820607012653528 
1.771579476662069 3.0082444984472096 60.91595394837084 0.7743436018196844 
1.6449860458625998 2.7513992764223127 57.795525222463255 0.7743436018196844 
epoch: 68, train time every whole data:452.85s
epoch: 68, total time:36004.53s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.90s
test time on whole data:61.34s
1.5076325713720704 2.4539822102809117 55.773390863280994 0.8490884969135879 
1.5373735656115626 2.5227496933764235 55.69744223731543 0.8418027835100798 
1.565760396790203 2.590507788787529 55.78848015163742 0.8346204384478277 
1.5892115591935636 2.637163280728658 56.18071927929304 0.8299186176353472 
1.6145814154612876 2.686083943815886 56.53571848520983 0.8252811857750468 
1.6402774789267707 2.738821391335283 57.1160682545458 0.818716968614872 
1.666104848802888 2.790244397686535 57.88808391324329 0.8116297277012746 
1.6853439184475159 2.8285648475286105 58.462587192129575 0.8054636806284206 
1.7054996946806176 2.875343964039912 59.104446500245814 0.7966019258957266 
1.726694622971295 2.9215728687721736 59.499736503677305 0.7897502533855857 
1.746564916826075 2.963060760422918 60.17699268684623 0.7825574106561419 
1.7739315483108873 3.0143535810592548 60.85605975309113 0.7747169014664452 
1.646581378116228 2.757162422066156 57.756741377495736 0.7747169014664452 
epoch: 69, train time every whole data:452.95s
epoch: 69, total time:36529.43s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.88s
test time on whole data:61.34s
1.5074129999600174 2.4527055615592275 55.858363013158275 0.849095435564803 
1.537254803982253 2.522109803195573 55.78432779805242 0.8416708080220066 
1.5655937288191524 2.5899459528150874 55.873489213020875 0.8344430378816183 
1.5889831657042461 2.637317243494944 56.25235031483003 0.8297615160886498 
1.6147725881379806 2.6873750604664597 56.597660986183776 0.8251131510976737 
1.641032582941066 2.741454255819313 57.173705949335066 0.8185097978764789 
1.6674157350652274 2.794402368049071 57.94850029866353 0.8112329823987957 
1.6867547337260274 2.8330600459438977 58.54774461519868 0.8048340704714108 
1.7065570256597407 2.8791153309102335 59.2249171794235 0.795800354916742 
1.7270532549431636 2.923423975975794 59.6631583334976 0.7888614121397891 
1.7458540048039564 2.9611020426163717 60.38847514416966 0.7819828278462561 
1.7722522298741554 3.0097307810396257 61.12762035949901 0.7742775380514161 
1.6467447378014155 2.7579408411044537 57.87012555451364 0.7742775380514161 
epoch: 70, train time every whole data:453.08s
epoch: 70, total time:37054.55s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.91s
test time on whole data:61.39s
1.5080827847962224 2.4566415467095757 55.67926083650182 0.8490091118548926 
1.5372812130810427 2.5235583606275656 55.70704649942132 0.841663090887399 
1.5650297086354168 2.5886976398902695 55.85314744424168 0.8345507553011117 
1.5882643800342366 2.634286400798205 56.23330254889052 0.8300002410811645 
1.6135606338358706 2.683253412871386 56.56201699960886 0.8254664680351804 
1.6397925765180872 2.7375855864201935 57.114562029926184 0.8187815861394463 
1.6659526486000311 2.7898468737696103 57.87504817942354 0.8115847757850373 
1.6847733971921817 2.8278006871463743 58.445266619818206 0.8052912794856184 
1.704266648985268 2.873165477308846 59.110316556797294 0.79635687979196 
1.7240743049004426 2.9157003115002107 59.53015874259903 0.7897181645022787 
1.7422665094598417 2.9521364865878366 60.24216313228171 0.7829995220981728 
1.7681731599994182 3.0010442124105374 60.95772328917404 0.7752510058913749 
1.6451264971698383 2.7537239209455606 57.77593272334131 0.7752510058913749 
epoch: 71, train time every whole data:452.88s
epoch: 71, total time:37579.63s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.84s
test time on whole data:61.26s
1.5076546976046548 2.4548363300222 55.75415496788542 0.8490884318893609 
1.5373173941341007 2.52341039045911 55.70561573103574 0.8417309044768992 
1.5656364703919916 2.5913580955772777 55.79748410098725 0.8345009227150385 
1.5896275059218918 2.639542265838338 56.19044949587499 0.8296488006691728 
1.615464939014188 2.68834797867107 56.53949493301089 0.825151974059116 
1.6417022115639632 2.7423782213932117 57.10851092731012 0.8184691857690993 
1.667727481520247 2.7951065569665317 57.87020311328101 0.8111400099315423 
1.6867247469506803 2.832911741990661 58.44620440502517 0.8049143404210922 
1.7060939512859499 2.878232505292299 59.10280406402144 0.7961073059440924 
1.726141720053252 2.9213766439899653 59.5184785891566 0.7894859907243275 
1.7443759852442002 2.956877802284303 60.214377533219945 0.7830567791432337 
1.7702756166223081 3.005330475125881 60.921731595870696 0.7754961067730649 
1.6465618933589523 2.7576530748955492 57.76422370591854 0.7754961067730649 
epoch: 72, train time every whole data:453.24s
epoch: 72, total time:38105.11s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.94s
test time on whole data:61.41s
1.5069636097881234 2.450850058964789 55.95895060367867 0.8490708618582621 
1.5364163326837477 2.5196829442518553 55.86301845168392 0.8417113706049847 
1.5648519267550713 2.588830336416517 55.90495840838175 0.8344588288345897 
1.5890534414971869 2.6384870663088558 56.24454324992876 0.829639415922793 
1.6155513324688766 2.690637521740859 56.555896949779914 0.8248938114934115 
1.6425430058113166 2.7458916082109153 57.123188373537594 0.818174612137973 
1.668987274230236 2.7991192215869316 57.88762074450759 0.8108988467650204 
1.6885075305866166 2.838086201652315 58.48225459907543 0.8045198483203634 
1.708151615225311 2.883626402657041 59.14993682455183 0.7956150502300693 
1.729058792500801 2.9284601095272773 59.592758174717765 0.7887138030536631 
1.7480359381605826 2.9658122179268305 60.30834101935526 0.7819538335403441 
1.7749520984630853 3.0155782489948955 61.03524702270911 0.7741554086069341 
1.6477560748475797 2.76087714766565 57.84232204932167 0.7741554086069341 
epoch: 73, train time every whole data:452.92s
epoch: 73, total time:38630.08s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.89s
test time on whole data:61.37s
1.5063478316005674 2.4477324006017622 56.0683732733414 0.849128354911826 
1.5350645259746483 2.5145395392371217 56.0016147336765 0.8417914502606332 
1.5628177542217254 2.5817370544280163 56.08293054674615 0.8344643407769289 
1.5859466006278637 2.6285161183683896 56.420840497066635 0.8297482924464566 
1.6114148072178165 2.6788726438453803 56.71755132490163 0.8250243573641994 
1.6379709404825809 2.733392906233163 57.260772904623195 0.8184397814510687 
1.6646784043430927 2.7869985668243955 58.0141242725325 0.8112296091805553 
1.684400986465936 2.8273662224125142 58.6042226503093 0.8047629363257107 
1.704812215479623 2.874423272904938 59.2768011971454 0.7958301904880863 
1.7255271068307616 2.9191405335329197 59.70171822306843 0.7890217326141544 
1.7445461440866903 2.957635016349314 60.39650612465945 0.7821932774227119 
1.7708724685441704 3.006531453768934 61.10198457056044 0.7746091780690837 
1.644533315489623 2.7517941006694593 57.97071482884222 0.7746091780690837 
epoch: 74, train time every whole data:451.95s
epoch: 74, total time:39154.22s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.75s
test time on whole data:61.14s
1.5075034342865858 2.4545166427177585 55.75950635629826 0.8490523736560709 
1.5369383018177358 2.5218459659945207 55.73999987518034 0.8417544083800836 
1.565232453779273 2.5895524866429094 55.85703473837545 0.8344093800146681 
1.588937148444798 2.637114644171626 56.23294643421399 0.829607948716132 
1.6147623896660017 2.6873726955027797 56.574527018811594 0.82491795948197 
1.641489662769561 2.74206133190816 57.14358530489234 0.818134809038207 
1.667642933390946 2.7946593388486827 57.905622597051575 0.8107894289641554 
1.6868203514473779 2.833553623195678 58.49702284581557 0.8042381487900798 
1.7066499811562577 2.8799883962640322 59.17176589379879 0.7950586857506099 
1.72731085182753 2.9241823062477303 59.61731545495474 0.7880855591274706 
1.7459386407360435 2.9614930184796497 60.32268913831125 0.7812610512578931 
1.7725429663169419 3.0114371730173195 61.054278364541325 0.7733029061453066 
1.646814092969921 2.758455245992244 57.82312380362406 0.7733029061453066 
epoch: 75, train time every whole data:452.57s
epoch: 75, total time:39678.56s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.73s
test time on whole data:61.09s
1.5071414270731842 2.452888559574396 55.84508570098924 0.8490754256473948 
1.5364731625010748 2.520441761060857 55.80279150520394 0.8417343907263165 
1.5646785484208237 2.5882569554065014 55.89160002113607 0.8344142241905228 
1.5883018017919468 2.6359140423912577 56.25012181507819 0.8296657110015687 
1.6141420086130855 2.686372632051106 56.57972173351846 0.8250166544469848 
1.6407865681566653 2.740963234553779 57.143116482199765 0.8183535329930884 
1.6670569209957584 2.7939228115312 57.906311808515674 0.8110888856329376 
1.6863846565017566 2.8328350127764623 58.49864068393169 0.8046814702945801 
1.706278308369308 2.8791453749698195 59.16887973814695 0.7956729095739177 
1.7270402315110855 2.923776131057748 59.60163245272583 0.788786445471867 
1.7459786576027316 2.961685955173163 60.30291708500454 0.7819590907558056 
1.7727456339726313 3.0115410915153724 61.02414275655964 0.7741107113773974 
1.6464173271258375 2.757652239952795 57.834677669800364 0.7741107113773974 
epoch: 76, train time every whole data:452.90s
epoch: 76, total time:40203.26s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.90s
test time on whole data:61.29s
1.5070937495527879 2.4525274389942546 55.84751360549268 0.8490790517716149 
1.5364261557251393 2.520326968599457 55.80871918263598 0.8416982420595626 
1.5645387535298332 2.5879549359935163 55.89555792616082 0.834395626996756 
1.5881848880033054 2.6355206733797814 56.25122631014763 0.8296498213674551 
1.6139749037042437 2.685926657307712 56.57290816388376 0.825005744815353 
1.640655389985868 2.7405676887084973 57.13037317804308 0.8183288420030569 
1.666863799493405 2.7934417004390206 57.889961766302264 0.811053315363412 
1.6860329027645113 2.832020899773324 58.480064674753805 0.8046715969850857 
1.7057711071786248 2.8779622775746927 59.15186706601844 0.7956895596246547 
1.7263553957548878 2.922205021285073 59.58411669058683 0.7888372112623938 
1.7451210189770374 2.9597136397713526 60.285888644007215 0.7820654874656572 
1.7716582664834957 3.0092561422036535 61.00476611752514 0.7742641967037576 
1.6460563609294283 2.7567563583245533 57.82534388394682 0.7742641967037576 
epoch: 77, train time every whole data:452.18s
epoch: 77, total time:40727.26s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.77s
test time on whole data:61.13s
1.5069947215950206 2.4518137770017567 55.878717387285214 0.8490635510810061 
1.5362470687544416 2.5195411961465903 55.83022741969052 0.8416858852792902 
1.5642960186370072 2.5869499016653474 55.912011439713105 0.8344141148684713 
1.5878972555926691 2.634544793179485 56.26403842336275 0.8296584072204408 
1.6136615362798883 2.6849335496253928 56.583441270430704 0.8250125914289707 
1.6403966961244032 2.73965476601125 57.140629233279874 0.8183413615391373 
1.6666884716187738 2.7927780299729594 57.89908743896104 0.8110631989948002 
1.6860532018547612 2.8318809852711997 58.48965233585982 0.8046397956491631 
1.7059693689631918 2.8782597000485954 59.16001668772067 0.7956387549334575 
1.7267037629137436 2.9230200294201825 59.59228308452972 0.7887243029842587 
1.7455941976103044 2.9607881687778304 60.296821308102764 0.7819349569312564 
1.7722870498045924 3.0107007598722944 61.02160480633741 0.7740701856759785 
1.6460657791457332 2.756588483050337 57.839140868174646 0.7740701856759785 
epoch: 78, train time every whole data:453.03s
epoch: 78, total time:41252.20s
predicting testing set batch 1 / 168, time: 0.37s
predicting testing set batch 101 / 168, time: 36.82s
test time on whole data:61.22s
1.507147014515031 2.4531192173910354 55.85393987400107 0.8490592623813957 
1.5365396467458812 2.5210503920016025 55.81331125846173 0.8416761691959619 
1.56470954467915 2.588405404361145 55.90400256846202 0.8344270532271962 
1.5883655434702302 2.6359930791085415 56.264660736660545 0.8296851225242264 
1.614259328439743 2.6865189200771447 56.59162261722561 0.8250280230193382 
1.6409225061060417 2.741177010173895 57.153190583477 0.8183601128729107 
1.6672008489627568 2.7940240527232043 57.916602801129855 0.8111086869632048 
1.6865434479280597 2.8329837846675807 58.5117023866744 0.8046888795673118 
1.7063845431065807 2.879038302479817 59.18608284278966 0.7957219538534178 
1.7270140406498242 2.923360508086719 59.62261056217572 0.7888754259049896 
1.7458271840738044 2.9608395556689113 60.329983113439546 0.782118811130365 
1.772454180846523 3.0104910574809582 61.05949920458274 0.7742948635805745 
1.6464473191269688 2.7575671547213463 57.85069848884186 0.7742948635805745 
epoch: 79, train time every whole data:452.75s
epoch: 79, total time:41776.83s
predicting testing set batch 1 / 168, time: 0.36s
predicting testing set batch 101 / 168, time: 36.83s
test time on whole data:61.26s
1.5071441325846882 2.4531516776946165 55.843982143816426 0.8490741562780296 
1.5365727204682216 2.521191650507546 55.810882336994915 0.8416807763720289 
1.5647330023091108 2.588610392516634 55.907703924090654 0.8344191230933561 
1.5884468127434097 2.636343806088954 56.27070674512152 0.8296481460981866 
1.6144157274312207 2.6869564449538696 56.59635274473332 0.824986686506246 
1.6411945240138364 2.741859146069476 57.15699463102527 0.8182911907396948 
1.6675790902485272 2.795121606623291 57.91685927546416 0.8109882107592539 
1.6869678875089933 2.834057718304927 58.50629861624844 0.8045858772064549 
1.7067295168552192 2.8800111273682054 59.17326069194226 0.7956289317494265 
1.7273426809204475 2.924403321358012 59.602625143636686 0.7887775798747411 
1.7461204645721509 2.9617818391605666 60.306653630396525 0.7820264284029607 
1.7727410249695004 3.011337220421787 61.032568838551796 0.7742130795208392 
1.6466656320521105 2.75823901820508 57.84383813399756 0.7742130795208392 
