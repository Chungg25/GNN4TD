total training epoch, fine tune epoch: 30 , 40
batch_size: 4
folder_dir: MAE_ASTGNN_h1d0w0_layer2_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention1_spt_trend_32
load file: data/bike.npz
ori length: 3001 , percent: 1.0 , scale: 3001
train: torch.Size([3001, 250, 2, 12]) torch.Size([3001, 250, 2, 12]) torch.Size([3001, 250, 2, 12])
val: torch.Size([672, 250, 2, 12]) torch.Size([672, 250, 2, 12]) torch.Size([672, 250, 2, 12])
test: torch.Size([672, 250, 2, 12]) torch.Size([672, 250, 2, 12]) torch.Size([672, 250, 2, 12])
TemporalPositionalEncoding max_len: 12
h_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
en_lookup_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
EncoderDecoder(
  (encoder): Encoder(
    (layers): ModuleList(
      (0): EncoderLayer(
        (self_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (2): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (3): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (feed_forward_gcn): ModuleList(
          (0): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn_cross): spatialAttentionScaledGCN_cross(
          (Theta): Linear(in_features=64, out_features=64, bias=False)
          (SAt_cross): Spatial_Attention_layer_cross(
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (Gate): Linear(in_features=64, out_features=1, bias=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (6): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (7): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (sublayer2): SublayerConnection2(
          (dropout): Dropout(p=0.0, inplace=False)
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): EncoderLayer(
        (self_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (2): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (3): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (feed_forward_gcn): ModuleList(
          (0): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn_cross): spatialAttentionScaledGCN_cross(
          (Theta): Linear(in_features=64, out_features=64, bias=False)
          (SAt_cross): Spatial_Attention_layer_cross(
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (Gate): Linear(in_features=64, out_features=1, bias=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (6): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (7): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (sublayer2): SublayerConnection2(
          (dropout): Dropout(p=0.0, inplace=False)
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): Decoder(
    (layers): ModuleList(
      (0): DecoderLayer(
        (self_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_qc_kc(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_qc_kc(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (src_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (2): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (3): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (feed_forward_gcn): ModuleList(
          (0): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn_cross): spatialAttentionScaledGCN_cross(
          (Theta): Linear(in_features=64, out_features=64, bias=False)
          (SAt_cross): Spatial_Attention_layer_cross(
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (Gate): Linear(in_features=64, out_features=1, bias=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (6): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (7): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (8): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (9): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (sublayer2): SublayerConnection2(
          (dropout): Dropout(p=0.0, inplace=False)
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): DecoderLayer(
        (self_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_qc_kc(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_qc_kc(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (conv1Ds_aware_temporal_context): ModuleList(
              (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
              (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (src_attn): ModuleList(
          (0): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (1): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (2): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (3): MultiHeadAttentionAwareTemporalContex_qc_k1d(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=64, bias=True)
              (1): Linear(in_features=64, out_features=64, bias=True)
            )
            (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (feed_forward_gcn): ModuleList(
          (0): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn_cross): spatialAttentionScaledGCN_cross(
          (Theta): Linear(in_features=64, out_features=64, bias=False)
          (SAt_cross): Spatial_Attention_layer_cross(
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (Gate): Linear(in_features=64, out_features=1, bias=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (6): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (7): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (8): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (9): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (sublayer2): SublayerConnection2(
          (dropout): Dropout(p=0.0, inplace=False)
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (src_embed): Sequential(
    (0): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (1): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(250, 64)
    )
  )
  (src_embed2): Sequential(
    (0): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (1): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(250, 64)
    )
  )
  (trg_embed): Sequential(
    (0): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (1): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(250, 64)
    )
  )
  (trg_embed2): Sequential(
    (0): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (1): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(250, 64)
    )
  )
  (prediction_generator): Linear(in_features=64, out_features=1, bias=True)
  (prediction_generator2): Linear(in_features=64, out_features=1, bias=True)
)
create params directory experiments/bike/MAE_ASTGNN_h1d0w0_layer2_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention1_spt_trend_32
Net's state_dict:
encoder.layers.0.self_attn.0.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.0.linears.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.0.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.0.linears.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.1.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.1.linears.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.1.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.1.linears.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.2.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.2.linears.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.2.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.2.linears.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.2.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.2.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.2.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.2.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.3.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.3.linears.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.3.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.3.linears.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.3.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.3.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.3.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.3.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.0.feed_forward_gcn.0.Theta.weight 	 torch.Size([64, 64])
encoder.layers.0.feed_forward_gcn.1.Theta.weight 	 torch.Size([64, 64])
encoder.layers.0.feed_forward_gcn_cross.Theta.weight 	 torch.Size([64, 64])
encoder.layers.0.feed_forward_gcn_cross.Gate.weight 	 torch.Size([1, 64])
encoder.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.2.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.2.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.3.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.3.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.4.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.4.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.5.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.5.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.6.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.6.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.7.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.7.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer2.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer2.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer2.norm2.weight 	 torch.Size([64])
encoder.layers.0.sublayer2.norm2.bias 	 torch.Size([64])
encoder.layers.1.self_attn.0.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.0.linears.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.0.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.0.linears.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.1.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.1.linears.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.1.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.1.linears.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.2.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.2.linears.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.2.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.2.linears.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.2.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.2.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.2.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.2.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.3.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.3.linears.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.3.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.3.linears.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.3.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.3.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.3.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.3.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.1.feed_forward_gcn.0.Theta.weight 	 torch.Size([64, 64])
encoder.layers.1.feed_forward_gcn.1.Theta.weight 	 torch.Size([64, 64])
encoder.layers.1.feed_forward_gcn_cross.Theta.weight 	 torch.Size([64, 64])
encoder.layers.1.feed_forward_gcn_cross.Gate.weight 	 torch.Size([1, 64])
encoder.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.2.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.2.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.3.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.3.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.4.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.4.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.5.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.5.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.6.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.6.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.7.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.7.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer2.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer2.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer2.norm2.weight 	 torch.Size([64])
encoder.layers.1.sublayer2.norm2.bias 	 torch.Size([64])
encoder.norm.weight 	 torch.Size([64])
encoder.norm.bias 	 torch.Size([64])
encoder.norm2.weight 	 torch.Size([64])
encoder.norm2.bias 	 torch.Size([64])
decoder.layers.0.self_attn.0.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.0.linears.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.0.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.0.linears.1.bias 	 torch.Size([64])
decoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.self_attn.0.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.0.self_attn.1.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.1.linears.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.1.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.1.linears.1.bias 	 torch.Size([64])
decoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.self_attn.1.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.0.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.0.linears.0.bias 	 torch.Size([64])
decoder.layers.0.src_attn.0.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.0.linears.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.0.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.0.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.0.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.0.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.1.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.1.linears.0.bias 	 torch.Size([64])
decoder.layers.0.src_attn.1.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.1.linears.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.1.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.1.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.1.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.1.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.2.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.2.linears.0.bias 	 torch.Size([64])
decoder.layers.0.src_attn.2.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.2.linears.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.2.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.2.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.2.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.2.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.3.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.3.linears.0.bias 	 torch.Size([64])
decoder.layers.0.src_attn.3.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.3.linears.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.3.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.3.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.3.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.3.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.feed_forward_gcn.0.Theta.weight 	 torch.Size([64, 64])
decoder.layers.0.feed_forward_gcn.1.Theta.weight 	 torch.Size([64, 64])
decoder.layers.0.feed_forward_gcn_cross.Theta.weight 	 torch.Size([64, 64])
decoder.layers.0.feed_forward_gcn_cross.Gate.weight 	 torch.Size([1, 64])
decoder.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.3.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.3.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.4.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.4.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.5.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.5.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.6.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.6.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.7.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.7.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.8.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.8.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.9.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.9.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer2.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer2.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer2.norm2.weight 	 torch.Size([64])
decoder.layers.0.sublayer2.norm2.bias 	 torch.Size([64])
decoder.layers.1.self_attn.0.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.0.linears.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.0.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.0.linears.1.bias 	 torch.Size([64])
decoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.self_attn.0.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.1.self_attn.1.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.1.linears.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.1.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.1.linears.1.bias 	 torch.Size([64])
decoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.self_attn.1.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.0.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.0.linears.0.bias 	 torch.Size([64])
decoder.layers.1.src_attn.0.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.0.linears.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.0.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.0.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.0.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.0.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.1.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.1.linears.0.bias 	 torch.Size([64])
decoder.layers.1.src_attn.1.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.1.linears.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.1.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.1.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.1.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.1.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.2.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.2.linears.0.bias 	 torch.Size([64])
decoder.layers.1.src_attn.2.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.2.linears.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.2.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.2.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.2.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.2.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.3.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.3.linears.0.bias 	 torch.Size([64])
decoder.layers.1.src_attn.3.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.3.linears.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.3.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.3.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.3.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.3.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.feed_forward_gcn.0.Theta.weight 	 torch.Size([64, 64])
decoder.layers.1.feed_forward_gcn.1.Theta.weight 	 torch.Size([64, 64])
decoder.layers.1.feed_forward_gcn_cross.Theta.weight 	 torch.Size([64, 64])
decoder.layers.1.feed_forward_gcn_cross.Gate.weight 	 torch.Size([1, 64])
decoder.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.3.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.3.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.4.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.4.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.5.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.5.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.6.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.6.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.7.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.7.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.8.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.8.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.9.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.9.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer2.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer2.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer2.norm2.weight 	 torch.Size([64])
decoder.layers.1.sublayer2.norm2.bias 	 torch.Size([64])
decoder.norm.weight 	 torch.Size([64])
decoder.norm.bias 	 torch.Size([64])
decoder.norm2.weight 	 torch.Size([64])
decoder.norm2.bias 	 torch.Size([64])
src_embed.0.pe 	 torch.Size([1, 1, 12, 64])
src_embed.1.embedding.weight 	 torch.Size([250, 64])
src_embed2.0.pe 	 torch.Size([1, 1, 12, 64])
src_embed2.1.embedding.weight 	 torch.Size([250, 64])
trg_embed.0.pe 	 torch.Size([1, 1, 12, 64])
trg_embed.1.embedding.weight 	 torch.Size([250, 64])
trg_embed2.0.pe 	 torch.Size([1, 1, 12, 64])
trg_embed2.1.embedding.weight 	 torch.Size([250, 64])
prediction_generator.weight 	 torch.Size([1, 64])
prediction_generator.bias 	 torch.Size([1])
prediction_generator2.weight 	 torch.Size([1, 64])
prediction_generator2.bias 	 torch.Size([1])
Net's total params: 783234
Optimizer's state_dict:
state 	 {}
param_groups 	 [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279]}]
predicting testing set batch 1 / 168, time: 0.62s
predicting testing set batch 101 / 168, time: 23.40s
test time on whole data:38.67s
52.848459878324306 68.16563246713581 2147.9389620911966 -0.017478169327317 
57.26616775370558 72.64514052885912 2328.566828695537 -0.012806845086664286 
58.97088238535209 74.40714409672393 2396.886322990662 -0.009839068631750665 
58.36658273446285 73.47774938920087 2370.8664150742975 -0.007946450842102454 
56.44075335861876 70.79801592170698 2290.0570069465475 -0.006663160676612931 
55.04387715108702 68.24927725709948 2230.8189289830034 -0.0056052248403107435 
55.47174349890073 67.20767856701374 2247.195242199264 -0.004518779335501063 
56.636235629329725 67.23226395913294 2293.2770677512613 -0.0035808612968495257 
57.13339109371097 67.12742760701363 2312.8727923518622 -0.0027070273237451738 
56.68012155572973 66.35312864561777 2294.1542801901555 -0.0018954117058266923 
56.141062253127494 65.65965162496242 2272.4301005611624 -0.0009704215263891273 
56.806019769098874 66.47876709563882 2300.9277840894442 0.00015422372240563153 
56.48377475512068 69.0447261227 2290.4991144401833 0.00015422372240563153 
epoch: 0, train time every whole data:136.56s
epoch: 0, total time:188.86s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.78s
test time on whole data:39.55s
2.6633509780625326 4.603583620778936 68.44840447302578 0.6214900525595961 
2.7023175713387984 4.6704327562422785 69.77424523275901 0.5826859444574086 
2.7533696923992994 4.75216662607322 71.45040480246053 0.5396668060300555 
2.79141018016388 4.817603387939707 72.36361984162586 0.49303548068893205 
2.8351437683642087 4.889863991346651 73.47710691102212 0.44898572055482955 
2.866997149559891 4.944905855908418 73.95887878650265 0.4046923264001414 
2.9310337021334893 5.021067988647227 75.91009518094562 0.35660512951603407 
3.020221780069882 5.111372143146762 79.12584199496533 0.31344432558943697 
3.075181040086296 5.161921752711499 80.78707431198954 0.27487937981343286 
3.1151401544694033 5.193886478393018 81.87260641377132 0.24776554192607264 
3.154905792495236 5.217857800391014 83.01148156928149 0.22512303944389842 
3.173767953905587 5.207134765802677 83.02660364647606 0.19980412692051366 
2.923569980254042 4.970417591992314 76.10082084102459 0.19980412692051366 
epoch: 1, train time every whole data:137.82s
epoch: 1, total time:378.32s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.80s
test time on whole data:39.60s
2.365423913975645 3.8232453557975776 61.12256186816549 0.6423324046487469 
2.399732288378601 3.902280776136967 61.99712164695883 0.6059135121768178 
2.489917913409127 4.076672365361852 61.773915575281094 0.5549841705137003 
2.528269149764042 4.146009923600984 63.010252785376984 0.5124340402612335 
2.572040579789008 4.224723116312824 64.0816678191023 0.4629385184052617 
2.6208035623742534 4.297355203574015 65.4799686814907 0.41265395971255403 
2.6647417155742823 4.35988620209641 66.51715952081865 0.36879822452803607 
2.6995773228078725 4.416788288783569 66.81619423841093 0.33135931890720843 
2.7394896975903817 4.458504491593125 67.62499413110118 0.2983733540097696 
2.784724989344588 4.495160926051043 68.70193165362217 0.26686666595990216 
2.8303482076273787 4.524847213177568 69.70584881874356 0.23999790112997743 
2.8686678868980104 4.534789064652271 70.32461877676724 0.22387081732515685 
2.6303114356277657 4.277938736724738 65.59652918195627 0.22387081732515685 
epoch: 2, train time every whole data:138.05s
epoch: 2, total time:569.35s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.87s
test time on whole data:39.75s
2.1257742968492566 3.4328492979256877 69.71860638259116 0.6664386856496745 
2.2129661286174365 3.608189829025294 72.33291579019266 0.6187770337308738 
2.3321732716703165 3.9560470597173296 66.0213180454671 0.5449792229127077 
2.3718520888099004 4.032402577836358 66.77582800700141 0.5171182224955886 
2.435578524512283 4.117655507580453 68.62768704479836 0.48342984726483174 
2.5010886005031923 4.201398077970283 69.90392665827012 0.44984869354793994 
2.560754387506151 4.299634827155983 68.7588097272264 0.41749222816729764 
2.611578831217119 4.37499460296626 69.18617249565484 0.38904922331179537 
2.6544099975332087 4.428567938217886 69.86170027165576 0.3614893290563464 
2.7186863348869874 4.488896969202287 71.66419741033818 0.3285253438525051 
2.7821311128198922 4.539437657164309 73.29479767283225 0.29893113266587795 
2.826374472573843 4.567090084859548 73.76038684397822 0.2771183951956932 
2.5111140039582986 4.185048319260833 69.99225243598585 0.2771183951956932 
epoch: 3, train time every whole data:138.04s
epoch: 3, total time:760.45s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.71s
test time on whole data:39.51s
2.2268215403819367 3.2624891232618225 76.28122162665053 0.7201521484669 
2.3089954431443696 3.459970311031017 76.29280630828909 0.6704725830672681 
2.376091858975412 3.7070258467336075 71.25227259615234 0.6031767317463033 
2.4421712005364578 3.804815288975405 73.29142516522734 0.5676662308111179 
2.5079395674522966 3.9016365104324033 74.5083029934313 0.5320155889036031 
2.5576424989229336 3.9962398519609885 73.0383126863134 0.49840358884245906 
2.5831551108934163 4.044921461167711 71.93964628928356 0.4818529468249735 
2.5753892326928853 4.069854021961669 69.12784095051225 0.4795134172789882 
2.5706482539515765 4.1034907168114785 67.04080681380779 0.47050558941375636 
2.583619436173478 4.142927272555704 67.0522176559495 0.4504502899199232 
2.606253607628601 4.182736702685145 67.54223061338766 0.4285186967349949 
2.635863323310922 4.215512883468063 68.33369368158915 0.40940102012770674 
2.497882589505357 3.918120396403326 71.30822310357728 0.40940102012770674 
epoch: 4, train time every whole data:138.08s
epoch: 4, total time:950.59s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.93s
test time on whole data:39.66s
1.9509326338265978 3.1143576729924685 61.96932283565908 0.7428192700971598 
2.0320336320420638 3.2788500863913175 63.85112482924764 0.7078419989705655 
2.1066487331872894 3.538558855648841 61.840218883608756 0.6649592824406697 
2.1595035396354008 3.6164069684275675 63.3665781167848 0.6409601658709453 
2.2203468367783796 3.7055549713188607 64.7534811680241 0.6138165539269159 
2.2460514259650592 3.772539675619699 63.314805619123604 0.5999815099400642 
2.224651187427076 3.7823267342227447 59.80160590024164 0.6077696499704442 
2.216240802852171 3.792267537691874 57.622026763425026 0.6145980266536917 
2.2221175780844478 3.8303870194403107 55.64658190652011 0.615942853288813 
2.237861581992447 3.8755945384421775 55.959345655895845 0.6027598110527217 
2.2758321881683634 3.9364233577234207 57.07946834229824 0.5769894885817102 
2.339494455312955 4.014633159718268 59.25240063780115 0.5375714080314418 
2.1859762162726875 3.6969037449760553 60.371264758898626 0.5375714080314418 
epoch: 5, train time every whole data:138.17s
epoch: 5, total time:1141.17s
predicting testing set batch 1 / 168, time: 0.25s
predicting testing set batch 101 / 168, time: 23.67s
test time on whole data:39.46s
1.8328130984218525 2.9926099882620014 60.40665285051537 0.7627522485852662 
1.8835904246338953 3.1298814050690376 61.73055612029677 0.7372825013202576 
1.9279443703604242 3.3037375714298176 61.387797933739996 0.70619169983573 
1.9490271080376669 3.3399653329477776 61.36463281775721 0.7005268485877143 
1.9951460567804142 3.419076690405133 61.71375700656312 0.6838435977920914 
2.0212543124156515 3.47253282594588 61.80411103001195 0.6695543547449975 
2.0329805956457165 3.5042971476833427 62.05033704698574 0.6589102052780078 
2.0673141425529584 3.508518632249678 63.45178204718579 0.6507905583529432 
2.0823483647795484 3.509616957477524 63.2278262087321 0.6481311906812273 
2.105209737347705 3.5447103919830654 63.52538716581704 0.6378857924880088 
2.157215194695053 3.6338271106570703 65.45177487203219 0.6132954852763923 
2.2541040292262498 3.7804390482852748 68.92351243706261 0.5718789340493935 
2.0257456195747614 3.4343739782680123 62.91993246395023 0.5718789340493935 
epoch: 6, train time every whole data:138.22s
epoch: 6, total time:1331.52s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.80s
test time on whole data:39.61s
1.9412521276160897 2.949969513057586 64.67189780799325 0.7780504410862802 
1.9948060169137483 3.0770869586818725 65.49649930360223 0.7550967132206639 
2.0248489153960807 3.219383898154107 63.348387300431774 0.7340287708340841 
2.0421866734254928 3.2645040122993505 62.62565709906116 0.7284366367379564 
2.091420196210256 3.345805991589899 62.96205719299377 0.7129295256260946 
2.11362569093039 3.3942436289568803 62.168206658218175 0.6988024161357416 
2.11628976066313 3.4198480872442736 61.55169569022092 0.6880343985178167 
2.1196579989163826 3.4334919357469533 61.12229494600329 0.6794718424236091 
2.123273745013046 3.436297627011465 60.79557692654603 0.6762528931979545 
2.134299251846082 3.4536878034076754 60.58918303822033 0.6688727414548996 
2.1514257933492993 3.5026875541585856 60.86552288923791 0.6536290678128527 
2.2143417702323447 3.613100893997003 63.10982992323177 0.6195901740391295 
2.0889523283760285 3.3472769749589455 62.44215435436923 0.6195901740391295 
epoch: 7, train time every whole data:138.11s
epoch: 7, total time:1522.33s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.80s
test time on whole data:39.58s
1.743719520395178 2.880033884167322 59.85730573132596 0.7785141477450414 
1.807924724153376 3.009683033477074 62.126139870365 0.7551658855812101 
1.850032768630201 3.1266388833059096 61.713073387536944 0.732809188258783 
1.872986654626383 3.1731944652875197 61.27655556677669 0.7247242537311323 
1.919536943901419 3.28012740992531 59.37593908115966 0.7096662782903497 
1.9754692455789162 3.3955567323224694 58.57942045326674 0.6907604430470895 
2.010561630790521 3.468643201428217 57.85953258283495 0.6794212095200988 
2.0441307569363465 3.4911448610596705 58.51322706397506 0.6722083459315412 
2.071116041101604 3.5181010844121996 58.23047150378989 0.6650839615184745 
2.1051514655554757 3.577581156041151 58.48765645162467 0.6534812771178319 
2.1106030603220596 3.6038753044591787 58.50674503502263 0.6497424637078886 
2.144479827591706 3.670090946513714 59.716767003579896 0.6288939451947189 
1.9713093866319322 3.358323581522738 59.520165017563144 0.6288939451947189 
epoch: 8, train time every whole data:137.81s
epoch: 8, total time:1712.82s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.84s
test time on whole data:39.62s
1.7561574558299922 2.9611771693541757 56.69665867903249 0.7787826895412514 
1.8115359789092271 3.0719573582712107 58.45724148053431 0.7568830295529316 
1.862675634771142 3.1925030556466787 58.47390896417991 0.7366604346501804 
1.8931823462087307 3.2559701202023708 58.79822897508063 0.7275125772001204 
1.9385577271217924 3.3451814653270033 59.89924871208946 0.7108273097712048 
1.965287364573617 3.4034083570132383 59.687002924057865 0.7020636366533803 
1.9953507335463627 3.471807765731782 59.91263385075646 0.6911501269607484 
2.0196106077048572 3.517798915994519 59.771511955254276 0.6837101263472208 
2.0239629541283386 3.5287866948058313 59.211848336075626 0.6831298440626827 
2.036125331902433 3.5511102758582123 59.09015527091987 0.6801501773965611 
2.07224096602778 3.6199882371740872 59.12335370803605 0.6701345138168022 
2.1119848517097 3.706563846568315 59.973141821114105 0.6465486021153704 
1.957222662702831 3.3924713876727357 59.091285288928475 0.6465486021153704 
epoch: 9, train time every whole data:138.08s
epoch: 9, total time:1902.88s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 24.02s
test time on whole data:39.82s
1.8833923689654717 2.976075401660639 64.65681351826169 0.7956179805071569 
1.9476366555175433 3.0929094212410755 66.93158177386653 0.7764199068924927 
2.0371551602252183 3.2472810634688454 68.74181361444826 0.7570044035863164 
2.083483693701437 3.3152812792998345 70.01875357587669 0.7499456519187485 
2.1395228978836287 3.408534323657756 71.12808532282958 0.7373307953365833 
2.216298398784672 3.5311747719821702 72.94148390421175 0.7211262853913136 
2.278287888733315 3.644187074026433 74.07856382409797 0.706244936838671 
2.324875965558081 3.7216292104391906 74.66778328146839 0.6987641156545698 
2.354158516300842 3.7772638906773017 74.93525956393012 0.692510438830798 
2.3801092587132007 3.827415822646066 75.45924328643856 0.6863634569720675 
2.436227441810604 3.907694532378794 76.94369225960955 0.6775792362748413 
2.4612107964132335 3.9771225101658616 77.33712588792653 0.6589733729831075 
2.211863253550604 3.549429262398507 72.32024524084456 0.6589733729831075 
epoch: 10, train time every whole data:138.07s
epoch: 10, total time:2092.68s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.78s
test time on whole data:39.53s
1.765515283647215 3.0027266262029824 56.46767178303265 0.7838652590878356 
1.8667549755375477 3.217935080444071 58.24737407122104 0.7588833705939075 
1.9848994531334334 3.4642655389775463 60.057471981882045 0.7252596330046601 
2.0454613367076075 3.5872663200141344 61.060114017399435 0.7068625460937487 
2.101770537795765 3.7211975485523374 62.24577692524924 0.6751353802561191 
2.121616122630824 3.74152080767902 63.04968051889199 0.6674472036792201 
2.111463020091433 3.706282049498512 63.02734491231388 0.6725804627414609 
2.1054093519008408 3.6678025771816305 62.855250737520365 0.6801723180168531 
2.07306138495143 3.6187473439098454 61.93377078792691 0.6844685415017785 
2.057639804043053 3.598917701362035 61.805744830420096 0.682286094567571 
2.0783993650142634 3.6393859331427696 62.40673465781777 0.6746954068928925 
2.101875428987401 3.695549039765469 62.87313856596079 0.6617996834775736 
2.034488838703401 3.5616760323158574 61.33594320484404 0.6617996834775736 
epoch: 11, train time every whole data:137.42s
epoch: 11, total time:2282.64s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.59s
test time on whole data:39.22s
1.6738314353278172 2.720630426274889 56.83771070029277 0.8080104190571655 
1.71256718352029 2.8227441860284146 58.11193952370539 0.7924095237669193 
1.7475455159952953 2.9565254836780928 57.73087641584536 0.77573948612366 
1.7647544946591591 3.0295323546144837 57.4732441766609 0.7700021810908003 
1.799750016459131 3.1287382798101007 57.5330170214427 0.7579273189727 
1.8444004826973237 3.2280977027738404 58.6368596258742 0.7420273464529722 
1.9033254937908302 3.3493723757182603 59.65706027620218 0.7233938541771464 
1.9567942886910445 3.4588727518565645 60.72887742348858 0.7047025136940617 
2.0082326537220783 3.559986446413976 61.328959514236246 0.6952805951333784 
2.0675478395340696 3.6511157488419643 62.077245745737486 0.6841589842855252 
2.1123363411027407 3.746170726010202 61.989248274564645 0.6794146028156559 
2.166310912387268 3.8448479597065757 63.09746838938993 0.6544146997387866 
1.8964497214905873 3.310354192506643 59.6003204936256 0.6544146997387866 
epoch: 12, train time every whole data:137.47s
epoch: 12, total time:2471.58s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.69s
test time on whole data:39.47s
1.6756967118637016 2.8185702026546426 55.96391699581247 0.8152010249856536 
1.7237836780618168 2.912104106646004 57.271138500535756 0.801770392625396 
1.7605626700918766 2.9784574179011245 57.22068402970022 0.7936870878565344 
1.798921636591355 3.0469929158121927 57.84094057817768 0.7871021094837837 
1.8442070122108396 3.1558482534512713 57.95623745924365 0.7741051624205191 
1.876063824640321 3.2226873406329912 58.47522137057136 0.7646304862232555 
1.8939956821299913 3.2537192633147303 58.772557803661805 0.7642815846048069 
1.9256307430814597 3.2910611515377295 59.61891414656473 0.7643349721554015 
1.9656824437621094 3.3488939659846393 60.202037472154245 0.7640521114455932 
2.0132703389241584 3.418077608755716 61.45887053441851 0.7554645979144092 
2.0682443733070754 3.5305446128036198 62.49231908239645 0.7435204525925235 
2.1209710300383824 3.63973407344923 63.6513985070427 0.7208874669239297 
1.8889191787252573 3.226888102332755 59.24379860630713 0.7208874669239297 
epoch: 13, train time every whole data:137.99s
epoch: 13, total time:2661.73s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.83s
test time on whole data:39.61s
1.6821748748739205 2.767497142695393 54.07461126274779 0.8181056207544725 
1.7226296872846072 2.839570618617173 55.247137278462986 0.805362540210757 
1.755729677805677 2.921574926390995 55.33575498251051 0.7971429153765398 
1.7854777400138833 2.9835054671946875 56.02937236355615 0.7860018161495276 
1.806960995556964 3.064893818772419 55.871938254822915 0.775282334128854 
1.836406637406775 3.1533097817379914 55.75321775662947 0.7642733395291602 
1.8545841555678773 3.2140123220917007 56.03675639594735 0.756672388215468 
1.8690972769849357 3.247135243041185 56.83707162922922 0.7510323373630551 
1.8760937653161762 3.2483983389312683 57.5748461672315 0.7515228051430309 
1.896357128135594 3.266156438724224 59.05348031405907 0.7454309923310896 
1.9337491974131693 3.3424940748258436 60.12114541200215 0.7359935131216334 
1.9841748891901225 3.4542298373796188 60.91977306902482 0.7156691558841001 
1.8336196687958084 3.1317413408202337 56.904684907238135 0.7156691558841001 
epoch: 14, train time every whole data:137.78s
epoch: 14, total time:2852.29s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.75s
test time on whole data:39.65s
1.721817490245881 2.8124102330096674 58.223430577958766 0.8144498582038747 
1.8046384093109518 2.986356575953588 59.6359844941457 0.7954869299113917 
1.8748804684182896 3.1322651932779 60.015228802316976 0.7817573389375994 
1.9370356527513692 3.2610421826274347 60.83265148196087 0.7663623596381347 
2.0160279036070263 3.446399917790497 62.05996692662069 0.7355657295757104 
2.0788188130552214 3.5944449530698384 62.60858004184273 0.7075245395552963 
2.1252643001257843 3.6840034006026254 63.15741579062559 0.6933030214679351 
2.1643089310764556 3.7234903164066355 64.2282029478299 0.6950022139822175 
2.197355918188535 3.763890894668426 64.3661517441185 0.6982890454449067 
2.2290066596513527 3.801993397729304 64.8182920408555 0.6987518395473007 
2.2846922655036406 3.887716891568997 66.14094797667393 0.699732027024752 
2.3197212764440724 3.963092529157617 66.40621473087273 0.6870537839124926 
2.062797340698215 3.523136621776073 62.70790279452638 0.6870537839124926 
epoch: 15, train time every whole data:137.94s
epoch: 15, total time:3043.95s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.83s
test time on whole data:39.61s
1.6528212296121887 2.7343872327691416 53.96243067629415 0.8196909589493121 
1.702998861571419 2.857718396689449 55.11747844519039 0.8042811828339861 
1.7339281700314688 2.923879566239619 56.16152695541764 0.7945868355960024 
1.7399981087731817 2.917417997747148 57.03142123322154 0.789465528058188 
1.7478751055844837 2.9305934439933914 58.28173738083474 0.7818007641542798 
1.7636633615482245 2.9760953479283474 58.716703824675456 0.7744372549447927 
1.7773614014100638 3.0015647812824318 59.101776791954386 0.7717673309330048 
1.7894535753549565 3.0320219254273595 58.799608863474404 0.7711042824575274 
1.822322291097382 3.110508514879458 58.24260912159672 0.7640105610173958 
1.8500122436330255 3.169742499702722 58.70386526396489 0.7536689150694131 
1.9034760377910875 3.285145619058114 58.79059597669421 0.7381697548831816 
1.950763845091863 3.3925343820397074 58.84118135002501 0.7229059653992885 
1.7862228526249455 3.03281908212342 57.64600294373958 0.7229059653992885 
epoch: 16, train time every whole data:137.94s
epoch: 16, total time:3235.15s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.74s
test time on whole data:39.58s
1.6952811752905448 2.829725848300776 55.69721004154612 0.8266573935684168 
1.729252219374868 2.8846767938831905 57.28794954673682 0.8124773224331373 
1.7615634754206986 2.955424945540145 58.46516219779738 0.7984418367226997 
1.77770005289137 2.9916275677006285 59.65374362917822 0.7856238359049004 
1.8032626165394627 3.0279417516806153 61.90280188557436 0.771765701988875 
1.8615655134606752 3.1396392428777538 63.31762612457668 0.7508838536130791 
1.9022523205103796 3.232622806265723 63.89572013792072 0.7385193643354101 
1.9346887018438428 3.3077071246755607 64.06544436195334 0.7313842333863914 
1.96464567627403 3.3737829756714772 63.44959875954657 0.7316584237863066 
1.9994773051182606 3.430899188619726 63.59760131996024 0.7269334551604253 
2.034205569015106 3.5017267072215508 63.81269144054378 0.7198799234317134 
2.0644160900753703 3.5819730276742963 63.84330916811184 0.7088838147880505 
1.877359226317884 3.197339058549594 61.58257644024287 0.7088838147880505 
epoch: 17, train time every whole data:138.00s
epoch: 17, total time:3425.50s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.83s
test time on whole data:39.61s
1.637381049248789 2.5614342527075014 55.78494599566988 0.8310154005615527 
1.6867787970347063 2.6770195863210513 56.477113786665356 0.8155786315746324 
1.7216047912800596 2.7890017630346304 55.851620074689144 0.8026954216246199 
1.767672268636436 2.8903386481572766 56.216220894401616 0.7888665929792241 
1.79548269479775 2.991258002915114 55.41536060858454 0.7810297518537839 
1.8361509450466504 3.1022167292663343 55.36604169282501 0.7678262376647035 
1.8536648005733178 3.146139491962025 55.31101256051342 0.7647494038725472 
1.8624633543044329 3.167406456706115 55.646558448573536 0.7627666542760788 
1.8639430195249262 3.1730067550986867 55.22951092486215 0.7642490631117682 
1.8713089445785929 3.1742802197300173 55.84343326672382 0.7590002221161809 
1.8909008188220184 3.220103400848402 55.9297091994752 0.754316329728752 
1.949463138222162 3.3532613514961156 56.63159073243603 0.7304644618349889 
1.8114012185058201 3.029293818378662 55.8085847495989 0.7304644618349889 
epoch: 18, train time every whole data:138.12s
epoch: 18, total time:3616.82s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.80s
test time on whole data:39.55s
1.6065555412520078 2.5673485630556168 55.05858986987743 0.8298329989658519 
1.6469307552594692 2.640037203884521 56.272942522473635 0.818811452249148 
1.6816572824923233 2.7322965453122365 55.6215842086891 0.807573861175333 
1.7074926503678518 2.790208801101896 55.2818586215852 0.8005828556369043 
1.7374896138700702 2.8501974056740336 54.98629046523924 0.7950349669212338 
1.761725433629982 2.9079570163927904 54.19820240667872 0.7923351708565696 
1.7850328353798637 2.964365203038931 53.800747066436436 0.7882390714120544 
1.8103746196235575 3.029376431415033 54.00779263741951 0.7843166389076074 
1.8387442967971521 3.0917797806285883 54.00491703343593 0.7820542165912383 
1.8622416137150002 3.1532657617751765 54.9655745744033 0.7734397402194222 
1.8863821246538843 3.1952737314603143 55.3159463015585 0.7666800367011046 
1.9296698269434274 3.299668075702999 55.9781143483588 0.7472533209321724 
1.7711913828320491 2.9432971496428815 54.95768915656342 0.7472533209321724 
epoch: 19, train time every whole data:137.88s
epoch: 19, total time:3807.49s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.77s
test time on whole data:39.55s
1.6930127197772797 2.6441181653864816 54.057442118341584 0.8278324278771118 
1.7324078566808077 2.7362191270896226 55.30063453711862 0.8138328609266623 
1.768166470974595 2.8446508128663823 55.41190746977094 0.8026483495708632 
1.8005108320337853 2.921345358424916 55.595181387269356 0.794345856040433 
1.8256224986077065 2.9860044701556174 55.77248350406049 0.7855861970772591 
1.847385218552092 3.034999616491904 55.96562567889082 0.7768668229841794 
1.8557750954535746 3.0336774723061355 56.60578711037685 0.7728331012883218 
1.8641568477666448 3.046433528863741 56.95337361764623 0.7683039610405152 
1.8774438535872668 3.065177273013874 57.20232186756268 0.7639016043982362 
1.8933953158120136 3.1027176939659564 58.01764841819951 0.7531004277492394 
1.9236639152393633 3.1627814355449173 58.91438547051617 0.7386952835160522 
1.9663084567899682 3.263799261668185 59.35110658624102 0.7196522806664488 
1.8373207567729248 2.991567250719259 56.5957358458109 0.7196522806664488 
epoch: 20, train time every whole data:137.75s
epoch: 20, total time:3999.25s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.80s
test time on whole data:39.56s
1.6412201092362937 2.554127737347085 59.83425064010509 0.8300899661240069 
1.6694551890864082 2.6346178356337075 59.79954248530932 0.8186471654530845 
1.7009221924044902 2.72169742452515 58.5925214468697 0.8091084088449668 
1.7298075888831879 2.785946027337247 58.02200514438699 0.8050502392898953 
1.772578369179918 2.8914644836851915 57.81339930151288 0.7947235269615475 
1.8308837463822925 3.0250596752562626 57.90870802768164 0.7766988480584804 
1.892276118917657 3.178027315688389 57.840607885620166 0.7557351446050138 
1.9383251483662143 3.2809430304997376 58.214657764700874 0.7393116125417758 
1.9624362654445604 3.3351505134237245 58.25115940727487 0.7311553624643454 
1.9599340399208345 3.305704714949041 58.003517710660745 0.7364256264125344 
1.9592823794695238 3.2947840446670567 58.36067511888147 0.7366241385857476 
1.9798631372975983 3.3535974611110557 58.794289659532616 0.7236966523084071 
1.8364153570490815 3.0436140785002443 58.45292042703456 0.7236966523084071 
epoch: 21, train time every whole data:137.41s
epoch: 21, total time:4192.12s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.64s
test time on whole data:39.31s
1.6250072464154413 2.611338619725951 55.5635732424148 0.829966050949892 
1.671317678516642 2.748813133895574 55.227518194619854 0.814462431448798 
1.7165591342553852 2.844148932180003 55.21149075900821 0.8038206148041553 
1.7354750396041643 2.8671457318516507 55.27811120904909 0.80536275200473 
1.7651237720295432 2.916737712608552 55.96281941131296 0.7988414148483567 
1.7761647134399308 2.917140272500761 56.58235383558108 0.7951603817928194 
1.7838102601292056 2.9226817590843073 56.945484997756864 0.7894625020495609 
1.7949746766361807 2.9408608409495582 57.78730678646683 0.7825296054789573 
1.8324256333148197 3.0158665253945958 58.480268268053784 0.7712181430202685 
1.870898514739016 3.1129648550830464 58.74768418711626 0.7576811349086777 
1.9006937154011712 3.200057287247409 58.78214822616917 0.747107752087637 
1.945397575962579 3.310448601638423 59.14321231928968 0.7309893783707669 
1.7848206633703398 2.956320995005041 56.97608302884763 0.7309893783707669 
epoch: 22, train time every whole data:136.93s
epoch: 22, total time:4384.43s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.64s
test time on whole data:39.31s
1.577248607187931 2.5862705575272953 56.28879311959072 0.8340929176482806 
1.6218547401216237 2.6985163000601813 57.52948422061481 0.8176648708955329 
1.6499226875395647 2.753313415486837 57.96217808558184 0.8098387100495849 
1.6602184005031095 2.7727402730651085 58.87546774162901 0.8059146622104443 
1.6755891187790604 2.7859846126538224 60.05441909453655 0.8023109573272237 
1.6947485416504067 2.8115618021465143 60.754042475804916 0.79814127431711 
1.7081041679290079 2.827846719118065 61.21543403779683 0.7964912301167454 
1.725318442387063 2.8599688782249046 61.461928314694184 0.7920880643869994 
1.7450870381292134 2.9013758682559097 61.36754416568023 0.7864762531165164 
1.7755814498522806 2.944775243560277 62.1333703910974 0.7789205142592001 
1.800653610475184 2.9883528014464225 62.748921399532165 0.7717726742123664 
1.8306914988845764 3.065692050100329 62.790706061673376 0.7598746405737467 
1.7054181919532518 2.8357941489204768 60.26531266152975 0.7598746405737467 
epoch: 23, train time every whole data:137.05s
epoch: 23, total time:4576.55s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.55s
test time on whole data:39.26s
1.6248757335132964 2.6354626010958713 55.63272436472947 0.8349780291837696 
1.6610461739205888 2.7194192558075008 56.644505676223254 0.82261724016669 
1.6992886642371083 2.796464711375202 57.25548228460683 0.8135178184989379 
1.7390698615552946 2.868867717661238 58.054133878435366 0.8065104167370761 
1.7907267309538133 2.962658256736338 58.97562530863948 0.7971337742932866 
1.8454732277724182 3.0781634558840465 59.57810986532359 0.7847832073327491 
1.8902016731729465 3.1639512653100113 60.35955134146279 0.7774851006412113 
1.9198455806910282 3.2076724936956102 60.96374658471496 0.7743477613698878 
1.9447990049911397 3.248177697545833 61.16099085742142 0.7686824737677591 
1.955022730297276 3.2772456899810365 61.43324527208007 0.7608762915512656 
1.9700931489154518 3.293315462520879 61.94636681211158 0.7567198076277404 
1.994342517940771 3.349445502195009 62.4651658811479 0.7471190678645847 
1.8362320873300944 3.0591313485563236 59.53926557939725 0.7471190678645847 
epoch: 24, train time every whole data:137.85s
epoch: 24, total time:4765.35s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.80s
test time on whole data:39.56s
1.5780927022932363 2.52753453001535 58.69455878744212 0.8381206645969731 
1.6087277480957232 2.593649667039302 59.69429002342572 0.828793333054698 
1.6310019250606143 2.6403200346837514 59.65923303590477 0.8217539797865674 
1.6549767166422236 2.6902553152644915 60.04909677989999 0.8153531532271863 
1.682341057391926 2.7469725137242897 60.54180541048352 0.8081183449228944 
1.705238919063427 2.790607602935779 60.57292299708362 0.8037138646300372 
1.7258223060386344 2.829093291763229 60.63342298665585 0.7996751194679588 
1.7474410758962233 2.874587590452541 60.71519509477985 0.7936370132475808 
1.7646819309751016 2.919775501036926 60.43180925617022 0.7878977826092195 
1.7785763892186361 2.9693388258202233 59.924755404524724 0.7804482408379281 
1.7967883711090045 3.0060986497643576 59.921428171895855 0.7782856823730705 
1.8268269697364774 3.073894372030309 60.202431841105295 0.7698854686527516 
1.708376342626769 2.809983720853067 60.08677001073115 0.7698854686527516 
epoch: 25, train time every whole data:138.17s
epoch: 25, total time:4955.87s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.79s
test time on whole data:39.60s
1.7723914541990629 2.7880235944879623 59.721008180965605 0.8327808618798442 
1.8113794808514594 2.8783849622138042 60.34124594065865 0.8200093406389481 
1.8504001223507027 2.9546495466226905 60.33148529663642 0.8146627095706682 
1.8838464157026085 3.0248093420321913 60.45005102104158 0.8119334315594281 
1.9131532821287178 3.091733778996324 60.58993900934284 0.806653034283288 
1.9327370674522328 3.1355689268166995 60.84729854370663 0.8024516922127657 
1.9534285058241692 3.1799027370763926 61.328069713718804 0.7966733888546121 
1.971883658482294 3.2173128431300753 61.90897793785546 0.7900375000055053 
1.997634869922662 3.284624199182002 62.51524538077477 0.7772240771046106 
2.033769151969325 3.364441007975304 63.518369313777214 0.7652542296638102 
2.070165201037856 3.4334345134884257 64.31672761622724 0.7553051192168773 
2.10138647318046 3.5078725404703337 64.81380899357843 0.7419706168561568 
1.9410146402584625 3.162184851234997 61.723599681697415 0.7419706168561568 
epoch: 26, train time every whole data:138.11s
epoch: 26, total time:5147.61s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.91s
test time on whole data:39.76s
1.6279185993730845 2.7389551879202187 51.070334146724065 0.8377113204546435 
1.6946864844964196 2.9011582907960176 52.1673287776269 0.8216635883967277 
1.7610757178681946 3.0426957966807704 53.00391161683514 0.8089133672491153 
1.8084551487565927 3.1314776346367896 54.08072425459741 0.7974856154315955 
1.849696509744706 3.2087413823182147 55.11753782965816 0.7810634122888035 
1.8751592448717427 3.2457082903585226 55.966659713722265 0.7679638536176264 
1.8927643612274634 3.279014478460798 56.378575672499245 0.7567523213639016 
1.9027413662355392 3.2864417616894146 56.75010971679683 0.7544669228238816 
1.9124974947059084 3.2924303950844034 57.16248919707889 0.7534805148827138 
1.9250275904592127 3.305718582196367 57.64918096340871 0.7520723917916061 
1.9397668849239569 3.330800132612384 58.20055739280452 0.7490477175433752 
1.9719520009370255 3.397178262607733 58.73649194108845 0.737995594714894 
1.8468117836333204 3.1855003103541053 55.523798954183675 0.737995594714894 
epoch: 27, train time every whole data:137.89s
epoch: 27, total time:5337.79s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.66s
test time on whole data:39.33s
1.6136293853377657 2.7017320991402682 53.226530139074214 0.8385928195022238 
1.6738270320636885 2.8460083533603058 53.736105826230144 0.8280585158918922 
1.7482136103936603 2.9966703909184615 54.40569801670807 0.81735143437249 
1.797685273312387 3.1008921149889352 55.37180302780777 0.807952921275597 
1.8482309165039943 3.2012247772108546 56.5056304273748 0.7954639259897754 
1.9012439622629789 3.3063410027519 57.47926418816224 0.7835366032131976 
1.9520611764192581 3.393409686032541 58.40900983945409 0.7801635311703075 
1.9869956111132743 3.442612180203982 59.15693857641089 0.7772068206157944 
2.001562344454229 3.44753686394752 59.68067842530178 0.7766644013309647 
2.003320057348304 3.428309393228717 60.22533690395725 0.7722429018187942 
2.005719206286151 3.4161754294482063 60.74099704156918 0.767707900403151 
2.0377976503415653 3.4916430633505233 61.30605857958299 0.7535373529527364 
1.880857185486438 3.2409086382187593 57.52050028649877 0.7535373529527364 
epoch: 28, train time every whole data:137.25s
epoch: 28, total time:5528.26s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.75s
test time on whole data:39.59s
1.5776408899173673 2.5074952084379003 58.074965509104416 0.8405485899288406 
1.6127367132627184 2.6021104127213546 58.17381321373254 0.8295307152989614 
1.6472182831557556 2.698917495089914 57.62632416834149 0.8205062796676295 
1.685309114875272 2.772128298302917 58.08019806173254 0.8148617701856594 
1.7188611083842282 2.8248597891337517 58.55472779832426 0.8106277702062572 
1.759027362046586 2.9009035181418423 59.13759193068885 0.8018010336125982 
1.7935040488213834 2.9740240452349775 59.63227376241168 0.7922019026383861 
1.8213391423037364 3.0266716210626647 60.04594577402271 0.7852265829021955 
1.8435092141358624 3.084680356023941 60.34327187517208 0.7752614468867381 
1.865601058207541 3.141109031489807 60.716237083339806 0.7627968913626596 
1.8918361968805215 3.1893605801540277 61.35499932575949 0.7546106407354634 
1.9341891916184022 3.2901137512122336 62.33558944193359 0.736614393701775 
1.7625643603007812 2.9269820093087295 59.50640409756522 0.736614393701775 
epoch: 29, train time every whole data:137.91s
epoch: 29, total time:5718.63s
fine tune the model ... 
epoch: 30, train time every whole data:290.11s
epoch: 30, total time:6008.76s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.98s
test time on whole data:39.82s
1.526152173302092 2.4974506953972684 55.28865455496918 0.8463537168155464 
1.5612062346034994 2.5841271985412453 55.68034851379241 0.8372471208926185 
1.5967939911447466 2.656747788226589 55.788131601520455 0.8305302864475996 
1.6269445512722291 2.7250573411646943 56.099740233963935 0.8255955231050375 
1.6609767399814335 2.7954115996359867 56.626826860262916 0.8182984643402014 
1.6925978651852125 2.8455452257681872 57.34334357749916 0.8122286054937813 
1.724354586553893 2.916691498737233 58.11400132977818 0.8015649000955718 
1.7525344763642976 2.9736418738164274 58.72628631246333 0.7929056054453986 
1.7773353583405593 3.0279940964942327 59.19550359272969 0.7837639632840943 
1.8002239570679763 3.0785817264120285 59.5871108089331 0.7731481904199347 
1.820657241857921 3.109917345871424 60.00639186479839 0.767669348352194 
1.8516410978329145 3.1764270045542813 60.50056740720704 0.7569727854415181 
1.6992848561255645 2.87326754643662 57.74651186535493 0.7569727854415181 
epoch: 31, train time every whole data:289.71s
epoch: 31, total time:6350.91s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.77s
test time on whole data:39.79s
1.5187507748421991 2.4747575786302876 55.96482703426401 0.8469529410003812 
1.5530153511490319 2.560156748291031 56.26037666391544 0.837811194498124 
1.588247341989584 2.635683876484661 56.10559996517874 0.8313927334577464 
1.623853883703727 2.717715129983124 56.31733901355508 0.8253990001842649 
1.6647376789339774 2.804132455215974 56.74253438952436 0.8175278862247256 
1.7064786111557235 2.8847674297072152 57.45190414255228 0.8081995205986924 
1.7413194323698324 2.961783272281279 58.13507355141317 0.7969856051262368 
1.7701390574931921 3.0225600113690505 58.635353327855825 0.787360005497898 
1.7918372674557779 3.069073490128301 58.98698413513229 0.7795339477565437 
1.8099854608438022 3.1086070508654515 59.23331253611936 0.7712211271734174 
1.8280209133118568 3.1321610648373377 59.6201001675573 0.7675091508693216 
1.8569518163376266 3.1900126231199013 60.150349695532846 0.7588842764883191 
1.7044447991321943 2.8892612543944813 57.8003962759671 0.7588842764883191 
epoch: 32, train time every whole data:304.41s
epoch: 32, total time:6707.14s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.84s
test time on whole data:39.69s
1.5198322868738323 2.486405762933954 54.96695062716823 0.8478731004184646 
1.556109529769403 2.579969246730245 55.26295410238712 0.8383131119310846 
1.5921642826117044 2.6583362461344358 55.354974157292745 0.8311880744692244 
1.6244499420707248 2.730800114586654 55.67074715986793 0.8261169248973208 
1.6574165420195177 2.797380165353055 56.099187663452696 0.8199038619330066 
1.6875788675675258 2.8481174598597807 56.76720117648158 0.8133589981173633 
1.7130844739727853 2.9041529586683965 57.34945176492406 0.804044998559967 
1.734158397424434 2.9455700626804697 57.73388036950705 0.7968495563991785 
1.750691271551308 2.9779719282480026 58.07146794282628 0.7906176144656338 
1.7689478902440696 3.0169987189793117 58.5275317181048 0.7820039969107994 
1.7862054586031784 3.040475136286961 59.046410475413424 0.7772091960186491 
1.8158611635778632 3.096400610079087 59.76436375771023 0.7681910069780316 
1.6838750088571954 2.8462381008354334 57.05134740611884 0.7681910069780316 
epoch: 33, train time every whole data:290.13s
epoch: 33, total time:7050.03s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.72s
test time on whole data:39.57s
1.5190687898604998 2.4812536407379198 55.537126717135564 0.8476855572103225 
1.550279521182002 2.5580230645617457 55.949600600002924 0.8388881285492188 
1.5818225836499284 2.6243201618402425 55.948318262981836 0.832451580780248 
1.6078205930823017 2.6854197547216705 56.10063834767982 0.8279194989143134 
1.6372504403124608 2.7459326704292955 56.445317639447666 0.8217514816698188 
1.6659927072106373 2.796368196701829 57.09140507221002 0.8156318713786553 
1.694813574277574 2.8581855073081637 57.759527862744186 0.8070696082143654 
1.721012981307205 2.9133311377693287 58.15307445970471 0.7996284048056579 
1.7452023272393715 2.966781261748618 58.45116709388264 0.7919478877523748 
1.7712617528327697 3.021918498651986 58.833047946854236 0.7829575369853645 
1.7919674083940862 3.055804418935784 59.14793752074438 0.7779844399119265 
1.8228879881657305 3.115394011188839 59.69306968192842 0.7698379065221287 
1.6757817222928806 2.8253699491280684 57.42593130446153 0.7698379065221287 
epoch: 34, train time every whole data:289.86s
epoch: 34, total time:7391.35s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.79s
test time on whole data:39.58s
1.515964467141245 2.4664285674272226 55.9601755964978 0.8474231489571927 
1.549990165693508 2.5579051157926207 55.99511410323843 0.8378104225993449 
1.5847390274435638 2.634377708834673 55.745570325481076 0.8313490101260942 
1.6174001615515776 2.7102941777095735 55.823353417031896 0.8263882773949915 
1.6546602998163018 2.788443623707021 56.09277547820397 0.8193989408724638 
1.6882414693080243 2.8507520323786353 56.67430870583341 0.8123520358617852 
1.715405720080382 2.907678547166826 57.31898351191048 0.8033789368170197 
1.736685838560618 2.9505449978090614 57.767669966433886 0.7957857621999133 
1.7552927358648962 2.988196897127825 58.185053133443176 0.7885361256700653 
1.775026944671447 3.0292646077708647 58.64561975548964 0.7798145807259922 
1.7971400770819081 3.0667104695102188 59.123148781127114 0.7739828854785457 
1.831381037720967 3.1383960245858753 59.78994288820555 0.7635613003923672 
1.6851606620778699 2.848015561805589 57.260215111235055 0.7635613003923672 
epoch: 35, train time every whole data:290.05s
epoch: 35, total time:7731.20s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.80s
test time on whole data:39.62s
1.513415703390858 2.4591238348946183 56.34558772231679 0.8476576049921292 
1.545487164184185 2.5405632512071605 56.74116274837174 0.8382610552863272 
1.5754091990595418 2.6063326104641558 56.76816190020183 0.8313558222867712 
1.6016983746108377 2.66743792288211 56.875799563741005 0.8262625571964102 
1.6339525446835905 2.7319692351381386 57.16019166854151 0.8197280207854077 
1.6673998589395944 2.797189849165496 57.741993009235614 0.8124384533593774 
1.6982272153371678 2.8667653437557696 58.31432465641859 0.8030465518339704 
1.7243240626535068 2.9215878732229754 58.7030061291607 0.7954280603063766 
1.7470821325586487 2.971583076863444 59.06067934325797 0.7872737350358807 
1.7695844511401262 3.018798695928744 59.539041201082085 0.7781770248538684 
1.7877833823419753 3.048946437519414 59.971892725454566 0.7722307861554703 
1.8170645768010014 3.1076979054522935 60.59355809354692 0.762387721519391 
1.6734523888084194 2.818823702781078 58.15135891148814 0.762387721519391 
epoch: 36, train time every whole data:289.64s
epoch: 36, total time:8074.25s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.86s
test time on whole data:39.60s
1.5169333421100994 2.479774772717079 55.19411339160754 0.8479751766148754 
1.5514012698614525 2.568749284236117 55.67970236522728 0.8379127086835773 
1.5858868834306263 2.6406483019168494 55.88335466393903 0.8309794061378016 
1.6144846911871185 2.704603755496047 56.15448007394096 0.825816456986453 
1.6482169326726526 2.769193820435296 56.60054608294042 0.8190875383584886 
1.6812538150159553 2.8340467817664776 57.254510076050344 0.811392631263615 
1.7135130588327134 2.9040342677887883 57.849119515432776 0.8016431382062071 
1.7402053707683725 2.959540292472678 58.22548295951319 0.7938105357414618 
1.7614130560647518 3.0042130382047123 58.60135139853566 0.7863307071774052 
1.7834797486852678 3.045792148553148 59.156315429381515 0.7781472749139186 
1.8036943649235404 3.076389468457815 59.70135291123966 0.7727824459140973 
1.8344613686048736 3.1358651161702036 60.37815702834358 0.7638343317920248 
1.6862453251797853 2.850850429616348 57.55663251758419 0.7638343317920248 
epoch: 37, train time every whole data:289.11s
epoch: 37, total time:8416.01s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.68s
test time on whole data:39.34s
1.5149352769485365 2.45809987470469 56.25326271941664 0.8488382369613562 
1.549052685950927 2.540250495016463 56.62902260381458 0.8397554670832176 
1.5847923160659239 2.618352686847287 56.70429433471753 0.8322917820199904 
1.6186214181247744 2.695031647266421 56.97147786677262 0.8260635489349917 
1.6570488260387488 2.769095808868403 57.47324787228643 0.8186896600911268 
1.6916421852825831 2.83543715730583 58.20487951474658 0.8106243294016576 
1.7225835871762996 2.9033264658051374 58.877503468382585 0.8003576758854674 
1.7476016650574193 2.9541426804198117 59.332748509808994 0.792164152284853 
1.7667613659562278 2.9967120567632484 59.73626827669809 0.7841588746788118 
1.7849421756693296 3.030648115075778 60.25320644148686 0.7765607459602923 
1.8054071359031256 3.066300820466488 60.76482847204064 0.7704512167849089 
1.8306615379397713 3.1123930187860163 61.38167955056627 0.7635063812606027 
1.6895041813428056 2.839193769548734 58.54863123575671 0.7635063812606027 
epoch: 38, train time every whole data:286.21s
epoch: 38, total time:8756.72s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.84s
test time on whole data:39.55s
1.5159746300560377 2.4810659295355872 55.369712817551374 0.8484731059620182 
1.552697015978041 2.5743395276328327 55.7138477141201 0.8387894666932638 
1.5907803428858696 2.65143359093039 56.00370699531607 0.8316663386841325 
1.6251547839704545 2.728708633454565 56.486866306974726 0.825122948971189 
1.6636149064196895 2.8039818318396645 57.17163338475303 0.8171365060245434 
1.6995694429664208 2.871373035675913 58.01813983724144 0.8087826324592342 
1.7300009259317248 2.9368601861983223 58.73099735353515 0.7986130993565677 
1.7549190476978465 2.989400257802171 59.139383295661844 0.7897711401165701 
1.7729447013482096 3.0294584182688786 59.43032978093353 0.7819659803950005 
1.787712456626374 3.055567020102039 59.75207156613873 0.7751443297804819 
1.8043966378071123 3.081951164520334 60.21060090705209 0.7696499163217813 
1.829146234253865 3.1251872331962804 60.932575049432614 0.7623839178410877 
1.6939092604951371 2.8680270260659064 58.08009621698176 0.7623839178410877 
epoch: 39, train time every whole data:286.23s
epoch: 39, total time:9098.85s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.66s
test time on whole data:39.43s
1.518584818574999 2.4853181996671743 54.84567472792141 0.8485816845690185 
1.555487757911462 2.57796503230202 55.18797442901652 0.8390184743773371 
1.5938516492891524 2.6585136234430027 55.33981969449058 0.8318622919620275 
1.6266721020310762 2.7322330077187136 55.614830670351054 0.8264442046366027 
1.663694564902268 2.805287841099112 56.115446226264744 0.8191839022684964 
1.6962788428383924 2.8671558825686545 56.8057043451758 0.8116259000523824 
1.7259118207907749 2.9284256012755616 57.448057072971956 0.801914413416728 
1.752151124595354 2.9822697185534777 57.851895286637024 0.7933033249704513 
1.774619806801102 3.0345498492167757 58.14751782700277 0.7839917904445053 
1.79489013622985 3.0747347236046836 58.47493945243223 0.7764728618397028 
1.814134957013563 3.110392969752101 58.83862574489226 0.7699476579279587 
1.8385511600431055 3.1512544818567805 59.42321819505555 0.7634428332018867 
1.696235728418425 2.874931444143058 57.00789676338055 0.7634428332018867 
epoch: 40, train time every whole data:289.77s
epoch: 40, total time:9443.77s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.82s
test time on whole data:39.58s
1.5141055015094933 2.4757385474867237 55.48288713492765 0.8480909676678813 
1.5500516031675395 2.5604272916909627 55.999180383622374 0.8386145705740392 
1.5861323745699512 2.6374302622665495 56.226471846462466 0.8308931688233973 
1.616913547554896 2.705700897300941 56.42178268456881 0.8257583321668529 
1.6543271595940348 2.7808989967036615 56.82908247274203 0.8182498012234184 
1.688180976542866 2.845819829462044 57.46514759772195 0.8108923113769083 
1.7185810658339233 2.9116631806260505 58.10443142691414 0.8013348068093287 
1.7429677591161536 2.964166482670777 58.62196935815685 0.7922880737589735 
1.7621118129277158 3.003184210966373 59.12257268270778 0.7844407278957555 
1.7791808656336119 3.0337503649712176 59.699633196151794 0.7770759729651796 
1.7973726703614175 3.068075780172428 60.24786043136362 0.7705133770189501 
1.8243632161147183 3.1186842173648706 60.87097542841391 0.762762332962755 
1.68619071274386 2.849270624125195 57.924429564193915 0.762762332962755 
epoch: 41, train time every whole data:289.74s
epoch: 41, total time:9785.25s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.86s
test time on whole data:39.58s
1.51082184608529 2.4464658307331075 56.03894641185432 0.8488541422770937 
1.543473849684 2.527463306359609 56.396156609014156 0.8394600216155371 
1.5748675869272224 2.5997778954217305 56.31566950885413 0.8322246721554436 
1.6033777146310146 2.666075821132354 56.26706795338436 0.8273571769552085 
1.6381062281412029 2.7421624438690717 56.48340130559044 0.8199117795545273 
1.6706066240912214 2.8081998367910224 57.01675470653819 0.8125801934235461 
1.7006339206443657 2.8755784595731697 57.49788043704114 0.8033311590264124 
1.7263293824866415 2.928527585022352 57.84748251999753 0.7957274817464588 
1.7477229401763705 2.9732844067970015 58.17855513282324 0.788292060124643 
1.7683046284600028 3.0112381031247617 58.64710894049833 0.7808689876946469 
1.789004652877826 3.0489540674785283 59.12767032687761 0.7741776370461131 
1.816383536421206 3.1003152961262637 59.73822715896666 0.7664086683379975 
1.6741360758855304 2.8181966547659387 57.462973417324825 0.7664086683379975 
epoch: 42, train time every whole data:289.92s
epoch: 42, total time:10127.34s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.76s
test time on whole data:39.50s
1.5098681051442844 2.4625791586339445 55.65299771629765 0.8491060475608289 
1.546047153096114 2.5524659903018616 55.98754265537881 0.8397015205121918 
1.5827576342269423 2.634307285668238 56.158811815121446 0.8319542803828306 
1.6171748318101855 2.7114249899915737 56.47714660224112 0.825695772143155 
1.6552553396479537 2.7902956382741153 56.98197843629642 0.8172125907846548 
1.6881517345146941 2.8531563100639885 57.69320688306679 0.809020914458824 
1.7147315877825022 2.9103037847251625 58.34269109100701 0.7993506068589062 
1.7350562419950786 2.9475318879473886 58.857423099845796 0.7920515038123264 
1.7511019061810027 2.9814008883194956 59.30966106819181 0.7844764790660053 
1.7676868320838326 3.01017791291274 59.977439136768155 0.7770554275189094 
1.7845053118270422 3.0387271567307903 60.62714512908737 0.7709228635282922 
1.8121806467529387 3.089151972348077 61.33541199068887 0.7625680763117673 
1.6803764437552142 2.838448623954032 58.11689135418838 0.7625680763117673 
epoch: 43, train time every whole data:289.18s
epoch: 43, total time:10468.19s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.78s
test time on whole data:39.66s
1.5215535592846572 2.4979608812410805 55.143924230966356 0.8479114073089445 
1.5590068594961473 2.5878778881902895 55.725057421930956 0.838082049696967 
1.5956723895606895 2.6631069935367466 56.096401776083646 0.8309386431087287 
1.626830764101286 2.729075046565243 56.46691095188253 0.8258204522240704 
1.6637046481668063 2.8017082039181913 57.008469529309146 0.8182063934510456 
1.6973318305497191 2.8657349897815005 57.67780121922734 0.8107999821516072 
1.7293047181136374 2.9358111996286858 58.32860983250504 0.8004218119269256 
1.7558002680490414 2.9906381534256785 58.79546545881345 0.7916435663555403 
1.7748154444747737 3.0342353857779463 59.17195352883334 0.7832647134908632 
1.7906995608309906 3.0630543744172263 59.6360915944346 0.775983096369533 
1.8089305046130681 3.094127070363678 60.18076060924897 0.7690582805047441 
1.8334094705566586 3.13683893676848 60.89453398643566 0.7613899490998578 
1.6964216681497897 2.873790864187973 57.927268380659534 0.7613899490998578 
epoch: 44, train time every whole data:289.20s
epoch: 44, total time:10810.00s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.84s
test time on whole data:39.67s
1.5079883583749512 2.4457368470242735 56.067283596178065 0.8490070660225031 
1.5416744439494574 2.5308772210297574 56.2510214659277 0.8395924106559243 
1.5745259792911155 2.6085924601005352 56.13519381444622 0.8321186072836593 
1.6049734848931076 2.6793213128063673 56.18602346932112 0.8267276431646575 
1.6402379463283079 2.751253129337299 56.49467195667703 0.8194449412100033 
1.6720058425405018 2.8093594529679233 57.07376816799072 0.8130904553499555 
1.700755850260279 2.867928713431714 57.68218157122359 0.8050255719439313 
1.7267590040641705 2.9240147443594373 58.184166000900994 0.7963693887355744 
1.7499286745529445 2.976203658080852 58.62359491434959 0.787359375705928 
1.771157624126279 3.017295264048004 59.10871249482389 0.7789052095524349 
1.7908950307359475 3.0539962785742407 59.59457524176155 0.7719315261043045 
1.8172451972290873 3.103712354044492 60.18285059436622 0.7641855965074965 
1.6748456196955124 2.821480695370953 57.63208038622959 0.7641855965074965 
epoch: 45, train time every whole data:290.13s
epoch: 45, total time:11151.33s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 24.01s
test time on whole data:39.98s
1.5116451993409898 2.468196525449671 55.39756725441294 0.8486732853992793 
1.548886519806016 2.5582273274344796 55.76441349251534 0.8389343344860054 
1.5872180392953257 2.6430347908717624 55.857731117557755 0.8310122829778819 
1.62352688961414 2.7228142090350906 56.150553538699555 0.8245167615049465 
1.6652732534953172 2.8056718047813884 56.70350157023646 0.815394261698027 
1.7003281330875166 2.8725428807565505 57.47551222865142 0.8063398032982029 
1.731129347780542 2.9403529975361007 58.20147521115848 0.7951458373504161 
1.7545287149542321 2.987677058221768 58.697796503902985 0.7870165311167038 
1.77125851172466 3.02324746392608 59.076922880657 0.7806260402635342 
1.7857579663089875 3.049157656761559 59.49666137418763 0.7747103499563517 
1.803061591843764 3.0802421297561096 60.010887431966744 0.7688670351174537 
1.8276677893307947 3.121962006023961 60.627076265296985 0.7624562368553672 
1.6925234963818572 2.8636076327326396 57.78844180339071 0.7624562368553672 
epoch: 46, train time every whole data:290.04s
epoch: 46, total time:11494.34s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.91s
test time on whole data:39.80s
1.5086169015673832 2.461721009560792 55.954388017502666 0.848733833622731 
1.544918941251756 2.548226546125642 56.34712010548164 0.8392360842802652 
1.5798436690510385 2.6259186823355027 56.54155787330435 0.8313993324149928 
1.6130923081235518 2.7001908444891316 56.78709201102271 0.8254439817592147 
1.654824832500535 2.7885083254477383 57.267810505342595 0.8162404742702143 
1.6920742413867265 2.861316545615387 57.93394260141489 0.8078993305874784 
1.7260261296372683 2.9361776408392597 58.52923052975162 0.79746787749679 
1.7531840771544016 2.993289599297251 58.91532911210765 0.788836789682511 
1.7718070858242434 3.0326449863780116 59.2035160755908 0.781815932803173 
1.7870054873546497 3.0601318499072567 59.579572906302936 0.7753275351737339 
1.8065346677595129 3.092205703572008 60.2017719723945 0.7682124805999662 
1.8342826777040249 3.141245701381704 61.01706843094756 0.7592401958682711 
1.6893509182762576 2.861735260629991 58.18995590875179 0.7592401958682711 
epoch: 47, train time every whole data:288.36s
epoch: 47, total time:11835.47s
predicting testing set batch 1 / 168, time: 0.24s
predicting testing set batch 101 / 168, time: 23.88s
test time on whole data:39.67s
1.5079853205240907 2.4468020760952203 56.53589817209528 0.8488830204500744 
1.5441462090566223 2.535961953796158 56.638922886503785 0.839607043542486 
1.5828834517555577 2.6247692672554783 56.682784458870415 0.8313974835722941 
1.6213874113643099 2.714714721158641 56.89660582501702 0.8240770894269422 
1.6662066565689941 2.807726401143967 57.34616792871373 0.8148793285758276 
1.7033706880296093 2.8761126608234195 58.03983621617458 0.8073190886010291 
1.7343035772429514 2.9412742707203128 58.697472538050086 0.7978887220538418 
1.7586084521084668 2.9905100840801415 59.18150044978718 0.7899790169468253 
1.7771242594381884 3.029979498300329 59.556635161602365 0.7826848346551892 
1.7923316186719707 3.060045700996513 59.9241768829756 0.7755693773480865 
1.8131863522631604 3.096273815414784 60.4854083903367 0.7684734039282609 
1.840269688765474 3.143535790820175 61.22198550246186 0.7606382077270849 
1.6951503071491163 2.8641463809019365 58.43403810770634 0.7606382077270849 
epoch: 48, train time every whole data:289.27s
epoch: 48, total time:12176.88s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.78s
test time on whole data:39.58s
1.5082465294516159 2.460425680340446 55.74083645585331 0.8495307957607728 
1.546388366805212 2.5510741474757825 56.16543895160163 0.8399215252596788 
1.585287221078007 2.6373309963454385 56.380269936313965 0.8315293060206682 
1.6250407980582011 2.728752068325352 56.65965837299455 0.8240511104230003 
1.673119109049617 2.8287713713846996 57.1515660218804 0.8143656255155651 
1.7165588085377324 2.914411980030352 57.87146108046053 0.8046829442226786 
1.7517744145656804 2.9957512874452408 58.5112979483853 0.7924494271516629 
1.7764146919470458 3.04559923816843 58.919888844443626 0.7839945103171025 
1.7909289392096301 3.0753523401191485 59.22117214338244 0.77753855605735 
1.800637979132345 3.087019772060605 59.611292924310234 0.7719258329395019 
1.8154090061978039 3.1091136159918413 60.302047288902415 0.7653657107566845 
1.8384645672786448 3.1448344575409006 61.20700741158927 0.7579975127439668 
1.7023558692759613 2.8904047576593292 58.14525690738761 0.7579975127439668 
epoch: 49, train time every whole data:289.43s
epoch: 49, total time:12520.05s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.77s
test time on whole data:39.55s
1.5065187697153362 2.455953459217721 55.581313496591825 0.8496489929648909 
1.5407558547797657 2.536128842118915 56.09091070523044 0.8405426930320488 
1.5741948348043397 2.610109793853523 56.359417137650816 0.832917046239964 
1.6070787824877493 2.6847391560676375 56.635557034241124 0.8264365280269222 
1.6463761073621432 2.7657790484863702 57.08456729788012 0.8180402277953628 
1.681966507621819 2.832651592390054 57.7207883416837 0.8102548288169332 
1.7141673623860059 2.901072409435919 58.3203667691389 0.8000305413708774 
1.7395109862938878 2.95143996182008 58.72974433017602 0.7918738632337495 
1.7576672720731723 2.9908531627869506 59.04644468773643 0.7845640454151591 
1.7722421477900019 3.0185776529923114 59.44923192143513 0.7782072651793496 
1.7885138322020038 3.0503215234097114 59.97544978038889 0.7715521609180546 
1.8114697000045508 3.086341158229609 60.650165231736786 0.7651563236692597 
1.6783718464600648 2.8309568311991047 57.97042028531772 0.7651563236692597 
epoch: 50, train time every whole data:289.95s
epoch: 50, total time:12862.76s
predicting testing set batch 1 / 168, time: 0.24s
predicting testing set batch 101 / 168, time: 23.86s
test time on whole data:39.65s
1.5186556100248403 2.4892777749347728 55.10899174301082 0.8490124628225694 
1.5576516213358513 2.5814842125175135 55.63419916894 0.8390327160668807 
1.5940207255809966 2.6570035406225614 55.979523712848035 0.8314610757947324 
1.6278659373152824 2.7286541325307394 56.39474928034467 0.8252799331843187 
1.6678277396479 2.8047637762444424 56.98829769961322 0.8169366371240527 
1.705675082789468 2.8769213525577095 57.717921329908926 0.8082910432044705 
1.7395892647134938 2.954530797853727 58.299388955567885 0.7973746202713339 
1.7643066996757295 3.0058795946261507 58.62196061858987 0.7900917505842616 
1.7781539788120204 3.034655358627187 58.82431986088585 0.7850255001444573 
1.7878102363149324 3.049069029928645 59.16498847307822 0.7806939446810193 
1.8021885840425356 3.0710565875578983 59.6754297225788 0.7748549839926626 
1.8244197690709538 3.1065196355037386 60.42460694103481 0.7680798173665763 
1.6973471041103336 2.870271972551535 57.73629411250276 0.7680798173665763 
epoch: 51, train time every whole data:289.84s
epoch: 51, total time:13204.75s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.75s
test time on whole data:39.45s
1.5102675244383337 2.4738669349625755 54.94204151120956 0.849335491994982 
1.5468291494557191 2.561688341155597 55.35917323849855 0.8401304677436732 
1.5833445654351797 2.640684004880499 55.66032154313256 0.8325640414954661 
1.617974276503903 2.71916730221453 56.03137659773084 0.8262438666890697 
1.6552966681971615 2.7949676752398473 56.59112108091738 0.8180552257684695 
1.6874939612384354 2.8524990334267466 57.38801187918884 0.81060341977205 
1.717030514409411 2.91333178847986 58.12624351468168 0.8009836477520316 
1.7430994713605337 2.966547076515975 58.72171083103842 0.7921843158931026 
1.7635301981724445 3.0128455261272618 59.192015900232875 0.7837096720975444 
1.7807695443444842 3.044900940793961 59.64325095301005 0.7770931313011469 
1.8011575081422926 3.0818747319719986 60.13488700961408 0.7700892359128387 
1.8278010817108055 3.1295348406834687 60.710897339634975 0.7625649855520081 
1.6862162052840586 2.856665398599083 57.708532132588076 0.7625649855520081 
epoch: 52, train time every whole data:286.55s
epoch: 52, total time:13545.76s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.59s
test time on whole data:39.27s
1.5066654878373125 2.4527016448415426 55.670928316804314 0.8496166370109303 
1.5425458695484946 2.5420854861462754 55.97676880018759 0.8404139270851086 
1.5779318199283665 2.620805032443582 56.22297409570018 0.8325462784941488 
1.61020712077866 2.691068444041319 56.47038066235768 0.8271390130486733 
1.6481774710153363 2.767647774578062 56.93344939382386 0.8192575687550299 
1.6812930760638167 2.827444960596157 57.64065309902938 0.8124476849545825 
1.7122157205514432 2.8936590320894924 58.33586439558622 0.8023223357803271 
1.7384814383028342 2.946218907435736 58.88132813916195 0.793391097574656 
1.7585911282316027 2.992266918760124 59.302779303583286 0.7845005372418526 
1.775878928436942 3.0260249225587423 59.71719191420802 0.7771513856891251 
1.793662853691993 3.0577783627963755 60.18384289016424 0.7704998981105612 
1.8169894045390012 3.098462681766814 60.7991346237715 0.7633822872308431 
1.6802200265771503 2.8336838166256464 58.01137233744972 0.7633822872308431 
epoch: 53, train time every whole data:287.77s
epoch: 53, total time:13888.18s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.86s
test time on whole data:39.73s
1.5072160430124828 2.457662240321924 55.31114308759222 0.8498246204513602 
1.5424371947674524 2.5423675437100317 55.706697355277214 0.8404969865070705 
1.576000466563251 2.616839704055611 55.84224673210487 0.8332190972288951 
1.6088697978504711 2.6898047978404915 56.03924936832598 0.8273569435048739 
1.644123527796939 2.7606046201996133 56.408102610113986 0.8202534200290484 
1.674314043458285 2.8138723300325914 57.00471060367845 0.8139764771911889 
1.7012035480673824 2.873382572624714 57.568726196022894 0.8046210054452164 
1.723073858445244 2.915977028487017 58.058755065592734 0.7970616244441028 
1.7399320299589032 2.9531963129215772 58.49663411393109 0.7892827362680847 
1.7541784294486222 2.9777755978884866 59.00763889313231 0.7831756597873698 
1.7718969293390179 3.0110875252194846 59.572631592319844 0.7765318048245767 
1.7960542739576526 3.0528092693214566 60.23994930778064 0.7699962649643445 
1.6699416785554753 2.811575916242838 57.43812803360271 0.7699962649643445 
epoch: 54, train time every whole data:289.31s
epoch: 54, total time:14231.43s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.70s
test time on whole data:39.54s
1.5137917124245848 2.4739313011296566 55.07705391032408 0.8492145928843562 
1.5508126770728046 2.5652512310454934 55.51429672731316 0.8392313970291453 
1.5862368754961838 2.641598773066848 55.78129684300998 0.8320564516455539 
1.6210835641552472 2.7172141236747622 56.083133100573015 0.8264928454171161 
1.659680009663992 2.795075953130276 56.64459639603634 0.818624656032174 
1.6902847054849068 2.846106348427103 57.40436492262981 0.8127396539114317 
1.7177928896716663 2.9052922144288633 58.097078979544726 0.8036647348739302 
1.7438205900889423 2.956337678819433 58.69143450701794 0.7954941050543959 
1.7645185405074486 3.001977181405521 59.1806845382461 0.7874094308544435 
1.782818083201136 3.0327122882594146 59.707662505489665 0.7813077901375786 
1.8007259860324363 3.063816773561184 60.26190161736125 0.7747560211612547 
1.8259081408354854 3.106341710493517 60.92587304127704 0.7676397426119124 
1.6881228145529028 2.848992742341196 57.78089074184544 0.7676397426119124 
epoch: 55, train time every whole data:289.67s
epoch: 55, total time:14574.07s
predicting testing set batch 1 / 168, time: 0.24s
predicting testing set batch 101 / 168, time: 23.83s
test time on whole data:39.56s
1.5063807603665407 2.4550371553497237 55.429250435046505 0.8495550584497735 
1.5431595049875655 2.550180963610361 55.67280189937838 0.8393665327956492 
1.577992821316013 2.6265455021504898 55.86808702051368 0.8319253517970012 
1.6116956978103234 2.703198647398501 56.145941725511626 0.8255110801671857 
1.6511234849488274 2.784671621797333 56.72741527402992 0.8164744067666677 
1.6861518163796336 2.848044293163773 57.49724033666843 0.8087642155396382 
1.7199986482399205 2.919632389757647 58.16876569096215 0.7985017650716403 
1.7491878726211865 2.976018326146451 58.6353094597197 0.7901522366160723 
1.7704520678611562 3.022536205345186 58.92654740763971 0.7822637533792287 
1.7875545620525344 3.0579699455048037 59.290276458022404 0.7756181814098557 
1.8080348575055776 3.098544079054725 59.859200409991075 0.767574162211186 
1.8357953857911662 3.1466587216129285 60.63991400803018 0.7590871392455145 
1.6872939566567038 2.857339775470081 57.738493577468816 0.7590871392455145 
epoch: 56, train time every whole data:286.67s
epoch: 56, total time:14914.59s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.88s
test time on whole data:39.62s
1.5061434741994988 2.449301829457885 56.24547926993362 0.8491257530107682 
1.5390586212282735 2.5278459551735755 56.68619745715764 0.8400522331801683 
1.572120381767285 2.601664155458429 56.78920070421907 0.8325887483784432 
1.6047579568525154 2.6788969413739605 56.92867681567101 0.8259471244497402 
1.6432072159965478 2.7588014557296825 57.31724222998389 0.8173863463891934 
1.6768418893280128 2.8205723296220016 57.92964486337908 0.809885881949088 
1.7068423798173844 2.886613052623801 58.47818662108825 0.8002685379528004 
1.731481088579233 2.9390566181960738 58.89126316837879 0.7918719502010129 
1.7491410722076184 2.9788572221516496 59.20233151303557 0.7847151095899576 
1.7653292640340292 3.0089472428604402 59.63981157877195 0.7782383243880685 
1.7850975833595508 3.0425353218954205 60.25156642710353 0.7716108472561294 
1.8117748433374579 3.091643265896665 61.01212822616373 0.7634179980005744 
1.6743163142256172 2.822736045832524 58.28105960641729 0.7634179980005744 
epoch: 57, train time every whole data:289.49s
epoch: 57, total time:15256.30s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.83s
test time on whole data:39.69s
1.5094299670071119 2.4669389597936533 55.22721926037305 0.849759321740535 
1.5461752471529124 2.55618215689071 55.51856670453088 0.8406777999822775 
1.5819435889377658 2.633556307018968 55.67591821625726 0.8334588152512813 
1.6179159623020816 2.716457366927075 55.8343930185099 0.8272040709530861 
1.6587120032883471 2.8015591396141644 56.28783295699843 0.8185714965391117 
1.6917411936792943 2.8584816736424745 56.93526447884222 0.811918803236378 
1.719522388100358 2.9161820643075287 57.540760890204034 0.8027224903781297 
1.7423916884931248 2.9580220433117104 58.00375577829515 0.7950758677648982 
1.758670379893322 2.996088267650943 58.41634531136002 0.7869355150465384 
1.7717975307121163 3.0222597524365145 58.92870150807011 0.7796274334343668 
1.788521322038823 3.049071877238588 59.69283050594897 0.7724719883635397 
1.812087071196309 3.089120546228983 60.546796848226414 0.7647389369968314 
1.6832423619001307 2.8454405313851527 57.38412450406823 0.7647389369968314 
epoch: 58, train time every whole data:289.08s
epoch: 58, total time:15600.08s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.86s
test time on whole data:39.63s
1.513092790799925 2.4796341208901773 54.79754766000969 0.8491360638298617 
1.5536393289462265 2.577818942401068 55.07720629833336 0.8397070641400163 
1.594885355905142 2.666934721044663 55.332320762169694 0.8323074685992986 
1.6353148601061354 2.758677647690123 55.73625244273435 0.8254171084268648 
1.6795129547443772 2.849423642744215 56.432990176056904 0.816016053805208 
1.7134735591929584 2.9108273145818715 57.28101081280058 0.8079258672778279 
1.7397676479031465 2.965517452226441 58.0439153872373 0.7979106121038166 
1.7598277478964024 3.004221219836337 58.668822795768094 0.7895412011645666 
1.7737405847391734 3.035631210296616 59.20143624035615 0.7814336652385865 
1.7873961884492033 3.0576065680302724 59.91239940958385 0.7742787106758943 
1.806266849372536 3.0888860837326857 60.87048344020018 0.7663200476632196 
1.8318306555667272 3.1336909349293607 61.92446664786462 0.7574780270312835 
1.699062376968496 2.8846374638694208 57.77336470116495 0.7574780270312835 
epoch: 59, train time every whole data:288.92s
epoch: 59, total time:15942.72s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.72s
test time on whole data:39.47s
1.508316428693987 2.461204037305269 55.46863912791742 0.8492767836782869 
1.5461996530867403 2.552982296355186 55.896013790794875 0.8396105476796873 
1.5849773557216285 2.639403163954602 56.168227260133705 0.8313301678407551 
1.623189103299131 2.7293359047119226 56.528623957796455 0.8233593393292401 
1.6683506770342411 2.819350576008623 57.205545424408434 0.8140973695178753 
1.7089949175766004 2.8970281807802163 58.06631470535083 0.8044932701396319 
1.7452830089314708 2.978703383029274 58.86435984005085 0.7920793509890813 
1.7744706247204116 3.0393362500839993 59.47811153131383 0.7821002244949713 
1.7927820306823898 3.0791033227066253 59.89356928823361 0.7744998297606391 
1.8048766153848597 3.0977448787088524 60.30183909585444 0.769221027493888 
1.822110945663548 3.122154560988272 60.97958462656491 0.7632260242860291 
1.846208710931064 3.163539058149279 61.85458972023593 0.7549122127157841 
1.7021466726438395 2.8907243206766733 58.39223690215969 0.7549122127157841 
epoch: 60, train time every whole data:289.36s
epoch: 60, total time:16284.98s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.94s
test time on whole data:39.75s
1.5087432487966226 2.470024525702669 55.29406449114479 0.8492396358050893 
1.5457099962309002 2.5600180152628114 55.69085948215552 0.8397105816952165 
1.5815346817783125 2.637417916952921 56.00362957168341 0.8322049745204375 
1.617060074727184 2.7198264093725593 56.31627773852328 0.8251642897801983 
1.6589569007105949 2.803405361457907 56.904218492474136 0.8168846847324336 
1.6969682984412426 2.8739039973002343 57.687047448060454 0.8088047279971883 
1.7324511149784638 2.948819012255244 58.4427053281631 0.7982155277919567 
1.7629306700696192 3.0107546587843954 59.077172167181715 0.7884239907097806 
1.7837275734189897 3.056258081246462 59.513879646154464 0.7801483474681972 
1.800839328457823 3.0883864505922394 59.95658546059824 0.7735188018418007 
1.8223935533413398 3.126901527233401 60.50680219525917 0.7660545202098288 
1.8499920088469628 3.1748256745255605 61.24612535810405 0.7576696279044782 
1.6967756208165046 2.881298909962802 58.05339272862765 0.7576696279044782 
epoch: 61, train time every whole data:289.31s
epoch: 61, total time:16626.72s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.78s
test time on whole data:39.65s
1.5052860540957855 2.4539670437529213 55.34411945345323 0.8499252118375009 
1.541851325474236 2.5434898281453413 55.64084730434353 0.8403596838541835 
1.5762142117921973 2.6156130680276752 55.87051614491851 0.8335545733717054 
1.6089346896466754 2.6878147411112594 56.102822620623705 0.8280402066054838 
1.6468680758729932 2.7652436487125382 56.582529346909574 0.8202083146064202 
1.6815309270625667 2.8301029838654035 57.2326426842908 0.8133329662507901 
1.711355771814606 2.897688006805113 57.833145714941516 0.8041886104807702 
1.7371056888515042 2.949189570802667 58.35912294927931 0.7962186194220311 
1.7565784698500342 2.997306758904832 58.76297437269855 0.7873718788725141 
1.7714376955699354 3.0261881829787503 59.191484962921116 0.7807314554885493 
1.7894328605743746 3.055886778427183 59.801036099925184 0.7741007549640533 
1.812409200235403 3.0962857845756075 60.584688628640805 0.7663421825652902 
1.6782504142366925 2.833939207700809 57.60892209907668 0.7663421825652902 
epoch: 62, train time every whole data:289.28s
epoch: 62, total time:16968.58s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.88s
test time on whole data:39.66s
1.5073818500576808 2.459607326194823 55.4828382265125 0.8499131922998947 
1.544063287915662 2.548526533952134 55.92847887637509 0.8404271999108478 
1.580595215028063 2.628075369729705 56.277778729862305 0.8327075040724811 
1.6159470015998398 2.709574708408739 56.62894870428429 0.8259433367568991 
1.6560345796770637 2.792515559946611 57.234311303052564 0.8170333828686087 
1.6902652146806496 2.856356009384059 58.008281907957446 0.8089645305761665 
1.7202162678413804 2.9205461183893138 58.67381078990977 0.7990571760032843 
1.7454093153207961 2.971163663067223 59.15722399604062 0.7903431769681232 
1.7632128291470663 3.0103266486516693 59.431787085075605 0.7831738690771115 
1.7779139485060282 3.03902478999631 59.74505675629926 0.7772694934946108 
1.7969262384184237 3.0692373523924514 60.27332835909228 0.771650872544672 
1.8210820898766673 3.1111961184383055 61.00038636859577 0.7644693191044883 
1.6849206531724434 2.850512297648105 58.15362216616343 0.7644693191044883 
epoch: 63, train time every whole data:289.55s
epoch: 63, total time:17310.66s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.83s
test time on whole data:39.60s
1.5058452112701322 2.454010967053074 55.578066206764255 0.8493207286196994 
1.5419696928892461 2.5441542162060826 55.71964770309774 0.8401693594943251 
1.5789838069292406 2.6279764780230974 55.79364427708761 0.832679227816095 
1.6152828127494347 2.7131935326268692 55.94127889971029 0.8263134580447451 
1.6574669682870486 2.7987314148741818 56.4158286831019 0.8182845320664164 
1.6943238730505108 2.869578910017101 57.114907811960734 0.8101182190043524 
1.7265777651486651 2.939297308731091 57.80227064146901 0.8002738951249958 
1.7543169879801572 2.9940279935649747 58.38870154162157 0.7916001783068765 
1.7750690982187434 3.0421772428796734 58.81548484343091 0.782986129933399 
1.7908235907035748 3.0693240321069366 59.263331568596946 0.7768933270686397 
1.8085966143488352 3.098530143988979 59.882481425020906 0.7698283268328104 
1.8322590660362372 3.1389469971364554 60.69911114465856 0.7615384192016436 
1.6901262906343189 2.865936331299866 57.617991169157804 0.7615384192016436 
epoch: 64, train time every whole data:289.18s
epoch: 64, total time:17652.71s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.80s
test time on whole data:39.68s
1.5049141290290724 2.45255117351597 55.58734029091815 0.8497364500460247 
1.5389815643168099 2.5359895720506023 55.9950981927208 0.8401395239369741 
1.5711017685924613 2.607662758026807 56.149769035221 0.8331385347605724 
1.603179505562055 2.6838573027315813 56.258038604633484 0.8271119796299944 
1.6400190607864586 2.7602835243457062 56.637801514968736 0.8195267944475938 
1.6720291120503985 2.8191395066453753 57.194409946908344 0.8131197304738337 
1.701609227963945 2.8824957425009785 57.78681578978383 0.8043076186357923 
1.7275535503979773 2.93608085910282 58.32051756863649 0.795187859404282 
1.7465583451988087 2.979968531621823 58.74923005858281 0.7863123539815001 
1.760629561727689 3.004326860073052 59.25339817692389 0.7796476019457759 
1.7773942779761163 3.0293271526517676 59.9894586733482 0.7732289884033984 
1.8022594430555723 3.0762165067627194 60.91330430475443 0.7642518753602798 
1.6705191288881136 2.8209252912328293 57.73635445887042 0.7642518753602798 
epoch: 65, train time every whole data:286.70s
epoch: 65, total time:17993.12s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.62s
test time on whole data:39.30s
1.5070619397577607 2.462200983076622 55.27181316205477 0.849478736429157 
1.545788807166829 2.5575621543007374 55.62323335542134 0.8395230779542406 
1.584132007036092 2.6416780409927796 55.81231894947935 0.8318493695494252 
1.621209667811791 2.7261490888525555 56.07358685284105 0.8250809789295478 
1.6635007253579264 2.811906521160497 56.599902834635294 0.8164616670306882 
1.6993525195219332 2.878927899784648 57.280555318594594 0.8084915084757432 
1.7304788418768773 2.9470392666495786 57.95707972085241 0.79832202610674 
1.7542943008678655 2.9927915805528955 58.50259122167573 0.7906705052350974 
1.7714642823118538 3.029997388263976 58.90821542366572 0.7837761675118053 
1.7863633005400854 3.0555923910140392 59.343116337875315 0.7781509378805624 
1.8060332705066318 3.086718110727902 59.99378356613578 0.7717088977842527 
1.832152520283081 3.1347652556804957 60.78919527948943 0.7632839242544635 
1.6918193485865607 2.8682588582771302 57.67971612582245 0.7632839242544635 
epoch: 66, train time every whole data:287.84s
epoch: 66, total time:18335.94s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.90s
test time on whole data:39.78s
1.5074116888142057 2.4611856428559924 55.46520511061777 0.849692252012624 
1.5449894403918158 2.551781593396807 55.93343167879068 0.8399494826403481 
1.5800535260962234 2.6269874673945006 56.229898163944824 0.8325228990287323 
1.6145633600931615 2.70651778599902 56.50250982651974 0.825609006406639 
1.6536694807068755 2.786983513726207 57.01963126001227 0.8170555137495824 
1.688712358471627 2.8515329188188665 57.64325950504637 0.8095189941137065 
1.7194927550691756 2.916895914797884 58.23591090856688 0.8001383102788492 
1.7458360959826302 2.9717411541633107 58.762791768346304 0.7909858643886037 
1.7657193387352108 3.0114673701076273 59.119199415798484 0.7839757472342029 
1.7824138310342317 3.0431514551627785 59.43618456823647 0.7783302221014184 
1.8008805089018174 3.0769518478304496 59.84102761281308 0.7727297957207023 
1.8244787526935162 3.1184133034913284 60.385886821309484 0.7666107725545416 
1.6856850947492077 2.8512454999572703 57.88133767642273 0.7666107725545416 
epoch: 67, train time every whole data:288.81s
epoch: 67, total time:18675.87s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.77s
test time on whole data:39.68s
1.5078390679386933 2.465300239167301 55.25562781240235 0.849473120522979 
1.5468102852408552 2.560783101166996 55.69618741150917 0.8390993780628776 
1.581945107441573 2.6339468977160863 56.093965419926526 0.8315760362506498 
1.613675851842832 2.7071510112227015 56.4406041012676 0.8247259531979653 
1.6498447479238467 2.778202123199549 57.03345163330832 0.816340584956354 
1.6805398238378444 2.831717510398084 57.74811501735705 0.8092676439509936 
1.7092909823334999 2.891962855486123 58.3427504851448 0.8003353354818048 
1.7338636997505312 2.9415255904472875 58.851138489661224 0.7924705078263043 
1.7519925608530287 2.98271226615908 59.16143184239071 0.7849267075933775 
1.7673098254711146 3.0148987100659563 59.594127137766286 0.7782407789952857 
1.7866736954196933 3.0484907454706307 60.20583313817153 0.7713982348894353 
1.8123820620297144 3.097360642494617 60.97371224610016 0.762912742933926 
1.678513975840269 2.8361922352039532 57.94984879583196 0.762912742933926 
epoch: 68, train time every whole data:288.90s
epoch: 68, total time:19019.01s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.94s
test time on whole data:39.79s
1.5111281630175986 2.471715596428344 55.30362795956007 0.8487973879320563 
1.5516654065611462 2.5711650677328626 55.570634971055846 0.8385560501849041 
1.5911944678421355 2.6570085243963097 55.79452449162518 0.8308379184675303 
1.6295496276943457 2.7441366950795745 56.05327140053541 0.8242599072889885 
1.6710656741784797 2.8270403068841805 56.62029298273315 0.8160633142064804 
1.704927229010101 2.885626511947113 57.3280482156233 0.8092938161861136 
1.7330376770995735 2.945271805359691 58.01646906715992 0.8001821683836192 
1.7549306252577475 2.988063725622419 58.61406157823481 0.7920278483089886 
1.7712468368947683 3.024595090092887 59.04670078584674 0.7843129144268539 
1.7862719057892404 3.051642517784572 59.50904885458197 0.778396296898603 
1.8055094507409348 3.087727410444784 60.06789419422899 0.7712955430487047 
1.832225605059415 3.1359756766670235 60.786268485854656 0.7634747158794636 
1.6952293890954573 2.8731733025147865 57.726006848835844 0.7634747158794636 
epoch: 69, train time every whole data:289.65s
epoch: 69, total time:19361.18s
predicting testing set batch 1 / 168, time: 0.23s
predicting testing set batch 101 / 168, time: 23.89s
test time on whole data:39.72s
1.510849897623683 2.4718184913621815 54.860880929836064 0.8488710785424451 
1.5506435672155625 2.571237847122512 55.04361858498596 0.8393096622211027 
1.5910669358406393 2.6619730698772806 55.1636593073147 0.8319878986535513 
1.630054784680495 2.7527341064897013 55.41946490380203 0.8251516466643627 
1.6701419385756766 2.8336236922814537 55.99286510288587 0.8166827458024049 
1.7016165844190512 2.8883611377040967 56.75998341702972 0.8091950093898919 
1.729381330579874 2.943532907679619 57.47437803876113 0.8001659445263156 
1.7534050481323862 2.991663047002946 58.09070948227689 0.7913569660582922 
1.7685767079001913 3.0247928754182314 58.49717718000148 0.7846684395062328 
1.7802805837275726 3.042243475267458 58.97519985001692 0.7795126450226605 
1.7978650205691478 3.069461325498915 59.68355220229057 0.7725510937946547 
1.8222193652253065 3.1135843993550396 60.571015814162756 0.7636425847101727 
1.6921751470407989 2.8707127658153344 57.21114749208911 0.7636425847101727 
