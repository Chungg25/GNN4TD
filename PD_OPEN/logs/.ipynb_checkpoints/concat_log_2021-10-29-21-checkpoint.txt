CUDA: True cuda:0
Read configuration file: configurations/bike.conf
total training epoch, fine tune epoch: 100 , 50
batch_size: 4
folder_dir: MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEconcat
load file: data/bike.npz
ori length: 3001 , percent: 1.0 , scale: 3001
train: torch.Size([3001, 250, 2, 12]) torch.Size([3001, 250, 2, 12]) torch.Size([3001, 250, 2, 12])
val: torch.Size([672, 250, 2, 12]) torch.Size([672, 250, 2, 12]) torch.Size([672, 250, 2, 12])
test: torch.Size([672, 250, 2, 12]) torch.Size([672, 250, 2, 12]) torch.Size([672, 250, 2, 12])
TemporalPositionalEncoding max_len: 12
h_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
en_lookup_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
EncoderDecoder(
  (encoder): Encoder(
    (layers): ModuleList(
      (0): EncoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
            (1): Linear(in_features=128, out_features=128, bias=True)
            (2): Linear(in_features=128, out_features=128, bias=True)
            (3): Linear(in_features=128, out_features=128, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn2): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (tcn2): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (sublayer_): SublayerConnection(
          (dropout): Dropout(p=0.0, inplace=False)
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): EncoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
            (1): Linear(in_features=128, out_features=128, bias=True)
            (2): Linear(in_features=128, out_features=128, bias=True)
            (3): Linear(in_features=128, out_features=128, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn2): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (tcn2): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (sublayer_): SublayerConnection(
          (dropout): Dropout(p=0.0, inplace=False)
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): EncoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
            (1): Linear(in_features=128, out_features=128, bias=True)
            (2): Linear(in_features=128, out_features=128, bias=True)
            (3): Linear(in_features=128, out_features=128, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn2): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (tcn2): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (sublayer_): SublayerConnection(
          (dropout): Dropout(p=0.0, inplace=False)
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): EncoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
            (1): Linear(in_features=128, out_features=128, bias=True)
            (2): Linear(in_features=128, out_features=128, bias=True)
            (3): Linear(in_features=128, out_features=128, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn2): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (tcn2): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (sublayer_): SublayerConnection(
          (dropout): Dropout(p=0.0, inplace=False)
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): Decoder(
    (layers): ModuleList(
      (0): DecoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (1): DecoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (2): DecoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (3): DecoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (decoder2): Decoder(
    (layers): ModuleList(
      (0): DecoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (1): DecoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (2): DecoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (3): DecoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (src_embed): Sequential(
    (0): Linear(in_features=1, out_features=64, bias=True)
    (1): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (2): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(250, 64)
    )
  )
  (src_embed2): Sequential(
    (0): Linear(in_features=1, out_features=64, bias=True)
    (1): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (2): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(250, 64)
    )
  )
  (trg_embed): Sequential(
    (0): Linear(in_features=1, out_features=64, bias=True)
    (1): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (2): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(250, 64)
    )
  )
  (trg_embed2): Sequential(
    (0): Linear(in_features=1, out_features=64, bias=True)
    (1): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (2): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(250, 64)
    )
  )
  (prediction_generator): Linear(in_features=64, out_features=1, bias=True)
  (prediction_generator2): Linear(in_features=64, out_features=1, bias=True)
)
delete the old one and create params directory experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEconcat
Net's state_dict:
encoder.layers.0.self_attn.linears.0.weight 	 torch.Size([128, 128])
encoder.layers.0.self_attn.linears.0.bias 	 torch.Size([128])
encoder.layers.0.self_attn.linears.1.weight 	 torch.Size([128, 128])
encoder.layers.0.self_attn.linears.1.bias 	 torch.Size([128])
encoder.layers.0.self_attn.linears.2.weight 	 torch.Size([128, 128])
encoder.layers.0.self_attn.linears.2.bias 	 torch.Size([128])
encoder.layers.0.self_attn.linears.3.weight 	 torch.Size([128, 128])
encoder.layers.0.self_attn.linears.3.bias 	 torch.Size([128])
encoder.layers.0.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.0.feed_forward_gcn2.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.0.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.tcn.filter_convs.bias 	 torch.Size([64])
encoder.layers.0.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.tcn.gate_convs.bias 	 torch.Size([64])
encoder.layers.0.tcn2.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.tcn2.filter_convs.bias 	 torch.Size([64])
encoder.layers.0.tcn2.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.tcn2.gate_convs.bias 	 torch.Size([64])
encoder.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.2.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.2.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.3.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.3.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.4.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.4.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer_.norm.weight 	 torch.Size([128])
encoder.layers.0.sublayer_.norm.bias 	 torch.Size([128])
encoder.layers.1.self_attn.linears.0.weight 	 torch.Size([128, 128])
encoder.layers.1.self_attn.linears.0.bias 	 torch.Size([128])
encoder.layers.1.self_attn.linears.1.weight 	 torch.Size([128, 128])
encoder.layers.1.self_attn.linears.1.bias 	 torch.Size([128])
encoder.layers.1.self_attn.linears.2.weight 	 torch.Size([128, 128])
encoder.layers.1.self_attn.linears.2.bias 	 torch.Size([128])
encoder.layers.1.self_attn.linears.3.weight 	 torch.Size([128, 128])
encoder.layers.1.self_attn.linears.3.bias 	 torch.Size([128])
encoder.layers.1.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.1.feed_forward_gcn2.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.1.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.tcn.filter_convs.bias 	 torch.Size([64])
encoder.layers.1.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.tcn.gate_convs.bias 	 torch.Size([64])
encoder.layers.1.tcn2.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.tcn2.filter_convs.bias 	 torch.Size([64])
encoder.layers.1.tcn2.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.tcn2.gate_convs.bias 	 torch.Size([64])
encoder.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.2.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.2.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.3.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.3.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.4.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.4.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer_.norm.weight 	 torch.Size([128])
encoder.layers.1.sublayer_.norm.bias 	 torch.Size([128])
encoder.layers.2.self_attn.linears.0.weight 	 torch.Size([128, 128])
encoder.layers.2.self_attn.linears.0.bias 	 torch.Size([128])
encoder.layers.2.self_attn.linears.1.weight 	 torch.Size([128, 128])
encoder.layers.2.self_attn.linears.1.bias 	 torch.Size([128])
encoder.layers.2.self_attn.linears.2.weight 	 torch.Size([128, 128])
encoder.layers.2.self_attn.linears.2.bias 	 torch.Size([128])
encoder.layers.2.self_attn.linears.3.weight 	 torch.Size([128, 128])
encoder.layers.2.self_attn.linears.3.bias 	 torch.Size([128])
encoder.layers.2.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.2.feed_forward_gcn2.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.2.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.tcn.filter_convs.bias 	 torch.Size([64])
encoder.layers.2.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.tcn.gate_convs.bias 	 torch.Size([64])
encoder.layers.2.tcn2.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.tcn2.filter_convs.bias 	 torch.Size([64])
encoder.layers.2.tcn2.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.tcn2.gate_convs.bias 	 torch.Size([64])
encoder.layers.2.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.2.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.2.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.3.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.3.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.4.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.4.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer_.norm.weight 	 torch.Size([128])
encoder.layers.2.sublayer_.norm.bias 	 torch.Size([128])
encoder.layers.3.self_attn.linears.0.weight 	 torch.Size([128, 128])
encoder.layers.3.self_attn.linears.0.bias 	 torch.Size([128])
encoder.layers.3.self_attn.linears.1.weight 	 torch.Size([128, 128])
encoder.layers.3.self_attn.linears.1.bias 	 torch.Size([128])
encoder.layers.3.self_attn.linears.2.weight 	 torch.Size([128, 128])
encoder.layers.3.self_attn.linears.2.bias 	 torch.Size([128])
encoder.layers.3.self_attn.linears.3.weight 	 torch.Size([128, 128])
encoder.layers.3.self_attn.linears.3.bias 	 torch.Size([128])
encoder.layers.3.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.3.feed_forward_gcn2.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.3.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.3.tcn.filter_convs.bias 	 torch.Size([64])
encoder.layers.3.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.3.tcn.gate_convs.bias 	 torch.Size([64])
encoder.layers.3.tcn2.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.3.tcn2.filter_convs.bias 	 torch.Size([64])
encoder.layers.3.tcn2.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.3.tcn2.gate_convs.bias 	 torch.Size([64])
encoder.layers.3.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.3.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.3.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.3.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.3.sublayer.2.norm.weight 	 torch.Size([64])
encoder.layers.3.sublayer.2.norm.bias 	 torch.Size([64])
encoder.layers.3.sublayer.3.norm.weight 	 torch.Size([64])
encoder.layers.3.sublayer.3.norm.bias 	 torch.Size([64])
encoder.layers.3.sublayer.4.norm.weight 	 torch.Size([64])
encoder.layers.3.sublayer.4.norm.bias 	 torch.Size([64])
encoder.layers.3.sublayer_.norm.weight 	 torch.Size([128])
encoder.layers.3.sublayer_.norm.bias 	 torch.Size([128])
encoder.norm.weight 	 torch.Size([64])
encoder.norm.bias 	 torch.Size([64])
encoder.norm2.weight 	 torch.Size([64])
encoder.norm2.bias 	 torch.Size([64])
decoder.layers.0.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.0.self_attn.linears.2.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.linears.2.bias 	 torch.Size([64])
decoder.layers.0.self_attn.linears.3.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.linears.3.bias 	 torch.Size([64])
decoder.layers.0.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.0.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.linears.2.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.linears.2.bias 	 torch.Size([64])
decoder.layers.0.src_attn.linears.3.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.linears.3.bias 	 torch.Size([64])
decoder.layers.0.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.0.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.tcn.filter_convs.bias 	 torch.Size([64])
decoder.layers.0.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.tcn.gate_convs.bias 	 torch.Size([64])
decoder.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.3.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.3.norm.bias 	 torch.Size([64])
decoder.layers.1.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.1.self_attn.linears.2.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.linears.2.bias 	 torch.Size([64])
decoder.layers.1.self_attn.linears.3.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.linears.3.bias 	 torch.Size([64])
decoder.layers.1.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.1.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.linears.2.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.linears.2.bias 	 torch.Size([64])
decoder.layers.1.src_attn.linears.3.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.linears.3.bias 	 torch.Size([64])
decoder.layers.1.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.1.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.tcn.filter_convs.bias 	 torch.Size([64])
decoder.layers.1.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.tcn.gate_convs.bias 	 torch.Size([64])
decoder.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.3.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.3.norm.bias 	 torch.Size([64])
decoder.layers.2.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.2.self_attn.linears.2.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.linears.2.bias 	 torch.Size([64])
decoder.layers.2.self_attn.linears.3.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.linears.3.bias 	 torch.Size([64])
decoder.layers.2.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.2.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.linears.2.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.linears.2.bias 	 torch.Size([64])
decoder.layers.2.src_attn.linears.3.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.linears.3.bias 	 torch.Size([64])
decoder.layers.2.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.2.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.tcn.filter_convs.bias 	 torch.Size([64])
decoder.layers.2.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.tcn.gate_convs.bias 	 torch.Size([64])
decoder.layers.2.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.3.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.3.norm.bias 	 torch.Size([64])
decoder.layers.3.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.3.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.3.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.3.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.3.self_attn.linears.2.weight 	 torch.Size([64, 64])
decoder.layers.3.self_attn.linears.2.bias 	 torch.Size([64])
decoder.layers.3.self_attn.linears.3.weight 	 torch.Size([64, 64])
decoder.layers.3.self_attn.linears.3.bias 	 torch.Size([64])
decoder.layers.3.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.3.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.3.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.3.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.3.src_attn.linears.2.weight 	 torch.Size([64, 64])
decoder.layers.3.src_attn.linears.2.bias 	 torch.Size([64])
decoder.layers.3.src_attn.linears.3.weight 	 torch.Size([64, 64])
decoder.layers.3.src_attn.linears.3.bias 	 torch.Size([64])
decoder.layers.3.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.3.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.3.tcn.filter_convs.bias 	 torch.Size([64])
decoder.layers.3.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.3.tcn.gate_convs.bias 	 torch.Size([64])
decoder.layers.3.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.3.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.3.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.3.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.3.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.3.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.3.sublayer.3.norm.weight 	 torch.Size([64])
decoder.layers.3.sublayer.3.norm.bias 	 torch.Size([64])
decoder.norm.weight 	 torch.Size([64])
decoder.norm.bias 	 torch.Size([64])
decoder2.layers.0.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder2.layers.0.self_attn.linears.0.bias 	 torch.Size([64])
decoder2.layers.0.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder2.layers.0.self_attn.linears.1.bias 	 torch.Size([64])
decoder2.layers.0.self_attn.linears.2.weight 	 torch.Size([64, 64])
decoder2.layers.0.self_attn.linears.2.bias 	 torch.Size([64])
decoder2.layers.0.self_attn.linears.3.weight 	 torch.Size([64, 64])
decoder2.layers.0.self_attn.linears.3.bias 	 torch.Size([64])
decoder2.layers.0.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder2.layers.0.src_attn.linears.0.bias 	 torch.Size([64])
decoder2.layers.0.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder2.layers.0.src_attn.linears.1.bias 	 torch.Size([64])
decoder2.layers.0.src_attn.linears.2.weight 	 torch.Size([64, 64])
decoder2.layers.0.src_attn.linears.2.bias 	 torch.Size([64])
decoder2.layers.0.src_attn.linears.3.weight 	 torch.Size([64, 64])
decoder2.layers.0.src_attn.linears.3.bias 	 torch.Size([64])
decoder2.layers.0.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder2.layers.0.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder2.layers.0.tcn.filter_convs.bias 	 torch.Size([64])
decoder2.layers.0.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder2.layers.0.tcn.gate_convs.bias 	 torch.Size([64])
decoder2.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
decoder2.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
decoder2.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
decoder2.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
decoder2.layers.0.sublayer.2.norm.weight 	 torch.Size([64])
decoder2.layers.0.sublayer.2.norm.bias 	 torch.Size([64])
decoder2.layers.0.sublayer.3.norm.weight 	 torch.Size([64])
decoder2.layers.0.sublayer.3.norm.bias 	 torch.Size([64])
decoder2.layers.1.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder2.layers.1.self_attn.linears.0.bias 	 torch.Size([64])
decoder2.layers.1.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder2.layers.1.self_attn.linears.1.bias 	 torch.Size([64])
decoder2.layers.1.self_attn.linears.2.weight 	 torch.Size([64, 64])
decoder2.layers.1.self_attn.linears.2.bias 	 torch.Size([64])
decoder2.layers.1.self_attn.linears.3.weight 	 torch.Size([64, 64])
decoder2.layers.1.self_attn.linears.3.bias 	 torch.Size([64])
decoder2.layers.1.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder2.layers.1.src_attn.linears.0.bias 	 torch.Size([64])
decoder2.layers.1.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder2.layers.1.src_attn.linears.1.bias 	 torch.Size([64])
decoder2.layers.1.src_attn.linears.2.weight 	 torch.Size([64, 64])
decoder2.layers.1.src_attn.linears.2.bias 	 torch.Size([64])
decoder2.layers.1.src_attn.linears.3.weight 	 torch.Size([64, 64])
decoder2.layers.1.src_attn.linears.3.bias 	 torch.Size([64])
decoder2.layers.1.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder2.layers.1.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder2.layers.1.tcn.filter_convs.bias 	 torch.Size([64])
decoder2.layers.1.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder2.layers.1.tcn.gate_convs.bias 	 torch.Size([64])
decoder2.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
decoder2.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
decoder2.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
decoder2.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
decoder2.layers.1.sublayer.2.norm.weight 	 torch.Size([64])
decoder2.layers.1.sublayer.2.norm.bias 	 torch.Size([64])
decoder2.layers.1.sublayer.3.norm.weight 	 torch.Size([64])
decoder2.layers.1.sublayer.3.norm.bias 	 torch.Size([64])
decoder2.layers.2.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder2.layers.2.self_attn.linears.0.bias 	 torch.Size([64])
decoder2.layers.2.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder2.layers.2.self_attn.linears.1.bias 	 torch.Size([64])
decoder2.layers.2.self_attn.linears.2.weight 	 torch.Size([64, 64])
decoder2.layers.2.self_attn.linears.2.bias 	 torch.Size([64])
decoder2.layers.2.self_attn.linears.3.weight 	 torch.Size([64, 64])
decoder2.layers.2.self_attn.linears.3.bias 	 torch.Size([64])
decoder2.layers.2.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder2.layers.2.src_attn.linears.0.bias 	 torch.Size([64])
decoder2.layers.2.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder2.layers.2.src_attn.linears.1.bias 	 torch.Size([64])
decoder2.layers.2.src_attn.linears.2.weight 	 torch.Size([64, 64])
decoder2.layers.2.src_attn.linears.2.bias 	 torch.Size([64])
decoder2.layers.2.src_attn.linears.3.weight 	 torch.Size([64, 64])
decoder2.layers.2.src_attn.linears.3.bias 	 torch.Size([64])
decoder2.layers.2.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder2.layers.2.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder2.layers.2.tcn.filter_convs.bias 	 torch.Size([64])
decoder2.layers.2.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder2.layers.2.tcn.gate_convs.bias 	 torch.Size([64])
decoder2.layers.2.sublayer.0.norm.weight 	 torch.Size([64])
decoder2.layers.2.sublayer.0.norm.bias 	 torch.Size([64])
decoder2.layers.2.sublayer.1.norm.weight 	 torch.Size([64])
decoder2.layers.2.sublayer.1.norm.bias 	 torch.Size([64])
decoder2.layers.2.sublayer.2.norm.weight 	 torch.Size([64])
decoder2.layers.2.sublayer.2.norm.bias 	 torch.Size([64])
decoder2.layers.2.sublayer.3.norm.weight 	 torch.Size([64])
decoder2.layers.2.sublayer.3.norm.bias 	 torch.Size([64])
decoder2.layers.3.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder2.layers.3.self_attn.linears.0.bias 	 torch.Size([64])
decoder2.layers.3.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder2.layers.3.self_attn.linears.1.bias 	 torch.Size([64])
decoder2.layers.3.self_attn.linears.2.weight 	 torch.Size([64, 64])
decoder2.layers.3.self_attn.linears.2.bias 	 torch.Size([64])
decoder2.layers.3.self_attn.linears.3.weight 	 torch.Size([64, 64])
decoder2.layers.3.self_attn.linears.3.bias 	 torch.Size([64])
decoder2.layers.3.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder2.layers.3.src_attn.linears.0.bias 	 torch.Size([64])
decoder2.layers.3.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder2.layers.3.src_attn.linears.1.bias 	 torch.Size([64])
decoder2.layers.3.src_attn.linears.2.weight 	 torch.Size([64, 64])
decoder2.layers.3.src_attn.linears.2.bias 	 torch.Size([64])
decoder2.layers.3.src_attn.linears.3.weight 	 torch.Size([64, 64])
decoder2.layers.3.src_attn.linears.3.bias 	 torch.Size([64])
decoder2.layers.3.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder2.layers.3.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder2.layers.3.tcn.filter_convs.bias 	 torch.Size([64])
decoder2.layers.3.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder2.layers.3.tcn.gate_convs.bias 	 torch.Size([64])
decoder2.layers.3.sublayer.0.norm.weight 	 torch.Size([64])
decoder2.layers.3.sublayer.0.norm.bias 	 torch.Size([64])
decoder2.layers.3.sublayer.1.norm.weight 	 torch.Size([64])
decoder2.layers.3.sublayer.1.norm.bias 	 torch.Size([64])
decoder2.layers.3.sublayer.2.norm.weight 	 torch.Size([64])
decoder2.layers.3.sublayer.2.norm.bias 	 torch.Size([64])
decoder2.layers.3.sublayer.3.norm.weight 	 torch.Size([64])
decoder2.layers.3.sublayer.3.norm.bias 	 torch.Size([64])
decoder2.norm.weight 	 torch.Size([64])
decoder2.norm.bias 	 torch.Size([64])
src_embed.0.weight 	 torch.Size([64, 1])
src_embed.0.bias 	 torch.Size([64])
src_embed.1.pe 	 torch.Size([1, 1, 12, 64])
src_embed.2.embedding.weight 	 torch.Size([250, 64])
src_embed2.0.weight 	 torch.Size([64, 1])
src_embed2.0.bias 	 torch.Size([64])
src_embed2.1.pe 	 torch.Size([1, 1, 12, 64])
src_embed2.2.embedding.weight 	 torch.Size([250, 64])
trg_embed.0.weight 	 torch.Size([64, 1])
trg_embed.0.bias 	 torch.Size([64])
trg_embed.1.pe 	 torch.Size([1, 1, 12, 64])
trg_embed.2.embedding.weight 	 torch.Size([250, 64])
trg_embed2.0.weight 	 torch.Size([64, 1])
trg_embed2.0.bias 	 torch.Size([64])
trg_embed2.1.pe 	 torch.Size([1, 1, 12, 64])
trg_embed2.2.embedding.weight 	 torch.Size([250, 64])
prediction_generator.weight 	 torch.Size([1, 64])
prediction_generator.bias 	 torch.Size([1])
prediction_generator2.weight 	 torch.Size([1, 64])
prediction_generator2.bias 	 torch.Size([1])
Net's total params: 1067138
Optimizer's state_dict:
state 	 {}
param_groups 	 [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375]}]
validation batch 1 / 168, loss: 1.91
validation batch 101 / 168, loss: 1.97
validation cost time: 52.1209s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEconcat/epoch_0.params
epoch: 0, learning rate 0.001000
epoch: 0, train time every whole data:173.87s
epoch: 0, total time:226.16s
validation batch 1 / 168, loss: 0.05
validation batch 101 / 168, loss: 0.04
validation cost time: 52.4951s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEconcat/epoch_1.params
epoch: 1, learning rate 0.001000
epoch: 1, train time every whole data:175.85s
epoch: 1, total time:454.65s
validation batch 1 / 168, loss: 0.06
validation batch 101 / 168, loss: 0.02
validation cost time: 57.5818s
epoch: 2, learning rate 0.001000
epoch: 2, train time every whole data:176.69s
epoch: 2, total time:688.93s
validation batch 1 / 168, loss: 0.18
validation batch 101 / 168, loss: 0.18
validation cost time: 52.5665s
epoch: 3, learning rate 0.001000
epoch: 3, train time every whole data:176.33s
epoch: 3, total time:917.83s
validation batch 1 / 168, loss: 0.16
validation batch 101 / 168, loss: 0.14
validation cost time: 52.6209s
epoch: 4, learning rate 0.001000
epoch: 4, train time every whole data:176.44s
epoch: 4, total time:1146.89s
validation batch 1 / 168, loss: 0.09
validation batch 101 / 168, loss: 0.07
validation cost time: 52.7238s
epoch: 5, learning rate 0.001000
epoch: 5, train time every whole data:176.65s
epoch: 5, total time:1376.27s
validation batch 1 / 168, loss: 0.17
validation batch 101 / 168, loss: 0.15
validation cost time: 52.6094s
epoch: 6, learning rate 0.001000
epoch: 6, train time every whole data:176.93s
epoch: 6, total time:1605.81s
validation batch 1 / 168, loss: 0.14
validation batch 101 / 168, loss: 0.10
validation cost time: 52.7595s
epoch: 7, learning rate 0.001000
epoch: 7, train time every whole data:176.04s
epoch: 7, total time:1834.61s
validation batch 1 / 168, loss: 0.15
validation batch 101 / 168, loss: 0.11
validation cost time: 52.8238s
epoch: 8, learning rate 0.001000
epoch: 8, train time every whole data:176.06s
epoch: 8, total time:2063.50s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.07
validation cost time: 52.8866s
epoch: 9, learning rate 0.001000
epoch: 9, train time every whole data:177.48s
epoch: 9, total time:2293.87s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.10
validation cost time: 52.7287s
epoch: 10, learning rate 0.001000
epoch: 10, train time every whole data:176.75s
epoch: 10, total time:2523.35s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.06
validation cost time: 52.8056s
epoch: 11, learning rate 0.001000
epoch: 11, train time every whole data:176.27s
epoch: 11, total time:2752.43s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.07
validation cost time: 52.6279s
epoch: 12, learning rate 0.001000
epoch: 12, train time every whole data:176.52s
epoch: 12, total time:2981.59s
validation batch 1 / 168, loss: 0.09
validation batch 101 / 168, loss: 0.04
validation cost time: 52.7756s
epoch: 13, learning rate 0.001000
epoch: 13, train time every whole data:176.32s
epoch: 13, total time:3210.69s
validation batch 1 / 168, loss: 0.08
validation batch 101 / 168, loss: 0.03
validation cost time: 52.7711s
epoch: 14, learning rate 0.001000
epoch: 14, train time every whole data:176.43s
epoch: 14, total time:3439.90s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.09
validation cost time: 52.6978s
epoch: 15, learning rate 0.001000
epoch: 15, train time every whole data:177.45s
epoch: 15, total time:3670.06s
validation batch 1 / 168, loss: 0.09
validation batch 101 / 168, loss: 0.04
validation cost time: 52.8689s
epoch: 16, learning rate 0.001000
epoch: 16, train time every whole data:176.76s
epoch: 16, total time:3899.69s
validation batch 1 / 168, loss: 0.07
validation batch 101 / 168, loss: 0.02
validation cost time: 52.7970s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEconcat/epoch_17.params
epoch: 17, learning rate 0.001000
epoch: 17, train time every whole data:176.32s
epoch: 17, total time:4128.99s
validation batch 1 / 168, loss: 0.10
validation batch 101 / 168, loss: 0.04
validation cost time: 52.9872s
epoch: 18, learning rate 0.001000
epoch: 18, train time every whole data:176.93s
epoch: 18, total time:4358.91s
validation batch 1 / 168, loss: 0.10
validation batch 101 / 168, loss: 0.05
validation cost time: 55.4824s
epoch: 19, learning rate 0.001000
epoch: 19, train time every whole data:176.56s
epoch: 19, total time:4590.96s
validation batch 1 / 168, loss: 0.09
validation batch 101 / 168, loss: 0.04
validation cost time: 52.7004s
epoch: 20, learning rate 0.001000
epoch: 20, train time every whole data:176.26s
epoch: 20, total time:4819.92s
validation batch 1 / 168, loss: 0.08
validation batch 101 / 168, loss: 0.04
validation cost time: 52.7977s
epoch: 21, learning rate 0.001000
epoch: 21, train time every whole data:176.16s
epoch: 21, total time:5048.88s
validation batch 1 / 168, loss: 0.09
validation batch 101 / 168, loss: 0.05
validation cost time: 52.7601s
epoch: 22, learning rate 0.001000
epoch: 22, train time every whole data:175.95s
epoch: 22, total time:5277.60s
validation batch 1 / 168, loss: 0.07
validation batch 101 / 168, loss: 0.03
validation cost time: 52.7230s
epoch: 23, learning rate 0.001000
epoch: 23, train time every whole data:176.26s
epoch: 23, total time:5506.59s
validation batch 1 / 168, loss: 0.06
validation batch 101 / 168, loss: 0.03
validation cost time: 53.7721s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEconcat/epoch_24.params
epoch: 24, learning rate 0.001000
epoch: 24, train time every whole data:177.39s
epoch: 24, total time:5737.95s
validation batch 1 / 168, loss: 0.06
validation batch 101 / 168, loss: 0.03
validation cost time: 52.7893s
epoch: 25, learning rate 0.001000
epoch: 25, train time every whole data:176.16s
epoch: 25, total time:5966.90s
validation batch 1 / 168, loss: 0.07
validation batch 101 / 168, loss: 0.03
validation cost time: 52.8145s
epoch: 26, learning rate 0.001000
epoch: 26, train time every whole data:176.78s
epoch: 26, total time:6196.50s
validation batch 1 / 168, loss: 0.08
validation batch 101 / 168, loss: 0.02
validation cost time: 52.8223s
epoch: 27, learning rate 0.001000
epoch: 27, train time every whole data:176.09s
epoch: 27, total time:6425.42s
validation batch 1 / 168, loss: 0.08
validation batch 101 / 168, loss: 0.03
validation cost time: 52.9149s
epoch: 28, learning rate 0.001000
epoch: 28, train time every whole data:177.46s
epoch: 28, total time:6655.80s
validation batch 1 / 168, loss: 0.09
validation batch 101 / 168, loss: 0.02
validation cost time: 52.7355s
epoch: 29, learning rate 0.001000
epoch: 29, train time every whole data:176.39s
epoch: 29, total time:6884.93s
validation batch 1 / 168, loss: 0.07
validation batch 101 / 168, loss: 0.02
validation cost time: 52.6963s
epoch: 30, learning rate 0.001000
epoch: 30, train time every whole data:176.16s
epoch: 30, total time:7113.78s
validation batch 1 / 168, loss: 0.07
validation batch 101 / 168, loss: 0.02
validation cost time: 52.6282s
epoch: 31, learning rate 0.001000
epoch: 31, train time every whole data:176.40s
epoch: 31, total time:7342.82s
validation batch 1 / 168, loss: 0.09
validation batch 101 / 168, loss: 0.03
validation cost time: 52.8418s
epoch: 32, learning rate 0.001000
epoch: 32, train time every whole data:176.31s
epoch: 32, total time:7571.97s
validation batch 1 / 168, loss: 0.08
validation batch 101 / 168, loss: 0.02
validation cost time: 52.8668s
epoch: 33, learning rate 0.001000
epoch: 33, train time every whole data:176.63s
epoch: 33, total time:7801.47s
validation batch 1 / 168, loss: 0.09
validation batch 101 / 168, loss: 0.02
validation cost time: 52.7787s
epoch: 34, learning rate 0.001000
epoch: 34, train time every whole data:176.32s
epoch: 34, total time:8030.58s
validation batch 1 / 168, loss: 0.08
validation batch 101 / 168, loss: 0.02
validation cost time: 52.8961s
epoch: 35, learning rate 0.001000
epoch: 35, train time every whole data:176.85s
epoch: 35, total time:8260.33s
validation batch 1 / 168, loss: 0.10
validation batch 101 / 168, loss: 0.02
validation cost time: 52.6622s
epoch: 36, learning rate 0.001000
epoch: 36, train time every whole data:176.98s
epoch: 36, total time:8489.97s
validation batch 1 / 168, loss: 0.07
validation batch 101 / 168, loss: 0.02
validation cost time: 52.7623s
epoch: 37, learning rate 0.001000
epoch: 37, train time every whole data:176.60s
epoch: 37, total time:8719.34s
validation batch 1 / 168, loss: 0.09
validation batch 101 / 168, loss: 0.03
validation cost time: 52.6939s
epoch: 38, learning rate 0.001000
epoch: 38, train time every whole data:176.72s
epoch: 38, total time:8948.75s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 52.7943s
epoch: 39, learning rate 0.001000
epoch: 39, train time every whole data:176.28s
epoch: 39, total time:9177.83s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.03
validation cost time: 52.9266s
epoch: 40, learning rate 0.001000
epoch: 40, train time every whole data:176.19s
epoch: 40, total time:9406.95s
validation batch 1 / 168, loss: 0.08
validation batch 101 / 168, loss: 0.02
validation cost time: 52.6605s
epoch: 41, learning rate 0.001000
epoch: 41, train time every whole data:177.47s
epoch: 41, total time:9637.09s
validation batch 1 / 168, loss: 0.08
validation batch 101 / 168, loss: 0.02
validation cost time: 52.7932s
epoch: 42, learning rate 0.001000
epoch: 42, train time every whole data:176.65s
epoch: 42, total time:9866.54s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 53.0440s
epoch: 43, learning rate 0.001000
epoch: 43, train time every whole data:176.67s
epoch: 43, total time:10096.26s
validation batch 1 / 168, loss: 0.09
validation batch 101 / 168, loss: 0.02
validation cost time: 52.8720s
epoch: 44, learning rate 0.001000
epoch: 44, train time every whole data:176.41s
epoch: 44, total time:10325.54s
validation batch 1 / 168, loss: 0.10
validation batch 101 / 168, loss: 0.02
validation cost time: 52.7690s
epoch: 45, learning rate 0.001000
epoch: 45, train time every whole data:176.37s
epoch: 45, total time:10554.68s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 52.6830s
epoch: 46, learning rate 0.001000
epoch: 46, train time every whole data:176.41s
epoch: 46, total time:10783.78s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 52.7427s
epoch: 47, learning rate 0.001000
epoch: 47, train time every whole data:176.80s
epoch: 47, total time:11013.33s
validation batch 1 / 168, loss: 0.10
validation batch 101 / 168, loss: 0.02
validation cost time: 52.8605s
epoch: 48, learning rate 0.001000
epoch: 48, train time every whole data:176.93s
epoch: 48, total time:11243.12s
validation batch 1 / 168, loss: 0.09
validation batch 101 / 168, loss: 0.02
validation cost time: 52.9443s
epoch: 49, learning rate 0.001000
epoch: 49, train time every whole data:176.23s
epoch: 49, total time:11472.30s
validation batch 1 / 168, loss: 0.08
validation batch 101 / 168, loss: 0.02
validation cost time: 52.7093s
epoch: 50, learning rate 0.001000
epoch: 50, train time every whole data:176.88s
epoch: 50, total time:11701.89s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 52.8049s
epoch: 51, learning rate 0.001000
epoch: 51, train time every whole data:176.68s
epoch: 51, total time:11931.38s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 52.8333s
epoch: 52, learning rate 0.001000
epoch: 52, train time every whole data:176.70s
epoch: 52, total time:12160.93s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 54.9718s
epoch: 53, learning rate 0.001000
epoch: 53, train time every whole data:176.19s
epoch: 53, total time:12392.10s
validation batch 1 / 168, loss: 0.15
validation batch 101 / 168, loss: 0.02
validation cost time: 52.7801s
epoch: 54, learning rate 0.001000
epoch: 54, train time every whole data:176.30s
epoch: 54, total time:12621.19s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 52.8034s
epoch: 55, learning rate 0.001000
epoch: 55, train time every whole data:176.77s
epoch: 55, total time:12850.76s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 52.9317s
epoch: 56, learning rate 0.001000
epoch: 56, train time every whole data:176.38s
epoch: 56, total time:13080.08s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 52.8154s
epoch: 57, learning rate 0.001000
epoch: 57, train time every whole data:176.43s
epoch: 57, total time:13309.32s
validation batch 1 / 168, loss: 0.10
validation batch 101 / 168, loss: 0.02
validation cost time: 52.8056s
epoch: 58, learning rate 0.001000
epoch: 58, train time every whole data:176.32s
epoch: 58, total time:13538.46s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 52.8641s
epoch: 59, learning rate 0.001000
epoch: 59, train time every whole data:176.98s
epoch: 59, total time:13768.31s
validation batch 1 / 168, loss: 0.14
validation batch 101 / 168, loss: 0.02
validation cost time: 52.7011s
epoch: 60, learning rate 0.001000
epoch: 60, train time every whole data:176.67s
epoch: 60, total time:13997.69s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 52.7076s
epoch: 61, learning rate 0.001000
epoch: 61, train time every whole data:176.44s
epoch: 61, total time:14226.84s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 52.9867s
epoch: 62, learning rate 0.001000
epoch: 62, train time every whole data:176.69s
epoch: 62, total time:14456.52s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 57.2091s
epoch: 63, learning rate 0.001000
epoch: 63, train time every whole data:176.63s
epoch: 63, total time:14690.36s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 52.9223s
epoch: 64, learning rate 0.001000
epoch: 64, train time every whole data:177.08s
epoch: 64, total time:14920.37s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 52.7302s
epoch: 65, learning rate 0.001000
epoch: 65, train time every whole data:176.45s
epoch: 65, total time:15149.55s
validation batch 1 / 168, loss: 0.14
validation batch 101 / 168, loss: 0.02
validation cost time: 52.7281s
epoch: 66, learning rate 0.001000
epoch: 66, train time every whole data:176.68s
epoch: 66, total time:15378.96s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 52.6965s
epoch: 67, learning rate 0.001000
epoch: 67, train time every whole data:176.45s
epoch: 67, total time:15608.11s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 52.7895s
epoch: 68, learning rate 0.001000
epoch: 68, train time every whole data:177.02s
epoch: 68, total time:15837.93s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 52.8549s
epoch: 69, learning rate 0.001000
epoch: 69, train time every whole data:176.22s
epoch: 69, total time:16067.01s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 52.7694s
epoch: 70, learning rate 0.001000
epoch: 70, train time every whole data:176.55s
epoch: 70, total time:16296.34s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 52.9624s
epoch: 71, learning rate 0.001000
epoch: 71, train time every whole data:176.21s
epoch: 71, total time:16525.52s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 52.8485s
epoch: 72, learning rate 0.001000
epoch: 72, train time every whole data:176.34s
epoch: 72, total time:16754.71s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 52.7727s
epoch: 73, learning rate 0.001000
epoch: 73, train time every whole data:176.18s
epoch: 73, total time:16983.67s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 52.7611s
epoch: 74, learning rate 0.001000
epoch: 74, train time every whole data:176.73s
epoch: 74, total time:17213.16s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 52.7678s
epoch: 75, learning rate 0.001000
epoch: 75, train time every whole data:177.52s
epoch: 75, total time:17443.45s
validation batch 1 / 168, loss: 0.10
validation batch 101 / 168, loss: 0.02
validation cost time: 52.9520s
epoch: 76, learning rate 0.001000
epoch: 76, train time every whole data:176.27s
epoch: 76, total time:17672.68s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 52.6896s
epoch: 77, learning rate 0.001000
epoch: 77, train time every whole data:176.56s
epoch: 77, total time:17901.93s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 52.8103s
epoch: 78, learning rate 0.001000
epoch: 78, train time every whole data:175.99s
epoch: 78, total time:18130.74s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 52.8940s
epoch: 79, learning rate 0.001000
epoch: 79, train time every whole data:176.28s
epoch: 79, total time:18359.92s
validation batch 1 / 168, loss: 0.15
validation batch 101 / 168, loss: 0.02
validation cost time: 52.8122s
epoch: 80, learning rate 0.001000
epoch: 80, train time every whole data:176.82s
epoch: 80, total time:18589.55s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 57.6985s
epoch: 81, learning rate 0.001000
epoch: 81, train time every whole data:176.25s
epoch: 81, total time:18823.51s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 52.7763s
epoch: 82, learning rate 0.001000
epoch: 82, train time every whole data:176.42s
epoch: 82, total time:19052.70s
validation batch 1 / 168, loss: 0.16
validation batch 101 / 168, loss: 0.02
validation cost time: 52.6945s
epoch: 83, learning rate 0.001000
epoch: 83, train time every whole data:176.32s
epoch: 83, total time:19281.72s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 52.7687s
epoch: 84, learning rate 0.001000
epoch: 84, train time every whole data:176.47s
epoch: 84, total time:19510.96s
validation batch 1 / 168, loss: 0.17
validation batch 101 / 168, loss: 0.02
validation cost time: 52.7267s
epoch: 85, learning rate 0.001000
epoch: 85, train time every whole data:176.20s
epoch: 85, total time:19739.89s
validation batch 1 / 168, loss: 0.15
validation batch 101 / 168, loss: 0.02
validation cost time: 52.7374s
epoch: 86, learning rate 0.001000
epoch: 86, train time every whole data:176.63s
epoch: 86, total time:19969.27s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 52.7984s
epoch: 87, learning rate 0.001000
epoch: 87, train time every whole data:176.23s
epoch: 87, total time:20198.30s
validation batch 1 / 168, loss: 0.16
validation batch 101 / 168, loss: 0.02
validation cost time: 52.7495s
epoch: 88, learning rate 0.001000
epoch: 88, train time every whole data:176.14s
epoch: 88, total time:20427.19s
validation batch 1 / 168, loss: 0.19
validation batch 101 / 168, loss: 0.02
validation cost time: 52.9446s
epoch: 89, learning rate 0.001000
epoch: 89, train time every whole data:177.29s
epoch: 89, total time:20657.44s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 52.6560s
epoch: 90, learning rate 0.001000
epoch: 90, train time every whole data:175.24s
epoch: 90, total time:20885.33s
validation batch 1 / 168, loss: 0.15
validation batch 101 / 168, loss: 0.02
validation cost time: 52.5420s
epoch: 91, learning rate 0.001000
epoch: 91, train time every whole data:176.22s
epoch: 91, total time:21114.10s
validation batch 1 / 168, loss: 0.14
validation batch 101 / 168, loss: 0.02
validation cost time: 54.2271s
epoch: 92, learning rate 0.001000
epoch: 92, train time every whole data:176.70s
epoch: 92, total time:21345.03s
validation batch 1 / 168, loss: 0.15
validation batch 101 / 168, loss: 0.02
validation cost time: 52.5771s
epoch: 93, learning rate 0.001000
epoch: 93, train time every whole data:175.25s
epoch: 93, total time:21572.86s
validation batch 1 / 168, loss: 0.15
validation batch 101 / 168, loss: 0.02
validation cost time: 52.4482s
epoch: 94, learning rate 0.001000
epoch: 94, train time every whole data:176.21s
epoch: 94, total time:21801.53s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 52.4507s
epoch: 95, learning rate 0.001000
epoch: 95, train time every whole data:176.31s
epoch: 95, total time:22030.29s
validation batch 1 / 168, loss: 0.16
validation batch 101 / 168, loss: 0.02
validation cost time: 52.5738s
epoch: 96, learning rate 0.001000
epoch: 96, train time every whole data:176.06s
epoch: 96, total time:22258.93s
validation batch 1 / 168, loss: 0.15
validation batch 101 / 168, loss: 0.02
validation cost time: 54.0596s
epoch: 97, learning rate 0.001000
epoch: 97, train time every whole data:175.16s
epoch: 97, total time:22488.15s
validation batch 1 / 168, loss: 0.16
validation batch 101 / 168, loss: 0.02
validation cost time: 52.6956s
epoch: 98, learning rate 0.001000
epoch: 98, train time every whole data:177.41s
epoch: 98, total time:22718.26s
validation batch 1 / 168, loss: 0.10
validation batch 101 / 168, loss: 0.02
validation cost time: 52.6291s
epoch: 99, learning rate 0.001000
epoch: 99, train time every whole data:175.96s
epoch: 99, total time:22946.84s
best epoch: 24
apply the best val model on the test data set ...
load weight from: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEconcat/epoch_24.params
predicting testing set batch 1 / 168, time: 0.31s
predicting testing set batch 101 / 168, time: 31.63s
test time on whole data:52.61s
input: (672, 250, 12, 2)
prediction: (672, 250, 12, 2)
data_target_tensor: (672, 250, 12, 2)
current epoch: 24, predict 0 points
MAE: 1.58
RMSE: 2.49
MAPE: 57.84
PCC: 0.85
current epoch: 24, predict 1 points
MAE: 1.74
RMSE: 2.79
MAPE: 64.71
PCC: 0.80
current epoch: 24, predict 2 points
MAE: 1.91
RMSE: 3.19
MAPE: 71.55
PCC: 0.75
current epoch: 24, predict 3 points
MAE: 2.09
RMSE: 3.59
MAPE: 78.31
PCC: 0.70
current epoch: 24, predict 4 points
MAE: 2.23
RMSE: 3.89
MAPE: 83.29
PCC: 0.65
current epoch: 24, predict 5 points
MAE: 2.36
RMSE: 4.17
MAPE: 87.20
PCC: 0.60
current epoch: 24, predict 6 points
MAE: 2.48
RMSE: 4.40
MAPE: 90.85
PCC: 0.56
current epoch: 24, predict 7 points
MAE: 2.53
RMSE: 4.48
MAPE: 93.19
PCC: 0.55
current epoch: 24, predict 8 points
MAE: 2.55
RMSE: 4.50
MAPE: 95.24
PCC: 0.56
current epoch: 24, predict 9 points
MAE: 2.60
RMSE: 4.59
MAPE: 98.19
PCC: 0.56
current epoch: 24, predict 10 points
MAE: 2.63
RMSE: 4.66
MAPE: 99.95
PCC: 0.56
current epoch: 24, predict 11 points
MAE: 2.57
RMSE: 4.53
MAPE: 97.10
PCC: 0.56
all MAE: 2.27
all RMSE: 4.01
all MAPE: 84.79
all PCC: 0.56
1.5833593828469692 2.4899345320742343 57.84263579673685 0.8463197881797601 
1.743619561497122 2.786235786927177 64.71065775412688 0.8045377857160297 
1.9142943623613211 3.1924031045169396 71.54804177689977 0.7503345892380314 
2.088237462734449 3.5889975291194944 78.30944338759511 0.695240287074005 
2.2327984989744034 3.8896359960354268 83.28930222675696 0.647207793465258 
2.3623283641292225 4.167704915967318 87.19980491811371 0.5981495833534504 
2.4757359765950766 4.400929933637892 90.84657085315517 0.5606115526682435 
2.526201548802533 4.4796515132917145 93.19193982463136 0.5535629113600964 
2.5494543519869803 4.502564469208072 95.23613046692344 0.5585019155599783 
2.600371230523945 4.592560498109173 98.19234567010064 0.5596603160512664 
2.6336641784380412 4.657603809428891 99.94954638843137 0.5586253418105955 
2.572393423638262 4.5310141830204005 97.09994888782425 0.5592626760096804 
2.2735381952106937 4.005806000775524 84.78549368867954 0.5592626760096804 
fine tune the model ... 
epoch: 100, learning rate 0.000100
epoch: 100, train time every whole data:389.47s
epoch: 100, total time:23399.75s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.0562s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEconcat/epoch_100.params
epoch: 101, learning rate 0.000100
epoch: 101, train time every whole data:387.50s
epoch: 101, total time:23840.44s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 52.6023s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEconcat/epoch_101.params
epoch: 102, learning rate 0.000100
epoch: 102, train time every whole data:392.86s
epoch: 102, total time:24286.14s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 57.6561s
epoch: 103, learning rate 0.000100
epoch: 103, train time every whole data:392.45s
epoch: 103, total time:24736.25s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 52.8482s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEconcat/epoch_103.params
epoch: 104, learning rate 0.000100
epoch: 104, train time every whole data:390.18s
epoch: 104, total time:25179.40s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 52.6716s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEconcat/epoch_104.params
epoch: 105, learning rate 0.000100
epoch: 105, train time every whole data:390.66s
epoch: 105, total time:25622.87s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 52.7221s
epoch: 106, learning rate 0.000100
epoch: 106, train time every whole data:395.22s
epoch: 106, total time:26070.82s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 57.6112s
epoch: 107, learning rate 0.000100
epoch: 107, train time every whole data:391.15s
epoch: 107, total time:26519.59s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.0837s
epoch: 108, learning rate 0.000100
epoch: 108, train time every whole data:392.00s
epoch: 108, total time:26964.68s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.6848s
epoch: 109, learning rate 0.000100
epoch: 109, train time every whole data:392.42s
epoch: 109, total time:27410.79s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 55.0717s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEconcat/epoch_109.params
epoch: 110, learning rate 0.000100
epoch: 110, train time every whole data:398.49s
epoch: 110, total time:27864.54s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 52.6918s
epoch: 111, learning rate 0.000100
epoch: 111, train time every whole data:387.67s
epoch: 111, total time:28304.90s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 52.6263s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEconcat/epoch_111.params
epoch: 112, learning rate 0.000100
epoch: 112, train time every whole data:388.93s
epoch: 112, total time:28746.63s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 52.6500s
epoch: 113, learning rate 0.000100
epoch: 113, train time every whole data:387.84s
epoch: 113, total time:29187.13s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 56.2759s
epoch: 114, learning rate 0.000100
epoch: 114, train time every whole data:405.76s
epoch: 114, total time:29649.17s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 52.6449s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEconcat/epoch_114.params
epoch: 115, learning rate 0.000100
epoch: 115, train time every whole data:387.52s
epoch: 115, total time:30089.47s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 52.5482s
epoch: 116, learning rate 0.000100
epoch: 116, train time every whole data:387.29s
epoch: 116, total time:30529.32s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 52.5886s
epoch: 117, learning rate 0.000100
epoch: 117, train time every whole data:390.72s
epoch: 117, total time:30972.63s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 52.6792s
epoch: 118, learning rate 0.000100
epoch: 118, train time every whole data:388.35s
epoch: 118, total time:31413.66s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 52.7259s
epoch: 119, learning rate 0.000100
epoch: 119, train time every whole data:393.75s
epoch: 119, total time:31860.15s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 55.9844s
epoch: 120, learning rate 0.000100
epoch: 120, train time every whole data:390.54s
epoch: 120, total time:32306.68s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 52.6789s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEconcat/epoch_120.params
epoch: 121, learning rate 0.000100
epoch: 121, train time every whole data:387.41s
epoch: 121, total time:32746.93s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 52.6116s
epoch: 122, learning rate 0.000100
epoch: 122, train time every whole data:393.61s
epoch: 122, total time:33193.15s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 52.6826s
epoch: 123, learning rate 0.000100
epoch: 123, train time every whole data:388.47s
epoch: 123, total time:33634.30s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 52.5663s
epoch: 124, learning rate 0.000100
epoch: 124, train time every whole data:391.67s
epoch: 124, total time:34078.55s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 52.5516s
epoch: 125, learning rate 0.000100
epoch: 125, train time every whole data:389.92s
epoch: 125, total time:34521.02s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 55.5825s
epoch: 126, learning rate 0.000100
epoch: 126, train time every whole data:398.32s
epoch: 126, total time:34974.92s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 52.7299s
epoch: 127, learning rate 0.000100
epoch: 127, train time every whole data:387.73s
epoch: 127, total time:35415.39s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 52.6757s
epoch: 128, learning rate 0.000100
epoch: 128, train time every whole data:389.43s
epoch: 128, total time:35857.50s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 55.7328s
epoch: 129, learning rate 0.000100
epoch: 129, train time every whole data:393.08s
epoch: 129, total time:36306.32s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 52.7417s
epoch: 130, learning rate 0.000100
epoch: 130, train time every whole data:389.84s
epoch: 130, total time:36748.90s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 52.5777s
epoch: 131, learning rate 0.000100
epoch: 131, train time every whole data:388.97s
epoch: 131, total time:37190.45s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 52.5020s
epoch: 132, learning rate 0.000100
epoch: 132, train time every whole data:388.74s
epoch: 132, total time:37631.70s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 52.4887s
epoch: 133, learning rate 0.000100
epoch: 133, train time every whole data:386.92s
epoch: 133, total time:38071.11s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 53.1150s
epoch: 134, learning rate 0.000100
epoch: 134, train time every whole data:392.37s
epoch: 134, total time:38516.60s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 52.6658s
epoch: 135, learning rate 0.000100
epoch: 135, train time every whole data:386.81s
epoch: 135, total time:38956.08s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 52.7121s
epoch: 136, learning rate 0.000100
epoch: 136, train time every whole data:387.09s
epoch: 136, total time:39395.89s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 52.6181s
epoch: 137, learning rate 0.000100
epoch: 137, train time every whole data:390.67s
epoch: 137, total time:39839.18s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 52.6615s
epoch: 138, learning rate 0.000100
epoch: 138, train time every whole data:387.81s
epoch: 138, total time:40279.65s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 52.6212s
epoch: 139, learning rate 0.000100
epoch: 139, train time every whole data:388.30s
epoch: 139, total time:40720.58s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 52.5410s
epoch: 140, learning rate 0.000100
epoch: 140, train time every whole data:388.01s
epoch: 140, total time:41161.13s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 52.6408s
epoch: 141, learning rate 0.000100
epoch: 141, train time every whole data:390.20s
epoch: 141, total time:41603.97s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 52.7600s
epoch: 142, learning rate 0.000100
epoch: 142, train time every whole data:387.27s
epoch: 142, total time:42044.00s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 52.6353s
epoch: 143, learning rate 0.000100
epoch: 143, train time every whole data:390.15s
epoch: 143, total time:42486.79s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 52.7028s
epoch: 144, learning rate 0.000100
epoch: 144, train time every whole data:393.32s
epoch: 144, total time:42932.82s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 52.6477s
epoch: 145, learning rate 0.000100
epoch: 145, train time every whole data:389.56s
epoch: 145, total time:43375.03s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 52.7572s
epoch: 146, learning rate 0.000100
epoch: 146, train time every whole data:391.40s
epoch: 146, total time:43819.20s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 52.6728s
epoch: 147, learning rate 0.000100
epoch: 147, train time every whole data:394.09s
epoch: 147, total time:44265.96s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 52.6230s
epoch: 148, learning rate 0.000100
epoch: 148, train time every whole data:386.82s
epoch: 148, total time:44705.41s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 57.5713s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEconcat/epoch_148.params
epoch: 149, learning rate 0.000100
epoch: 149, train time every whole data:387.00s
epoch: 149, total time:45150.09s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.01
validation cost time: 52.5676s
best epoch: 148
apply the best val model on the test data set ...
load weight from: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEconcat/epoch_148.params
predicting testing set batch 1 / 168, time: 0.31s
predicting testing set batch 101 / 168, time: 31.58s
test time on whole data:52.60s
input: (672, 250, 12, 2)
prediction: (672, 250, 12, 2)
data_target_tensor: (672, 250, 12, 2)
current epoch: 148, predict 0 points
MAE: 1.46
RMSE: 2.38
MAPE: 54.18
PCC: 0.86
current epoch: 148, predict 1 points
MAE: 1.53
RMSE: 2.51
MAPE: 55.54
PCC: 0.84
current epoch: 148, predict 2 points
MAE: 1.56
RMSE: 2.58
MAPE: 56.11
PCC: 0.84
current epoch: 148, predict 3 points
MAE: 1.60
RMSE: 2.65
MAPE: 56.73
PCC: 0.83
current epoch: 148, predict 4 points
MAE: 1.64
RMSE: 2.73
MAPE: 57.27
PCC: 0.82
current epoch: 148, predict 5 points
MAE: 1.68
RMSE: 2.81
MAPE: 57.81
PCC: 0.81
current epoch: 148, predict 6 points
MAE: 1.71
RMSE: 2.90
MAPE: 58.25
PCC: 0.80
current epoch: 148, predict 7 points
MAE: 1.72
RMSE: 2.93
MAPE: 58.31
PCC: 0.79
current epoch: 148, predict 8 points
MAE: 1.73
RMSE: 2.95
MAPE: 58.75
PCC: 0.78
current epoch: 148, predict 9 points
MAE: 1.74
RMSE: 2.95
MAPE: 59.49
PCC: 0.78
current epoch: 148, predict 10 points
MAE: 1.75
RMSE: 2.97
MAPE: 60.41
PCC: 0.78
current epoch: 148, predict 11 points
MAE: 1.77
RMSE: 2.98
MAPE: 61.18
PCC: 0.77
all MAE: 1.66
all RMSE: 2.79
all MAPE: 57.83
all PCC: 0.77
1.4633142435256214 2.3820680127087557 54.17841201711215 0.8589655250685425 
1.530649916150563 2.508953324402497 55.544695136021595 0.8448192411606233 
1.5633407868508782 2.5805202306718917 56.10537468969853 0.8368851929728526 
1.5961826647616746 2.6500008432822 56.726277802709355 0.8293671097236359 
1.6372900290035952 2.7301736116756508 57.265915858526974 0.8201344613863604 
1.6755286517510457 2.814798161654936 57.805853648311846 0.8081611418644958 
1.7077936895409864 2.8963083608026237 58.25070605297855 0.7951283150386346 
1.7228273731330852 2.931444275504796 58.3075554638117 0.7888628752216907 
1.7341011432579585 2.950132997041023 58.74639129065233 0.7842929230394817 
1.7421794752053739 2.9522958257808294 59.48586740628411 0.781820885745224 
1.7521392544594017 2.965241026083896 60.407462765203654 0.7773509055892633 
1.7651498412471265 2.980855538574697 61.177573661600505 0.7736766133352349 
1.6575414224072758 2.78548436334495 57.83361422787533 0.7736766133352349 
