CUDA: True cuda:0
Read configuration file: configurations/bike.conf
total training epoch, fine tune epoch: 100 , 50
batch_size: 4
folder_dir: MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_sharespatial
load file: data/bike.npz
ori length: 3001 , percent: 1.0 , scale: 3001
train: torch.Size([3001, 250, 2, 12]) torch.Size([3001, 250, 2, 12]) torch.Size([3001, 250, 2, 12])
val: torch.Size([672, 250, 2, 12]) torch.Size([672, 250, 2, 12]) torch.Size([672, 250, 2, 12])
test: torch.Size([672, 250, 2, 12]) torch.Size([672, 250, 2, 12]) torch.Size([672, 250, 2, 12])
TemporalPositionalEncoding max_len: 12
h_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
en_lookup_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
EncoderDecoder(
  (encoder): Encoder(
    (layers): ModuleList(
      (0): EncoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=128, out_features=128, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (tcn2): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (1): EncoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=128, out_features=128, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (tcn2): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (2): EncoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=128, out_features=128, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (tcn2): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (3): EncoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=128, out_features=128, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (tcn2): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): Decoder(
    (layers): ModuleList(
      (0): DecoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (1): DecoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (2): DecoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (3): DecoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (decoder2): Decoder(
    (layers): ModuleList(
      (0): DecoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (1): DecoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (2): DecoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (3): DecoderLayer(
        (self_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadAttention(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): Linear(in_features=64, out_features=64, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (tcn): TCN(
          (filter_convs): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (gate_convs): Conv1d(64, 64, kernel_size=(1, 3), stride=(1,), padding=(0, 1))
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (3): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (src_embed): Sequential(
    (0): Linear(in_features=1, out_features=64, bias=True)
    (1): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (2): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(250, 64)
    )
  )
  (src_embed2): Sequential(
    (0): Linear(in_features=1, out_features=64, bias=True)
    (1): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (2): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(250, 64)
    )
  )
  (trg_embed): Sequential(
    (0): Linear(in_features=1, out_features=64, bias=True)
    (1): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (2): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(250, 64)
    )
  )
  (trg_embed2): Sequential(
    (0): Linear(in_features=1, out_features=64, bias=True)
    (1): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (2): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(250, 64)
    )
  )
  (prediction_generator): Linear(in_features=64, out_features=1, bias=True)
  (prediction_generator2): Linear(in_features=64, out_features=1, bias=True)
)
delete the old one and create params directory experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_sharespatial
Net's state_dict:
encoder.layers.0.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.linears.2.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.linears.2.bias 	 torch.Size([64])
encoder.layers.0.self_attn.linears.3.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.linears.3.bias 	 torch.Size([64])
encoder.layers.0.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([128, 128])
encoder.layers.0.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.tcn.filter_convs.bias 	 torch.Size([64])
encoder.layers.0.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.tcn.gate_convs.bias 	 torch.Size([64])
encoder.layers.0.tcn2.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.tcn2.filter_convs.bias 	 torch.Size([64])
encoder.layers.0.tcn2.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.tcn2.gate_convs.bias 	 torch.Size([64])
encoder.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.2.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.2.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.3.norm.weight 	 torch.Size([128])
encoder.layers.0.sublayer.3.norm.bias 	 torch.Size([128])
encoder.layers.1.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.linears.2.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.linears.2.bias 	 torch.Size([64])
encoder.layers.1.self_attn.linears.3.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.linears.3.bias 	 torch.Size([64])
encoder.layers.1.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([128, 128])
encoder.layers.1.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.tcn.filter_convs.bias 	 torch.Size([64])
encoder.layers.1.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.tcn.gate_convs.bias 	 torch.Size([64])
encoder.layers.1.tcn2.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.tcn2.filter_convs.bias 	 torch.Size([64])
encoder.layers.1.tcn2.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.tcn2.gate_convs.bias 	 torch.Size([64])
encoder.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.2.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.2.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.3.norm.weight 	 torch.Size([128])
encoder.layers.1.sublayer.3.norm.bias 	 torch.Size([128])
encoder.layers.2.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.linears.2.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.linears.2.bias 	 torch.Size([64])
encoder.layers.2.self_attn.linears.3.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.linears.3.bias 	 torch.Size([64])
encoder.layers.2.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([128, 128])
encoder.layers.2.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.tcn.filter_convs.bias 	 torch.Size([64])
encoder.layers.2.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.tcn.gate_convs.bias 	 torch.Size([64])
encoder.layers.2.tcn2.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.tcn2.filter_convs.bias 	 torch.Size([64])
encoder.layers.2.tcn2.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.tcn2.gate_convs.bias 	 torch.Size([64])
encoder.layers.2.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.2.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.2.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.3.norm.weight 	 torch.Size([128])
encoder.layers.2.sublayer.3.norm.bias 	 torch.Size([128])
encoder.layers.3.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.3.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.3.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.3.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.3.self_attn.linears.2.weight 	 torch.Size([64, 64])
encoder.layers.3.self_attn.linears.2.bias 	 torch.Size([64])
encoder.layers.3.self_attn.linears.3.weight 	 torch.Size([64, 64])
encoder.layers.3.self_attn.linears.3.bias 	 torch.Size([64])
encoder.layers.3.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([128, 128])
encoder.layers.3.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.3.tcn.filter_convs.bias 	 torch.Size([64])
encoder.layers.3.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.3.tcn.gate_convs.bias 	 torch.Size([64])
encoder.layers.3.tcn2.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.3.tcn2.filter_convs.bias 	 torch.Size([64])
encoder.layers.3.tcn2.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.3.tcn2.gate_convs.bias 	 torch.Size([64])
encoder.layers.3.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.3.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.3.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.3.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.3.sublayer.2.norm.weight 	 torch.Size([64])
encoder.layers.3.sublayer.2.norm.bias 	 torch.Size([64])
encoder.layers.3.sublayer.3.norm.weight 	 torch.Size([128])
encoder.layers.3.sublayer.3.norm.bias 	 torch.Size([128])
encoder.norm.weight 	 torch.Size([64])
encoder.norm.bias 	 torch.Size([64])
encoder.norm2.weight 	 torch.Size([64])
encoder.norm2.bias 	 torch.Size([64])
decoder.layers.0.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.0.self_attn.linears.2.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.linears.2.bias 	 torch.Size([64])
decoder.layers.0.self_attn.linears.3.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.linears.3.bias 	 torch.Size([64])
decoder.layers.0.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.0.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.linears.2.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.linears.2.bias 	 torch.Size([64])
decoder.layers.0.src_attn.linears.3.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.linears.3.bias 	 torch.Size([64])
decoder.layers.0.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.0.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.tcn.filter_convs.bias 	 torch.Size([64])
decoder.layers.0.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.tcn.gate_convs.bias 	 torch.Size([64])
decoder.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.3.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.3.norm.bias 	 torch.Size([64])
decoder.layers.1.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.1.self_attn.linears.2.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.linears.2.bias 	 torch.Size([64])
decoder.layers.1.self_attn.linears.3.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.linears.3.bias 	 torch.Size([64])
decoder.layers.1.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.1.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.linears.2.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.linears.2.bias 	 torch.Size([64])
decoder.layers.1.src_attn.linears.3.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.linears.3.bias 	 torch.Size([64])
decoder.layers.1.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.1.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.tcn.filter_convs.bias 	 torch.Size([64])
decoder.layers.1.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.tcn.gate_convs.bias 	 torch.Size([64])
decoder.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.3.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.3.norm.bias 	 torch.Size([64])
decoder.layers.2.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.2.self_attn.linears.2.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.linears.2.bias 	 torch.Size([64])
decoder.layers.2.self_attn.linears.3.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.linears.3.bias 	 torch.Size([64])
decoder.layers.2.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.2.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.linears.2.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.linears.2.bias 	 torch.Size([64])
decoder.layers.2.src_attn.linears.3.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.linears.3.bias 	 torch.Size([64])
decoder.layers.2.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.2.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.tcn.filter_convs.bias 	 torch.Size([64])
decoder.layers.2.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.tcn.gate_convs.bias 	 torch.Size([64])
decoder.layers.2.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.3.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.3.norm.bias 	 torch.Size([64])
decoder.layers.3.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.3.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.3.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.3.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.3.self_attn.linears.2.weight 	 torch.Size([64, 64])
decoder.layers.3.self_attn.linears.2.bias 	 torch.Size([64])
decoder.layers.3.self_attn.linears.3.weight 	 torch.Size([64, 64])
decoder.layers.3.self_attn.linears.3.bias 	 torch.Size([64])
decoder.layers.3.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.3.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.3.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.3.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.3.src_attn.linears.2.weight 	 torch.Size([64, 64])
decoder.layers.3.src_attn.linears.2.bias 	 torch.Size([64])
decoder.layers.3.src_attn.linears.3.weight 	 torch.Size([64, 64])
decoder.layers.3.src_attn.linears.3.bias 	 torch.Size([64])
decoder.layers.3.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.3.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.3.tcn.filter_convs.bias 	 torch.Size([64])
decoder.layers.3.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.3.tcn.gate_convs.bias 	 torch.Size([64])
decoder.layers.3.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.3.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.3.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.3.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.3.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.3.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.3.sublayer.3.norm.weight 	 torch.Size([64])
decoder.layers.3.sublayer.3.norm.bias 	 torch.Size([64])
decoder.norm.weight 	 torch.Size([64])
decoder.norm.bias 	 torch.Size([64])
decoder2.layers.0.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder2.layers.0.self_attn.linears.0.bias 	 torch.Size([64])
decoder2.layers.0.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder2.layers.0.self_attn.linears.1.bias 	 torch.Size([64])
decoder2.layers.0.self_attn.linears.2.weight 	 torch.Size([64, 64])
decoder2.layers.0.self_attn.linears.2.bias 	 torch.Size([64])
decoder2.layers.0.self_attn.linears.3.weight 	 torch.Size([64, 64])
decoder2.layers.0.self_attn.linears.3.bias 	 torch.Size([64])
decoder2.layers.0.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder2.layers.0.src_attn.linears.0.bias 	 torch.Size([64])
decoder2.layers.0.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder2.layers.0.src_attn.linears.1.bias 	 torch.Size([64])
decoder2.layers.0.src_attn.linears.2.weight 	 torch.Size([64, 64])
decoder2.layers.0.src_attn.linears.2.bias 	 torch.Size([64])
decoder2.layers.0.src_attn.linears.3.weight 	 torch.Size([64, 64])
decoder2.layers.0.src_attn.linears.3.bias 	 torch.Size([64])
decoder2.layers.0.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder2.layers.0.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder2.layers.0.tcn.filter_convs.bias 	 torch.Size([64])
decoder2.layers.0.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder2.layers.0.tcn.gate_convs.bias 	 torch.Size([64])
decoder2.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
decoder2.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
decoder2.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
decoder2.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
decoder2.layers.0.sublayer.2.norm.weight 	 torch.Size([64])
decoder2.layers.0.sublayer.2.norm.bias 	 torch.Size([64])
decoder2.layers.0.sublayer.3.norm.weight 	 torch.Size([64])
decoder2.layers.0.sublayer.3.norm.bias 	 torch.Size([64])
decoder2.layers.1.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder2.layers.1.self_attn.linears.0.bias 	 torch.Size([64])
decoder2.layers.1.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder2.layers.1.self_attn.linears.1.bias 	 torch.Size([64])
decoder2.layers.1.self_attn.linears.2.weight 	 torch.Size([64, 64])
decoder2.layers.1.self_attn.linears.2.bias 	 torch.Size([64])
decoder2.layers.1.self_attn.linears.3.weight 	 torch.Size([64, 64])
decoder2.layers.1.self_attn.linears.3.bias 	 torch.Size([64])
decoder2.layers.1.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder2.layers.1.src_attn.linears.0.bias 	 torch.Size([64])
decoder2.layers.1.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder2.layers.1.src_attn.linears.1.bias 	 torch.Size([64])
decoder2.layers.1.src_attn.linears.2.weight 	 torch.Size([64, 64])
decoder2.layers.1.src_attn.linears.2.bias 	 torch.Size([64])
decoder2.layers.1.src_attn.linears.3.weight 	 torch.Size([64, 64])
decoder2.layers.1.src_attn.linears.3.bias 	 torch.Size([64])
decoder2.layers.1.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder2.layers.1.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder2.layers.1.tcn.filter_convs.bias 	 torch.Size([64])
decoder2.layers.1.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder2.layers.1.tcn.gate_convs.bias 	 torch.Size([64])
decoder2.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
decoder2.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
decoder2.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
decoder2.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
decoder2.layers.1.sublayer.2.norm.weight 	 torch.Size([64])
decoder2.layers.1.sublayer.2.norm.bias 	 torch.Size([64])
decoder2.layers.1.sublayer.3.norm.weight 	 torch.Size([64])
decoder2.layers.1.sublayer.3.norm.bias 	 torch.Size([64])
decoder2.layers.2.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder2.layers.2.self_attn.linears.0.bias 	 torch.Size([64])
decoder2.layers.2.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder2.layers.2.self_attn.linears.1.bias 	 torch.Size([64])
decoder2.layers.2.self_attn.linears.2.weight 	 torch.Size([64, 64])
decoder2.layers.2.self_attn.linears.2.bias 	 torch.Size([64])
decoder2.layers.2.self_attn.linears.3.weight 	 torch.Size([64, 64])
decoder2.layers.2.self_attn.linears.3.bias 	 torch.Size([64])
decoder2.layers.2.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder2.layers.2.src_attn.linears.0.bias 	 torch.Size([64])
decoder2.layers.2.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder2.layers.2.src_attn.linears.1.bias 	 torch.Size([64])
decoder2.layers.2.src_attn.linears.2.weight 	 torch.Size([64, 64])
decoder2.layers.2.src_attn.linears.2.bias 	 torch.Size([64])
decoder2.layers.2.src_attn.linears.3.weight 	 torch.Size([64, 64])
decoder2.layers.2.src_attn.linears.3.bias 	 torch.Size([64])
decoder2.layers.2.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder2.layers.2.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder2.layers.2.tcn.filter_convs.bias 	 torch.Size([64])
decoder2.layers.2.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder2.layers.2.tcn.gate_convs.bias 	 torch.Size([64])
decoder2.layers.2.sublayer.0.norm.weight 	 torch.Size([64])
decoder2.layers.2.sublayer.0.norm.bias 	 torch.Size([64])
decoder2.layers.2.sublayer.1.norm.weight 	 torch.Size([64])
decoder2.layers.2.sublayer.1.norm.bias 	 torch.Size([64])
decoder2.layers.2.sublayer.2.norm.weight 	 torch.Size([64])
decoder2.layers.2.sublayer.2.norm.bias 	 torch.Size([64])
decoder2.layers.2.sublayer.3.norm.weight 	 torch.Size([64])
decoder2.layers.2.sublayer.3.norm.bias 	 torch.Size([64])
decoder2.layers.3.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder2.layers.3.self_attn.linears.0.bias 	 torch.Size([64])
decoder2.layers.3.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder2.layers.3.self_attn.linears.1.bias 	 torch.Size([64])
decoder2.layers.3.self_attn.linears.2.weight 	 torch.Size([64, 64])
decoder2.layers.3.self_attn.linears.2.bias 	 torch.Size([64])
decoder2.layers.3.self_attn.linears.3.weight 	 torch.Size([64, 64])
decoder2.layers.3.self_attn.linears.3.bias 	 torch.Size([64])
decoder2.layers.3.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder2.layers.3.src_attn.linears.0.bias 	 torch.Size([64])
decoder2.layers.3.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder2.layers.3.src_attn.linears.1.bias 	 torch.Size([64])
decoder2.layers.3.src_attn.linears.2.weight 	 torch.Size([64, 64])
decoder2.layers.3.src_attn.linears.2.bias 	 torch.Size([64])
decoder2.layers.3.src_attn.linears.3.weight 	 torch.Size([64, 64])
decoder2.layers.3.src_attn.linears.3.bias 	 torch.Size([64])
decoder2.layers.3.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder2.layers.3.tcn.filter_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder2.layers.3.tcn.filter_convs.bias 	 torch.Size([64])
decoder2.layers.3.tcn.gate_convs.weight 	 torch.Size([64, 64, 1, 3])
decoder2.layers.3.tcn.gate_convs.bias 	 torch.Size([64])
decoder2.layers.3.sublayer.0.norm.weight 	 torch.Size([64])
decoder2.layers.3.sublayer.0.norm.bias 	 torch.Size([64])
decoder2.layers.3.sublayer.1.norm.weight 	 torch.Size([64])
decoder2.layers.3.sublayer.1.norm.bias 	 torch.Size([64])
decoder2.layers.3.sublayer.2.norm.weight 	 torch.Size([64])
decoder2.layers.3.sublayer.2.norm.bias 	 torch.Size([64])
decoder2.layers.3.sublayer.3.norm.weight 	 torch.Size([64])
decoder2.layers.3.sublayer.3.norm.bias 	 torch.Size([64])
decoder2.norm.weight 	 torch.Size([64])
decoder2.norm.bias 	 torch.Size([64])
src_embed.0.weight 	 torch.Size([64, 1])
src_embed.0.bias 	 torch.Size([64])
src_embed.1.pe 	 torch.Size([1, 1, 12, 64])
src_embed.2.embedding.weight 	 torch.Size([250, 64])
src_embed2.0.weight 	 torch.Size([64, 1])
src_embed2.0.bias 	 torch.Size([64])
src_embed2.1.pe 	 torch.Size([1, 1, 12, 64])
src_embed2.2.embedding.weight 	 torch.Size([250, 64])
trg_embed.0.weight 	 torch.Size([64, 1])
trg_embed.0.bias 	 torch.Size([64])
trg_embed.1.pe 	 torch.Size([1, 1, 12, 64])
trg_embed.2.embedding.weight 	 torch.Size([250, 64])
trg_embed2.0.weight 	 torch.Size([64, 1])
trg_embed2.0.bias 	 torch.Size([64])
trg_embed2.1.pe 	 torch.Size([1, 1, 12, 64])
trg_embed2.2.embedding.weight 	 torch.Size([250, 64])
prediction_generator.weight 	 torch.Size([1, 64])
prediction_generator.bias 	 torch.Size([1])
prediction_generator2.weight 	 torch.Size([1, 64])
prediction_generator2.bias 	 torch.Size([1])
Net's total params: 901250
Optimizer's state_dict:
state 	 {}
param_groups 	 [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355]}]
validation batch 1 / 168, loss: 2.86
validation batch 101 / 168, loss: 2.93
validation cost time: 53.0850s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_sharespatial/epoch_0.params
epoch: 0, learning rate 0.001000
epoch: 0, train time every whole data:176.86s
epoch: 0, total time:230.14s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.13
validation cost time: 58.1436s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_sharespatial/epoch_1.params
epoch: 1, learning rate 0.001000
epoch: 1, train time every whole data:178.01s
epoch: 1, total time:466.43s
validation batch 1 / 168, loss: 0.14
validation batch 101 / 168, loss: 0.12
validation cost time: 53.8590s
epoch: 2, learning rate 0.001000
epoch: 2, train time every whole data:177.83s
epoch: 2, total time:698.13s
validation batch 1 / 168, loss: 0.08
validation batch 101 / 168, loss: 0.05
validation cost time: 53.9657s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_sharespatial/epoch_3.params
epoch: 3, learning rate 0.001000
epoch: 3, train time every whole data:177.47s
epoch: 3, total time:929.77s
validation batch 1 / 168, loss: 0.08
validation batch 101 / 168, loss: 0.08
validation cost time: 53.9070s
epoch: 4, learning rate 0.001000
epoch: 4, train time every whole data:177.67s
epoch: 4, total time:1161.35s
validation batch 1 / 168, loss: 0.08
validation batch 101 / 168, loss: 0.04
validation cost time: 54.0006s
epoch: 5, learning rate 0.001000
epoch: 5, train time every whole data:177.43s
epoch: 5, total time:1392.79s
validation batch 1 / 168, loss: 0.08
validation batch 101 / 168, loss: 0.03
validation cost time: 54.0026s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_sharespatial/epoch_6.params
epoch: 6, learning rate 0.001000
epoch: 6, train time every whole data:177.63s
epoch: 6, total time:1624.80s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.06
validation cost time: 53.8552s
epoch: 7, learning rate 0.001000
epoch: 7, train time every whole data:177.49s
epoch: 7, total time:1856.15s
validation batch 1 / 168, loss: 0.08
validation batch 101 / 168, loss: 0.04
validation cost time: 53.9789s
epoch: 8, learning rate 0.001000
epoch: 8, train time every whole data:177.66s
epoch: 8, total time:2087.79s
validation batch 1 / 168, loss: 0.10
validation batch 101 / 168, loss: 0.02
validation cost time: 53.9663s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_sharespatial/epoch_9.params
epoch: 9, learning rate 0.001000
epoch: 9, train time every whole data:177.96s
epoch: 9, total time:2319.88s
validation batch 1 / 168, loss: 0.08
validation batch 101 / 168, loss: 0.03
validation cost time: 54.0243s
epoch: 10, learning rate 0.001000
epoch: 10, train time every whole data:178.30s
epoch: 10, total time:2552.21s
validation batch 1 / 168, loss: 0.08
validation batch 101 / 168, loss: 0.02
validation cost time: 54.1341s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_sharespatial/epoch_11.params
epoch: 11, learning rate 0.001000
epoch: 11, train time every whole data:178.46s
epoch: 11, total time:2784.97s
validation batch 1 / 168, loss: 0.08
validation batch 101 / 168, loss: 0.03
validation cost time: 53.8464s
epoch: 12, learning rate 0.001000
epoch: 12, train time every whole data:177.95s
epoch: 12, total time:3016.77s
validation batch 1 / 168, loss: 0.05
validation batch 101 / 168, loss: 0.02
validation cost time: 54.0022s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_sharespatial/epoch_13.params
epoch: 13, learning rate 0.001000
epoch: 13, train time every whole data:178.24s
epoch: 13, total time:3249.18s
validation batch 1 / 168, loss: 0.05
validation batch 101 / 168, loss: 0.02
validation cost time: 54.1847s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_sharespatial/epoch_14.params
epoch: 14, learning rate 0.001000
epoch: 14, train time every whole data:178.00s
epoch: 14, total time:3481.53s
validation batch 1 / 168, loss: 0.09
validation batch 101 / 168, loss: 0.02
validation cost time: 54.0332s
epoch: 15, learning rate 0.001000
epoch: 15, train time every whole data:178.27s
epoch: 15, total time:3713.84s
validation batch 1 / 168, loss: 0.05
validation batch 101 / 168, loss: 0.03
validation cost time: 54.2002s
epoch: 16, learning rate 0.001000
epoch: 16, train time every whole data:178.12s
epoch: 16, total time:3946.17s
validation batch 1 / 168, loss: 0.06
validation batch 101 / 168, loss: 0.02
validation cost time: 53.9449s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_sharespatial/epoch_17.params
epoch: 17, learning rate 0.001000
epoch: 17, train time every whole data:178.19s
epoch: 17, total time:4178.49s
validation batch 1 / 168, loss: 0.07
validation batch 101 / 168, loss: 0.03
validation cost time: 54.1268s
epoch: 18, learning rate 0.001000
epoch: 18, train time every whole data:178.11s
epoch: 18, total time:4410.73s
validation batch 1 / 168, loss: 0.05
validation batch 101 / 168, loss: 0.02
validation cost time: 54.1116s
epoch: 19, learning rate 0.001000
epoch: 19, train time every whole data:177.95s
epoch: 19, total time:4642.81s
validation batch 1 / 168, loss: 0.08
validation batch 101 / 168, loss: 0.02
validation cost time: 54.0216s
epoch: 20, learning rate 0.001000
epoch: 20, train time every whole data:178.13s
epoch: 20, total time:4874.96s
validation batch 1 / 168, loss: 0.10
validation batch 101 / 168, loss: 0.02
validation cost time: 53.9333s
epoch: 21, learning rate 0.001000
epoch: 21, train time every whole data:178.33s
epoch: 21, total time:5107.22s
validation batch 1 / 168, loss: 0.10
validation batch 101 / 168, loss: 0.02
validation cost time: 54.0325s
epoch: 22, learning rate 0.001000
epoch: 22, train time every whole data:178.14s
epoch: 22, total time:5339.40s
validation batch 1 / 168, loss: 0.10
validation batch 101 / 168, loss: 0.02
validation cost time: 54.1495s
epoch: 23, learning rate 0.001000
epoch: 23, train time every whole data:177.86s
epoch: 23, total time:5571.41s
validation batch 1 / 168, loss: 0.10
validation batch 101 / 168, loss: 0.02
validation cost time: 54.0594s
epoch: 24, learning rate 0.001000
epoch: 24, train time every whole data:177.88s
epoch: 24, total time:5803.35s
validation batch 1 / 168, loss: 0.09
validation batch 101 / 168, loss: 0.02
validation cost time: 54.0157s
epoch: 25, learning rate 0.001000
epoch: 25, train time every whole data:178.35s
epoch: 25, total time:6035.72s
validation batch 1 / 168, loss: 0.10
validation batch 101 / 168, loss: 0.02
validation cost time: 53.9924s
epoch: 26, learning rate 0.001000
epoch: 26, train time every whole data:178.06s
epoch: 26, total time:6267.78s
validation batch 1 / 168, loss: 0.08
validation batch 101 / 168, loss: 0.02
validation cost time: 54.2792s
epoch: 27, learning rate 0.001000
epoch: 27, train time every whole data:177.99s
epoch: 27, total time:6500.05s
validation batch 1 / 168, loss: 0.09
validation batch 101 / 168, loss: 0.02
validation cost time: 53.9544s
epoch: 28, learning rate 0.001000
epoch: 28, train time every whole data:177.92s
epoch: 28, total time:6731.93s
validation batch 1 / 168, loss: 0.14
validation batch 101 / 168, loss: 0.02
validation cost time: 54.0338s
epoch: 29, learning rate 0.001000
epoch: 29, train time every whole data:178.11s
epoch: 29, total time:6964.08s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 53.9511s
epoch: 30, learning rate 0.001000
epoch: 30, train time every whole data:177.80s
epoch: 30, total time:7195.84s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 57.1122s
epoch: 31, learning rate 0.001000
epoch: 31, train time every whole data:178.20s
epoch: 31, total time:7431.15s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 53.9763s
epoch: 32, learning rate 0.001000
epoch: 32, train time every whole data:178.02s
epoch: 32, total time:7663.15s
validation batch 1 / 168, loss: 0.17
validation batch 101 / 168, loss: 0.02
validation cost time: 53.9424s
epoch: 33, learning rate 0.001000
epoch: 33, train time every whole data:178.01s
epoch: 33, total time:7895.11s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 54.1584s
epoch: 34, learning rate 0.001000
epoch: 34, train time every whole data:178.10s
epoch: 34, total time:8127.38s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 55.4374s
epoch: 35, learning rate 0.001000
epoch: 35, train time every whole data:178.16s
epoch: 35, total time:8360.97s
validation batch 1 / 168, loss: 0.15
validation batch 101 / 168, loss: 0.02
validation cost time: 53.9889s
epoch: 36, learning rate 0.001000
epoch: 36, train time every whole data:178.04s
epoch: 36, total time:8593.01s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 53.9985s
epoch: 37, learning rate 0.001000
epoch: 37, train time every whole data:178.13s
epoch: 37, total time:8825.15s
validation batch 1 / 168, loss: 0.14
validation batch 101 / 168, loss: 0.02
validation cost time: 54.0658s
epoch: 38, learning rate 0.001000
epoch: 38, train time every whole data:177.82s
epoch: 38, total time:9057.03s
validation batch 1 / 168, loss: 0.17
validation batch 101 / 168, loss: 0.02
validation cost time: 54.0460s
epoch: 39, learning rate 0.001000
epoch: 39, train time every whole data:177.69s
epoch: 39, total time:9288.77s
validation batch 1 / 168, loss: 0.16
validation batch 101 / 168, loss: 0.02
validation cost time: 53.9792s
epoch: 40, learning rate 0.001000
epoch: 40, train time every whole data:177.80s
epoch: 40, total time:9520.56s
validation batch 1 / 168, loss: 0.15
validation batch 101 / 168, loss: 0.02
validation cost time: 54.0011s
epoch: 41, learning rate 0.001000
epoch: 41, train time every whole data:177.79s
epoch: 41, total time:9752.36s
validation batch 1 / 168, loss: 0.17
validation batch 101 / 168, loss: 0.02
validation cost time: 53.3791s
epoch: 42, learning rate 0.001000
epoch: 42, train time every whole data:177.89s
epoch: 42, total time:9983.64s
validation batch 1 / 168, loss: 0.13
validation batch 101 / 168, loss: 0.02
validation cost time: 54.2195s
epoch: 43, learning rate 0.001000
epoch: 43, train time every whole data:177.80s
epoch: 43, total time:10215.66s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 54.0784s
epoch: 44, learning rate 0.001000
epoch: 44, train time every whole data:177.86s
epoch: 44, total time:10447.60s
validation batch 1 / 168, loss: 0.16
validation batch 101 / 168, loss: 0.02
validation cost time: 53.9886s
epoch: 45, learning rate 0.001000
epoch: 45, train time every whole data:178.35s
epoch: 45, total time:10679.95s
validation batch 1 / 168, loss: 0.17
validation batch 101 / 168, loss: 0.02
validation cost time: 54.0800s
epoch: 46, learning rate 0.001000
epoch: 46, train time every whole data:177.61s
epoch: 46, total time:10911.64s
validation batch 1 / 168, loss: 0.14
validation batch 101 / 168, loss: 0.02
validation cost time: 54.0885s
epoch: 47, learning rate 0.001000
epoch: 47, train time every whole data:177.86s
epoch: 47, total time:11143.60s
validation batch 1 / 168, loss: 0.12
validation batch 101 / 168, loss: 0.02
validation cost time: 54.0604s
epoch: 48, learning rate 0.001000
epoch: 48, train time every whole data:177.87s
epoch: 48, total time:11375.53s
validation batch 1 / 168, loss: 0.18
validation batch 101 / 168, loss: 0.02
validation cost time: 53.9976s
epoch: 49, learning rate 0.001000
epoch: 49, train time every whole data:178.19s
epoch: 49, total time:11607.72s
validation batch 1 / 168, loss: 0.16
validation batch 101 / 168, loss: 0.02
validation cost time: 54.0779s
epoch: 50, learning rate 0.001000
epoch: 50, train time every whole data:177.77s
epoch: 50, total time:11839.58s
validation batch 1 / 168, loss: 0.11
validation batch 101 / 168, loss: 0.02
validation cost time: 53.9579s
epoch: 51, learning rate 0.001000
epoch: 51, train time every whole data:177.74s
epoch: 51, total time:12071.28s
validation batch 1 / 168, loss: 0.14
validation batch 101 / 168, loss: 0.02
validation cost time: 54.0111s
epoch: 52, learning rate 0.001000
epoch: 52, train time every whole data:177.96s
epoch: 52, total time:12303.26s
validation batch 1 / 168, loss: 0.16
validation batch 101 / 168, loss: 0.02
validation cost time: 54.0067s
epoch: 53, learning rate 0.001000
epoch: 53, train time every whole data:177.86s
epoch: 53, total time:12535.12s
validation batch 1 / 168, loss: 0.15
validation batch 101 / 168, loss: 0.02
validation cost time: 59.0067s
epoch: 54, learning rate 0.001000
epoch: 54, train time every whole data:177.82s
epoch: 54, total time:12771.96s
validation batch 1 / 168, loss: 0.15
validation batch 101 / 168, loss: 0.02
validation cost time: 53.9176s
epoch: 55, learning rate 0.001000
epoch: 55, train time every whole data:178.18s
epoch: 55, total time:13004.05s
validation batch 1 / 168, loss: 0.16
validation batch 101 / 168, loss: 0.02
validation cost time: 54.0893s
epoch: 56, learning rate 0.001000
epoch: 56, train time every whole data:177.84s
epoch: 56, total time:13235.98s
validation batch 1 / 168, loss: 0.16
validation batch 101 / 168, loss: 0.02
validation cost time: 53.9522s
epoch: 57, learning rate 0.001000
epoch: 57, train time every whole data:177.97s
epoch: 57, total time:13467.91s
validation batch 1 / 168, loss: 0.14
validation batch 101 / 168, loss: 0.02
validation cost time: 54.2000s
epoch: 58, learning rate 0.001000
epoch: 58, train time every whole data:178.09s
epoch: 58, total time:13700.20s
validation batch 1 / 168, loss: 0.17
validation batch 101 / 168, loss: 0.02
validation cost time: 54.1161s
epoch: 59, learning rate 0.001000
epoch: 59, train time every whole data:177.94s
epoch: 59, total time:13932.27s
validation batch 1 / 168, loss: 0.17
validation batch 101 / 168, loss: 0.02
validation cost time: 54.1075s
epoch: 60, learning rate 0.001000
epoch: 60, train time every whole data:178.27s
epoch: 60, total time:14164.65s
validation batch 1 / 168, loss: 0.19
validation batch 101 / 168, loss: 0.02
validation cost time: 54.0875s
epoch: 61, learning rate 0.001000
epoch: 61, train time every whole data:178.03s
epoch: 61, total time:14396.77s
validation batch 1 / 168, loss: 0.17
validation batch 101 / 168, loss: 0.02
validation cost time: 54.1708s
epoch: 62, learning rate 0.001000
epoch: 62, train time every whole data:177.83s
epoch: 62, total time:14628.78s
validation batch 1 / 168, loss: 0.16
validation batch 101 / 168, loss: 0.02
validation cost time: 54.1008s
epoch: 63, learning rate 0.001000
epoch: 63, train time every whole data:178.11s
epoch: 63, total time:14861.00s
validation batch 1 / 168, loss: 0.15
validation batch 101 / 168, loss: 0.02
validation cost time: 54.2662s
epoch: 64, learning rate 0.001000
epoch: 64, train time every whole data:178.05s
epoch: 64, total time:15093.32s
validation batch 1 / 168, loss: 0.16
validation batch 101 / 168, loss: 0.02
validation cost time: 53.9815s
epoch: 65, learning rate 0.001000
epoch: 65, train time every whole data:178.06s
epoch: 65, total time:15325.36s
validation batch 1 / 168, loss: 0.18
validation batch 101 / 168, loss: 0.02
validation cost time: 54.0343s
epoch: 66, learning rate 0.001000
epoch: 66, train time every whole data:178.23s
epoch: 66, total time:15557.63s
validation batch 1 / 168, loss: 0.16
validation batch 101 / 168, loss: 0.02
validation cost time: 54.1878s
epoch: 67, learning rate 0.001000
epoch: 67, train time every whole data:178.14s
epoch: 67, total time:15789.96s
validation batch 1 / 168, loss: 0.18
validation batch 101 / 168, loss: 0.02
validation cost time: 55.2934s
epoch: 68, learning rate 0.001000
epoch: 68, train time every whole data:177.86s
epoch: 68, total time:16023.12s
validation batch 1 / 168, loss: 0.17
validation batch 101 / 168, loss: 0.02
validation cost time: 54.0343s
epoch: 69, learning rate 0.001000
epoch: 69, train time every whole data:178.33s
epoch: 69, total time:16255.49s
validation batch 1 / 168, loss: 0.17
validation batch 101 / 168, loss: 0.02
validation cost time: 54.2330s
epoch: 70, learning rate 0.001000
epoch: 70, train time every whole data:178.13s
epoch: 70, total time:16487.86s
validation batch 1 / 168, loss: 0.17
validation batch 101 / 168, loss: 0.02
validation cost time: 54.0859s
epoch: 71, learning rate 0.001000
epoch: 71, train time every whole data:178.16s
epoch: 71, total time:16720.11s
validation batch 1 / 168, loss: 0.17
validation batch 101 / 168, loss: 0.02
validation cost time: 54.2222s
epoch: 72, learning rate 0.001000
epoch: 72, train time every whole data:178.00s
epoch: 72, total time:16952.34s
validation batch 1 / 168, loss: 0.16
validation batch 101 / 168, loss: 0.02
validation cost time: 54.0128s
epoch: 73, learning rate 0.001000
epoch: 73, train time every whole data:177.81s
epoch: 73, total time:17184.17s
validation batch 1 / 168, loss: 0.18
validation batch 101 / 168, loss: 0.02
validation cost time: 54.0097s
epoch: 74, learning rate 0.001000
epoch: 74, train time every whole data:177.90s
epoch: 74, total time:17416.08s
validation batch 1 / 168, loss: 0.19
validation batch 101 / 168, loss: 0.02
validation cost time: 54.1444s
epoch: 75, learning rate 0.001000
epoch: 75, train time every whole data:177.87s
epoch: 75, total time:17648.10s
validation batch 1 / 168, loss: 0.17
validation batch 101 / 168, loss: 0.02
validation cost time: 54.1031s
epoch: 76, learning rate 0.001000
epoch: 76, train time every whole data:178.30s
epoch: 76, total time:17880.51s
validation batch 1 / 168, loss: 0.16
validation batch 101 / 168, loss: 0.02
validation cost time: 54.1626s
epoch: 77, learning rate 0.001000
epoch: 77, train time every whole data:178.00s
epoch: 77, total time:18112.68s
validation batch 1 / 168, loss: 0.15
validation batch 101 / 168, loss: 0.02
validation cost time: 54.1061s
epoch: 78, learning rate 0.001000
epoch: 78, train time every whole data:178.17s
epoch: 78, total time:18344.96s
validation batch 1 / 168, loss: 0.19
validation batch 101 / 168, loss: 0.02
validation cost time: 54.0933s
epoch: 79, learning rate 0.001000
epoch: 79, train time every whole data:178.27s
epoch: 79, total time:18577.33s
validation batch 1 / 168, loss: 0.17
validation batch 101 / 168, loss: 0.02
validation cost time: 57.3366s
epoch: 80, learning rate 0.001000
epoch: 80, train time every whole data:178.15s
epoch: 80, total time:18812.83s
validation batch 1 / 168, loss: 0.17
validation batch 101 / 168, loss: 0.02
validation cost time: 54.1498s
epoch: 81, learning rate 0.001000
epoch: 81, train time every whole data:178.02s
epoch: 81, total time:19045.00s
validation batch 1 / 168, loss: 0.18
validation batch 101 / 168, loss: 0.02
validation cost time: 54.0044s
epoch: 82, learning rate 0.001000
epoch: 82, train time every whole data:177.91s
epoch: 82, total time:19276.92s
validation batch 1 / 168, loss: 0.17
validation batch 101 / 168, loss: 0.02
validation cost time: 54.0906s
epoch: 83, learning rate 0.001000
epoch: 83, train time every whole data:177.91s
epoch: 83, total time:19508.92s
validation batch 1 / 168, loss: 0.17
validation batch 101 / 168, loss: 0.02
validation cost time: 54.0260s
epoch: 84, learning rate 0.001000
epoch: 84, train time every whole data:177.86s
epoch: 84, total time:19740.81s
validation batch 1 / 168, loss: 0.16
validation batch 101 / 168, loss: 0.02
validation cost time: 54.0675s
epoch: 85, learning rate 0.001000
epoch: 85, train time every whole data:178.42s
epoch: 85, total time:19973.30s
validation batch 1 / 168, loss: 0.17
validation batch 101 / 168, loss: 0.02
validation cost time: 54.0745s
epoch: 86, learning rate 0.001000
epoch: 86, train time every whole data:178.23s
epoch: 86, total time:20205.61s
validation batch 1 / 168, loss: 0.18
validation batch 101 / 168, loss: 0.02
validation cost time: 55.4668s
epoch: 87, learning rate 0.001000
epoch: 87, train time every whole data:177.77s
epoch: 87, total time:20438.85s
validation batch 1 / 168, loss: 0.17
validation batch 101 / 168, loss: 0.02
validation cost time: 53.8111s
epoch: 88, learning rate 0.001000
epoch: 88, train time every whole data:177.92s
epoch: 88, total time:20670.59s
validation batch 1 / 168, loss: 0.16
validation batch 101 / 168, loss: 0.02
validation cost time: 54.0505s
epoch: 89, learning rate 0.001000
epoch: 89, train time every whole data:177.98s
epoch: 89, total time:20902.62s
validation batch 1 / 168, loss: 0.14
validation batch 101 / 168, loss: 0.02
validation cost time: 54.0672s
epoch: 90, learning rate 0.001000
epoch: 90, train time every whole data:177.77s
epoch: 90, total time:21134.46s
validation batch 1 / 168, loss: 0.22
validation batch 101 / 168, loss: 0.02
validation cost time: 54.1075s
epoch: 91, learning rate 0.001000
epoch: 91, train time every whole data:177.81s
epoch: 91, total time:21366.39s
validation batch 1 / 168, loss: 0.18
validation batch 101 / 168, loss: 0.02
validation cost time: 54.0393s
epoch: 92, learning rate 0.001000
epoch: 92, train time every whole data:177.97s
epoch: 92, total time:21598.40s
validation batch 1 / 168, loss: 0.17
validation batch 101 / 168, loss: 0.02
validation cost time: 54.1591s
epoch: 93, learning rate 0.001000
epoch: 93, train time every whole data:177.89s
epoch: 93, total time:21830.46s
validation batch 1 / 168, loss: 0.19
validation batch 101 / 168, loss: 0.02
validation cost time: 53.9952s
epoch: 94, learning rate 0.001000
epoch: 94, train time every whole data:178.30s
epoch: 94, total time:22062.76s
validation batch 1 / 168, loss: 0.18
validation batch 101 / 168, loss: 0.02
validation cost time: 53.9656s
epoch: 95, learning rate 0.001000
epoch: 95, train time every whole data:177.85s
epoch: 95, total time:22294.58s
validation batch 1 / 168, loss: 0.18
validation batch 101 / 168, loss: 0.02
validation cost time: 54.0456s
epoch: 96, learning rate 0.001000
epoch: 96, train time every whole data:177.96s
epoch: 96, total time:22526.59s
validation batch 1 / 168, loss: 0.18
validation batch 101 / 168, loss: 0.02
validation cost time: 54.0872s
epoch: 97, learning rate 0.001000
epoch: 97, train time every whole data:177.80s
epoch: 97, total time:22758.48s
validation batch 1 / 168, loss: 0.17
validation batch 101 / 168, loss: 0.02
validation cost time: 53.9391s
epoch: 98, learning rate 0.001000
epoch: 98, train time every whole data:178.12s
epoch: 98, total time:22990.54s
validation batch 1 / 168, loss: 0.18
validation batch 101 / 168, loss: 0.02
validation cost time: 54.1179s
epoch: 99, learning rate 0.001000
epoch: 99, train time every whole data:178.17s
epoch: 99, total time:23222.84s
best epoch: 17
apply the best val model on the test data set ...
load weight from: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_sharespatial/epoch_17.params
predicting testing set batch 1 / 168, time: 0.32s
predicting testing set batch 101 / 168, time: 32.63s
test time on whole data:54.29s
input: (672, 250, 12, 2)
prediction: (672, 250, 12, 2)
data_target_tensor: (672, 250, 12, 2)
current epoch: 17, predict 0 points
MAE: 1.73
RMSE: 2.91
MAPE: 57.33
PCC: 0.82
current epoch: 17, predict 1 points
MAE: 1.85
RMSE: 3.11
MAPE: 63.18
PCC: 0.77
current epoch: 17, predict 2 points
MAE: 1.99
RMSE: 3.42
MAPE: 68.81
PCC: 0.71
current epoch: 17, predict 3 points
MAE: 2.14
RMSE: 3.76
MAPE: 75.01
PCC: 0.66
current epoch: 17, predict 4 points
MAE: 2.31
RMSE: 4.13
MAPE: 81.08
PCC: 0.61
current epoch: 17, predict 5 points
MAE: 2.45
RMSE: 4.44
MAPE: 85.79
PCC: 0.56
current epoch: 17, predict 6 points
MAE: 2.54
RMSE: 4.64
MAPE: 89.03
PCC: 0.52
current epoch: 17, predict 7 points
MAE: 2.57
RMSE: 4.67
MAPE: 89.67
PCC: 0.51
current epoch: 17, predict 8 points
MAE: 2.53
RMSE: 4.59
MAPE: 87.02
PCC: 0.51
current epoch: 17, predict 9 points
MAE: 2.49
RMSE: 4.51
MAPE: 83.88
PCC: 0.51
current epoch: 17, predict 10 points
MAE: 2.43
RMSE: 4.39
MAPE: 79.53
PCC: 0.52
current epoch: 17, predict 11 points
MAE: 2.37
RMSE: 4.16
MAPE: 74.62
PCC: 0.54
all MAE: 2.28
all RMSE: 4.10
all MAPE: 77.91
all PCC: 0.54
1.7337043080899333 2.9058990992527782 57.3275205161419 0.8207676547985643 
1.8544962963904477 3.1126582778099463 63.17541888030611 0.765368774095211 
1.987800095682609 3.418023854630581 68.81293107263025 0.7109702625634157 
2.140477978309084 3.7612010510923564 75.00871055874566 0.6595296242131604 
2.3097212093599317 4.132367647308015 81.08470067612234 0.6057663888818 
2.448354693623792 4.437363055639983 85.79215800802794 0.5550377613236224 
2.5445776309761263 4.638392126805633 89.02746431571681 0.5191835698093837 
2.5684077137773413 4.671955156099868 89.66692573356568 0.5065041296959987 
2.5305338833238045 4.590088492237802 87.01515185079406 0.5074453027353941 
2.491847141599194 4.510480468672804 83.8806157947123 0.5114726691493097 
2.433930128960116 4.391859927561582 79.53443283802808 0.5183523343444216 
2.3687983882899974 4.160793539992719 74.61718664744423 0.5390309521134286 
2.2843874556985315 4.1037065993271575 77.91245939802067 0.5390309521134286 
fine tune the model ... 
epoch: 100, learning rate 0.000100
epoch: 100, train time every whole data:404.72s
epoch: 100, total time:23692.72s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 54.2850s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_sharespatial/epoch_100.params
epoch: 101, learning rate 0.000100
epoch: 101, train time every whole data:402.69s
epoch: 101, total time:24149.91s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 54.1506s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_sharespatial/epoch_101.params
epoch: 102, learning rate 0.000100
epoch: 102, train time every whole data:403.74s
epoch: 102, total time:24607.91s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 54.2864s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_sharespatial/epoch_102.params
epoch: 103, learning rate 0.000100
epoch: 103, train time every whole data:402.93s
epoch: 103, total time:25065.27s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 54.1974s
epoch: 104, learning rate 0.000100
epoch: 104, train time every whole data:403.48s
epoch: 104, total time:25522.96s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 54.1677s
epoch: 105, learning rate 0.000100
epoch: 105, train time every whole data:402.70s
epoch: 105, total time:25979.83s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 54.2141s
epoch: 106, learning rate 0.000100
epoch: 106, train time every whole data:403.16s
epoch: 106, total time:26437.21s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 54.2402s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_sharespatial/epoch_106.params
epoch: 107, learning rate 0.000100
epoch: 107, train time every whole data:402.94s
epoch: 107, total time:26894.49s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 54.2264s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_sharespatial/epoch_107.params
epoch: 108, learning rate 0.000100
epoch: 108, train time every whole data:403.56s
epoch: 108, total time:27352.39s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 54.2864s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_sharespatial/epoch_108.params
epoch: 109, learning rate 0.000100
epoch: 109, train time every whole data:402.78s
epoch: 109, total time:27809.57s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 54.1520s
epoch: 110, learning rate 0.000100
epoch: 110, train time every whole data:404.05s
epoch: 110, total time:28267.78s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 54.3490s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_sharespatial/epoch_110.params
epoch: 111, learning rate 0.000100
epoch: 111, train time every whole data:403.89s
epoch: 111, total time:28726.13s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 54.1075s
epoch: 112, learning rate 0.000100
epoch: 112, train time every whole data:402.16s
epoch: 112, total time:29182.40s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 54.1651s
epoch: 113, learning rate 0.000100
epoch: 113, train time every whole data:404.50s
epoch: 113, total time:29641.06s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 54.2680s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_sharespatial/epoch_113.params
epoch: 114, learning rate 0.000100
epoch: 114, train time every whole data:403.35s
epoch: 114, total time:30098.89s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 54.1238s
epoch: 115, learning rate 0.000100
epoch: 115, train time every whole data:402.29s
epoch: 115, total time:30555.30s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 54.0583s
epoch: 116, learning rate 0.000100
epoch: 116, train time every whole data:402.29s
epoch: 116, total time:31011.66s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.9611s
epoch: 117, learning rate 0.000100
epoch: 117, train time every whole data:400.09s
epoch: 117, total time:31465.72s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 54.1884s
epoch: 118, learning rate 0.000100
epoch: 118, train time every whole data:402.29s
epoch: 118, total time:31922.20s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 54.0695s
epoch: 119, learning rate 0.000100
epoch: 119, train time every whole data:402.84s
epoch: 119, total time:32379.12s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 54.1409s
epoch: 120, learning rate 0.000100
epoch: 120, train time every whole data:403.45s
epoch: 120, total time:32836.71s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 54.0849s
epoch: 121, learning rate 0.000100
epoch: 121, train time every whole data:402.09s
epoch: 121, total time:33292.89s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 54.1333s
epoch: 122, learning rate 0.000100
epoch: 122, train time every whole data:402.91s
epoch: 122, total time:33749.94s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.9704s
epoch: 123, learning rate 0.000100
epoch: 123, train time every whole data:401.97s
epoch: 123, total time:34205.88s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 54.0434s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_sharespatial/epoch_123.params
epoch: 124, learning rate 0.000100
epoch: 124, train time every whole data:401.54s
epoch: 124, total time:34661.63s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 54.1586s
epoch: 125, learning rate 0.000100
epoch: 125, train time every whole data:402.80s
epoch: 125, total time:35118.60s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 54.1073s
epoch: 126, learning rate 0.000100
epoch: 126, train time every whole data:402.04s
epoch: 126, total time:35574.75s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 54.1799s
epoch: 127, learning rate 0.000100
epoch: 127, train time every whole data:402.46s
epoch: 127, total time:36031.39s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 54.1855s
epoch: 128, learning rate 0.000100
epoch: 128, train time every whole data:403.85s
epoch: 128, total time:36489.43s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 54.1182s
epoch: 129, learning rate 0.000100
epoch: 129, train time every whole data:402.17s
epoch: 129, total time:36945.72s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 54.0434s
epoch: 130, learning rate 0.000100
epoch: 130, train time every whole data:403.37s
epoch: 130, total time:37403.14s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 54.1508s
epoch: 131, learning rate 0.000100
epoch: 131, train time every whole data:402.07s
epoch: 131, total time:37859.37s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 54.0740s
epoch: 132, learning rate 0.000100
epoch: 132, train time every whole data:401.93s
epoch: 132, total time:38315.37s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 54.0793s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_sharespatial/epoch_132.params
epoch: 133, learning rate 0.000100
epoch: 133, train time every whole data:401.08s
epoch: 133, total time:38770.68s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.8789s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_sharespatial/epoch_133.params
epoch: 134, learning rate 0.000100
epoch: 134, train time every whole data:401.78s
epoch: 134, total time:39226.49s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 54.0375s
epoch: 135, learning rate 0.000100
epoch: 135, train time every whole data:401.74s
epoch: 135, total time:39682.27s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 54.0794s
epoch: 136, learning rate 0.000100
epoch: 136, train time every whole data:402.44s
epoch: 136, total time:40138.79s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 57.6727s
epoch: 137, learning rate 0.000100
epoch: 137, train time every whole data:402.55s
epoch: 137, total time:40599.03s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 54.0012s
epoch: 138, learning rate 0.000100
epoch: 138, train time every whole data:402.65s
epoch: 138, total time:41055.68s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 59.1888s
epoch: 139, learning rate 0.000100
epoch: 139, train time every whole data:404.09s
epoch: 139, total time:41518.97s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 54.1639s
save parameters to file: experiments/bike/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE0TEallattention_sharespatial/epoch_139.params
epoch: 140, learning rate 0.000100
epoch: 140, train time every whole data:399.81s
epoch: 140, total time:41973.09s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 53.9399s
epoch: 141, learning rate 0.000100
epoch: 141, train time every whole data:402.67s
epoch: 141, total time:42429.70s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 54.1063s
epoch: 142, learning rate 0.000100
epoch: 142, train time every whole data:401.00s
epoch: 142, total time:42884.81s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 54.3675s
epoch: 143, learning rate 0.000100
epoch: 143, train time every whole data:401.42s
epoch: 143, total time:43340.60s
validation batch 1 / 168, loss: 0.03
validation batch 101 / 168, loss: 0.02
validation cost time: 54.1089s
epoch: 144, learning rate 0.000100
epoch: 144, train time every whole data:402.89s
epoch: 144, total time:43797.61s
